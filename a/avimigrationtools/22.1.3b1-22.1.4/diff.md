# Comparing `tmp/avimigrationtools-22.1.3b1.tar.gz` & `tmp/avimigrationtools-22.1.4.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "avimigrationtools-22.1.3b1.tar", last modified: Mon Dec 19 06:50:22 2022, max compression
+gzip compressed data, was "avimigrationtools-22.1.4.tar", last modified: Wed Jun 28 11:00:53 2023, max compression
```

## Comparing `avimigrationtools-22.1.3b1.tar` & `avimigrationtools-22.1.4.tar`

### file list

```diff
@@ -1,210 +1,214 @@
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.862532 avimigrationtools-22.1.3b1/
--rw-r--r--   0 runner    (1001) docker     (116)      391 2022-12-19 06:50:21.000000 avimigrationtools-22.1.3b1/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (116)      481 2022-12-19 06:50:22.862532 avimigrationtools-22.1.3b1/PKG-INFO
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.842532 avimigrationtools-22.1.3b1/avi/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.842532 avimigrationtools-22.1.3b1/avi/migrationtools/
--rw-r--r--   0 runner    (1001) docker     (116)      138 2022-12-19 06:50:21.000000 avimigrationtools-22.1.3b1/avi/migrationtools/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.846532 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)     6022 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_config_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)      516 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_constants.py
--rw-r--r--   0 runner    (1001) docker     (116)    12668 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    36960 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_parser.py
--rw-r--r--   0 runner    (1001) docker     (116)     2030 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_utils.py
--rw-r--r--   0 runner    (1001) docker     (116)     5262 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/monitor_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     2244 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/persistance_conversion.py
--rw-r--r--   0 runner    (1001) docker     (116)     6991 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/pool_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     6629 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ssl_converter.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.846532 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/test/
--rw-r--r--   0 runner    (1001) docker     (116)     3609 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/test/dummy_input.json
--rw-r--r--   0 runner    (1001) docker     (116)     3609 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/test/test_input.json
--rw-r--r--   0 runner    (1001) docker     (116)    24891 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/vs_converter.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.846532 avimigrationtools-22.1.3b1/avi/migrationtools/ansible/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ansible/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)    24991 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ansible/ansible_config_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     3337 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ansible/ansible_constant.py
--rw-r--r--   0 runner    (1001) docker     (116)    11479 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ansible/ansible_traffic_generation.py
--rw-r--r--   0 runner    (1001) docker     (116)     8680 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/ansible/avi_config_to_ansible.py
--rw-r--r--   0 runner    (1001) docker     (116)     3413 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/avi_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    64619 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/avi_migration_utils.py
--rw-r--r--   0 runner    (1001) docker     (116)     8812 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/avi_orphan_object.py
--rw-r--r--   0 runner    (1001) docker     (116)     2587 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/avi_rest_lib.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.846532 avimigrationtools-22.1.3b1/avi/migrationtools/common/
--rw-r--r--   0 runner    (1001) docker     (116)     1917 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/common/avi_resource_types.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    14054 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/config_patch.py
--rw-r--r--   0 runner    (1001) docker     (116)     9831 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/custom_config.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.846532 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)     8420 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/clone_cross_tenant_obj.py
--rw-r--r--   0 runner    (1001) docker     (116)    25407 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/command_status.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    10255 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)   112452 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/conversion_util.py
--rw-r--r--   0 runner    (1001) docker     (116)     5524 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/converter_constants.py
--rw-r--r--   0 runner    (1001) docker     (116)     8936 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/datagroup_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    13911 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_config_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    36490 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     9062 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_parser.py
--rw-r--r--   0 runner    (1001) docker     (116)     8656 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_v10_defaults.conf
--rw-r--r--   0 runner    (1001) docker     (116)    14270 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_v11_defaults.conf
--rw-r--r--   0 runner    (1001) docker     (116)    54537 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/monitor_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    20195 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/persistence_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    60893 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/policy_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    33362 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/pool_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    92407 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/profile_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     1573 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/scp_util.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.850532 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)    93760 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/avi_config.json
--rw-r--r--   0 runner    (1001) docker     (116)    15369 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/bigip_v10.conf
--rw-r--r--   0 runner    (1001) docker     (116)    85001 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/bigip_v11.conf
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.850532 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/
--rw-r--r--   0 runner    (1001) docker     (116)     1314 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/cacert.pem
--rw-r--r--   0 runner    (1001) docker     (116)     1834 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/cakey.pem
--rw-r--r--   0 runner    (1001) docker     (116)     1160 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/default.crt
--rw-r--r--   0 runner    (1001) docker     (116)     1709 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/default.key
--rw-r--r--   0 runner    (1001) docker     (116)     1160 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.crt
--rw-r--r--   0 runner    (1001) docker     (116)     1707 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.key
--rw-r--r--   0 runner    (1001) docker     (116)      212 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)      528 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/conftest.py
--rw-r--r--   0 runner    (1001) docker     (116)     2236 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/custom_config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     3489 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/excel_reader.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    69446 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/hol_advanced_bigip.conf
--rw-r--r--   0 runner    (1001) docker     (116)     1079 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/ignore-config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)      445 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/passphrase.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     1570 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/patch.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     3128 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_avi_to_ansible.py
--rw-r--r--   0 runner    (1001) docker     (116)     1856 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_config_patch.py
--rw-r--r--   0 runner    (1001) docker     (116)     2292 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_f5_conversion_v10.py
--rw-r--r--   0 runner    (1001) docker     (116)     2285 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_f5_conversion_v11.py
--rw-r--r--   0 runner    (1001) docker     (116)    84047 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_migrationtool.py
--rw-r--r--   0 runner    (1001) docker     (116)     4469 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_pool_converter.conf
--rw-r--r--   0 runner    (1001) docker     (116)     4122 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_pool_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     2238 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_profile_conversion.py
--rw-r--r--   0 runner    (1001) docker     (116)     1351 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_profile_converter.conf
--rw-r--r--   0 runner    (1001) docker     (116)    43392 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/vs_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    28875 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/f5_discovery.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.850532 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)    11144 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_config_convertor.py
--rw-r--r--   0 runner    (1001) docker     (116)    10743 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_convertor.py
--rw-r--r--   0 runner    (1001) docker     (116)    10239 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_parser.py
--rw-r--r--   0 runner    (1001) docker     (116)     7308 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.850532 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/parser_files/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/parser_files/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)     3299 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/parser_files/gslb_template.jinja
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.850532 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/test/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)     2215 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/test/test_run.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.854532 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)    12163 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/command_status.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    35467 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/csvs_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     2481 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_config_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     7200 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_monitor_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     6276 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_service_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     4077 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_vs_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    40647 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/lbvs_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    18386 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/monitor_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    11067 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_config_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    18398 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     6156 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_gslb_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     5506 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_parser.py
--rw-r--r--   0 runner    (1001) docker     (116)     5456 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ns_constants.py
--rw-r--r--   0 runner    (1001) docker     (116)    51345 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ns_service_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    88619 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ns_util.py
--rw-r--r--   0 runner    (1001) docker     (116)      426 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/passpharse.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    65137 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/policy_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    46301 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/profile_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)      749 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/scp_util.py
--rw-r--r--   0 runner    (1001) docker     (116)     3623 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ssl_ciphers.yaml
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.854532 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.854532 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/certs/
--rw-r--r--   0 runner    (1001) docker     (116)      497 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/certs/CD.cert.key
--rw-r--r--   0 runner    (1001) docker     (116)     1679 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/certs/ns-server.key
--rw-r--r--   0 runner    (1001) docker     (116)      493 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/certs/test1.key
--rw-r--r--   0 runner    (1001) docker     (116)      372 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/conftest.py
--rw-r--r--   0 runner    (1001) docker     (116)     1318 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/ignore-config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    12905 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/input_vs_configuration.conf
--rw-r--r--   0 runner    (1001) docker     (116)     4979 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/netscaler_e2e_test.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    38465 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/ns.conf
--rw-r--r--   0 runner    (1001) docker     (116)    25093 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/ns_passphrase.conf
--rw-r--r--   0 runner    (1001) docker     (116)      445 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/passphrase.yaml
--rw-r--r--   0 runner    (1001) docker     (116)      139 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/patch.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    56484 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.cfg
--rw-r--r--   0 runner    (1001) docker     (116)     9319 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.py
--rw-r--r--   0 runner    (1001) docker     (116)    21026 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_csv_status.py
--rw-r--r--   0 runner    (1001) docker     (116)    26339 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_migrationtool.py
--rw-r--r--   0 runner    (1001) docker     (116)    12749 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_netscaler_config.py
--rw-r--r--   0 runner    (1001) docker     (116)    11921 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_upload_output_config.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.858532 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/
--rw-r--r--   0 runner    (1001) docker     (116)      936 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (116)     5537 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/alb_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    11565 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/base_client.py
--rwxr-xr-x   0 runner    (1001) docker     (116)     9106 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/command_status.yaml
--rwxr-xr-x   0 runner    (1001) docker     (116)    67584 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/conversion_util.py
--rw-r--r--   0 runner    (1001) docker     (116)      629 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/converter_constants.py
--rw-r--r--   0 runner    (1001) docker     (116)      227 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/custom_config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     2202 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/get_certificates.py
--rw-r--r--   0 runner    (1001) docker     (116)      586 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/install_nsx_dependencies.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    26942 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/monitor_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    13072 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsx_cleanup.py
--rwxr-xr-x   0 runner    (1001) docker     (116)     4779 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_cleanup.py
--rw-r--r--   0 runner    (1001) docker     (116)     4044 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_client.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    10526 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_config_converter.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    23402 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_converter.py
--rwxr-xr-x   0 runner    (1001) docker     (116)     7031 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_rollback.py
--rwxr-xr-x   0 runner    (1001) docker     (116)     6108 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    49801 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_util.py
--rw-r--r--   0 runner    (1001) docker     (116)      463 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/patch.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    15156 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/persistant_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    60824 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/policy_converter.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    24685 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/pools_converter.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    13084 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/profile_converter.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    14152 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/ssl_profile_converter.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.858532 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/
--rw-r--r--   0 runner    (1001) docker     (116)        0 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)    14111 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/avi_config.json
--rw-r--r--   0 runner    (1001) docker     (116)    64868 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/config.json
--rw-r--r--   0 runner    (1001) docker     (116)      301 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)      425 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/conftest.py
--rw-r--r--   0 runner    (1001) docker     (116)      134 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/default_params.json
--rw-r--r--   0 runner    (1001) docker     (116)     4345 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/excel_reader.py
--rw-r--r--   0 runner    (1001) docker     (116)      463 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/patch.yaml
--rw-r--r--   0 runner    (1001) docker     (116)    22978 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_migrationtool.py
--rw-r--r--   0 runner    (1001) docker     (116)     7831 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_monitor_converter.conf
--rw-r--r--   0 runner    (1001) docker     (116)     1644 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_monitor_converter.py
--rwxr-xr-x   0 runner    (1001) docker     (116)    28399 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_nsxt_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)    14398 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_nsxt_functional.py
--rw-r--r--   0 runner    (1001) docker     (116)     5044 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_pool_converter.conf
--rw-r--r--   0 runner    (1001) docker     (116)     1613 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_pool_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)     4241 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_profile_converter.conf
--rw-r--r--   0 runner    (1001) docker     (116)     1681 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_profile_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)      464 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test_cd.py
--rwxr-xr-x   0 runner    (1001) docker     (116)     1830 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/v_client.py
--rw-r--r--   0 runner    (1001) docker     (116)    81338 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/vs_converter.py
--rw-r--r--   0 runner    (1001) docker     (116)  1094786 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/pb_attributes.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     4340 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/scp_util.py
--rw-r--r--   0 runner    (1001) docker     (116)     2333 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.858532 avimigrationtools-22.1.3b1/avi/migrationtools/test/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.862532 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/
--rw-r--r--   0 runner    (1001) docker     (116)       77 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/__init__.py
--rw-r--r--   0 runner    (1001) docker     (116)      513 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/config.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     4831 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/excel_reader.py
--rw-r--r--   0 runner    (1001) docker     (116)     4548 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_clean_reboot.py
--rw-r--r--   0 runner    (1001) docker     (116)     1679 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_tenant_cloud.py
--rw-r--r--   0 runner    (1001) docker     (116)     1101 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_validation.py
--rw-r--r--   0 runner    (1001) docker     (116)    48026 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_validation_avi.json
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.862532 avimigrationtools-22.1.3b1/avi/migrationtools/v2alb_converter/
--rw-r--r--   0 runner    (1001) docker     (116)      454 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/v2alb_converter/discovery_status.yaml
--rw-r--r--   0 runner    (1001) docker     (116)     7557 2022-12-19 06:49:35.000000 avimigrationtools-22.1.3b1/avi/migrationtools/vs_filter.py
-drwxr-xr-x   0 runner    (1001) docker     (116)        0 2022-12-19 06:50:22.862532 avimigrationtools-22.1.3b1/avimigrationtools.egg-info/
--rw-r--r--   0 runner    (1001) docker     (116)      481 2022-12-19 06:50:22.000000 avimigrationtools-22.1.3b1/avimigrationtools.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (116)     9843 2022-12-19 06:50:22.000000 avimigrationtools-22.1.3b1/avimigrationtools.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (116)        1 2022-12-19 06:50:22.000000 avimigrationtools-22.1.3b1/avimigrationtools.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (116)      202 2022-12-19 06:50:22.000000 avimigrationtools-22.1.3b1/avimigrationtools.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (116)        4 2022-12-19 06:50:22.000000 avimigrationtools-22.1.3b1/avimigrationtools.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (116)       38 2022-12-19 06:50:22.862532 avimigrationtools-22.1.3b1/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (116)     2341 2022-12-19 06:50:21.000000 avimigrationtools-22.1.3b1/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.478458 avimigrationtools-22.1.4/
+-rw-r--r--   0 runner    (1001) docker     (123)      391 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)      479 2023-06-28 11:00:53.478458 avimigrationtools-22.1.4/PKG-INFO
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.458458 avimigrationtools-22.1.4/avi/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.458458 avimigrationtools-22.1.4/avi/migrationtools/
+-rw-r--r--   0 runner    (1001) docker     (123)      134 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/avi/migrationtools/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.462458 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6022 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_config_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      516 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12668 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36960 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2030 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5262 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/monitor_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2244 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/persistance_conversion.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6991 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/pool_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6629 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ssl_converter.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.462458 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/test/
+-rw-r--r--   0 runner    (1001) docker     (123)     3609 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/test/dummy_input.json
+-rw-r--r--   0 runner    (1001) docker     (123)     3609 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/test/test_input.json
+-rw-r--r--   0 runner    (1001) docker     (123)    24891 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ace_converter/vs_converter.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.462458 avimigrationtools-22.1.4/avi/migrationtools/ansible/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ansible/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24991 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ansible/ansible_config_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3337 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ansible/ansible_constant.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11479 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ansible/ansible_traffic_generation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8680 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/ansible/avi_config_to_ansible.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6030 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/avi_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    65224 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/avi_migration_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8504 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/avi_orphan_object.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3019 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/avi_rest_lib.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.462458 avimigrationtools-22.1.4/avi/migrationtools/common/
+-rw-r--r--   0 runner    (1001) docker     (123)     1917 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/common/avi_resource_types.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    14017 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/config_patch.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9838 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/custom_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.462458 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11584 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/ciphers_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8420 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/clone_cross_tenant_obj.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25572 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/command_status.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    10255 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)   114166 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/conversion_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5072 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/converter_constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9541 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/datagroup_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14039 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_config_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    37760 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9103 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8656 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_v10_defaults.conf
+-rw-r--r--   0 runner    (1001) docker     (123)    14270 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_v11_defaults.conf
+-rw-r--r--   0 runner    (1001) docker     (123)    55819 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/monitor_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20583 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/persistence_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    60491 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/policy_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    33192 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/pool_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    97693 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/profile_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1694 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/scp_util.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.466458 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    93760 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/avi_config.json
+-rw-r--r--   0 runner    (1001) docker     (123)    15369 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/bigip_v10.conf
+-rw-r--r--   0 runner    (1001) docker     (123)    85001 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/bigip_v11.conf
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.466458 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/
+-rw-r--r--   0 runner    (1001) docker     (123)     1314 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/cacert.pem
+-rw-r--r--   0 runner    (1001) docker     (123)     1834 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/cakey.pem
+-rw-r--r--   0 runner    (1001) docker     (123)     1160 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/default.crt
+-rw-r--r--   0 runner    (1001) docker     (123)     1709 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/default.key
+-rw-r--r--   0 runner    (1001) docker     (123)     1160 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.crt
+-rw-r--r--   0 runner    (1001) docker     (123)     1707 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.key
+-rw-r--r--   0 runner    (1001) docker     (123)      212 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      528 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2236 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/custom_config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     3489 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/excel_reader.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    69722 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/hol_advanced_bigip.conf
+-rw-r--r--   0 runner    (1001) docker     (123)     1079 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/ignore-config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      445 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/passphrase.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     1570 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/patch.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     3128 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_avi_to_ansible.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1856 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_config_patch.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2292 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_f5_conversion_v10.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2285 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_f5_conversion_v11.py
+-rw-r--r--   0 runner    (1001) docker     (123)    84361 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_migrationtool.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4469 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_pool_converter.conf
+-rw-r--r--   0 runner    (1001) docker     (123)     4122 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_pool_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2238 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_profile_conversion.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1351 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_profile_converter.conf
+-rw-r--r--   0 runner    (1001) docker     (123)    49578 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_converter/vs_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28747 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/f5_discovery.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.466458 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11144 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_config_convertor.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10743 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_convertor.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10239 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7308 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.466458 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/parser_files/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/parser_files/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3299 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/parser_files/gslb_template.jinja
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.466458 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/test/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2215 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/test/test_run.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.470458 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12163 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/command_status.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    35467 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/csvs_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2481 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_config_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7200 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_monitor_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6276 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_service_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4077 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_vs_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    40647 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/lbvs_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18386 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/monitor_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11067 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_config_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18503 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6156 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_gslb_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5506 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5456 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ns_constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)    51345 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ns_service_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    88618 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ns_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)      426 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/passpharse.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    65137 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/policy_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    46301 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/profile_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      749 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/scp_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3623 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ssl_ciphers.yaml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.470458 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.470458 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/certs/
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/certs/CD.cert.key
+-rw-r--r--   0 runner    (1001) docker     (123)     1679 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/certs/ns-server.key
+-rw-r--r--   0 runner    (1001) docker     (123)      493 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/certs/test1.key
+-rw-r--r--   0 runner    (1001) docker     (123)      372 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1318 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/ignore-config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    12905 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/input_vs_configuration.conf
+-rw-r--r--   0 runner    (1001) docker     (123)     4979 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/netscaler_e2e_test.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    38465 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/ns.conf
+-rw-r--r--   0 runner    (1001) docker     (123)    25093 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/ns_passphrase.conf
+-rw-r--r--   0 runner    (1001) docker     (123)      445 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/passphrase.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      139 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/patch.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    56484 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     9319 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21026 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_csv_status.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26339 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_migrationtool.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12749 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_netscaler_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11921 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_upload_output_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.474458 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/
+-rw-r--r--   0 runner    (1001) docker     (123)      936 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     5537 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/alb_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11565 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/base_client.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     4780 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/cleanup.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     9273 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/command_status.yaml
+-rwxr-xr-x   0 runner    (1001) docker     (123)    67595 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/conversion_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/converter_constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)      227 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/custom_config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     2202 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/get_certificates.py
+-rw-r--r--   0 runner    (1001) docker     (123)      586 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/install_nsx_dependencies.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    26944 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/monitor_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13072 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsx_cleanup.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     4780 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_cleanup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4044 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_client.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    10528 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_config_converter.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    23405 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_converter.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     7033 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_rollback.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     6110 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    51536 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)      463 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/patch.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    15156 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/persistant_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    60825 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/policy_converter.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    25607 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/pools_converter.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    13084 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/profile_converter.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     7033 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/rollback.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    14283 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/ssl_profile_converter.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.474458 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14111 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/avi_config.json
+-rw-r--r--   0 runner    (1001) docker     (123)    64868 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/config.json
+-rw-r--r--   0 runner    (1001) docker     (123)      301 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      425 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)      134 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/default_params.json
+-rw-r--r--   0 runner    (1001) docker     (123)     4345 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/excel_reader.py
+-rw-r--r--   0 runner    (1001) docker     (123)      463 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/patch.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    22979 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_migrationtool.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7831 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_monitor_converter.conf
+-rw-r--r--   0 runner    (1001) docker     (123)     1644 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_monitor_converter.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    28399 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_nsxt_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14399 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_nsxt_functional.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5044 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_pool_converter.conf
+-rw-r--r--   0 runner    (1001) docker     (123)     1613 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_pool_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4241 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_profile_converter.conf
+-rw-r--r--   0 runner    (1001) docker     (123)     1681 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_profile_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      464 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test_cd.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     6110 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/traffic_cutover.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     1830 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/v_client.py
+-rw-r--r--   0 runner    (1001) docker     (123)    81344 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/vs_converter.py
+-rw-r--r--   0 runner    (1001) docker     (123)  1094786 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/pb_attributes.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     4284 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/scp_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2326 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.474458 avimigrationtools-22.1.4/avi/migrationtools/test/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.474458 avimigrationtools-22.1.4/avi/migrationtools/test/common/
+-rw-r--r--   0 runner    (1001) docker     (123)       77 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     4831 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/excel_reader.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4548 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/test_clean_reboot.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1679 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/test_tenant_cloud.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1101 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/test_validation.py
+-rw-r--r--   0 runner    (1001) docker     (123)    48026 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/test/common/test_validation_avi.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.474458 avimigrationtools-22.1.4/avi/migrationtools/v2alb_converter/
+-rw-r--r--   0 runner    (1001) docker     (123)      454 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/v2alb_converter/discovery_status.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     7635 2023-06-28 10:59:24.000000 avimigrationtools-22.1.4/avi/migrationtools/vs_filter.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-28 11:00:53.478458 avimigrationtools-22.1.4/avimigrationtools.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)      479 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/avimigrationtools.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    10040 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/avimigrationtools.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/avimigrationtools.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      195 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/avimigrationtools.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        4 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/avimigrationtools.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-06-28 11:00:53.478458 avimigrationtools-22.1.4/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     2332 2023-06-28 11:00:53.000000 avimigrationtools-22.1.4/setup.py
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_config_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_config_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_constants.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_constants.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_parser.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_parser.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ace_utils.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ace_utils.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/monitor_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/monitor_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/persistance_conversion.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/persistance_conversion.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/pool_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/pool_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/ssl_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/ssl_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/test/dummy_input.json` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/test/dummy_input.json`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/test/test_input.json` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/test/test_input.json`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ace_converter/vs_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ace_converter/vs_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ansible/ansible_config_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/ansible/ansible_config_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ansible/ansible_constant.py` & `avimigrationtools-22.1.4/avi/migrationtools/ansible/ansible_constant.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ansible/ansible_traffic_generation.py` & `avimigrationtools-22.1.4/avi/migrationtools/ansible/ansible_traffic_generation.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/ansible/avi_config_to_ansible.py` & `avimigrationtools-22.1.4/avi/migrationtools/ansible/avi_config_to_ansible.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/avi_migration_utils.py` & `avimigrationtools-22.1.4/avi/migrationtools/avi_migration_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-import pandas
 import argparse
 import ast
 import copy
 import getpass
 import logging
+import networkx as nx
 import os
+import pandas
+import pexpect
 import random
 import string
+import yaml
 from functools import reduce
 from urllib.parse import urlparse, parse_qs
 from datetime import datetime
 from socket import gethostname
 
-import networkx as nx
-import pexpect
-import yaml
 from OpenSSL import crypto
 from openpyxl import load_workbook, Workbook
 
 import avi.migrationtools.f5_converter.converter_constants as conv_const
 
 LOG = logging.getLogger(__name__)
 csv_writer_dict_list = []
@@ -35,22 +35,28 @@
 def set_update_count():
     global warning_count, error_count
     warning_count = 0
     error_count = 0
 
 
 def update_count(type='warning'):
+    '''
+    Method for updating warning and error count
+    '''
     global warning_count, error_count
     if type == 'warning':
         warning_count += 1
     elif type == 'error':
         error_count += 1
 
 
 def get_count(type='None'):
+    '''
+    Method for getting error and warning count
+    '''
     if type == 'warning':
         return warning_count
     elif type == 'error':
         return error_count
     return {'warning': warning_count, 'error': error_count}
 
 
@@ -61,17 +67,23 @@
         else:
             setattr(args, self.dest, getpass.getpass(prompt=self.dest))
 
 
 class MigrationUtil(object):
 
     def add_conv_status(self, **args):
+        '''
+        Method for addding conversion status
+        '''
         pass
 
     def add_status_row(self, **args):
+        '''
+        Method for adding rows
+        '''
         pass
 
     def get_conv_status(self, skipped, indirect_list, ignore_dict, input_object,
                         user_ignore=None, na_list=None):
         """
         Update skipped list for conversion status
         :param skipped: All skipped attributes after conversion
@@ -112,20 +124,23 @@
             status = conv_const.STATUS_PARTIAL
         else:
             status = conv_const.STATUS_SUCCESSFUL
         conv_status['status'] = status
         return conv_status
 
     def get_tenant_ref(self, name):
+        '''
+        returns tenant ref
+        '''
         tenant = 'admin'
         if name and name.startswith('/'):
             parts = name.split('/', 2)
             tenant = parts[1]
             if not parts[2]:
-                LOG.warning('Invalid tenant ref : %s' % name)
+                LOG.warning('Invalid tenant ref : %s', name)
             name = parts[2]
         elif name and '/' in name:
             parts = name.split('/')
             # Changed the index to get the tenant and name in case of
             # prefixed name
             tenant = parts[-2]
             name = parts[-1]
@@ -135,14 +150,17 @@
             name = name.split('/')[1]
         if ' ' in tenant:
             tenant = tenant.split(' ')[-1]
         tenant.strip()
         return tenant, name
 
     def create_self_signed_cert(self):
+        '''
+        Method for creating self signed certifiates
+        '''
         # create a key pair
         key = crypto.PKey()
         key.generate_key(crypto.TYPE_RSA, 2048)
 
         # create a self-signed cert
         cert = crypto.X509()
         cert.get_subject().C = "US"
@@ -183,15 +201,18 @@
         :param pool_group_name: Name of Pool group
         :param csv_pool_rows: List of pool(NsxT type) csv rows
         :param csv_writer_dict_list: List of nsxt csv rows
         :param vs_ref: Name of VS
         :param profile_csv_list: List of profile(NsxT type) csv rows
         :return:
         """
-        pool_group_objects = list(filter(lambda pg: pg["name"] == pool_group_name, avi_config['PoolGroup']))
+        pool_group_objects = list(
+            filter(
+                lambda pg: pg["name"] == pool_group_name,
+                avi_config['PoolGroup']))
         pool_members = pool_group_objects[0]['members']
         skipped_setting = {
             'pools': []
         }
         for pool_member in pool_members:
             pool_name = self.get_name(pool_member['pool_ref'])
             self.get_skipped_pool(
@@ -240,20 +261,20 @@
                 if health_monitor_skipped_setting:
                     pool_skipped_setting['pool_name'] = pool_name
                     pool_skipped_setting['health_monitor'] = \
                         health_monitor_skipped_setting
             if pool_object[0].get('ssl_key_and_certificate_ref', None):
                 ssl_key_cert = self.get_name(
                     pool_object[0]['ssl_key_and_certificate_ref'])
-                LOG.debug('[SslKeyAndCertificate] certificate {}'.format(ssl_key_cert))
+                LOG.debug('[SslKeyAndCertificate] certificate %s', ssl_key_cert)
                 sslkc_skip = self.get_csv_skipped_list(
                     profile_csv_list, ssl_key_cert, vs_ref,
                     field_key='ssl_cert_key')
                 if sslkc_skip:
-                    LOG.debug('[SslKeyAndCertificate] Skipped Attribute {}'.format(sslkc_skip))
+                    LOG.debug('[SslKeyAndCertificate] Skipped Attribute %s', sslkc_skip)
                     pool_skipped_setting['pool_name'] = pool_name
                     pool_skipped_setting['ssl_key_and_certificate'] = sslkc_skip
             else:
                 LOG.info('Ssl key and certificate ref is not found')
             if pool_object[0].get('ssl_profile_ref', None):
                 name, skipped = self.get_ssl_profile_skipped(
                     profile_csv_list, pool_object[0]['ssl_profile_ref'], vs_ref)
@@ -275,15 +296,15 @@
                         'name'] = name
                     pool_skipped_setting['Application Persistence profile'][
                         'skipped_list'] = skipped
 
             if pool_skipped_setting:
                 skipped_setting['pools'].append(pool_skipped_setting)
         else:
-            LOG.debug('[PoolObject] Not Found for pool {}'.format(pool_name))
+            LOG.debug('[PoolObject] Not Found for pool %s', pool_name)
 
     def get_pool_skipped(self, csv_objects, pool_name, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param csv_objects: CSV row of object from xlsx report
         :param pool_name: Name of pool
         :param vs_ref: Name of VS
@@ -424,14 +445,17 @@
                 ('vs_datascripts' in virtual_service and
                  virtual_service['vs_datascripts']):
             vs_csv_row['Complexity Level'] = conv_const.COMPLEXITY_ADVANCED
         else:
             vs_csv_row['Complexity Level'] = conv_const.COMPLEXITY_BASIC
 
     def remove_dup_key(self, obj_list):
+        '''
+        Method for removing dup key from converted config
+        '''
         for obj in obj_list:
             obj.pop('dup_of', None)
 
     def check_for_duplicates(self, src_obj, obj_list, obj_type,
                              merge_object_mapping, ent_type, prefix, syslist):
         """
         Checks for duplicate objects except name and description values
@@ -460,17 +484,17 @@
             if src_cp.items() == tmp_cp.items():
                 dup_lst.append(src_obj["name"])
                 tmp_obj["dup_of"] = dup_lst
                 old_name = tmp_obj['name']
                 if tmp_obj["name"] in merge_object_mapping[obj_type].keys():
                     merge_object_mapping[obj_type]['no'] += 1
                     no = merge_object_mapping[obj_type]['no']
-                    mid_name = ent_type and ('Merged-%s-%s-%s-%s' % (ent_type,
-                                                                     obj_type, ran_str, str(no))) or (
-                                       'Merged-%s-%s-%s' % (obj_type, ran_str, str(no)))
+                    mid_name = ent_type and ('Merged-%s-%s-%s-%s' %
+                                             (ent_type, obj_type, ran_str, str(no))) or (
+                        'Merged-%s-%s-%s' % (obj_type, ran_str, str(no)))
                     new_name = '%s-%s' % (prefix, mid_name) if prefix else \
                         mid_name
                     tmp_obj["name"] = new_name
                 return tmp_obj["name"], old_name
         return None, None
 
     def upload_file(self, file_path):
@@ -493,22 +517,22 @@
                 file_str = file_obj.read()
                 file_str = file_str  # .decode("utf-8")
         except UnicodeDecodeError:
             try:
                 file_str = file_str  # .decode('latin-1')
             except:
                 update_count('error')
-                LOG.error("[UnicodeDecode] Error to read file %s" % file_path,
+                LOG.error("[UnicodeDecode] Error to read file %s", file_path,
                           exc_info=True)
         except IOError:
             update_count('warning')
-            LOG.warn("Cannot read file %s" % file_path)
+            LOG.warning("Cannot read file %s", file_path)
         except:
             update_count('error')
-            LOG.error("Error accessing file %s" % file_path, exc_info=True)
+            LOG.error("Error accessing file %s", file_path, exc_info=True)
         return file_str
 
     def get_name(self, url):
         """
         This function defines that return name object from url
         :param url:
         :return: Name of object
@@ -525,40 +549,41 @@
         parsed = urlparse(url)
         return parse_qs(parsed.query).get('tenant', ['admin'])[0]
 
     def get_obj_type_from_ref(self, url):
         return url.split('/api/')[1].split('/')[0].split('?')[0]
 
     def get_object_ref(self, object_name, object_type, tenant='admin',
-                       cloud_name='Default-Cloud', prefix=None, cloud_tenant ="admin"):
+                       cloud_name='Default-Cloud', prefix=None, cloud_tenant="admin"):
         """
-        This function defines that to genarte object ref in the format of
+        This function defines that to generate object ref in the format of
         /api/object_type/?tenant=tenant_name&name=object_name&cloud=cloud_name
         :param object_name: Name of object
         :param object_type: Type of object
         :param tenant: Name of tenant
         :param cloud_name: Name of cloud
         :param prefix : Prefix for objects
         :return: Return generated object ref
         """
         # Added prefix for objects
         if prefix:
             object_name = prefix + '-' + object_name
 
-        cloud_supported_types = ['pool', 'poolgroup', 'vsvip', 'vrfcontext',
-                                 'serviceenginegroup', 'network', 'vsdatascriptset','networksecuritypolicy']
+        cloud_supported_types = [
+            'pool', 'poolgroup', 'vsvip', 'vrfcontext', 'serviceenginegroup', 'network',
+            'vsdatascriptset', 'networksecuritypolicy']
         if not cloud_name:
             cloud_name = "Default-Cloud"
 
         if object_type == 'tenant':
             ref = '/api/tenant/?name=%s' % object_name
             if object_name not in tenants:
                 tenants.append(object_name)
         elif object_type == 'cloud':
-            ref = '/api/%s/?tenant=%s&name=%s' % (object_type ,cloud_tenant, object_name)
+            ref = '/api/%s/?tenant=%s&name=%s' % (object_type, cloud_tenant, object_name)
         elif object_type == 'vrfcontext':
             ref = '/api/%s/?tenant=%s&name=%s&cloud=%s' % (
                 object_type, cloud_tenant, object_name, cloud_name)
         elif object_type in cloud_supported_types:
             ref = '/api/%s/?tenant=%s&name=%s&cloud=%s' % (
                 object_type, tenant, object_name, cloud_name)
         else:
@@ -566,15 +591,15 @@
                 object_type, tenant, object_name)
         # if cloud_name:
         #     ref += '&cloud=%s' % cloud_name
         return ref
 
     # Print iterations progress
     def print_progress_bar(self, iteration, total, msg, prefix='', suffix='',
-                           decimals=1, length=50, fill='#', printEnd="\\"):
+                           decimals=1, length=50, fill='#', print_end="\\"):
         """
         Call in a loop to create terminal progress bar
         @params:
             iteration   - Required  : current iteration (Int)
             total       - Required  : total iterations (Int)
             prefix      - Optional  : prefix string (Str)
             suffix      - Optional  : suffix string (Str)
@@ -584,36 +609,35 @@
             fill        - Optional  : bar fill character (Str)
         """
         percent = ("{0:." + str(decimals) + "f}"). \
             format(100 * (iteration / float(total)))
         filledLength = int(length * iteration // total)
         bar = fill * filledLength + '-' * (length - filledLength)
         if (iteration < total):
-            print(f'\r{prefix} |{bar}| {percent}% {suffix}', end=printEnd)
+            print(f'\r{prefix} |{bar}| {percent}% {suffix}', end=print_end)
         else:
             print(f'\r{prefix} |{bar}| {percent}% {suffix}')
 
     def validate_value(self, entity_names, prop_name, value, limit_data, obj,
                        valname):
-
         """
         :param entity_names: list of name of the avi entity/object
         :param prop_name: property name
         :param value: property value
         :param limit_data: data from generated yaml
         :param obj: obj name
         :return: validity and new value
         """
         valid = None
         new_value = value
-        msgvar = valname and entity_names and '%s-->%s-->%s' % (valname,
-                                                                '-->'.join(entity_names),
-                                                                prop_name) or valname and '%s-->%s' \
-                 % (valname, prop_name) or entity_names and '%s-->%s' % (
-                     '-->'.join(entity_names), prop_name) or '%s' % prop_name
+        msgvar = valname and entity_names and '%s-->%s-->%s' % \
+            (valname, '-->'.join(entity_names), prop_name) or valname and '%s-->%s' % (
+                valname, prop_name) or entity_names and '%s-->%s' %\
+            ('-->'.join(entity_names), prop_name)\
+            or '%s' % prop_name
         for key, val in limit_data.items():
             pr = val.get(obj, {})
             if not pr:
                 continue
             LOG.debug("Validating property '%s'", msgvar)
             p_key = self.get_to_prop(val, pr, entity_names, prop_name,
                                      limit_data)
@@ -624,18 +648,18 @@
             LOG.debug("Property '%s' is not present in generated yaml, reason "
                       "being the property doesn't have any attribute from the "
                       "list %s", msgvar, str(['default_value', 'range',
                                               'special_values', 'ref_type']))
             return None, None
         if new_value is not None:
             # commenting this since now in Python 3 strings are already in unicode format.
-            if type(new_value) == str:
+            if isinstance(new_value, str):
                 new_value = new_value.encode()
-            if type(new_value) == eval(typ) or (eval(typ) == int and
-                                                str(new_value).isdigit()):
+            if isinstance(new_value, eval(typ)) or (eval(typ) == int and
+                                                    str(new_value).isdigit()):
                 special_value = p_key.get('special_values')
                 if typ == 'int':
                     new_value = int(new_value)
                     if special_value and str(new_value) in special_value:
                         valid = True
                         LOG.debug("Special value %s is fine", str(new_value))
                     else:
@@ -708,15 +732,14 @@
                         return self.get_to_prop(val, vr, entity_names,
                                                 prop_name, limit_data)
         p_key = pr.get('properties', {}).get(prop_name, {})
         if p_key:
             return p_key
 
     def validation(self, avi_config):
-
         """
         Validator function for all avi objects
         :param avi_config:
         :return:
         """
 
         LOG.debug("Starting Validation checks ... ")
@@ -740,33 +763,33 @@
         for k, v in dictval.items():
             if k in ['tenant_ref', 'name', 'cloud_ref', 'health_monitor_refs',
                      'ssl_profile_ref', 'application_persistence_profile_ref',
                      'application_profile_ref', 'network_profile_ref',
                      'pki_profile_ref', 'pool_ref', 'pool_group_ref',
                      'http_policy_set_ref', 'ssl_key_and_certificate_refs',
                      'vsvip_ref', 'description']:
-                msvar = valname and heir and '%s-->%s-->%s' % (valname,
-                                                               '-->'.join(heir), k) or valname and '%s-->%s' % (
-                            valname, k) or heir and '%s-->%s' % ('-->'.join(heir),
-                                                                 k) or '%s' % k
+                msvar = valname and heir and '%s-->%s-->%s' % \
+                    (valname, '-->'.join(heir), k) or valname and '%s-->%s' % (
+                        valname, k) or heir and '%s-->%s' % ('-->'.join(heir),
+                                                             k) or '%s' % k
                 LOG.debug("Skipping validation checks for '%s'", msvar)
                 continue
             else:
                 if isinstance(v, list):
                     for listval in v:
                         if isinstance(listval, dict):
                             k not in heir and heir.append(k) or None
                             self.validate_prop(listval, heir, limit_data, obj,
                                                valname)
                             heir and heir.pop() or None
                         else:
                             mgvar = valname and heir and '%s-->%s-->%s' % (
                                 valname, '-->'.join(heir), k) or valname \
-                                    and '%s-->%s' % (valname, k) or heir and \
-                                    '%s-->%s' % ('-->'.join(heir), k) or \
+                                and '%s-->%s' % (valname, k) or heir and \
+                                '%s-->%s' % ('-->'.join(heir), k) or \
                                     '%s' % k
                             LOG.debug("Property '%s' has value as a list %s, "
                                       "not supported currently", mgvar, str(v))
                             # valid, val = self.validate_value(heir, k, listval,
                             # limit_data)
                             # if valid is False:
                             # LOG.debug("Correcting the value for %s" % k)
@@ -776,17 +799,18 @@
                     self.validate_prop(v, heir, limit_data, obj, valname)
                     heir and heir.pop() or None
                 else:
                     valid, val = self.validate_value(heir, k, v, limit_data,
                                                      obj, valname)
                     if valid is False:
                         mvar = valname and heir and '%s-->%s-->%s' % (valname,
-                                                                      '-->'.join(heir), k) or valname and '%s-->%s' % (
-                                   valname, k) or heir and '%s-->%s' % (
-                                   '-->'.join(heir), k) or '%s' % k
+                                                                      '-->'.join(heir), k) \
+                            or valname and '%s-->%s' % (
+                            valname, k) or heir and '%s-->%s' % (
+                            '-->'.join(heir), k) or '%s' % k
                         LOG.debug("Correcting the value for '%s' from '%s' to "
                                   "'%s'", mvar, str(v), str(val))
                         dictval[k] = val
 
     def check_certificate_expiry(self, input_dir, cert_file_name):
         cert_file_name = cert_file_name.replace(':Common:', '')
         cert_text = self.upload_file(input_dir + os.path.sep + cert_file_name)
@@ -795,15 +819,15 @@
                                                 cert_text if type(cert_text) == str
                                                 else cert_text.decode())
             expiry_date = datetime.strptime(cert_date.get_notAfter().decode('utf-8'),
                                             "%Y%m%d%H%M%SZ")
             present_date = datetime.now()
             if expiry_date < present_date:
                 LOG.warning("Certificate %s is expired creating self "
-                            "signed cert." % cert_file_name)
+                            "signed cert.", cert_file_name)
                 return False
             else:
                 return True
         else:
             LOG.warn('Cannot load cert %s to check expiry skipping the check' %
                      cert_file_name)
             update_count('warning')
@@ -813,15 +837,15 @@
         """
         Filters vs and its references from full configuration
         :param avi_config: full configuration
         :return: graph
         """
         avi_graph = nx.DiGraph()
         avi_graph.add_node('AVI', type='Tree')
-        for vs in avi_config.get('VirtualService',[]):
+        for vs in avi_config.get('VirtualService', []):
             name = vs['name']
             avi_graph.add_node(name, type='VS')
             avi_graph.add_edge('AVI', name)
             self.find_and_add_ne(vs, avi_config, avi_graph, name, depth=0)
         return avi_graph
 
     def find_and_add_ne(self, obj_dict, avi_config, avi_graph, vsname, depth):
@@ -857,26 +881,26 @@
                 for member in obj_dict[key]:
                     self.find_and_add_ne(member, avi_config, avi_graph, vsname,
                                          depth)
             elif key == 'hostname':
                 sername = obj_dict[key]
                 if avi_graph.has_node(sername):
                     node_type = [n[1]['type'] for n in list(
-                        avi_graph.nodes().data()) if n[0] == sername]
+                        avi_graph.nodes(data=True)) if n[0] == sername]
                     node_type = '{}-{}'.format(node_type[0], 'Server')
                     avi_graph.add_node(sername, type=node_type)
                     avi_graph.add_edge(vsname, sername)
                 else:
                     avi_graph.add_node(sername, type='Server')
                     avi_graph.add_edge(vsname, sername)
             elif key == 'name' and depth == 1 and '-rule-' in obj_dict[key]:
                 rule_name = obj_dict[key]
                 if avi_graph.has_node(rule_name):
                     node_type = [n[1]['type'] for n in list(
-                        avi_graph.nodes().data()) if n[0] == rule_name]
+                        avi_graph.nodes(data=True)) if n[0] == rule_name]
                     node_type = '{}-{}'.format(node_type[0], 'Rule')
                     avi_graph.add_node(rule_name, type=node_type)
                     avi_graph.add_edge(vsname, rule_name)
                 else:
                     avi_graph.add_node(rule_name, type='Rule')
                     avi_graph.add_edge(vsname, rule_name)
         return
@@ -897,33 +921,33 @@
         found_obj_list = avi_config.get(avi_conf_key)
         found_obj = [obj for obj in found_obj_list if obj['name'] == name] if \
             found_obj_list else []
         if found_obj:
             found_obj = found_obj[0]
             if avi_graph.has_node(name):
                 nod_type = [node[1]['type'] for node in list(
-                    avi_graph.nodes().data()) if node[0] == name]
+                    avi_graph.nodes(data=True)) if node[0] == name]
                 nod_type = '{}-{}'.format(nod_type[0], path_key_map[entity])
                 avi_graph.add_node(name, type=nod_type)
                 avi_graph.add_edge(vsname, name)
             else:
                 avi_graph.add_node(name, type=path_key_map[entity])
                 avi_graph.add_edge(vsname, name)
         elif entity in ['applicationprofile', 'networkprofile', 'healthmonitor',
                         'sslkeyandcertificate', 'sslprofile',
                         'applicationpersistenceprofile']:
             if str.startswith(str(name), 'System-'):
                 return
         else:
             update_count()
-            LOG.warning('Reference not found for %s with name %s' % (
-                entity, name))
+            LOG.warning('Reference not found for %s with name %s',
+                        entity, name)
             return
         depth += 1
-        new_name=""
+        new_name = ""
         if found_obj:
             new_name = found_obj.get('name')
         if new_name:
             self.find_and_add_ne(found_obj, avi_config, avi_graph, new_name,
                                  depth)
 
     def get_project_path(self):
@@ -933,15 +957,15 @@
         """
         Parses reference string to extract object type and
         :param url: reference url to be parsed
         :return: entity and object name
         """
         parsed = urlparse(url)
         return parsed.path.split('/')[2], \
-               parse_qs(parsed.query)['name'][0]
+            parse_qs(parsed.query)['name'][0]
 
     def get_path_key_map(self):
         yml_file = os.path.join(self.get_project_path(),
                                 './common/avi_resource_types.yaml')
         yml_data = yaml.load(open(yml_file, 'r'), Loader=yaml.Loader)
         # Converts avi object types to avi resource types
         data_lower_case = map(lambda x: x.lower(),
@@ -1038,19 +1062,19 @@
         pivot_table = \
             pandas.pivot_table(df, index=["Status", "F5 type", "F5 SubType"],
                                values=[], aggfunc=[len], fill_value=0)
         # create dataframe for pivot table using pandas
         pivot_df = pandas.DataFrame(pivot_table)
         main_book = \
             load_workbook(report_path)
-        main_writer = pandas.ExcelWriter(report_path, engine='openpyxl')
-        main_writer.book = main_book
+        main_writer = pandas.ExcelWriter(report_path, engine='openpyxl',mode='a')
+        main_writer._book = main_book
         # Add pivot table in Pivot sheet
         pivot_df.to_excel(main_writer, 'Pivot Sheet')
-        main_writer.save()
+        main_writer.close()
 
     def vs_complexity_level(self):
         """
         This method calculate the complexity of vs.
         :return:
         """
         # Get the VS object list which is having status successful and partial.
@@ -1102,15 +1126,15 @@
         :param avi_graph: avi graph
         :param vs: VS list
         :return:
         """
         tmplist = []
         if isinstance(obj, str) and obj.startswith('Duplicate of'):
             obj_name = None
-            LOG.debug("Object has merged: %s" % obj)
+            LOG.debug("Object has merged: %s", obj)
         else:
             obj_name = obj.get('name', obj.get('hostname'))
         if obj_name:
             if avi_graph.has_node(obj_name):
                 LOG.debug("Checked predecessor for %s", obj_name)
                 predecessor = list(avi_graph.predecessors(obj_name))
                 if predecessor:
@@ -1131,18 +1155,18 @@
         if len(predecessor) > 1:
             for node in predecessor:
                 if node in tmplist:
                     continue
                 nodelist = [node]
                 self.get_predecessor(nodelist, avi_graph, vs, tmplist)
         elif len(predecessor):
-            node_obj = [nod for nod in list(avi_graph.nodes().data()) if
+            node_obj = [nod for nod in list(avi_graph.nodes(data=True)) if
                         nod[0] == predecessor[0]]
             if node_obj and (node_obj[0][1]['type'] == 'VS' or 'VS' in node_obj[
-                0][1]['type']):
+                    0][1]['type']):
                 LOG.debug("Predecessor %s found", predecessor[0])
                 vs.extend(predecessor)
             else:
                 tmplist.extend(predecessor)
                 LOG.debug("Checked predecessor for %s", predecessor[0])
                 nodelist = list(avi_graph.predecessors(predecessor[0]))
                 self.get_predecessor(nodelist, avi_graph, vs, tmplist)
@@ -1226,15 +1250,15 @@
                 csv_pool_rows = self.get_csv_object_list(csv_writer_dict_list,
                                                          ['pool'])
                 self.get_skipped_pool(
                     avi_config, pool_name, csv_pool_rows, csv_writer_dict_list,
                     vs_ref, profile_csv_list, pool_skipped_settings)
                 if pool_skipped_settings['pools']:
                     skipped_setting['Pool'] = pool_skipped_settings
-            # Get the skipepd list for http policy.
+            # Get the skipped list for http policy.
             if 'http_policies' in virtual_service:
                 policy_csv_list = self.get_csv_object_list(
                     csv_writer_dict_list, ['policy', 'profile'])
                 for http_ref in virtual_service['http_policies']:
                     policy_set_name, skipped_list = self.get_policy_set_skipped(
                         policy_csv_list, http_ref['http_policy_set_ref'],
                         vs_ref)
@@ -1243,17 +1267,18 @@
                         skipped_setting['Httppolicy']['name'] = policy_set_name
                         skipped_setting['Httppolicy'][
                             'skipped_list'] = skipped_list
                     # Get the http policy name
                     pool_csv_rows = \
                         self.get_csv_object_list(csv_writer_dict_list, ['pool'])
                     for each_http_policy in avi_config['HTTPPolicySet']:
-                        if each_http_policy['name'] == policy_set_name and 'http_request_policy' in each_http_policy:
+                        if each_http_policy['name'] == policy_set_name and\
+                                'http_request_policy' in each_http_policy:
                             for http_req in each_http_policy[
-                              'http_request_policy']['rules']:
+                                    'http_request_policy']['rules']:
                                 if http_req.get('switching_action', {}):
                                     self.get_skip_pools_policy(
                                         policy_set_name, http_req,
                                         avi_config, pool_csv_rows, vs_ref,
                                         profile_csv_list, skipped_setting)
 
             # # Get the skipped list for application_profile_ref.
@@ -1376,15 +1401,14 @@
                     skipped_setting['Httppolicy'] = {}
                     skipped_setting['Httppolicy']['name'] = policy_set_name
                 skipped_setting['Httppolicy']['Pool'] = pool_skipped_settings
 
     def update_skip_duplicates(self, obj, obj_list, obj_type, converted_objs,
                                name, default_profile_name, merge_object_mapping,
                                ent_type, prefix, syslist):
-
         """
         Merge duplicate profiles
         :param obj: Source object to find duplicates for
         :param obj_list: List of object to search duplicates in
         :param obj_type: Type of object to add in converted_objs status
         :param converted_objs: Converted avi object or merged object name
         :param name: Name of the object
@@ -1403,15 +1427,22 @@
             dup_of, old_name = \
                 self.check_for_duplicates(obj, obj_list, obj_type,
                                           merge_object_mapping, ent_type,
                                           prefix, syslist)
         if dup_of:
             converted_objs.append({obj_type: "Duplicate of %s" % dup_of})
             LOG.info(
-                "Duplicate profiles: %s merged in %s" % (obj['name'], dup_of))
+                "Duplicate profiles: %s merged in %s", obj['name'], dup_of)
             if isinstance(merge_object_mapping, dict):
                 if old_name in merge_object_mapping[obj_type].keys():
                     merge_object_mapping[obj_type].update({old_name: dup_of})
                 merge_object_mapping[obj_type].update({name: dup_of})
         else:
             obj_list.append(obj)
             converted_objs.append({obj_type: obj})
+
+    def get_updated_vs_name_after_triming(self, vs_name, avi_config):
+        vs = [vs for vs in avi_config['VirtualService']
+              if vs['description'] == vs_name]
+        if vs:
+            vs_name = vs[0]['name']
+        return vs_name
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/avi_orphan_object.py` & `avimigrationtools-22.1.4/avi/migrationtools/avi_orphan_object.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,93 +21,93 @@
                 'stringgroup': 'StringGroup', 'vrfcontext': 'VrfContext',
                 'applicationprofile': 'ApplicationProfile', 'vsdatascriptset':
                     'VSDataScriptSet', 'networksecuritypolicy':
                     'NetworkSecurityPolicy', 'applicationpersistenceprofile':
                     'ApplicationPersistenceProfile', 'prioritylabels':
                     'PriorityLabels', 'vsvip': 'VsVip', 'tenant': "Tenant",
                 'serviceenginegroup': 'ServiceEngineGroup',
-                'virtualservice': 'VirtualService','ipaddrgroup': 'IpAddrGroup'}
+                'virtualservice': 'VirtualService', 'ipaddrgroup': 'IpAddrGroup'}
 
 DEFAULT_META_ORDER = [
-        "ControllerLicense",
-        "SeProperties",
-        "SecureChannelToken",
-        "SecureChannelMapping",
-        "VIMgrIPSubnetRuntime",
-        "Tenant",
-        "ControllerProperties",
-        "CloudProperties",
-        "SecureChannelAvailableLocalIPs",
-        "JobEntry",
-        "Role",
-        "DebugController",
-        "AutoScaleLaunchConfig",
-        "MicroService",
-        "AuthProfile",
-        "AnalyticsProfile",
-        "APICLifsRuntime",
-        "LogControllerMapping",
-        "SnmpTrapProfile",
-        "AlertSyslogConfig",
-        "NetworkRuntime",
-        "AlertObjectList",
-        "VIPGNameInfo",
-        "CertificateManagementProfile",
-        "CloudRuntime",
-        "CloudConnectorUser",
-        "DebugServiceEngine",
-        "HardwareSecurityModuleGroup",
-        "HealthMonitor",
-        "VIDCInfo",
-        "VIMgrControllerRuntime",
-        "GlobalHealthMonitor",
-        "IpamDnsProviderProfile",
-        "StringGroup",
-        "Backup",
-        "DebugVirtualService",
-        "AlertScriptConfig",
-        "NetworkProfile",
-        "GlobalLB",
-        "IpAddrGroup",
-        "Cluster",
-        "SSLProfile",
-        "PKIProfile",
-        "ApplicationPersistenceProfile",
-        "MicroServiceGroup",
-        "SSLKeyAndCertificate",
-        "GlobalService",
-        "ApplicationProfile",
-        "NetworkSecurityPolicy",
-        "SystemConfiguration",
-        "Cloud",
-        "AlertEmailConfig",
-        "PriorityLabels",
-        "PoolGroupDeploymentPolicy",
-        "VIMgrVMRuntime",
-        "VrfContext",
-        "ActionGroupConfig",
-        "VIMgrHostRuntime",
-        "AlertConfig",
-        "VIMgrNWRuntime",
-        "VIMgrClusterRuntime",
-        "VIMgrSEVMRuntime",
-        "ServerAutoScalePolicy",
-        "Network",
-        "VIMgrDCRuntime",
-        "ServiceEngineGroup",
-        "Pool",
-        "VIMgrVcenterRuntime",
-        "ServiceEngine",
-        "PoolGroup",
-        "HTTPPolicySet",
-        "VSDataScriptSet",
-        "VirtualService",
-        "Alert",
-        "Application"
-    ]
+    "ControllerLicense",
+    "SeProperties",
+    "SecureChannelToken",
+    "SecureChannelMapping",
+    "VIMgrIPSubnetRuntime",
+    "Tenant",
+    "ControllerProperties",
+    "CloudProperties",
+    "SecureChannelAvailableLocalIPs",
+    "JobEntry",
+    "Role",
+    "DebugController",
+    "AutoScaleLaunchConfig",
+    "MicroService",
+    "AuthProfile",
+    "AnalyticsProfile",
+    "APICLifsRuntime",
+    "LogControllerMapping",
+    "SnmpTrapProfile",
+    "AlertSyslogConfig",
+    "NetworkRuntime",
+    "AlertObjectList",
+    "VIPGNameInfo",
+    "CertificateManagementProfile",
+    "CloudRuntime",
+    "CloudConnectorUser",
+    "DebugServiceEngine",
+    "HardwareSecurityModuleGroup",
+    "HealthMonitor",
+    "VIDCInfo",
+    "VIMgrControllerRuntime",
+    "GlobalHealthMonitor",
+    "IpamDnsProviderProfile",
+    "StringGroup",
+    "Backup",
+    "DebugVirtualService",
+    "AlertScriptConfig",
+    "NetworkProfile",
+    "GlobalLB",
+    "IpAddrGroup",
+    "Cluster",
+    "SSLProfile",
+    "PKIProfile",
+    "ApplicationPersistenceProfile",
+    "MicroServiceGroup",
+    "SSLKeyAndCertificate",
+    "GlobalService",
+    "ApplicationProfile",
+    "NetworkSecurityPolicy",
+    "SystemConfiguration",
+    "Cloud",
+    "AlertEmailConfig",
+    "PriorityLabels",
+    "PoolGroupDeploymentPolicy",
+    "VIMgrVMRuntime",
+    "VrfContext",
+    "ActionGroupConfig",
+    "VIMgrHostRuntime",
+    "AlertConfig",
+    "VIMgrNWRuntime",
+    "VIMgrClusterRuntime",
+    "VIMgrSEVMRuntime",
+    "ServerAutoScalePolicy",
+    "Network",
+    "VIMgrDCRuntime",
+    "ServiceEngineGroup",
+    "Pool",
+    "VIMgrVcenterRuntime",
+    "ServiceEngine",
+    "PoolGroup",
+    "HTTPPolicySet",
+    "VSDataScriptSet",
+    "VirtualService",
+    "Alert",
+    "Application"
+]
 
 
 def get_name_and_entity(url):
     """
     Parses reference string to extract object type and
     :param url: reference url to be parsed
     :return: entity and object name
@@ -129,15 +129,15 @@
     found_obj = None
     name_obj = None
     if avi_conf_key in avi_config:
         found_obj_list = avi_config[avi_conf_key]
         found_obj = [obj for obj in found_obj_list if obj['name'] == name]
     if found_obj:
         found_obj = found_obj[0]
-        tenant =  None
+        tenant = None
         if 'tenant_ref' in found_obj:
             link, tenant = get_name_and_entity(found_obj['tenant_ref'])
         name_obj = '%s-%s-%s' % (found_obj['name'], avi_conf_key, tenant)
         if new_config and name_obj not in new_config:
             new_config.append(name_obj)
         find_and_add_objects(found_obj, avi_config, new_config, vs_ref_dict)
 
@@ -157,15 +157,15 @@
             if not obj_dict[key]:
                 continue
             entity, name = get_name_and_entity(obj_dict[key])
             tenant_name = None
             # creating vs reference dict with unique keys
             if 'tenant_ref' in obj_dict:
                 ee, tenant_name = get_name_and_entity(obj_dict['tenant_ref'])
-            key = '%s$$%s$$%s' %(name, entity, tenant_name)
+            key = '%s$$%s$$%s' % (name, entity, tenant_name)
             if vs_flag:
                 vs_name = obj_dict['name']
             if vs_name:
                 if key in vs_ref_dict and vs_name not in vs_ref_dict[key]:
                     vs_ref_dict[key].append(vs_name)
                 else:
                     vs_ref_dict[key] = [vs_name]
@@ -202,20 +202,20 @@
     Filters vs and its references from full configuration
     :param avi_config: full configuration
     :param vs_names: comma separated vs names to filter
     :return: Filtered config dict
     """
     global vs_ref_dict_g
     new_config = []
-    vs_ref_dict = dict()
+    vs_ref_dict = {}
     for vs in avi_config.get('VirtualService'):
         vs_flag = True
         if 'tenant_ref' in vs:
             link, tenant = get_name_and_entity(vs['tenant_ref'])
-        else :
+        else:
             tenant = 'admin'
         name = '%s-%s-%s' % (vs['name'], 'VirtualService', tenant)
         new_config.append(name)
         find_and_add_objects(vs, avi_config, new_config, vs_ref_dict,
                              vs_flag=vs_flag)
     vs_ref_dict_g = vs_ref_dict
     return new_config
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/avi_rest_lib.py` & `avimigrationtools-22.1.4/avi/migrationtools/avi_rest_lib.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,52 +1,67 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-from avi.sdk.avi_api import ApiSession
 import logging
+from avi.sdk.avi_api import ApiSession
 from requests.packages import urllib3
 
 LOG = logging.getLogger(__name__)
 
-#disabling warning for SSL
+# disabling warning for SSL
 urllib3.disable_warnings()
 
+
 def upload_config_to_controller(avi_config_dict, controller_ip, username,
                                 password, tenant='admin', api_version='18.2.6'):
+    """
+    Method to upload migrated config to controller
+
+    Args:
+        avi_config_dict : Passed migrated avi configuration
+        controller_ip : destination controller ip address
+        username : destination controller username
+        password : destination controller password
+        tenant : tenant ref
+        api_version : controller versioion . Defaults to '18.2.6'.
+
+
+    """
     LOG.debug("Uploading config to controller")
     session = ApiSession.get_session(controller_ip, username, password=password,
                                      tenant=tenant, api_version=api_version)
     try:
         d = {'configuration': avi_config_dict}
         path = 'configuration/import'
         resp = session.post(path, data=d, timeout=7200)
         if resp.status_code < 300:
             LOG.info("Config uploaded to controller successfully")
         else:
-            LOG.error("Upload error response:" + resp.text)
+            LOG.error("Upload error response: %s", resp.text)
             raise Exception("Upload error response:" + resp.text)
-    except Exception as e:
+    except Exception as exception:
         LOG.error("Failed config upload", exc_info=True)
         print("Error")
-        raise Exception(e)
+        raise Exception(exception)
 
 
 def download_gslb_from_controller(controller_ip, username, password, tenant='admin'):
     """ Function to download the gslb configuration from controller """
     LOG.debug("Downloading gslb config from the controller")
     session = ApiSession.get_session(controller_ip, username,
                                      password, tenant="admin")
     try:
         path = 'gslb'
         resp = session.get(path)
         return resp.text
-    except Exception as e:
+    except Exception as exception:
         LOG.error("Failed gslb config download", exec_info=True)
         print("Error in Downloading gslb config")
-        raise Exception(e)
+        raise Exception(exception)
+
 
 def get_object_from_controller(object_type, object_name, controller_ip, username, password, tenant):
     """
     This function defines that it get the object from controller or raise
     exception if object status code is less than 299
     :param uri: URI to get the object
     :param controller_ip: ip of controller
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/common/avi_resource_types.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/common/avi_resource_types.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/config_patch.py` & `avimigrationtools-22.1.4/avi/migrationtools/config_patch.py`

 * *Files 1% similar despite different names*

```diff
@@ -28,30 +28,32 @@
 
 """
 import argparse
 import json
 import logging
 import sys
 import traceback
+import os
 
 import yaml
 import re
 import collections
 from copy import deepcopy
 from avi.migrationtools.avi_migration_utils import MigrationUtil
-import avi.migrationtools.ansible.avi_config_to_ansible as avi_config_to_ansible
+from avi.migrationtools.ansible import avi_config_to_ansible
 
 log = logging.getLogger(__name__)
 
 
 class ConfigPatch(object):
     """
     This class implements patching of configuration object that are either
     exported from Avi Controller or created by the configuration migration
     """
+
     def __init__(self, avi_cfg, patches):
         """
         :param avi_cfg: Avi config dictionary
         :param patches: Patch dictionary
         """
         log.debug('input patch %s', patches)
         self.avi_cfg = avi_cfg
@@ -92,15 +94,15 @@
             for k, v in obj.items():
                 if k.endswith('ref') or k.endswith('_refs'):
                     if isinstance(v, list):
                         if old_ref in v:
                             # need to remove and add the item.
                             log.debug('refs changed %s to %s', old_ref, new_ref)
                             new_refs = set(v)
-                            new_refs.pop(old_ref)
+                            new_refs.remove(old_ref)
                             new_refs.add(new_ref)
                             obj[k] = list(new_refs)
                     elif v == old_ref:
                         log.debug('refs changed %s to %s', v, new_ref)
                         obj[k] = new_ref
                 elif isinstance(v, dict):
                     self.update_obj_refs(
@@ -240,16 +242,16 @@
         """
         cfg_objs = new_cfg.get(obj_type, [])
         if obj_type == 'Tenant' and 'match_name' in patch_data \
                 and 'name' in patch_data['patch']:
             self.update_tenant_references(
                 new_cfg, patch_data['match_name'], patch_data['patch']['name'])
         if not cfg_objs:
-            log.warn('Could not apply patch %s: %s as no matching obj found',
-                     obj_type, patch_data)
+            log.warning('Could not apply patch %s: %s as no matching obj found',
+                        obj_type, patch_data)
             return new_cfg
         for obj in cfg_objs:
             obj_name = obj['name']
             rexp = None
             list_match = False
             if 'match_name' in patch_data:
                 regex_pattern = '^%s$' % patch_data['match_name']
@@ -343,17 +345,17 @@
 
     with open(args.patchconfig) as f:
         patches = yaml.load(f, Loader=yaml.Loader)
     cp = ConfigPatch(acfg, patches)
     patched_cfg = cp.patch()
     with open(args.aviconfig + '.patched', 'w') as f:
         f.write(json.dumps(patched_cfg, indent=4))
-
     with open(args.aviconfig + '.patched', "r+") as f:
         avi_cfg = json.loads(f.read())
-    output_dir = args.aviconfig[0:args.aviconfig.rindex("/") + 1]
+
+    output_dir = os.getcwd()
     aac = avi_config_to_ansible.AviAnsibleConverter(
         avi_cfg, output_dir)
     if args.yaml:
         aac.write_yaml()
     elif args.ansible:
         aac.write_ansible_playbook()
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/custom_config.py` & `avimigrationtools-22.1.4/avi/migrationtools/custom_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,26 +1,27 @@
 # !/usr/bin/env python3
 
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 # Version 0.06
 
+import argparse
+import re
 import urllib3
 import yaml
-import re
-import argparse
+
 from avi.sdk.avi_api import ApiSession
 urllib3.disable_warnings()
 api_results = {}
 
 
 def ref_clean_up(obj):
     """
     Loops through list of policies and datascripts and removes un-needed fields
-    :param obj: Object for which referances to clean up
+    :param obj: Object for which references to clean up
     :return Updated object
     """
     clean_up = ['uuid', 'url', '_last_modified', 'is_internal_policy']
     if isinstance(obj, dict):
         return {k: ref_clean_up(v) for k, v in obj.items()}
     elif isinstance(obj, list):
         # clean all unused k/v pairs in api call
@@ -178,15 +179,15 @@
                                 {
                                     'name': script['name'],
                                     'datascript':
                                         [{
                                             'evt': ds['evt'],
                                             'script': ds['script']
                                         }]
-                                }
+                            }
                         }
                     )
         if "NetworkSecurityPolicy" == k:
             for policy_item in v:
                 results.extend(policyset(policy_item, "NetworkSecurityPolicy"))
     return ref_clean_up(results)
 
@@ -244,26 +245,29 @@
     HELP_STR = '''
     For all iRules in migration scope, configure them on the Avi Controller as appropriate object
         Network Security policy
         HTTP Security policy
         HTTP Request policy
         HTTP Response policy
         DataScript
-    
-    Script convertsall Network Security, HTTP Security, HTTP Request, HTTP Response polices and Datascripts on controller into YAML file to run with the F5 Migration tool
 
-    Script will complete a GET API call to controller for policies and datascripts, convert the RAW JSON to YAML, and write it to a file calledconverted_irules.yml.
+    Script convertsall Network Security, HTTP Security, HTTP Request,
+    HTTP Response polices and Datascripts on controller into YAML file to run with the F5 Migration tool
+
+    Script will complete a GET API call to controller for policies and datascripts,
+    convert the RAW JSON to YAML, and write it to a file calledconverted_irules.yml.
 
     For policies that require multiple indexes
         You must save each policy with a unique name while configuring it in the UI
- 
-        The script parses the longest match for the policy name. The longest match should be exactly what the irule name is on the F5.
+
+        The script parses the longest match for the policy name.
+        The longest match should be exactly what the irule name is on the F5.
             Example
                 mobile-https.redirect.irule (Actual iRule name)
-                mobile-https.redirect.irule-mobilesecure.com 
+                mobile-https.redirect.irule-mobilesecure.com
             The longest match between the two policies is "mobile-https.redirect.irule
 
         Suffix
             Must have two dashes "--" followed by a unique word (--foo --bar,--one, --two, etc)
 
         Policies that belong to the same HTTP policy set need to have a suffix tying them together
             Example
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/clone_cross_tenant_obj.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/clone_cross_tenant_obj.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/command_status.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/command_status.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -134,27 +134,26 @@
     - 'monitor'
     - 'service-down-action'
     - 'load-balancing-mode'
     - 'description'
     - 'slow-ramp-time'
     - 'reselect-tries'
     - "partition"
+    - "min-active-members"
 
     Pool_supported_attr_convert_servers_config:
     - 'address'
     - 'state'
     - 'session'
     - 'ratio'
     - 'description'
     - 'connection-limit'
     - 'rate-limit'
     - 'priority-group'
 
-    Pool_ignore_val:
-        min-active-members: '1'
 
     Profile_supported_types:
     - "client-ssl"
     - "server-ssl"
     - "http"
     - "dns"
     - "fasthttp"
@@ -286,14 +285,20 @@
     - 'options'
     - 'unclean-shutdown'
     - 'crl-file'
     - 'ca-file'
     - 'defaults-from'
     - 'peer-cert-mode'
     - "partition"
+    - "passphrase"
+    - "ocsp-stapling"
+    - "alert-timeout"
+    - "session-ticket-timeout"
+    - "sni-default"
+    - "server-name"
 
     Profile_na_http:
     - 'lws-width'
     - 'lws-separator'
     - 'allow-http-10'
     - 'enforcement'
 
@@ -310,14 +315,15 @@
     - "basic-auth-realm"
     - "header-erase"
     - "header-insert"
     - "partition"
     - "redirect-rewrite"
     - "via-host-name"
     - "via-request"
+    - "hsts"
 
     Profile_supported_http_enforcement:
     - "max-header-size"
 
     Profile_http_enf_ignore_for_defaults:
         'unknown-method': 'allow'
         'max-header-count': '64'
@@ -569,14 +575,16 @@
     - 'description'
     - 'disabled'
     - 'translate-port'
     - 'source'
     - 'rate-limit'
     - 'connection-limit'
     - "partition"
+    - "mirror"
+    - "nat64"
 
     VS_na_attr:
     - 'vs-index'
     - "translate-address"
     - "app-service"
     - 'creation-time'
     - 'last-modified-time'
@@ -1104,14 +1112,15 @@
     - 'persist'
     - 'disabled'
     - 'description'
     - 'snatpool'
     - 'translate service'
     - 'source'
     - 'limit'
+    - "mirror"
 
     VS_na_attr:
     - 'vs-index'
     - "translate-address"
     - "app-service"
     - 'creation-time'
     - 'last-modified-time'
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/config.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/config.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/conversion_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/conversion_util.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,54 +1,54 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
+import ast
 import copy
 import logging
 import os
+import re
 from functools import reduce
 
-import pandas
-import ast
-import re
-import random
 import avi.migrationtools.f5_converter.converter_constants as conv_const
-
-from xlsxwriter import Workbook
+import pandas
+from avi.migrationtools.avi_migration_utils import MigrationUtil, tenants
 from openpyxl import load_workbook
 from pkg_resources import parse_version
-from avi.migrationtools.avi_migration_utils import MigrationUtil, tenants
+from xlsxwriter import Workbook
 
 LOG = logging.getLogger(__name__)
 csv_writer_dict_list = []
 
 # Added variable for checking progress and get overall object.
 ppcount = 0
 ptotal_count = 0
 global fully_migrated
 fully_migrated = 0
 used_pool_groups = {}
 used_pool = {}
 
+
 class F5Util(MigrationUtil):
+    '''
+    Class F5 Utils
+    '''
 
     def get_avi_pool_down_action(self, action):
         """
         Maps Pool down action from F5 config to Avi Config
         :param action: F5 action string
         :return: Avi action String
         """
-        action_close_con = {
-            "type": "FAIL_ACTION_CLOSE_CONN"
-        }
+        action_close_con = {"type": "FAIL_ACTION_CLOSE_CONN"}
         if action == "reset":
             return action_close_con
         if action == "reselect":
             return action_close_con
-        else:
-            return action_close_con
+
+        return action_close_con
 
     def get_cc_algo_val(self, cc_algo):
         """
         congestion-control algorithm conversion
         :param cc_algo: F5 algorithm value
         :return: Avi algorithm value
         """
@@ -56,65 +56,64 @@
         if cc_algo == "high-speed":
             avi_algo_val = "CC_ALGO_HTCP"
         elif cc_algo == "cubic":
             avi_algo_val = "CC_ALGO_CUBIC"
         return avi_algo_val
 
     def add_conv_status(self, f5_type, f5_sub_type, f5_id, conv_status,
-                        avi_object=None, need_review=None):
+                        avi_object=None, f5_object=None, need_review=None):
         """
         Adds as status row in conversion status csv
         :param f5_type: Object type
         :param f5_sub_type: Object sub type
         :param f5_id: Name oconv_f object
         :param conv_status: dict of conversion status
         :param avi_object: Converted objectconverted avi object
         """
         global csv_writer_dict_list
         # Added space if f5_sub_type None for pivot table
         row = {
-            'F5 type': f5_type,
-            'F5 SubType': f5_sub_type if f5_sub_type else ' ',
-            'F5 ID': f5_id,
-            'Status': conv_status.get('status', ''),
-            'Skipped settings': str(conv_status.get('skipped', '')),
-            'Skipped for defaults': str(conv_status.get('default_skip', '')),
-            'Indirect mapping': str(conv_status.get('indirect', '')),
-            'Not Applicable': str(conv_status.get('na_list', '')),
-            'User Ignored': str(conv_status.get('user_ignore', '')),
-            'Avi Object': str(avi_object),
-            'Needs Review': need_review
+            "F5 type": f5_type,
+            "F5 SubType": f5_sub_type if f5_sub_type else " ",
+            "F5 ID": f5_id,
+            "Status": conv_status.get("status", ""),
+            "Skipped settings": str(conv_status.get("skipped", "")),
+            "Skipped for defaults": str(conv_status.get("default_skip", "")),
+            "Indirect mapping": str(conv_status.get("indirect", "")),
+            "Not Applicable": str(conv_status.get("na_list", "")),
+            "User Ignored": str(conv_status.get("user_ignore", "")),
+            "F5 Object": str(f5_object),
+            "Avi Object": str(avi_object),
+            "Needs Review": need_review,
         }
         csv_writer_dict_list.append(row)
 
-    def add_status_row(self, f5_type, f5_sub_type, f5_id, status, avi_obj=None):
+    def add_status_row(self, f5_type, f5_sub_type,
+                       f5_id, status, avi_obj=None):
         """
         Adds as status row in conversion status csv
         :param f5_type: Object type
         :param f5_sub_type: Object sub type
         :param f5_id: Name of object
         :param status: conversion status
         :param avi_obj: Converted avi object
         """
         global csv_writer_dict_list
         # Added space if f5_sub_type None for pivot table
         row = {
-            'F5 type': f5_type,
-            'F5 SubType': f5_sub_type if f5_sub_type else ' ',
-            'F5 ID': f5_id,
-            'Status': status
-        }
+            "F5 type": f5_type,
+            "F5 SubType": f5_sub_type if f5_sub_type else " ",
+            "F5 ID": f5_id,
+            "Status": status}
         if avi_obj:
-            row.update({
-                'Avi Object': str(avi_obj)
-            })
+            row.update({"Avi Object": str(avi_obj)})
         csv_writer_dict_list.append(row)
 
-    def add_complete_conv_status(self, output_dir, avi_config, report_name,
-                                 vs_level_status):
+    def add_complete_conv_status(
+            self, output_dir, avi_config, report_name, vs_level_status):
 
         global csv_writer_dict_list
         global ptotal_count
         for status in conv_const.STATUS_LIST:
             status_list = [row for row in csv_writer_dict_list if
                            row['Status'] == status]
             print('%s: %s' % (status, len(status_list)))
@@ -132,15 +131,15 @@
     def get_port_by_protocol(self, protocol):
         """
         Instead of default ports for protocols F5 config has protocol in
         destination value for Avi object need to conver it to port number
         :param protocol: protocol name
         :return: integer value for protocol
         """
-        if protocol == 'http':
+        if protocol == "http":
             port = conv_const.HTTP_PORT
         elif protocol == "https":
             port = conv_const.HTTPS_PORT
         elif protocol == "ftp":
             port = conv_const.FTP_PORT
         elif protocol == "smtp":
             port = conv_const.SMTP_PORT
@@ -154,28 +153,36 @@
             port = conv_const.SSH_PORT
         elif protocol == "xfer":
             port = conv_const.XFER_PORT
         elif protocol == "pcsync-https":
             port = conv_const.PCSYNC_HTTPS_PORT
         elif protocol == "macromedia-fcs":
             port = conv_const.MACROMEDIA_FCS_PORT
-        elif protocol == 'imap':
+        elif protocol == "imap":
             port = conv_const.IMAP_PORT
-        elif protocol == 'pop3':
+        elif protocol == "pop3":
             port = conv_const.POP3_PORT
         elif protocol == "any":
             port = None
         else:
             return None
         return port
 
-    def update_skip_duplicates(self, obj, obj_list, obj_type, converted_objs,
-                               name, default_profile_name, merge_object_mapping,
-                               ent_type, prefix, syslist):
-
+    def update_skip_duplicates(
+            self,
+            obj,
+            obj_list,
+            obj_type,
+            converted_objs,
+            name,
+            default_profile_name,
+            merge_object_mapping,
+            ent_type,
+            prefix,
+            syslist):
         """
         Merge duplicate profiles
         :param obj: Source object to find duplicates for
         :param obj_list: List of object to search duplicates in
         :param obj_type: Type of object to add in converted_objs status
         :param converted_objs: Converted avi object or merged object name
         :param name: Name of the object
@@ -186,23 +193,22 @@
         :param syslist: System object list
         :return:
         """
         dup_of = None
         if isinstance(merge_object_mapping, dict):
             merge_object_mapping[obj_type].update({name: name})
         # root default profiles are skipped for merging
-        if not name == default_profile_name or obj_type == 'ssl_profile':
-            dup_of, old_name = \
-                self.check_for_duplicates(obj, obj_list, obj_type,
-                                          merge_object_mapping, ent_type,
-                                          prefix, syslist)
+        if not name == default_profile_name or obj_type == "ssl_profile":
+            dup_of, old_name = self.check_for_duplicates(
+                obj, obj_list, obj_type, merge_object_mapping, ent_type, prefix, syslist)
         if dup_of:
             converted_objs.append({obj_type: "Duplicate of %s" % dup_of})
             LOG.info(
-                "Duplicate profiles: %s merged in %s" % (obj['name'], dup_of))
+                "Duplicate profiles: %s merged in %s",
+                obj["name"], dup_of)
             if isinstance(merge_object_mapping, dict):
                 if old_name in merge_object_mapping[obj_type].keys():
                     merge_object_mapping[obj_type].update({old_name: dup_of})
                 merge_object_mapping[obj_type].update({name: dup_of})
         else:
             obj_list.append(obj)
             converted_objs.append({obj_type: obj})
@@ -212,28 +218,31 @@
         Creates Avi String group object
         :param name: name of string group
         :param content_types: list of content type
         :param tenant: tenant name to add tenant reference
         :return:
         """
         sg_obj = {"name": name + "-content_type", "type": "SG_TYPE_STRING"}
-        kv = []
+        key_value = []
         for content_type in content_types:
             if content_type is None:
-                LOG.warning('%s content_types %s has none', name, content_types)
+                LOG.warning(
+                    "%s content_types %s has none",
+                    name,
+                    content_types)
                 continue
             uri = {"key": content_type}
-            kv.append(uri)
-        sg_obj["kv"] = kv
+            key_value.append(uri)
+        sg_obj["kv"] = key_value
         # Changed tenant ref to new reference.
-        sg_obj['tenant_ref'] = self.get_object_ref(tenant, 'tenant')
+        sg_obj["tenant_ref"] = self.get_object_ref(tenant, "tenant")
         return sg_obj
 
-    def get_vs_ssl_profiles(self, profiles, avi_config, prefix,
-                            merge_object_mapping, sys_dict, f5_config):
+    def get_vs_ssl_profiles(self, profiles, avi_config,
+                            prefix, merge_object_mapping, sys_dict, f5_config):
         """
         Searches for profile refs in converted profile config if not found
         creates default profiles
         :param profiles: profiles in f5 config assigned to VS
         :param avi_config: converted avi config
         :param prefix: prefix for objects
         :param merge_object_mapping: Merged object mappings
@@ -248,77 +257,77 @@
         if isinstance(profiles, str):
             profiles = profiles.replace(" {}", "")
             profiles = {profiles: None}
         for key in profiles.keys():
             # Called tenant ref to get object name.
             tenant, name = self.get_tenant_ref(key)
             if prefix:
-                name = prefix + '-' + name
+                name = prefix + "-" + name
             ssl_profile_list = avi_config.get("SSLProfile", [])
-            sys_ssl = sys_dict['SSLProfile']
-            ssl_profiles = [ob for ob in sys_ssl if ob['name'] ==
-                            merge_object_mapping['ssl_profile'].get(name)
-                            ] or [obj for obj in ssl_profile_list
-                                  if (obj['name'] == name or name in
-                                      obj.get("dup_of", []))]
+            sys_ssl = sys_dict["SSLProfile"]
+            ssl_profiles = [ob for ob in sys_ssl
+                            if ob["name"] == merge_object_mapping["ssl_profile"].get(name)]\
+                or [obj for obj in ssl_profile_list
+                    if (obj["name"] == name or name in obj.get("dup_of", []))]
             if ssl_profiles:
-                cert_name = ssl_profiles[0].get('cert_name', None)
+                cert_name = ssl_profiles[0].get("cert_name", None)
                 if not cert_name:
                     cert_name = name
                 ssl_key_cert_list = avi_config.get("SSLKeyAndCertificate", [])
-                sys_key_cert = sys_dict['SSLKeyAndCertificate']
-                key_cert = [ob for ob in sys_key_cert if ob['name'] ==
-                            merge_object_mapping['ssl_cert_key'].get(cert_name)
-                            ] or [obj for obj in ssl_key_cert_list if
-                                  (obj['name'] == cert_name or obj['name'] ==
-                                   '%s-%s'% (cert_name, conv_const.PLACE_HOLDER_STR) or cert_name in
-                                   obj.get("dup_of", []))]
+                sys_key_cert = sys_dict["SSLKeyAndCertificate"]
+                key_cert = [
+                    ob for ob in sys_key_cert if ob["name"] ==
+                    merge_object_mapping["ssl_cert_key"].get(cert_name)] or [
+                    obj for obj in ssl_key_cert_list if (
+                        obj["name"] == cert_name or obj["name"] == "%s-%s" %
+                        (cert_name, conv_const.PLACE_HOLDER_STR) or cert_name in obj.get(
+                            "dup_of", []))]
                 # key_cert = key_cert[0]['name'] if key_cert else None
                 if key_cert:
                     key_cert = self.get_object_ref(
-                        key_cert[0]['name'], 'sslkeyandcertificate',
-                        tenant=self.get_name(key_cert[0]['tenant_ref']))
+                        key_cert[0]["name"],
+                        "sslkeyandcertificate",
+                        tenant=self.get_name(
+                            key_cert[0]["tenant_ref"]))
                 profile = profiles[key]
                 context = profile.get("context") if profile else None
                 if (not context) and isinstance(profile, dict):
-                    if 'serverside' in profile:
-                        context = 'serverside'
-                    elif 'clientside' in profile:
-                        context = 'clientside'
+                    if "serverside" in profile:
+                        context = "serverside"
+                    elif "clientside" in profile:
+                        context = "clientside"
                 pki_list = avi_config.get("PKIProfile", [])
-                syspki = sys_dict['PKIProfile']
-                pki_profiles = [ob for ob in syspki if ob['name'] ==
-                                merge_object_mapping['pki_profile'].get(
-                                    name)] or \
-                               [obj for obj in pki_list if
-                                (obj['name'] == name or
-                                 name in obj.get("dup_of", []))]
-                pki_profile = pki_profiles[0]['name'] if pki_profiles else None
-                mode = 'SSL_CLIENT_CERTIFICATE_NONE'
+                syspki = sys_dict["PKIProfile"]
+                pki_profiles = [
+                    ob for ob in syspki if ob["name"] == merge_object_mapping["pki_profile"].get(name)]\
+                    or [
+                    obj for obj in pki_list if (
+                        obj["name"] == name or name in obj.get(
+                            "dup_of", []))]
+                pki_profile = pki_profiles[0]["name"] if pki_profiles else None
+                mode = "SSL_CLIENT_CERTIFICATE_NONE"
                 if pki_profile:
-                    mode = pki_profiles[0].pop('mode',
-                                               'SSL_CLIENT_CERTIFICATE_NONE')
+                    mode = pki_profiles[0].pop(
+                        "mode", "SSL_CLIENT_CERTIFICATE_NONE")
                     pki_profile = self.get_object_ref(
-                        pki_profiles[0]["name"], 'pkiprofile',
-                        tenant=self.get_name(pki_profiles[0]['tenant_ref']))
+                        pki_profiles[0]["name"], "pkiprofile", tenant=self.get_name(
+                            pki_profiles[0]["tenant_ref"]))
                 if context == "clientside":
                     ssl_prof_ref = self.get_object_ref(
-                        ssl_profiles[0]["name"], 'sslprofile',
-                        tenant=self.get_name(ssl_profiles[0]['tenant_ref']))
-                    vs_ssl_profile_names.append({"profile": ssl_prof_ref,
-                                                 "cert": key_cert,
-                                                 "pki": pki_profile,
-                                                 'mode': mode})
+                        ssl_profiles[0]["name"], "sslprofile", tenant=self.get_name(
+                            ssl_profiles[0]["tenant_ref"]))
+                    vs_ssl_profile_names.append(
+                        {"profile": ssl_prof_ref, "cert": key_cert, "pki": pki_profile, "mode": mode})
                 elif context == "serverside":
                     ssl_prof_ref = self.get_object_ref(
-                        ssl_profiles[0]["name"], 'sslprofile',
-                        tenant=self.get_name(ssl_profiles[0]['tenant_ref']))
+                        ssl_profiles[0]["name"], "sslprofile", tenant=self.get_name(
+                            ssl_profiles[0]["tenant_ref"]))
                     pool_ssl_profile_names.append(
                         {"profile": ssl_prof_ref, "cert": key_cert,
-                         "pki": pki_profile, 'mode': mode})
+                         "pki": pki_profile, "mode": mode})
         return vs_ssl_profile_names, pool_ssl_profile_names
 
     def get_vs_app_profiles(self, profiles, avi_config, tenant_ref, prefix,
                             oc_prof, enable_ssl, merge_object_mapping,
                             sys_dict):
         """
         Searches for profile refs in converted profile config if not found
@@ -331,93 +340,104 @@
         :param enable_ssl: VS ssl enabled flag
         :param merge_object_mapping: Merged object mappings
         :param sys_dict: System object dict
 
         :return: returns list of profile refs assigned to VS in avi config
         """
         app_profile_refs = []
-        app_prof_conf = dict()
+        app_prof_conf = {}
         app_profile_list = avi_config.get("ApplicationProfile", [])
-        unsupported_profiles = avi_config.get('UnsupportedProfiles', [])
-        sys_app = sys_dict['ApplicationProfile']
+        unsupported_profiles = avi_config.get("UnsupportedProfiles", [])
+        sys_app = sys_dict["ApplicationProfile"]
         if not profiles:
             profiles = {}
         if isinstance(profiles, str):
             profiles = profiles.replace(" {}", "")
             profiles = {profiles: None}
         for name in profiles.keys():
             # Called tenant ref to get object name.
             name = self.get_tenant_ref(name)[1]
             # Added prefix for objects
             if prefix:
                 name = '%s-%s' % (prefix, name)
-            app_profiles = [ob for ob in sys_app if ob['name'] ==
-                            merge_object_mapping['app_profile'].get(name)] or [
-                               obj for obj in app_profile_list if
-                               (obj['name'] == name
-                                or name in obj.get("dup_of", []))]
+            app_profiles = [ob for ob in sys_app
+                            if ob["name"] == merge_object_mapping["app_profile"].get(name)] \
+                or [obj
+                    for obj in app_profile_list
+                    if (obj["name"] == name or name in obj.get("dup_of", []))]
             if app_profiles:
-                app_prof_name = app_profiles[0]['name']
-                app_profile_refs.append(self.get_object_ref(
-                    app_prof_name, 'applicationprofile',
-                    tenant=self.get_name(app_profiles[0]['tenant_ref'])))
-
-                if app_profiles[0].get('HTTPPolicySet', None):
-                    app_prof_conf['policy_name'] = app_profiles[0]['HTTPPolicySet']
-                if app_profiles[0].get('fallback_host', None):
-                    app_prof_conf['f_host'] = app_profiles[0]['fallback_host']
+                app_prof_name = app_profiles[0]["name"]
+                app_profile_refs.append(
+                    self.get_object_ref(
+                        app_prof_name,
+                        "applicationprofile",
+                        tenant=self.get_name(
+                            app_profiles[0]["tenant_ref"]))
+                )
+
+                if app_profiles[0].get("HTTPPolicySet", None):
+                    app_prof_conf["policy_name"] = app_profiles[0]["HTTPPolicySet"]
+                if app_profiles[0].get("fallback_host", None):
+                    app_prof_conf["f_host"] = app_profiles[0]["fallback_host"]
                 # prerequisite user need to create default auth profile
-                if app_profiles[0].get('realm', None):
-                    app_prof_conf['realm'] = {
+                if app_profiles[0].get("realm", None):
+                    app_prof_conf["realm"] = {
                         "type": "HTTP_BASIC_AUTH",
                         "auth_profile_ref": self.get_object_ref(
-                            'System-Default-Auth-Profile', 'authprofile',
+                            "System-Default-Auth-Profile",
+                            "authprofile",
                             tenant=self.get_name(
-                                app_profiles[0]['tenant_ref'])),
-                        "realm": app_profiles[0]['realm']
+                                app_profiles[0]["tenant_ref"])),
+                        "realm": app_profiles[0]["realm"],
                     }
 
         if not app_profile_refs:
-            not_supported = [key for key in profiles.keys() if
-                             key in unsupported_profiles]
+            not_supported = [
+                key for key in profiles.keys() if key in unsupported_profiles]
             if not_supported:
                 LOG.warning(
-                    'Profiles not supported by Avi : %s' % not_supported)
+                    "Profiles not supported by Avi : %s",
+                    not_supported)
                 return app_prof_conf
             if enable_ssl:
                 app_profile_refs.append(
-                    self.get_object_ref('System-SSL-Application',
-                                        'applicationprofile', tenant='admin'))
-                app_prof_conf['app_prof'] = app_profile_refs
+                    self.get_object_ref(
+                        "System-SSL-Application",
+                        "applicationprofile",
+                        tenant="admin"))
+                app_prof_conf["app_prof"] = app_profile_refs
                 return app_prof_conf
             else:
                 app_profile_refs.append(
-                    self.get_object_ref('System-L4-Application',
-                                        'applicationprofile', tenant='admin'))
-                app_prof_conf['app_prof'] = app_profile_refs
+                    self.get_object_ref(
+                        "System-L4-Application",
+                        "applicationprofile",
+                        tenant="admin"))
+                app_prof_conf["app_prof"] = app_profile_refs
                 return app_prof_conf
             # Added prefix for objects
             if prefix:
                 value = '%s-%s' % (prefix, value)
-            default_app_profile = [ob for ob in sys_app if ob['name'] ==
-                                   merge_object_mapping['app_profile'].get(
-                                       value)] or [
-                                      obj for obj in app_profile_list if
-                                      (obj['name'] == value
-                                       or value in obj.get("dup_of", []))]
-            tenant = self.get_name(default_app_profile[0]['tenant_ref']) if \
-                default_app_profile else '/api/tenant/?name=admin'
+            default_app_profile = [
+                ob for ob in sys_app if ob["name"] == merge_object_mapping["app_profile"].get(value)] or [
+                obj for obj in app_profile_list if (
+                    obj["name"] == value or value in obj.get(
+                        "dup_of", []))]
+            tenant = self.get_name(
+                default_app_profile[0]["tenant_ref"]) if default_app_profile else "/api/tenant/?name=admin"
             app_profile_refs.append(
-                self.get_object_ref(default_app_profile[0]['name'],
-                                    'applicationprofile', tenant=tenant))
-        app_prof_conf['app_prof'] = app_profile_refs
+                self.get_object_ref(
+                    default_app_profile[0]["name"],
+                    "applicationprofile",
+                    tenant=tenant))
+        app_prof_conf["app_prof"] = app_profile_refs
         return app_prof_conf
 
-    def get_vs_ntwk_profiles(self, profiles, avi_config, prefix,
-                             merge_object_mapping, sys_dict):
+    def get_vs_ntwk_profiles(self, profiles, avi_config,
+                             prefix, merge_object_mapping, sys_dict):
         """
         Searches for profile refs in converted profile config if not found
         creates default profiles
         :param profiles: profiles in f5 config assigned to VS
         :param avi_config: converted avi config
         :param prefix: prefix for objects
         :param merge_object_mapping: merged object mappings
@@ -431,153 +451,177 @@
             profiles = profiles.replace(" {}", "")
             profiles = {profiles: None}
         for name in profiles.keys():
             # Called tenant method to get object name
             tenant, name = self.get_tenant_ref(name)
             # Added prefix for objects
             if prefix:
-                name = prefix + '-' + name
+                name = prefix + "-" + name
             ntwk_prof_lst = avi_config.get("NetworkProfile")
-            sysnw = sys_dict['NetworkProfile']
-            network_profiles = [ob for ob in sysnw if
-                                ob['name'] == merge_object_mapping[
-                                    'network_profile'].get(name)] or \
-                               [obj for obj in ntwk_prof_lst if (
-                                       obj['name'] == name or name in
-                                       obj.get("dup_of", []))]
+            sysnw = sys_dict["NetworkProfile"]
+            network_profiles = [
+                ob for ob in sysnw if ob["name"] == merge_object_mapping["network_profile"].get(name)] or [
+                obj for obj in ntwk_prof_lst if (
+                    obj["name"] == name or name in obj.get(
+                        "dup_of", []))]
             if network_profiles:
                 network_profile_ref = self.get_object_ref(
-                    network_profiles[0]['name'], 'networkprofile',
-                    tenant=self.get_name(network_profiles[0]['tenant_ref']))
+                    network_profiles[0]["name"], "networkprofile", tenant=self.get_name(
+                        network_profiles[0]["tenant_ref"]))
                 network_profile_names.append(network_profile_ref)
         return network_profile_names
 
     def update_service(self, port, vs, enable_ssl):
         """
         iterates over services of existing vs in converted list to update
         services for port overlapping scenario
         :param port: port for currant VS
         :param vs: VS from converted config list
         :param enable_ssl: value to put in service object
         :return: boolean if service is updated or not
         """
         service_updated = False
         vs_new_service = []
-        for service in vs['services']:
-            port_end = service.get('port_range_end', None)
-            if not port_end and int(service['port']) == int(port):
-                return 'duplicate_ip_port'
-            if port_end and (service['port'] <= int(port) <= port_end):
+        for service in vs["services"]:
+            port_end = service.get("port_range_end", None)
+            if not port_end and int(service["port"]) == int(port):
+                return "duplicate_ip_port"
+            if port_end and (service["port"] <= int(port) <= port_end):
                 if port not in [conv_const.PORT_START, conv_const.PORT_END]:
-                    if service['port'] == int(port) == port_end:
-                        return 'duplicate_ip_port'
-                    elif service['port'] == int(port):
-                        service['port'] = int(port) + 1
-                    elif service['port_range_end'] == int(port):
-                        service['port_range_end'] = int(port) - 1
+                    if service["port"] == int(port) == port_end:
+                        return "duplicate_ip_port"
+                    if service["port"] == int(port):
+                        service["port"] = int(port) + 1
+                    elif service["port_range_end"] == int(port):
+                        service["port_range_end"] = int(port) - 1
                     else:
                         new_port = int(port) + 1
-                        new_end = service['port_range_end']
-                        service['port_range_end'] = int(port) - 1
-                        new_service = {'port': new_port,
-                                       'port_range_end': new_end,
-                                       'enable_ssl': enable_ssl}
+                        new_end = service["port_range_end"]
+                        service["port_range_end"] = int(port) - 1
+                        new_service = {
+                            "port": new_port,
+                            "port_range_end": new_end,
+                            "enable_ssl": enable_ssl}
                         vs_new_service.append(new_service)
                 elif port == conv_const.PORT_START:
-                    service['port'] = 2
+                    service["port"] = 2
                 elif port == conv_const.PORT_END:
-                    service['port_range_end'] = (conv_const.PORT_START - 1)
+                    service["port_range_end"] = conv_const.PORT_START - 1
                 service_updated = True
                 break
-        vs['services'].extend(vs_new_service)
+        vs["services"].extend(vs_new_service)
         return service_updated
 
-    def get_service_obj(self, destination, avi_config, enable_ssl,
-                        controller_version, tenant_name, cloud_name, prefix,
-                        vs_name, input_vrf=None):
+    def get_service_obj(
+            self,
+            destination,
+            avi_config,
+            enable_ssl,
+            controller_version,
+            tenant_name,
+            cloud_name,
+            prefix,
+            vs_name,protocol,
+            input_vrf=None):
         """
         Checks port overlapping scenario for port value 0 in F5 config
         :param destination: IP and Port destination of VS
         :param avi_config: Dict of avi config
         :param enable_ssl: value to put in service objects
         :param controller_version: Version of controller
         :param tenant_name: Name of tenant
         :param cloud_name: Name of cloud
         :param prefix: name prefix
         :param vs_name: Name of VS
         :param input_vrf: Vrf context name
         :return: services_obj, ip_addr of vs and ref of vsvip
         """
 
-        parts = destination.split(':')
+        parts = destination.split(".")
+        if len(parts) > 2:
+            parts = destination.split(":")
         ip_addr = parts[0]
         ip_addr = ip_addr.strip()
         vrf = None
         # Removed unwanted string from ip address
-        if '%' in ip_addr:
-            ip_addr, vrf = ip_addr.split('%')
+        if "%" in ip_addr:
+            ip_addr, vrf = ip_addr.split("%")
         # Added support to skip virtualservice with ip address any
-        if ip_addr == 'any':
+        if ip_addr == "any":
             LOG.debug("Skipped:VS with IP address: %s" % str(destination))
             return None, None, None, None
         # Added check for IP V4
-        matches = re.findall('^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', ip_addr)
-        if not matches or ip_addr == '0.0.0.0':
-            LOG.warning(
-                'Avi does not support IPv6 Generated random ipv4 for vs:'
-                ' %s' % ip_addr)
-            ip_addr = ".".join(map(str, (
-                random.randint(0, 255) for _ in range(4))))
+        matches = re.findall(
+            "^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$", ip_addr)
+        if not matches or ip_addr == "0.0.0.0":
+            # LOG.warning(
+            #     'Avi does not support IPv6 Generated random ipv4 for vs:'
+            #     ' %s' % ip_addr)
+            # ip_addr = ".".join(map(str, (
+            #     random.randint(0, 255) for _ in range(4))))
+            ip_type = "V6"
         port = parts[1] if len(parts) == 2 else conv_const.DEFAULT_PORT
         # Get the list of vs which shared the same vip
-        if parse_version(controller_version) >= parse_version('17.1'):
+        if parse_version(controller_version) >= parse_version("17.1"):
             # vs_dup_ips = \
             #     [vs for vs in avi_config['VirtualService'] if
             #      vs['vip'][0]['ip_address']['addr'] ==
             #      ip_addr]
             vs_dup_ips = []
-            for vs in avi_config['VirtualService']:
-                vs_ip = vs['vsvip_ref'].split('name=')[1].split('-')[0]
+            for vs in avi_config["VirtualService"]:
+                vs_ip = None
+                if vs.get("vsvip_ref"):
+                    vsvip_name=self.get_name(vs["vsvip_ref"])
+                    if prefix:
+                        #vsvip_name=f5-1.1.1.1-vsvip
+                        vs_ip = vsvip_name.split(prefix+'-')[1].split('-')[0]
+                    else:
+                        #vsvip_name=1.1.1.1-vsvip
+                        vs_ip = vsvip_name.split("-")[0]
+
                 if ip_addr == vs_ip:
                     vs_dup_ips.append(vs)
         else:
-            vs_dup_ips = \
-                [vs for vs in avi_config['VirtualService'] if
-                 vs['ip_address']['addr'] == ip_addr]
+            vs_dup_ips = [vs for vs in avi_config["VirtualService"] if vs.get(
+                "ip_address") and vs["ip_address"]["addr"] == ip_addr]
 
-        if port == 'any':
-            port = '0'
+        if port == "any":
+            port = "0"
         if isinstance(port, str) and (not port.isdigit()):
             port = self.get_port_by_protocol(port)
         # Port is None then skip vs
         if not port:
             LOG.debug("Skipped:Port not supported %s" % str(parts[1]))
             return None, None, None, None
+
         if int(port) > 0:
             for vs in vs_dup_ips:
                 service_updated = self.update_service(port, vs, enable_ssl)
-                if service_updated == 'duplicate_ip_port':
-                    LOG.debug('Skipped: Duplicate IP-Port for vs %s', vs_name)
-                    return None, None, None, None
-                if service_updated:
-                    break
-            services_obj = [{'port': port, 'enable_ssl': enable_ssl}]
+                if service_updated == "duplicate_ip_port":
+                    dup_vs_protocol=self.get_protocol_of_vs(vs.get("network_profile_ref"),avi_config)
+                    if protocol == dup_vs_protocol:
+                        LOG.debug("Skipped: Duplicate Protocol for vs %s", vs_name)
+                        return None, None, None, None
+                    else:
+                        service_updated = True
+
+            services_obj = [{"port": port, "enable_ssl": enable_ssl}]
+
         else:
             used_ports = []
             for vs in vs_dup_ips:
-                for service in vs['services']:
-                    if service.get('port_range_end', None):
-                        used_ports.extend(range(
-                            int(service['port']),
-                            int(service['port_range_end']) + 1
-                        ))
+                for service in vs["services"]:
+                    if service.get("port_range_end", None):
+                        used_ports.extend(
+                            range(int(service["port"]), int(service["port_range_end"]) + 1))
                     else:
-                        used_ports.append(int(service['port']))
-            if used_ports and min(used_ports) == 1 and max(used_ports) == 65535:
-                LOG.debug('Skipped: Duplicate IP-Port for vs %s', vs_name)
+                        used_ports.append(int(service["port"]))
+            if used_ports and min(used_ports) == 1 and max(
+                    used_ports) == 65535:
+                LOG.debug("Skipped: Duplicate IP-Port for vs %s", vs_name)
                 return None, None, None, None
             if used_ports:
                 services_obj = []
                 if conv_const.PORT_END not in used_ports:
                     used_ports.append(conv_const.PORT_END + 1)
                 used_ports = sorted(used_ports, key=int)
                 start = conv_const.PORT_START
@@ -585,54 +629,58 @@
                     if start == used_ports[i]:
                         start += 1
                         continue
                     end = int(used_ports[i]) - 1
                     if end < start:
                         start += 1
                         continue
-                    services_obj.append({'port': start,
-                                         'port_range_end': end,
-                                         'enable_ssl': enable_ssl})
+                    services_obj.append(
+                        {"port": start, "port_range_end": end, "enable_ssl": enable_ssl})
                     start = int(used_ports[i]) + 1
             else:
-                services_obj = [
-                    {'port': 1, 'port_range_end': conv_const.PORT_END,
-                     'enable_ssl': enable_ssl}]
+                services_obj = [{"port": 1,
+                                 "port_range_end": conv_const.PORT_END,
+                                 "enable_ssl": enable_ssl}]
         # Getting vrf ref
         if vrf:
             self.add_vrf(avi_config, vrf, cloud_name)
 
-        vrf_config = avi_config['VrfContext']
-        vrf_ref = self.get_vrf_context_ref(destination, vrf_config,
-                                           'virtual service', vs_name,
-                                           cloud_name)
+        vrf_config = avi_config["VrfContext"]
+        vrf_ref = self.get_vrf_context_ref(
+            destination,
+            vrf_config,
+            "virtual service",
+            vs_name,
+            cloud_name)
+
         if input_vrf:
-            vrf_ref = self.get_object_ref(input_vrf, 'vrfcontext',
-                                          cloud_name=cloud_name)
+            vrf_ref = self.get_object_ref(
+                input_vrf, "vrfcontext", cloud_name=cloud_name)
         if not vrf_ref:
-            vrf_ref = self.get_object_ref('global', 'vrfcontext',
-                                          cloud_name=cloud_name)
-
+            vrf_ref = self.get_object_ref(
+                "global", "vrfcontext", cloud_name=cloud_name)
         updated_vsvip_ref = None
-        if parse_version(controller_version) >= parse_version('17.1'):
+        if parse_version(controller_version) >= parse_version("17.1"):
             vs_vip_name = self.create_update_vsvip(
-                ip_addr, avi_config['VsVip'],
-                self.get_object_ref(tenant_name, 'tenant'),
-                self.get_object_ref(cloud_name, 'cloud', tenant=tenant_name),
+                ip_addr,
+                avi_config["VsVip"],
+                self.get_object_ref(tenant_name, "tenant"),
+                self.get_object_ref(cloud_name, "cloud", tenant=tenant_name),
                 prefix,
-                vrf_ref)
-            if vs_vip_name == '':
-                updated_vsvip_ref = ''
+                vrf_ref,
+            )
+            if vs_vip_name == "":
+                updated_vsvip_ref = ""
             else:
-                updated_vsvip_ref = self.get_object_ref(vs_vip_name, 'vsvip',
-                                                        tenant_name, cloud_name)
+                updated_vsvip_ref = self.get_object_ref(
+                    vs_vip_name, "vsvip", tenant_name, cloud_name)
         return services_obj, ip_addr, updated_vsvip_ref, vrf_ref
 
-    def clone_pool(self, pool_name, clone_for, avi_pool_list, is_vs,
-                   tenant=None):
+    def clone_pool(self, pool_name, clone_for,
+                   avi_pool_list, is_vs, tenant=None):
         """
         If pool is shared with other VS pool is cloned for other VS as Avi dose
         not support shared pools with new pool name as <pool_name>-<vs_name>
         :param pool_name: Name of the pool to be cloned
         :param clone_for: Name of the VS for pool to be cloned
         :param avi_pool_list: new pool to be added to this list
         :param is_vs: True if this cloning is for VS
@@ -646,89 +694,102 @@
                 new_pool = copy.deepcopy(pool)
                 break
         if new_pool:
             if pool_name in used_pool:
                 used_pool[pool_name] += 1
             else:
                 used_pool[pool_name] = 1
-            LOG.debug('Cloning Pool for %s', clone_for)
+            LOG.debug("Cloning Pool for %s", clone_for)
             new_pool["name"] = '{}-{}'.format(pool_name, used_pool[pool_name])
             if tenant:
-                new_pool["tenant_ref"] = self.get_object_ref(tenant, 'tenant')
+                new_pool["tenant_ref"] = self.get_object_ref(tenant, "tenant")
             if is_vs:
                 # removing config added from VS config to pool
                 new_pool["application_persistence_profile_ref"] = None
                 new_pool["ssl_profile_ref"] = None
                 new_pool["ssl_key_and_certificate_ref"] = None
                 new_pool["pki_profile_ref"] = None
             avi_pool_list.append(new_pool)
             pool_ref = new_pool["name"]
-            LOG.debug("Cloned pool successfully %s for %s " % (
-                new_pool["name"], clone_for))
+            LOG.debug(
+                "Cloned pool successfully %s for %s ",
+                new_pool["name"], clone_for)
             return pool_ref
 
-    def remove_https_mon_from_pool(self, avi_config, pool_ref, tenant, sysdict):
-        pool = [p for p in avi_config['Pool'] if p['name'] == pool_ref]
+    def remove_https_mon_from_pool(
+            self, avi_config, pool_ref, tenant, sysdict):
+        pool = [p for p in avi_config["Pool"] if p["name"] == pool_ref]
         if pool:
-            hm_refs = pool[0].get('health_monitor_refs', [])
+            hm_refs = pool[0].get("health_monitor_refs", [])
             for hm_ref in hm_refs:
-                hm = [h for h in (sysdict['HealthMonitor'] + avi_config[
-                    'HealthMonitor']) if
-                      self.get_object_ref(
-                          h['name'], 'healthmonitor', tenant=tenant) == hm_ref]
-                if hm and hm[0]['type'] == 'HEALTH_MONITOR_HTTPS':
-                    if hm[0].get("ssl_attributes", None) and not hm[0]['ssl_attributes'].get("ssl_profile_ref", ""):
-                        pool[0]['health_monitor_refs'].remove(hm_ref)
+                hm = [
+                    h for h in (
+                        sysdict["HealthMonitor"] +
+                        avi_config["HealthMonitor"]) if self.get_object_ref(
+                        h["name"],
+                        "healthmonitor",
+                        tenant=tenant) == hm_ref]
+                if hm and hm[0]["type"] == "HEALTH_MONITOR_HTTPS":
+                    if hm[0].get(
+                            "ssl_attributes",
+                            None) and not hm[0]["ssl_attributes"].get(
+                            "ssl_profile_ref",
+                            ""):
+                        pool[0]["health_monitor_refs"].remove(hm_ref)
                         LOG.warning(
                             'Skipping %s this reference from %s pool '
                             'because of health monitor type is HTTPS and VS '
                             'has no ssl profile.'
                             % (hm_ref, pool_ref))
 
     def remove_http_mon_from_pool(self, avi_config, pool_ref, tenant, sysdict):
-        pool = [p for p in avi_config['Pool'] if p['name'] == pool_ref]
+        pool = [p for p in avi_config["Pool"] if p["name"] == pool_ref]
         if pool:
-            hm_refs = pool[0].get('health_monitor_refs', [])
+            hm_refs = pool[0].get("health_monitor_refs", [])
             for hm_ref in hm_refs:
-                hm = [h for h in (sysdict['HealthMonitor'] + avi_config[
-                    'HealthMonitor']) if
-                      self.get_object_ref(
-                          h['name'], 'healthmonitor', tenant=tenant) == hm_ref]
+                hm = [
+                    h for h in (
+                        sysdict["HealthMonitor"] +
+                        avi_config["HealthMonitor"]) if self.get_object_ref(
+                        h["name"],
+                        "healthmonitor",
+                        tenant=tenant) == hm_ref]
 
-                if hm and hm[0]['type'] == 'HEALTH_MONITOR_HTTP':
-                    pool[0]['health_monitor_refs'].remove(hm_ref)
+                if hm and hm[0]["type"] == "HEALTH_MONITOR_HTTP":
+                    pool[0]["health_monitor_refs"].remove(hm_ref)
                     LOG.warning(
-                        'Skipping %s this reference from %s pool because of'
-                        ' health monitor type is HTTPS and VS has no ssl '
-                        'profile.' % (hm_ref, pool_ref))
-
-    def remove_https_mon_from_pool_group(self, avi_config, poolgroup_ref,
-                                         tenant, sysdict):
-        poolgroup = [p for p in avi_config['PoolGroup'] if self.get_object_ref(
-            p['name'], 'poolgroup', tenant=tenant) == poolgroup_ref]
+                        "Skipping %s this reference from %s pool because of"
+                        " health monitor type is HTTPS and VS has no ssl "
+                        "profile.", hm_ref, pool_ref
+                    )
+
+    def remove_https_mon_from_pool_group(
+            self, avi_config, poolgroup_ref, tenant, sysdict):
+        poolgroup = [p for p in avi_config["PoolGroup"] if self.get_object_ref(
+            p["name"], "poolgroup", tenant=tenant) == poolgroup_ref]
         if poolgroup:
-            pool_members = [p['pool_ref'] for p in poolgroup[0]['members']]
+            pool_members = [p["pool_ref"] for p in poolgroup[0]["members"]]
             for pool_ref in pool_members:
                 pool_ref = self.get_name(pool_ref)
-                self.remove_https_mon_from_pool(avi_config, pool_ref, tenant,
-                                                sysdict)
+                self.remove_https_mon_from_pool(
+                    avi_config, pool_ref, tenant, sysdict)
 
-    def remove_http_mon_from_pool_group(self, avi_config, poolgroup_ref, tenant,
-                                        sysdict):
-        poolgroup = [p for p in avi_config['PoolGroup'] if self.get_object_ref(
-            p['name'], 'poolgroup', tenant=tenant) == poolgroup_ref]
+    def remove_http_mon_from_pool_group(
+            self, avi_config, poolgroup_ref, tenant, sysdict):
+        poolgroup = [p for p in avi_config["PoolGroup"] if self.get_object_ref(
+            p["name"], "poolgroup", tenant=tenant) == poolgroup_ref]
         if poolgroup:
-            pool_members = [p['pool_ref'] for p in poolgroup[0]['members']]
+            pool_members = [p["pool_ref"] for p in poolgroup[0]["members"]]
             for pool_ref in pool_members:
                 pool_name = self.get_name(pool_ref)
                 self.remove_http_mon_from_pool(
                     avi_config, pool_name, tenant, sysdict)
 
-    def add_ssl_to_pool(self, avi_pool_list, pool_ref, pool_ssl_profiles,
-                        tenant='admin'):
+    def add_ssl_to_pool(self, avi_pool_list, pool_ref,
+                        pool_ssl_profiles, tenant="admin"):
         """
         F5 serverside SSL need to be added to pool if VS contains serverside SSL
         profile this method add that profile to pool
         :param avi_pool_list: List of pools to search pool object
         :param pool_ref: name of the pool
         :param pool_ssl_profiles: ssl profiles to be added to pool
         :param tenant: tenant name
@@ -736,40 +797,47 @@
         for pool in avi_pool_list:
             if pool_ref == pool["name"]:
                 if pool_ssl_profiles["profile"]:
                     pool["ssl_profile_ref"] = pool_ssl_profiles["profile"]
                 if pool_ssl_profiles["pki"]:
                     pool["pki_profile_ref"] = pool_ssl_profiles["pki"]
                 if pool_ssl_profiles["cert"]:
-                    pool["ssl_key_and_certificate_ref"] = pool_ssl_profiles[
-                        "cert"]
+                    pool["ssl_key_and_certificate_ref"] = pool_ssl_profiles["cert"]
 
-    def add_ssl_to_pool_group(self, avi_config, pool_group_ref, ssl_pool,
-                              tenant_ref):
+    def add_ssl_to_pool_group(
+            self, avi_config, pool_group_ref, ssl_pool, tenant_ref):
         """
 
         :param avi_config:
         :param pool_group_ref:
         :param ssl_pool:
         :param tenant_ref:
         :return:
         """
-        pool_group = [obj for obj in avi_config['PoolGroup']
-                      if obj['name'] == pool_group_ref]
+        pool_group = [obj for obj in avi_config["PoolGroup"]
+                      if obj["name"] == pool_group_ref]
         if pool_group:
             pool_group = pool_group[0]
-            for member in pool_group['members']:
-                pool_name = self.get_name(member['pool_ref'])
+            for member in pool_group["members"]:
+                pool_name = self.get_name(member["pool_ref"])
                 self.add_ssl_to_pool(
-                    avi_config['Pool'], pool_name, ssl_pool, tenant_ref)
+                    avi_config["Pool"], pool_name, ssl_pool, tenant_ref)
 
-    def update_pool_for_persist(self, avi_pool_list, pool_ref, persist_profile,
-                                hash_profiles, persist_config, tenant,
-                                merge_object_mapping, syspersist,
-                                app_prof_type):
+    def update_pool_for_persist(
+        self,
+        avi_pool_list,
+        pool_ref,
+        persist_profile,
+        hash_profiles,
+        persist_config,
+        tenant,
+        merge_object_mapping,
+        syspersist,
+        app_prof_type,
+    ):
         """
         Updates pool for persistence profile assigned in F5 VS config
         :param avi_pool_list: List of all converted pool objects to avi config
         :param pool_ref: pool name to be updated
         :param persist_profile: persistence profile to be added to pool
         :param hash_profiles: list of profile name for which pool's lb algorithm
         updated to hash
@@ -784,63 +852,76 @@
         persist_type = None
         pool_obj = [pool for pool in avi_pool_list if pool["name"] == pool_ref]
         if not pool_obj:
             LOG.error("Pool %s not found to add profile %s" %
                       (pool_ref, persist_profile))
             return False, None
         pool_obj = pool_obj[0]
-        persist_profile_obj = \
-            [ob for ob in syspersist if ob['name'] ==
-             merge_object_mapping['app_per_profile'].get(persist_profile)] or \
-            [obj for obj in persist_config if (
-                    obj["name"] == persist_profile or persist_profile
-                    in obj.get("dup_of", []))]
+        persist_profile_obj = [
+            ob for ob in syspersist if ob["name"] ==
+            merge_object_mapping["app_per_profile"].get(persist_profile)] or [
+            obj for obj in persist_config if (
+                obj["name"] == persist_profile or persist_profile in obj.get(
+                    "dup_of", []))]
         persist_ref_key = "application_persistence_profile_ref"
         if persist_profile_obj:
-            if app_prof_type == 'APPLICATION_PROFILE_TYPE_L4' and (
-                    persist_profile_obj[0]['persistence_type'] !=
-                    'PERSISTENCE_TYPE_CLIENT_IP_ADDRESS'):
+            if app_prof_type == "APPLICATION_PROFILE_TYPE_L4" and (
+                    persist_profile_obj[0]["persistence_type"] != "PERSISTENCE_TYPE_CLIENT_IP_ADDRESS"):
                 pool_obj[persist_ref_key] = self.get_object_ref(
-                                                'System-Persistence-Client-IP',
-                                                'applicationpersistenceprofile')
-                persist_type = 'PERSISTENCE_TYPE_CLIENT_IP_ADDRESS'
-                LOG.debug("Defaulted to Client IP persistence profile for '%s' "
-                          "Pool in VS of L4 app type " % pool_ref)
+                    "System-Persistence-Client-IP", "applicationpersistenceprofile")
+                persist_type = "PERSISTENCE_TYPE_CLIENT_IP_ADDRESS"
+                LOG.debug(
+                    "Defaulted to Client IP persistence profile for '%s' "
+                    "Pool in VS of L4 app type ",
+                    pool_ref)
             else:
-                obj_tenant = persist_profile_obj[0]['tenant_ref']
-                pool_obj[persist_ref_key] = \
-                    self.get_object_ref(
-                        persist_profile_obj[0]['name'],
-                        'applicationpersistenceprofile',
-                        tenant=self.get_name(obj_tenant))
-                persist_type = persist_profile_obj[0]['persistence_type']
+                obj_tenant = persist_profile_obj[0]["tenant_ref"]
+                pool_obj[persist_ref_key] = self.get_object_ref(
+                    persist_profile_obj[0]["name"],
+                    "applicationpersistenceprofile",
+                    tenant=self.get_name(obj_tenant))
+                persist_type = persist_profile_obj[0]["persistence_type"]
         elif persist_profile == "hash" or persist_profile in hash_profiles:
             del pool_obj["lb_algorithm"]
             hash_algorithm = "LB_ALGORITHM_CONSISTENT_HASH_SOURCE_IP_ADDRESS"
             pool_obj["lb_algorithm_hash"] = hash_algorithm
         else:
             pool_updated = False
         return pool_updated, persist_type
 
     def update_pool_group_for_persist(
-            self, avi_config, pool_ref, persist_profile, hash_profiles,
-            persist_config, tenant, merge_object_mapping, syspersist,
+            self,
+            avi_config,
+            pool_ref,
+            persist_profile,
+            hash_profiles,
+            persist_config,
+            tenant,
+            merge_object_mapping,
+            syspersist,
             app_prof_type):
         pool_group_updated = True
         persist_type = None
-        pool_group = [obj for obj in avi_config['PoolGroup']
-                      if obj['name'] == pool_ref]
+        pool_group = [obj for obj in avi_config["PoolGroup"]
+                      if obj["name"] == pool_ref]
         if pool_group:
             pool_group = pool_group[0]
-            for member in pool_group['members']:
-                pool_name = self.get_name(member['pool_ref'])
+            for member in pool_group["members"]:
+                pool_name = self.get_name(member["pool_ref"])
                 pool_updated, persist_type = self.update_pool_for_persist(
-                    avi_config['Pool'], pool_name, persist_profile,
-                    hash_profiles, persist_config, tenant, merge_object_mapping,
-                    syspersist, app_prof_type)
+                    avi_config["Pool"],
+                    pool_name,
+                    persist_profile,
+                    hash_profiles,
+                    persist_config,
+                    tenant,
+                    merge_object_mapping,
+                    syspersist,
+                    app_prof_type,
+                )
                 if not pool_updated:
                     pool_group_updated = False
         return pool_group_updated, persist_type
 
     def update_pool_for_fallback(self, host, avi_pool_list, pool_ref):
         """
         Update pool for fallback host config
@@ -848,216 +929,194 @@
         :param avi_pool_list: List of all converted pools
         :param pool_ref: Name of the pool for which config is to be added
         """
         pool_obj = [pool for pool in avi_pool_list if pool["name"] == pool_ref]
         if pool_obj:
             pool_obj = pool_obj[0]
             fail_action = {
-                "redirect":
-                    {
-                        "status_code": "HTTP_REDIRECT_STATUS_CODE_302",
-                        "host": host,
-                        "protocol": "HTTPS"
-                    },
-                "type": "FAIL_ACTION_HTTP_REDIRECT"
+                "redirect": {
+                    "status_code": "HTTP_REDIRECT_STATUS_CODE_302",
+                    "host": host,
+                    "protocol": "HTTPS"},
+                "type": "FAIL_ACTION_HTTP_REDIRECT",
             }
             pool_obj["fail_action"] = fail_action
 
     def get_snat_list_for_vs(self, snat_pool):
         """
         Converts the f5 snat pool config object to Avi snat list
         :param snat_pool: f5 snat pool config
         :return: Avi snat list
         """
         snat_list = []
         members = snat_pool.get("members")
         ips = []
         if isinstance(members, dict):
-            ips = members.keys() + members.values()
+            ips = list(members.keys()) + list(members.values())
         elif isinstance(members, str):
             ips = [members]
         ips = [ip for ip in ips if ip]
         for ip in ips:
             # Removed unwanted string from ip address
-            if '/' in ip or '%' in ip:
-                ip = ip.split('/')[-1]
-                ip = ip.split('%')[-2]
-            snat_obj = {
-                "type": "V4",
-                "addr": ip
-            }
+            if "/" in ip:
+                ip = ip.split("/")[-1]
+            if "%" in ip:
+                ip = ip.split("%")[-2]
+            snat_obj = {"type": "V4", "addr": ip}
             snat_list.append(snat_obj)
         return snat_list
 
     def cleanup_config(self, avi_config):
         self.remove_dup_key(avi_config["SSLKeyAndCertificate"])
         self.remove_dup_key(avi_config["ApplicationProfile"])
         self.remove_dup_key(avi_config["NetworkProfile"])
         self.remove_dup_key(avi_config["SSLProfile"])
         self.remove_dup_key(avi_config["PKIProfile"])
         self.remove_dup_key(avi_config["ApplicationPersistenceProfile"])
         self.remove_dup_key(avi_config["HealthMonitor"])
         self.remove_dup_key(avi_config["IpAddrGroup"])
-        avi_config.pop('hash_algorithm', [])
-        avi_config.pop('OneConnect', [])
-        avi_config.pop('UnsupportedProfiles', [])
-        for profile in avi_config['ApplicationProfile']:
-            profile.pop('HTTPPolicySet', None)
-            profile.pop('realm', [])
-            profile.pop('fallback_host', [])
-        for profile in avi_config.get('PKIProfile', []):
-            profile.pop('mode', None)
-        for profile in avi_config.get('SSLProfile', []):
-            profile.pop('cert_name', None)
-        if 'Tenant' in avi_config:
-            for tenant in avi_config['Tenant']:
-                if tenant['name'] == 'admin':
-                    avi_config['Tenant'].remove(tenant)
-
+        avi_config.pop("hash_algorithm", [])
+        avi_config.pop("OneConnect", [])
+        avi_config.pop("UnsupportedProfiles", [])
+        for profile in avi_config["ApplicationProfile"]:
+            profile.pop("HTTPPolicySet", None)
+            profile.pop("realm", [])
+            profile.pop("fallback_host", [])
+        for profile in avi_config.get("PKIProfile", []):
+            profile.pop("mode", None)
+        for profile in avi_config.get("SSLProfile", []):
+            profile.pop("cert_name", None)
+        if "Tenant" in avi_config:
+            for tenant in avi_config["Tenant"]:
+                if tenant["name"] == "admin":
+                    avi_config["Tenant"].remove(tenant)
 
     def create_hdr_erase_rule(self, name, hdr_name, rule_index):
         return self.create_header_rule(
             name, hdr_name, "HTTP_REMOVE_HDR", None, rule_index)
 
     def create_hdr_insert_rule(self, name, hdr_name, val, rule_index):
         return self.create_header_rule(
             name, hdr_name, "HTTP_ADD_HDR", val.strip(), rule_index)
 
-    def create_header_rule(self, name, hdr_name, action, val,
-                           rule_index):
-        rule = {
-            "name": name,
-            "index": rule_index,
-            "hdr_action": [
-                {
-                    "action": action,
-                    "hdr": {
-                        "name": hdr_name.strip(),
-                        "value": {
-                            "val": val
-                        }
-                    }
-                }
-            ]
-        }
+    def create_header_rule(self, name, hdr_name, action, val, rule_index):
+        rule = {"name": name, "index": rule_index, "hdr_action": [
+            {"action": action, "hdr": {"name": hdr_name.strip(), "value": {"val": val}}}], }
         return rule
 
     def create_network_security_rule(self, name, ip, mask, tenant):
-        if '%' in ip:
-            ip = ip.split('%')[0]
-        rule = {
-            "name": name,
-            "tenant_ref": self.get_object_ref(tenant, 'tenant'),
-            "rules": [
-                {
-                    "index": 1,
-                    "enable": True,
-                    "name": "Rule 1",
-                    "age": 0,
-                    "action": "NETWORK_SECURITY_POLICY_ACTION_TYPE_DENY",
-                    "match": {
-                        "client_ip": {
-                            "prefixes": [
-                                {
-                                    "ip_addr": {
-                                        "type": "V4",
-                                        "addr": ip
-                                    },
-                                    "mask": mask
-                                }
-                            ],
-                            "match_criteria": "IS_NOT_IN"
-                        }
-                    },
-                    "log": False
+        if "%" in ip:
+            ip = ip.split("%")[0]
+        rule = {"name": name,
+                "tenant_ref": self.get_object_ref(tenant,
+                                                  "tenant"),
+                "rules": [{"index": 1,
+                           "enable": True,
+                           "name": "Rule 1",
+                           "age": 0,
+                           "action": "NETWORK_SECURITY_POLICY_ACTION_TYPE_DENY",
+                           "match": {"client_ip": {"prefixes": [{"ip_addr": {"type": "V4",
+                                                                             "addr": ip},
+                                                                 "mask": mask}],
+                                                   "match_criteria": "IS_NOT_IN"}},
+                           "log": False,
+                           }],
                 }
-            ]
-        }
         return rule
 
-    def add_vrf(self,  avi_config, vrf, cloud_ref):
+    def add_vrf(self, avi_config, vrf, cloud_ref):
         vrf_name = 'vrf-%s' % vrf
-        vrf_list = avi_config['VrfContext']
-        vrf_obj = [obj for obj in vrf_list if obj['name'] == vrf_name]
+        vrf_list = avi_config["VrfContext"]
+        vrf_obj = [obj for obj in vrf_list if obj["name"] == vrf_name]
         if not vrf_obj:
             vrf_obj = {
                 "name": vrf_name,
                 "system_default": False,
-                "cloud_ref": self.get_object_ref(cloud_ref, 'cloud'),
-                "tenant_ref": self.get_object_ref('admin', 'tenant')
+                "cloud_ref": self.get_object_ref(cloud_ref, "cloud"),
+                "tenant_ref": self.get_object_ref("admin", "tenant"),
             }
-            if vrf_name == 'global':
-                vrf_obj['system_default'] = True
+            if vrf_name == "global":
+                vrf_obj["system_default"] = True
             vrf_list.append(vrf_obj)
 
-
     def get_app_profile_type(self, profile_name, avi_config):
-        profiles = avi_config.get('ApplicationProfile', [])
+        profiles = avi_config.get("ApplicationProfile", [])
         # Called tenant method to get object name
         profile_name = self.get_tenant_ref(profile_name)[1]
-        profile = [obj for obj in profiles if obj['name'] == profile_name]
+        profile = [obj for obj in profiles if obj["name"] == profile_name]
         if profile:
-            return profile[0]['type']
-        else:
-            return 'APPLICATION_PROFILE_TYPE_HTTP'
+            return profile[0]["type"]
 
-    def update_pool_for_service_port(self, pool_list, pool_name, hm_list,
-                                     sys_hm_list):
+        return "APPLICATION_PROFILE_TYPE_HTTP"
+
+    def update_pool_for_service_port(
+            self, pool_list, pool_name, hm_list, sys_hm_list):
         rem_hm = []
-        pool = [obj for obj in pool_list if obj['name'] == pool_name]
+        pool = [obj for obj in pool_list if obj["name"] == pool_name]
         if pool:
-            pool[0]['use_service_port'] = True
+            pool[0]["use_service_port"] = True
             # Checking monitor ports if use_service_port is true
-            if pool[0].get('health_monitor_refs'):
-                for hm in pool[0]['health_monitor_refs']:
+            if pool[0].get("health_monitor_refs"):
+                for hm in pool[0]["health_monitor_refs"]:
                     hm_name = self.get_name(hm)
-                    hm_ob = [ob for ob in (hm_list + sys_hm_list) if
-                             ob['name'] == hm_name]
-                    if hm_ob and (not hm_ob[0].get('monitor_port')):
+                    hm_ob = [
+                        ob for ob in (
+                            hm_list +
+                            sys_hm_list) if ob["name"] == hm_name]
+                    if hm_ob and (not hm_ob[0].get("monitor_port")):
                         rem_hm.append(hm)
-                        LOG.debug("Removing monitor reference of %s from pool"
-                                  " %s as 'use_service_port' is true but "
-                                  "monitor has no port", hm_name,
-                                  pool_name)
+                        LOG.debug(
+                            "Removing monitor reference of %s from pool"
+                            " %s as 'use_service_port' is true but "
+                            "monitor has no port", hm_name, pool_name, )
                 if rem_hm:
-                    pool[0]['health_monitor_refs'] = [
-                        h_monitor for h_monitor in pool[0]
-                        ['health_monitor_refs'] if h_monitor not in rem_hm]
+                    pool[0]["health_monitor_refs"] = [h_monitor
+                                                      for h_monitor in pool[0]["health_monitor_refs"]
+                                                      if h_monitor not in rem_hm]
 
                     rem_hm = [self.get_name(hmonitor) for hmonitor in rem_hm]
-                    csv_row = [cl for cl in csv_writer_dict_list if cl[
-                               'F5 type'] == 'pool' and self.get_tenant_ref(
-                        cl['F5 ID'])[1] == pool_name]
+                    csv_row = [cl for cl in csv_writer_dict_list if cl["F5 type"] ==
+                               "pool" and self.get_tenant_ref(cl["F5 ID"])[1] == pool_name]
                     if csv_row:
-                        if csv_row[0]['Skipped settings'] in ('[]', ''):
-                            csv_row[0]['Skipped settings'] = str([{
-                                                            'monitor': rem_hm}])
+                        if csv_row[0]["Skipped settings"] in ("[]", ""):
+                            csv_row[0]["Skipped settings"] = str(
+                                [{"monitor": rem_hm}])
                         else:
-                            init_val = eval(csv_row[0]['Skipped settings'])
+                            init_val = eval(csv_row[0]["Skipped settings"])
                             if not isinstance(init_val, list):
                                 init_val = [init_val]
                             mon_val = [
-                                val['monitor'].extend(rem_hm) for val in
-                                init_val if isinstance(val, dict) and
-                                'monitor' in val]
+                                val["monitor"].extend(rem_hm) for val in init_val if isinstance(
+                                    val, dict) and "monitor" in val]
                             if bool(mon_val):
-                                csv_row[0]['Skipped settings'] = str(init_val)
+                                csv_row[0]["Skipped settings"] = str(init_val)
                             else:
-                                init_val.append({'monitor': rem_hm})
-                                csv_row[0]['Skipped settings'] = str(init_val)
-                        csv_row[0]['Status'] = conv_const.STATUS_PARTIAL
-                        csv_row[0]['Avi Object'] = str({'pools': pool})
+                                init_val.append({"monitor": rem_hm})
+                                csv_row[0]["Skipped settings"] = str(init_val)
+                        csv_row[0]["Status"] = conv_const.STATUS_PARTIAL
+                        csv_row[0]["Avi Object"] = str({"pools": pool})
 
     def rreplace(self, s, old, new, occurrence):
         li = s.rsplit(old, occurrence)
         return new.join(li)
 
-    def clone_pool_if_shared(self, ref, avi_config, vs_name, tenant, p_tenant,
-                             persist_type, controller_version, app_prof_ref,
-                             sysdict, cloud_name='Default-Cloud', prefix=None):
+    def clone_pool_if_shared(
+        self,
+        ref,
+        avi_config,
+        vs_name,
+        tenant,
+        p_tenant,
+        persist_type,
+        controller_version,
+        app_prof_ref,
+        sysdict,
+        cloud_name="Default-Cloud",
+        prefix=None,
+    ):
         """
         clones pool or pool group if its shard between multiple VS or partitions
         in F5
         :param ref: reference of pool or pool group
         :param avi_config: Avi configuration cloned pool or pool groups to be
         added
         :param vs_name: Name of the vs to be added
@@ -1071,169 +1130,195 @@
         :param prefix:
         :return:
         """
         is_pool_group = False
         pool_group_obj = None
         # Added prefix for objects
         if prefix:
-            ref = prefix + '-' + ref
+            ref = prefix + "-" + ref
         # Search the pool or pool group with name in avi config for the same
         # tenant as VS
-        pool_obj = [pool for pool in avi_config['Pool'] if pool['name'] == ref
-                    and pool['tenant_ref'] == self.get_object_ref(tenant,
-                    'tenant')]
+        pool_obj = [pool for pool in avi_config["Pool"] if pool["name"] ==
+                    ref and pool["tenant_ref"] == self.get_object_ref(tenant, "tenant")]
         pool_per_ref = pool_obj[0].get(
-            'application_persistence_profile_ref') if pool_obj else None
+            "application_persistence_profile_ref") if pool_obj else None
         pool_per_name = self.get_name(pool_per_ref) if pool_per_ref else None
-        pool_per_types = [obj['persistence_type'] for obj in (avi_config[
-                          'ApplicationPersistenceProfile'] + sysdict[
-                          'ApplicationPersistenceProfile']) if obj['name'] ==
-                          pool_per_name] if pool_per_name else []
+        pool_per_types = (
+            [
+                obj["persistence_type"]
+                for obj in (avi_config["ApplicationPersistenceProfile"] + sysdict["ApplicationPersistenceProfile"])
+                if obj["name"] == pool_per_name
+            ]
+            if pool_per_name
+            else []
+        )
         pool_per_type = pool_per_types[0] if pool_per_types else None
         if not pool_obj:
-            pool_group_obj = [pool for pool in avi_config['PoolGroup']
-                              if pool['name'] == ref and
-                              pool['tenant_ref'] == self.get_object_ref(
-                    tenant, 'tenant')]
+            pool_group_obj = [
+                pool
+                for pool in avi_config["PoolGroup"]
+                if pool["name"] == ref and pool["tenant_ref"] == self.get_object_ref(tenant, "tenant")
+            ]
         if pool_group_obj:
             is_pool_group = True
         if p_tenant:
-            shared_vs = [obj for obj in avi_config['VirtualService']
-                         if obj.get("pool_ref", "") == self.get_object_ref(
-                    ref, 'pool', tenant=p_tenant, cloud_name=cloud_name)]
+            shared_vs = [
+                obj for obj in avi_config["VirtualService"] if obj.get(
+                    "pool_ref",
+                    "") == self.get_object_ref(
+                    ref,
+                    "pool",
+                    tenant=p_tenant,
+                    cloud_name=cloud_name)]
             if not shared_vs:
-                shared_vs = [obj for obj in avi_config['VirtualService']
-                             if obj.get("pool_group_ref", "") ==
-                             self.get_object_ref(
-                                 ref, 'poolgroup', tenant=p_tenant,
-                                 cloud_name=cloud_name)]
+                shared_vs = [
+                    obj for obj in avi_config["VirtualService"] if obj.get(
+                        "pool_group_ref",
+                        "") == self.get_object_ref(
+                        ref,
+                        "poolgroup",
+                        tenant=p_tenant,
+                        cloud_name=cloud_name)]
         else:
-            shared_vs = [obj for obj in avi_config['VirtualService']
-                         if obj.get("pool_ref", "") == self.get_object_ref(
-                    ref, 'pool', tenant=tenant, cloud_name=cloud_name)]
+            shared_vs = [
+                obj for obj in avi_config["VirtualService"] if obj.get(
+                    "pool_ref", "") == self.get_object_ref(
+                    ref, "pool", tenant=tenant, cloud_name=cloud_name)]
             if not shared_vs:
-                shared_vs = [obj for obj in avi_config['VirtualService']
-                             if obj.get("pool_group_ref", "") ==
-                             self.get_object_ref(
-                                 ref, 'poolgroup', tenant=tenant,
-                                 cloud_name=cloud_name)]
+                shared_vs = [
+                    obj for obj in avi_config["VirtualService"] if obj.get(
+                        "pool_group_ref",
+                        "") == self.get_object_ref(
+                        ref,
+                        "poolgroup",
+                        tenant=tenant,
+                        cloud_name=cloud_name)]
         if not tenant == p_tenant:
             if is_pool_group:
-                ref = self.clone_pool_group(ref, vs_name, avi_config, True,
-                                            tenant, cloud_name=cloud_name)
+                ref = self.clone_pool_group(
+                    ref, vs_name, avi_config, True, tenant, cloud_name=cloud_name)
             else:
-                ref = self.clone_pool(ref, vs_name, avi_config['Pool'],
-                                      True, tenant)
+                ref = self.clone_pool(
+                    ref, vs_name, avi_config["Pool"], True, tenant)
         if shared_vs:
             if is_pool_group:
-                ref = self.clone_pool_group(ref, vs_name, avi_config, True,
-                                            tenant, cloud_name=cloud_name)
+                ref = self.clone_pool_group(
+                    ref, vs_name, avi_config, True, tenant, cloud_name=cloud_name)
             else:
-                shared_appref = shared_vs[0].get('application_profile_ref')
+                shared_appref = shared_vs[0].get("application_profile_ref")
                 shared_apptype = None
                 if shared_appref:
                     shared_appname = self.get_name(shared_appref)
-                    shared_appobjs = [ob for ob in (avi_config[
-                                      'ApplicationProfile'] + sysdict[
-                                      'ApplicationProfile']) if ob['name'] ==
-                                      shared_appname]
+                    shared_appobjs = [
+                        ob for ob in (
+                            avi_config["ApplicationProfile"] +
+                            sysdict["ApplicationProfile"]) if ob["name"] == shared_appname]
                     shared_appobj = shared_appobjs[0] if shared_appobjs else {}
-                    shared_apptype = shared_appobj['type'] if shared_appobj \
-                        else None
+                    shared_apptype = shared_appobj["type"] if shared_appobj else None
                 app_prof_name = self.get_name(app_prof_ref)
-                app_prof_objs = [appob for appob in (avi_config[
-                                 'ApplicationProfile'] + sysdict[
-                                 'ApplicationProfile']) if appob['name'] ==
-                                 app_prof_name]
+                app_prof_objs = [
+                    appob for appob in (
+                        avi_config["ApplicationProfile"] +
+                        sysdict["ApplicationProfile"]) if appob["name"] == app_prof_name]
                 app_prof_obj = app_prof_objs[0] if app_prof_objs else {}
-                app_prof_type = app_prof_obj['type'] if app_prof_obj else None
+                app_prof_type = app_prof_obj["type"] if app_prof_obj else None
 
                 if self.is_pool_clone_criteria(
-                        controller_version, app_prof_type, shared_apptype,
-                        persist_type, pool_per_type, shared_appobj,
+                        controller_version,
+                        app_prof_type,
+                        shared_apptype,
+                        persist_type,
+                        pool_per_type,
+                        shared_appobj,
                         app_prof_obj):
-                    LOG.debug('Cloned the pool %s for VS %s', ref, vs_name)
-                    ref = self.clone_pool(ref, vs_name, avi_config['Pool'],
-                                          True, tenant)
+                    LOG.debug("Cloned the pool %s for VS %s", ref, vs_name)
+                    ref = self.clone_pool(
+                        ref, vs_name, avi_config["Pool"], True, tenant)
                 else:
                     LOG.debug("Shared pool %s for VS %s", ref, vs_name)
 
         return ref, is_pool_group
 
-    def is_pool_clone_criteria(self, controller_version, app_prof_type,
-                               shared_apptype, persist_type, pool_per_type,
-                               shared_appobj, app_prof_obj):
-        if parse_version(controller_version) < parse_version(
-           '17.1.6') or app_prof_type != 'APPLICATION_PROFILE_TYPE_HTTP' \
-           or shared_apptype != app_prof_type or (
-                persist_type != None and persist_type !=
-                'PERSISTENCE_TYPE_HTTP_COOKIE') or (
-                pool_per_type != None and pool_per_type !=
-                'PERSISTENCE_TYPE_HTTP_COOKIE') or (
-                shared_appobj.get('http_profile', {}).get(
-                    'connection_multiplexing_enabled') != app_prof_obj.get(
-                    'http_profile', {}).get('connection_multiplexing_enabled') or (
-                shared_appobj.get('http_profile', {}).get(
-                    'cache_config') != app_prof_obj.get(
-                    'http_profile', {}).get('cache_config'))):
+    def is_pool_clone_criteria(
+            self,
+            controller_version,
+            app_prof_type,
+            shared_apptype,
+            persist_type,
+            pool_per_type,
+            shared_appobj,
+            app_prof_obj):
+        if (
+            parse_version(controller_version) < parse_version("17.1.6")
+            or app_prof_type != "APPLICATION_PROFILE_TYPE_HTTP"
+            or shared_apptype != app_prof_type
+            or (persist_type is not None and persist_type != "PERSISTENCE_TYPE_HTTP_COOKIE")
+            or (pool_per_type is not None and pool_per_type != "PERSISTENCE_TYPE_HTTP_COOKIE")
+            or (
+                shared_appobj.get("http_profile", {}).get(
+                    "connection_multiplexing_enabled")
+                != app_prof_obj.get("http_profile", {}).get("connection_multiplexing_enabled")
+                or (shared_appobj.get("http_profile", {}).get("cache_config") != app_prof_obj.get("http_profile", {}).get("cache_config"))
+            )
+        ):
             return True
-        else:
-            return False
 
-    def clone_pool_group(self, pool_group_name, clone_for, avi_config, is_vs,
-                         tenant='admin', cloud_name='Default-Cloud'):
+        return False
+
+    def clone_pool_group(self, pool_group_name, clone_for, avi_config,
+                         is_vs, tenant="admin", cloud_name="Default-Cloud"):
         """
         If pool is shared with other VS pool is cloned for other VS as Avi dose
         not support shared pools with new pool name as <pool_name>-<vs_name>
         :param pool_group_name: Name of the pool group to be cloned
         :param clone_for: Name of the object/entity for pool group to be cloned
         :param avi_config: new pool to be added to avi config
         :param is_vs: True if clone is called for VS
         :param tenant: if f5 pool is shared across partition then coned for
         tenant
         :param cloud_name:
         :return: new pool group name
         """
         pg_ref = None
         new_pool_group = None
-        for pool_group in avi_config['PoolGroup']:
+        for pool_group in avi_config["PoolGroup"]:
             if pool_group["name"] == pool_group_name:
                 new_pool_group = copy.deepcopy(pool_group)
                 break
         if new_pool_group:
             if pool_group_name in used_pool_groups:
                 used_pool_groups[pool_group_name] += 1
             else:
                 used_pool_groups[pool_group_name] = 1
-            LOG.debug('Cloning pool group for %s', clone_for)
+            LOG.debug("Cloning pool group for %s", clone_for)
             new_pool_group["name"] = '{}-{}'.format(
                 pool_group_name, used_pool_groups[pool_group_name])
+
             pg_ref = new_pool_group["name"]
-            new_pool_group["tenant_ref"] = self.get_object_ref(tenant, 'tenant')
-            avi_config['PoolGroup'].append(new_pool_group)
-            for member in new_pool_group['members']:
-                pool_name = self.get_name(member['pool_ref'])
-                pool_name = self.clone_pool(pool_name, clone_for,
-                                            avi_config['Pool'], is_vs, tenant)
-                member['pool_ref'] = self.get_object_ref(
-                    pool_name, 'pool', tenant=tenant, cloud_name=cloud_name)
+            new_pool_group["tenant_ref"] = self.get_object_ref(
+                tenant, "tenant")
+            avi_config["PoolGroup"].append(new_pool_group)
+            for member in new_pool_group["members"]:
+                pool_name = self.get_name(member["pool_ref"])
+                pool_name = self.clone_pool(
+                    pool_name, clone_for, avi_config["Pool"], is_vs, tenant)
+                member["pool_ref"] = self.get_object_ref(
+                    pool_name, "pool", tenant=tenant, cloud_name=cloud_name)
         return pg_ref
 
     def add_tenants(self, avi_config_dict):
         if tenants:
-            avi_config_dict['Tenant'] = []
+            avi_config_dict["Tenant"] = []
             for tenant in tenants:
-                avi_config_dict['Tenant'].append({
-                    'name': tenant,
-                    'local': True
-                })
+                avi_config_dict["Tenant"].append(
+                    {"name": tenant, "local": True})
 
     def get_cell_format(self, workbook, cell_format_info):
-        format_col = cell_format_info['col']
-        format = workbook.add_format(cell_format_info['fromat'])
+        format_col = cell_format_info["col"]
+        format = workbook.add_format(cell_format_info["fromat"])
         return format_col, format
 
     def write_status_report_and_pivot_table_in_xlsx(
             self, output_dir, report_name, vs_level_status):
         """
         This function defines that add status sheet and pivot table sheet in
         xlsx format
@@ -1242,26 +1327,47 @@
         :param vs_level_status: Flag to include VS wise detailed status or not
         :return: None
         """
         global ppcount
         global ptotal_count
         # List of fieldnames for headers
         if vs_level_status:
-            fieldnames = ['F5 type', 'F5 SubType', 'F5 ID', 'Status',
-                          'Skipped settings', 'Indirect mapping',
-                          'Not Applicable', 'User Ignored',
-                          'Skipped for defaults', 'Complexity Level',
-                          'VS Reference', 'Overall skipped settings',
-                          'Avi Object', 'Needs Review']
+            fieldnames = [
+                "F5 type",
+                "F5 SubType",
+                "F5 ID",
+                "Status",
+                "Skipped settings",
+                "Indirect mapping",
+                "Not Applicable",
+                "User Ignored",
+                "Skipped for defaults",
+                "Complexity Level",
+                "VS Reference",
+                "Overall skipped settings",
+                "F5 Object",
+                "Avi Object",
+                "Needs Review",
+            ]
         else:
-            fieldnames = ['F5 type', 'F5 SubType', 'F5 ID', 'Status',
-                          'Skipped settings', 'Indirect mapping',
-                          'Not Applicable',
-                          'User Ignored', 'Skipped for defaults',
-                          'Complexity Level', 'Avi Object', 'Needs Review']
+            fieldnames = [
+                "F5 type",
+                "F5 SubType",
+                "F5 ID",
+                "Status",
+                "Skipped settings",
+                "Indirect mapping",
+                "Not Applicable",
+                "User Ignored",
+                "Skipped for defaults",
+                "Complexity Level",
+                "F5 Object",
+                "Avi Object",
+                "Needs Review",
+            ]
 
         # xlsx workbook
         report_path = output_dir + os.path.sep + "%s-ConversionStatus.xlsx" % \
                                                  report_name
         status_wb = Workbook(report_path)
         # xlsx worksheet
         status_ws = status_wb.add_worksheet("Status Sheet")
@@ -1275,249 +1381,272 @@
         for row_data in csv_writer_dict_list:
             ppcount += 1
             for _key, _value in row_data.items():
                 col = fieldnames.index(_key)
                 status_ws.write(row, col, _value)
             # Added call for progress function.
             msg = "excel sheet conversion started..."
-            self.print_progress_bar(ppcount, ptotal_count, msg,
-                                    prefix='Progress', suffix='')
+            self.print_progress_bar(
+                ppcount,
+                ptotal_count,
+                msg,
+                prefix="Progress",
+                suffix="")
             row += 1
         status_wb.close()
         # create dataframe for row list
         df = pandas.DataFrame(csv_writer_dict_list, columns=fieldnames)
         # create pivot table using pandas
-        pivot_table = \
-            pandas.pivot_table(df, index=["Status", "F5 type", "F5 SubType"],
-                               values=[], aggfunc=[len], fill_value=0)
+        pivot_table = pandas.pivot_table(
+            df,
+            index=[
+                "Status",
+                "F5 type",
+                "F5 SubType"],
+            values=[],
+            aggfunc=[len],
+            fill_value=0)
         # create dataframe for pivot table using pandas
         pivot_df = pandas.DataFrame(pivot_table)
-        master_book = \
-            load_workbook(report_path)
-        master_writer = pandas.ExcelWriter(report_path, engine='openpyxl')
-        master_writer.book = master_book
+        main_book = load_workbook(report_path)
+        main_writer = pandas.ExcelWriter(report_path, engine="openpyxl",mode='a')
+        main_writer._book = main_book
         # Add pivot table in Pivot sheet
-        pivot_df.to_excel(master_writer, 'Pivot Sheet')
-        master_writer.save()
+        pivot_df.to_excel(main_writer, "Pivot Sheet")
+        main_writer.close()
 
     def format_string_to_json(self, avi_string):
         """
         This function defines that it convert string into json format to
         convert into dict
         :param avi_string: string to be converted
         :return: Return converted string
         """
-        avi_string = avi_string.split('__/__')[0]
+        avi_string = avi_string.split("__/__")[0]
         return ast.literal_eval(avi_string)
 
     def get_csv_object_list(self, csv_writer_dict_list, command_list):
         """
         This method is used for getting csv object
         :param csv_writer_dict_list: CSV row of object from xlsx report
         :param command_list: List of netscaler commands
         :return: List of CSV rows
         """
 
-        csv_object = [row for row in csv_writer_dict_list if
-                      row['Status'] in [conv_const.STATUS_PARTIAL,
-                                        conv_const.STATUS_SUCCESSFUL] and
-                      '->' not in row['Avi Object'] and
-                      row['F5 type'] in command_list]
+        csv_object = [
+            row
+            for row in csv_writer_dict_list
+            if row["Status"] in [conv_const.STATUS_PARTIAL, conv_const.STATUS_SUCCESSFUL]
+            and "->" not in row["Avi Object"]
+            and row["F5 type"] in command_list
+        ]
         return csv_object
 
     def get_and_update_csv_row(self, csv_object, vs_ref):
         """
         This function defines that update csv row.
         :param csv_object: csv object
         :param vs_ref: Name of VS
         :return: Skipped attribute list
         """
 
-        if 'VS Reference' in csv_object and \
-                vs_ref not in csv_object['VS Reference']:
-            csv_object['VS Reference'] += ',' + vs_ref
+        if "VS Reference" in csv_object and vs_ref not in csv_object["VS Reference"]:
+            csv_object["VS Reference"] += "," + vs_ref
         else:
-            csv_object['VS Reference'] = vs_ref
-        repls = ('[', ''), (']', '')
+            csv_object["VS Reference"] = vs_ref
+        repls = ("[", ""), ("]", "")
         skipped_setting_csv = reduce(
-            lambda a, kv: a.replace(*kv), repls, csv_object['Skipped settings'])
+            lambda a, kv: a.replace(
+                *kv), repls, csv_object["Skipped settings"])
         if skipped_setting_csv:
             return [skipped_setting_csv]
 
-    def get_csv_skipped_list(self, csv_objects, name_of_object, vs_ref,
-                             field_key=None):
+    def get_csv_skipped_list(
+            self, csv_objects, name_of_object, vs_ref, field_key=None):
         """
         This method is used for getting skipped list from vs.
         :param csv_objects: CSV row of object from xlsx report
         :param name_of_object: Name of object
         :param vs_ref: Name of VS
         :param field_key: Key fromm avi json which is specific for object type
         :return: Return skipped attribute list
         """
 
         for csv_object in csv_objects:
-            avi_objects = self.format_string_to_json(csv_object['Avi Object'])
+            avi_objects = self.format_string_to_json(csv_object["Avi Object"])
             if isinstance(avi_objects, dict):
                 avi_objects = [avi_objects]
             if not avi_objects:
                 avi_objects = []
             for avi_object_json in avi_objects:
                 object_found = False
                 if field_key:
-                    if field_key in avi_object_json and 'Duplicate' not in \
-                            avi_object_json[field_key] and (
-                            avi_object_json[field_key]['name'] ==
-                            name_of_object):
+                    if (
+                        field_key in avi_object_json
+                        and "Duplicate" not in avi_object_json[field_key]
+                        and (avi_object_json[field_key]["name"] == name_of_object)
+                    ):
                         object_found = True
                 else:
-                    if avi_object_json.get('name') and \
-                                    avi_object_json['name'] == name_of_object:
+                    if avi_object_json.get(
+                            "name") and avi_object_json["name"] == name_of_object:
                         object_found = True
 
                 if object_found:
                     return self.get_and_update_csv_row(csv_object, vs_ref)
 
-    def get_ssl_profile_skipped(self, profile_csv_list, ssl_profile_ref,
-                                vs_ref):
+    def get_ssl_profile_skipped(
+            self, profile_csv_list, ssl_profile_ref, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param profile_csv_list: List of profile(F5 type) csv rows
         :param ssl_profile_ref: Reference of ssl profile
         :param vs_ref: Name of VS
         :return: ssl profile name and skipped sttribute list
         """
 
         ssl_profile_name = self.get_name(ssl_profile_ref)
         skipped_list = self.get_csv_skipped_list(
-            profile_csv_list, ssl_profile_name, vs_ref, field_key='ssl_profile')
+            profile_csv_list, ssl_profile_name, vs_ref, field_key="ssl_profile")
         return ssl_profile_name, skipped_list
 
-    def get_application_profile_skipped(self, profile_csv_list, app_profile_ref,
-                                        vs_ref):
+    def get_application_profile_skipped(
+            self, profile_csv_list, app_profile_ref, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param profile_csv_list: List of profile(F5 type) csv rows
         :param app_profile_ref: Reference of application profile
         :param vs_ref: Name of VS
         :return: application profile name and skipped sttribute list
         """
 
         app_profile_name = self.get_name(app_profile_ref)
         skipped_list = self.get_csv_skipped_list(
-            profile_csv_list, app_profile_name, vs_ref, field_key='app_profile')
+            profile_csv_list, app_profile_name, vs_ref, field_key="app_profile")
         return app_profile_name, skipped_list
 
-    def get_network_profile_skipped(self, profile_csv_list, network_profile_ref,
-                                    vs_ref):
+    def get_network_profile_skipped(
+            self, profile_csv_list, network_profile_ref, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param profile_csv_list: List of profile(F5 type) csv rows
         :param network_profile_ref: Reference of Network profile
         :param vs_ref: Name of VS
         :return: network profile name and skipped sttribute list
         """
 
         network_profile_name = self.get_name(network_profile_ref)
         skipped_list = self.get_csv_skipped_list(
-            profile_csv_list, network_profile_name, vs_ref,
-            field_key='network_profile')
+            profile_csv_list,
+            network_profile_name,
+            vs_ref,
+            field_key="network_profile")
         return network_profile_name, skipped_list
 
     def get_policy_set_skipped(self, profile_csv_list, policy_set_ref, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param profile_csv_list: List of profile(F5 type) csv rows
         :param policy_set_ref: Reference of policy set
         :param vs_ref: Name of VS
         :return: policy set name and skipped sttribute list
         """
 
         policy_set_name = self.get_name(policy_set_ref)
         skipped_list = self.get_csv_skipped_list(
-            profile_csv_list, policy_set_name, vs_ref, field_key='policy_set')
+            profile_csv_list, policy_set_name, vs_ref, field_key="policy_set")
         return policy_set_name, skipped_list
 
-    def get_app_persistence_profile_skipped(self, csv_writer_dict_list,
-                                            pool_object, vs_ref):
+    def get_app_persistence_profile_skipped(
+            self, csv_writer_dict_list, pool_object, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param csv_writer_dict_list: List of csv rows
         :param pool_object: object of pool
         :param vs_ref: Name of VS
         :return: profile name and skipped attribute list
         """
 
         app_persistence_profile_name = self.get_name(
-            pool_object['application_persistence_profile_ref'])
-        csv_object = self.get_csv_object_list(csv_writer_dict_list,
-                                              ['persistence'])
+            pool_object["application_persistence_profile_ref"])
+        csv_object = self.get_csv_object_list(
+            csv_writer_dict_list, ["persistence"])
         skipped_list = self.get_csv_skipped_list(
-            csv_object, app_persistence_profile_name, vs_ref,
-            field_key='app_per_profile')
+            csv_object,
+            app_persistence_profile_name,
+            vs_ref,
+            field_key="app_per_profile")
         return app_persistence_profile_name, skipped_list
 
     def get_pool_skipped(self, csv_objects, pool_name, vs_ref):
         """
         This functions defines that get the skipped list of CSV row
         :param csv_objects: CSV row of object from xlsx report
         :param pool_name: Name of pool
         :param vs_ref: Name of VS
         :return: Skipped list of csv row
         """
 
         for csv_object in csv_objects:
-            avi_object = self.format_string_to_json(csv_object['Avi Object'])
-            if 'pools' in avi_object:
-                pool_object = [pool for pool in avi_object['pools']
-                               if pool['name'] == pool_name]
+            avi_object = self.format_string_to_json(csv_object["Avi Object"])
+            if "pools" in avi_object:
+                pool_object = [
+                    pool for pool in avi_object["pools"] if pool["name"] == pool_name]
                 if pool_object:
                     return self.get_and_update_csv_row(csv_object, vs_ref)
 
-    def get_pool_skipped_list(self, avi_config, pool_group_name, csv_pool_rows,
-                              csv_writer_dict_list, vs_ref, profile_csv_list):
+    def get_pool_skipped_list(
+            self,
+            avi_config,
+            pool_group_name,
+            csv_pool_rows,
+            csv_writer_dict_list,
+            vs_ref,
+            profile_csv_list):
         """
         This method is used for getting pool skipped list.
         :param avi_config: AVI dict
         :param pool_group_name: Name of Pool group
         :param csv_pool_rows: List of pool(F5 type) csv rows
         :param csv_writer_dict_list: List of F5 csv rows
         :param vs_ref: Name of VS
         :param profile_csv_list: List of profile(F5 type) csv rows
         :return:
         """
 
-        pool_group_objects = [pool_group_object for pool_group_object in
-                              avi_config['PoolGroup'] if
-                              pool_group_object['name']
-                              == pool_group_name]
-        pool_members = pool_group_objects[0]['members']
-        skipped_setting = {
-            'pools': []
-        }
+        pool_group_objects = [pool_group_object for pool_group_object in avi_config["PoolGroup"]
+                              if pool_group_object["name"] == pool_group_name]
+        pool_members = pool_group_objects[0]["members"]
+        skipped_setting = {"pools": []}
         for pool_member in pool_members:
-            pool_name = self.get_name(pool_member['pool_ref'])
+            pool_name = self.get_name(pool_member["pool_ref"])
             self.get_skipped_pool(
-                avi_config, pool_name, csv_pool_rows, csv_writer_dict_list,
-                vs_ref, profile_csv_list, skipped_setting)
-        if skipped_setting['pools']:
+                avi_config,
+                pool_name,
+                csv_pool_rows,
+                csv_writer_dict_list,
+                vs_ref,
+                profile_csv_list,
+                skipped_setting)
+        if skipped_setting["pools"]:
             return skipped_setting
 
     def vs_complexity_level(self):
         """
         This method calculate the complexity of vs.
         :return:
         """
         # Get the VS object list which is having status successful and partial.
-        vs_csv_objects = [row for row in csv_writer_dict_list
-                          if row['Status'] in [conv_const.STATUS_PARTIAL,
-                                               conv_const.STATUS_SUCCESSFUL]
-                          and row['F5 type'] == 'virtual']
+        vs_csv_objects = [
+            row for row in csv_writer_dict_list if row["Status"] in [
+                conv_const.STATUS_PARTIAL,
+                conv_const.STATUS_SUCCESSFUL] and row["F5 type"] == "virtual"]
         for vs_csv_object in vs_csv_objects:
             virtual_service = self.format_string_to_json(
-                vs_csv_object['Avi Object'])
+                vs_csv_object["Avi Object"])
             # Update the complexity level of VS as Basic or Advanced
             self.update_vs_complexity_level(vs_csv_object, virtual_service)
 
     def vs_per_skipped_setting_for_references(self, avi_config):
         """
         This functions defines that Add the skipped setting per VS CSV row
         :param avi_config: this method use avi_config for checking vs skipped
@@ -1526,198 +1655,213 @@
 
         # Get the count of vs fully migrated
         global fully_migrated
         global ptotal_count
         global ppcount
         fully_migrated = 0
         # Get the VS object list which is having status successful and partial.
-        vs_csv_objects = [row for row in csv_writer_dict_list
-                          if row['Status'] in [conv_const.STATUS_PARTIAL,
-                                               conv_const.STATUS_SUCCESSFUL]
-                          and row['F5 type'] == 'virtual']
+        vs_csv_objects = [
+            row for row in csv_writer_dict_list if row["Status"] in [
+                conv_const.STATUS_PARTIAL,
+                conv_const.STATUS_SUCCESSFUL] and row["F5 type"] == "virtual"]
         # Get the list of csv rows which has profile as F5 Type
         profile_csv_list = self.get_csv_object_list(
-            csv_writer_dict_list, ['profile'])
+            csv_writer_dict_list, ["profile"])
         ptotal_count = ptotal_count + len(vs_csv_objects)
         for vs_csv_object in vs_csv_objects:
             ppcount += 1
             skipped_setting = {}
             virtual_service = self.format_string_to_json(
-                vs_csv_object['Avi Object'])
+                vs_csv_object["Avi Object"])
             # Update the complexity level of VS as Basic or Advanced
             self.update_vs_complexity_level(vs_csv_object, virtual_service)
-            vs_ref = virtual_service['name']
-            repls = ('[', ''), (']', '')
+            vs_ref = virtual_service["name"]
+            repls = ("[", ""), ("]", "")
             # Get list of skipped setting attributes
-            skipped_setting_csv = reduce(lambda a, kv: a.replace(*kv), repls,
-                                         vs_csv_object['Skipped settings'])
+            skipped_setting_csv = reduce(lambda a, kv: a.replace(
+                *kv), repls, vs_csv_object["Skipped settings"])
             if skipped_setting_csv:
-                skipped_setting['virtual_service'] = [skipped_setting_csv]
+                skipped_setting["virtual_service"] = [skipped_setting_csv]
             # Get the skipped list for ssl key and cert
-            if 'ssl_key_and_certificate_refs' in virtual_service:
-                for ssl_key_and_certificate_ref in \
-                        virtual_service['ssl_key_and_certificate_refs']:
+            if "ssl_key_and_certificate_refs" in virtual_service:
+                for ssl_key_and_certificate_ref in virtual_service["ssl_key_and_certificate_refs"]:
                     ssl_key_cert = self.get_name(ssl_key_and_certificate_ref)
                     ssl_kc_skip = self.get_csv_skipped_list(
-                        profile_csv_list, ssl_key_cert, vs_ref,
-                        field_key='ssl_cert_key')
+                        profile_csv_list, ssl_key_cert, vs_ref, field_key="ssl_cert_key")
                     if ssl_kc_skip:
-                        skipped_setting['ssl cert key'] = {}
-                        skipped_setting['ssl cert key']['name'] = ssl_key_cert
-                        skipped_setting['ssl cert key'][
-                            'skipped_list'] = ssl_kc_skip
+                        skipped_setting["ssl cert key"] = {}
+                        skipped_setting["ssl cert key"]["name"] = ssl_key_cert
+                        skipped_setting["ssl cert key"]["skipped_list"] = ssl_kc_skip
 
             # Get the skipped list for ssl profile name.
             # Changed ssl profile name to ssl profile ref.
-            if 'ssl_profile_ref' in virtual_service:
+            if "ssl_profile_ref" in virtual_service:
                 name, skipped = self.get_ssl_profile_skipped(
-                    profile_csv_list, virtual_service['ssl_profile_ref'],
-                    vs_ref)
+                    profile_csv_list, virtual_service["ssl_profile_ref"], vs_ref)
                 if skipped:
-                    skipped_setting['ssl profile'] = {}
-                    skipped_setting['ssl profile']['name'] = name
-                    skipped_setting['ssl profile']['skipped_list'] = skipped
+                    skipped_setting["ssl profile"] = {}
+                    skipped_setting["ssl profile"]["name"] = name
+                    skipped_setting["ssl profile"]["skipped_list"] = skipped
             # Get the skipped list for pool group.
-            if 'pool_group_ref' in virtual_service:
+            if "pool_group_ref" in virtual_service:
                 pool_group_name = self.get_name(
-                    virtual_service['pool_group_ref'])
-                csv_pool_rows = self.get_csv_object_list(csv_writer_dict_list,
-                                                         ['pool'])
+                    virtual_service["pool_group_ref"])
+                csv_pool_rows = self.get_csv_object_list(
+                    csv_writer_dict_list, ["pool"])
                 pool_group_skipped_settings = self.get_pool_skipped_list(
-                    avi_config, pool_group_name, csv_pool_rows,
-                    csv_writer_dict_list, vs_ref, profile_csv_list)
+                    avi_config,
+                    pool_group_name,
+                    csv_pool_rows,
+                    csv_writer_dict_list,
+                    vs_ref,
+                    profile_csv_list)
                 if pool_group_skipped_settings:
-                    skipped_setting['Pool Group'] = pool_group_skipped_settings
+                    skipped_setting["Pool Group"] = pool_group_skipped_settings
             # Get the skipped list for pool.
-            if 'pool_ref' in virtual_service:
-                pool_skipped_settings = {'pools': []}
-                pool_name = self.get_name(virtual_service['pool_ref'])
-                csv_pool_rows = self.get_csv_object_list(csv_writer_dict_list,
-                                                         ['pool'])
+            if "pool_ref" in virtual_service:
+                pool_skipped_settings = {"pools": []}
+                pool_name = self.get_name(virtual_service["pool_ref"])
+                csv_pool_rows = self.get_csv_object_list(
+                    csv_writer_dict_list, ["pool"])
                 self.get_skipped_pool(
-                    avi_config, pool_name, csv_pool_rows, csv_writer_dict_list,
-                    vs_ref, profile_csv_list, pool_skipped_settings)
-                if pool_skipped_settings['pools']:
-                    skipped_setting['Pool'] = pool_skipped_settings
+                    avi_config,
+                    pool_name,
+                    csv_pool_rows,
+                    csv_writer_dict_list,
+                    vs_ref,
+                    profile_csv_list,
+                    pool_skipped_settings)
+                if pool_skipped_settings["pools"]:
+                    skipped_setting["Pool"] = pool_skipped_settings
             # Get the skipepd list for http policy.
-            if 'http_policies' in virtual_service:
+            if "http_policies" in virtual_service:
                 policy_csv_list = self.get_csv_object_list(
-                    csv_writer_dict_list, ['policy', 'profile'])
-                for http_ref in virtual_service['http_policies']:
+                    csv_writer_dict_list, ["policy", "profile"])
+                for http_ref in virtual_service["http_policies"]:
                     policy_set_name, skipped_list = self.get_policy_set_skipped(
-                        policy_csv_list, http_ref['http_policy_set_ref'],
-                        vs_ref)
+                        policy_csv_list, http_ref["http_policy_set_ref"], vs_ref)
                     if skipped_list:
-                        skipped_setting['Httppolicy'] = {}
-                        skipped_setting['Httppolicy']['name'] = policy_set_name
-                        skipped_setting['Httppolicy'][
-                            'skipped_list'] = skipped_list
+                        skipped_setting["Httppolicy"] = {}
+                        skipped_setting["Httppolicy"]["name"] = policy_set_name
+                        skipped_setting["Httppolicy"]["skipped_list"] = skipped_list
                     # Get the http policy name
-                    pool_csv_rows = \
-                        self.get_csv_object_list(csv_writer_dict_list, ['pool'])
-                    for each_http_policy in avi_config['HTTPPolicySet']:
-                        if each_http_policy['name'] == policy_set_name and 'http_request_policy' in each_http_policy:
-                            for http_req in each_http_policy[
-                              'http_request_policy']['rules']:
-                                if http_req.get('switching_action', {}):
+                    pool_csv_rows = self.get_csv_object_list(
+                        csv_writer_dict_list, ["pool"])
+                    for each_http_policy in avi_config["HTTPPolicySet"]:
+                        if each_http_policy["name"] == policy_set_name and\
+                                "http_request_policy" in each_http_policy:
+                            for http_req in each_http_policy["http_request_policy"]["rules"]:
+                                if http_req.get("switching_action", {}):
                                     self.get_skip_pools_policy(
-                                        policy_set_name, http_req,
-                                        avi_config, pool_csv_rows, vs_ref,
-                                        profile_csv_list, skipped_setting)
+                                        policy_set_name,
+                                        http_req,
+                                        avi_config,
+                                        pool_csv_rows,
+                                        vs_ref,
+                                        profile_csv_list,
+                                        skipped_setting)
 
             # # Get the skipped list for application_profile_ref.
-            if 'application_profile_ref' in virtual_service and 'admin:System' \
-                    not in virtual_service['application_profile_ref']:
+            if "application_profile_ref" in virtual_service and "admin:System" not in virtual_service[
+                    "application_profile_ref"]:
                 name, skipped = self.get_application_profile_skipped(
-                    profile_csv_list,
-                    virtual_service['application_profile_ref'],
-                    vs_ref)
+                    profile_csv_list, virtual_service["application_profile_ref"], vs_ref)
                 if skipped:
-                    skipped_setting['Application profile'] = {}
-                    skipped_setting['Application profile'][
-                        'name'] = name
-                    skipped_setting['Application profile'][
-                        'skipped_list'] = skipped
+                    skipped_setting["Application profile"] = {}
+                    skipped_setting["Application profile"]["name"] = name
+                    skipped_setting["Application profile"]["skipped_list"] = skipped
             # # Get the skipped list for network profile ref.
-            if 'network_profile_ref' in virtual_service and 'admin:System' \
-                    not in virtual_service['network_profile_ref']:
+            if "network_profile_ref" in virtual_service and "admin:System" not in virtual_service[
+                    "network_profile_ref"]:
                 name, skipped = self.get_network_profile_skipped(
-                    profile_csv_list, virtual_service['network_profile_ref'],
-                    vs_ref)
+                    profile_csv_list, virtual_service["network_profile_ref"], vs_ref)
                 if skipped:
-                    skipped_setting['Network profile'] = {}
-                    skipped_setting['Network profile'][
-                        'name'] = name
-                    skipped_setting['Network profile'][
-                        'skipped_list'] = skipped
+                    skipped_setting["Network profile"] = {}
+                    skipped_setting["Network profile"]["name"] = name
+                    skipped_setting["Network profile"]["skipped_list"] = skipped
             # Update overall skipped setting of VS csv row
             if skipped_setting:
                 vs_csv_object.update(
-                    {'Overall skipped settings': str(skipped_setting)})
+                    {"Overall skipped settings": str(skipped_setting)})
             else:
                 vs_csv_object.update(
-                    {'Overall skipped settings': "FULLY MIGRATION"})
+                    {"Overall skipped settings": "FULLY MIGRATION"})
                 fully_migrated += 1
             # Added call for progress function.
             msg = "excel sheet conversion started..."
-            self.print_progress_bar(ppcount, ptotal_count, msg,
-                                    prefix='Progress', suffix='')
-        csv_objects = [row for row in csv_writer_dict_list
-                       if row['Status'] in [
-                           conv_const.STATUS_PARTIAL,
-                           conv_const.STATUS_SUCCESSFUL]
-                       and row['F5 type'] != 'virtual']
+            self.print_progress_bar(
+                ppcount,
+                ptotal_count,
+                msg,
+                prefix="Progress",
+                suffix="")
+        csv_objects = [
+            row for row in csv_writer_dict_list if row["Status"] in [
+                conv_const.STATUS_PARTIAL,
+                conv_const.STATUS_SUCCESSFUL] and row["F5 type"] != "virtual"]
 
         # Update the vs reference not in used if objects are not attached to
         # VS directly or indirectly
         for row in csv_objects:
-            if 'VS Reference' not in row or row['VS Reference'] == '':
-                row['VS Reference'] = conv_const.STATUS_NOT_IN_USE
+            if "VS Reference" not in row or row["VS Reference"] == "":
+                row["VS Reference"] = conv_const.STATUS_NOT_IN_USE
 
-    def create_update_vsvip(self, vip, vsvip_config, tenant_ref, cloud_ref,
-                            prefix, vrf_ref):
+    def create_update_vsvip(self, vip, vsvip_config,
+                            tenant_ref, cloud_ref, prefix, vrf_ref):
         """
         This functions defines that create or update VSVIP object.
         :param vip: vip of VS
         :param vsvip_config: List of vs object
         :param tenant_ref: tenant reference
         :param cloud_ref: cloud reference
         :param prefix: Name prefix
         :param vrf_ref: VRF reference
         :return: None
         """
 
-        name = vip + '-vsvip'
+        name = vip + "-vsvip"
         # Added prefix for objects
         if prefix:
             name = '%s-%s' % (prefix, name)
         # Get the exsting vsvip object list if present
-        vsvip = [vip_obj for vip_obj in vsvip_config if vip_obj['name'] == name
-                 and vip_obj.get('vrf_context_ref') == vrf_ref]
+        vsvip = [vip_obj for vip_obj in vsvip_config if vip_obj["name"]
+                 == name and vip_obj.get("vrf_context_ref") == vrf_ref]
         if vsvip:
-            diff_ten = [vips for vips in vsvip if vips['tenant_ref'] !=
-                        tenant_ref]
+            diff_ten = [
+                vips for vips in vsvip if vips["tenant_ref"] != tenant_ref]
             if diff_ten:
-                LOG.debug('VsVip %s is repeated with vrf %s but different '
-                          'tenant %s', name, self.get_name(vrf_ref) if vrf_ref
-                          else 'None', self.get_name(tenant_ref))
-                name = ''
+                LOG.debug(
+                    "VsVip %s is repeated with vrf %s but different "
+                    "tenant %s",
+                    name,
+                    self.get_name(vrf_ref) if vrf_ref else "None",
+                    self.get_name(tenant_ref),
+                )
+                name = ""
         # If VSVIP object not present then create new VSVIP object.
         else:
+            vip_ip_type = "V4"
+            ip_address_feild = "ip_address"
+            matches = re.findall(
+                "^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$", vip)
+            if not matches or vip == "0.0.0.0":
+                vip_ip_type = "V6"
+                ip_address_feild = "ip6_address"
             vsvip_object = {
                 "name": name,
                 "tenant_ref": tenant_ref,
                 "cloud_ref": cloud_ref,
                 "vip": [
                     {
                         "vip_id": "0",
-                        "ip_address": {
-                            "type": "V4",
-                            "addr": vip
-                        }
+                        ip_address_feild: {
+                            #  "type": "V4",
+                            "addr": vip,
+                            "type": vip_ip_type,
+                        },
                     }
                 ],
             }
             if vrf_ref:
                 vsvip_object["vrf_context_ref"] = vrf_ref
             vsvip_config.append(vsvip_object)
 
@@ -1726,260 +1870,264 @@
     def update_static_route(self, route):
         """
         This function defines that convert convert static routes
         :param route: Object of net static route
         :return: Return static route object
         """
         msg = None
-        next_hop_ip = route.get('gw', route.get('gateway'))
-        if next_hop_ip and '%' in next_hop_ip:
-            next_hop_ip = next_hop_ip.split('%')[0]
+        next_hop_ip = route.get("gw", route.get("gateway"))
+        if next_hop_ip and "%" in next_hop_ip:
+            next_hop_ip = next_hop_ip.split("%")[0]
 
-        ip_addr = route.get('network', None)
+        ip_addr = route.get("network", None)
         vrf = None
         # Get the mask from subnet mask
-        if ip_addr and '%' in ip_addr:
-            ip_addr, vrf = ip_addr.split('%')
-            vrf = 'vrf-' + (
-                    '/' in vrf and vrf.split('/')[0] or vrf) if vrf else None
-        if ip_addr and '/' in ip_addr:
-            ip_addr = ip_addr.split('/')[0]
+        if ip_addr and "%" in ip_addr:
+            ip_addr, vrf = ip_addr.split("%")
+            vrf = "vrf-" + ("/" in vrf and vrf.split("/")
+                            [0] or vrf) if vrf else None
+        if ip_addr and "/" in ip_addr:
+            ip_addr = ip_addr.split("/")[0]
 
         # set subnet mask to 0.0.0.0 if its equal to default
-        if not ip_addr or ip_addr == 'default':
-            ip_addr = '0.0.0.0'
+        if not ip_addr or ip_addr == "default":
+            ip_addr = "0.0.0.0"
 
-        mask = sum([bin(int(x)).count('1') for x in ip_addr.split('.')])
+        mask = sum([bin(int(x)).count("1") for x in ip_addr.split(".")])
         if next_hop_ip and ip_addr:
             static_route = {
                 "route_id": 1,
                 "prefix": {
                     "ip_addr": {
                         "type": "V4",
-                        "addr": ip_addr
-                    },
-                    "mask": mask
-                },
+                        "addr": ip_addr},
+                    "mask": mask},
                 "next_hop": {
                     "type": "V4",
-                    "addr": next_hop_ip
-                }
+                    "addr": next_hop_ip},
             }
             return static_route, vrf, msg
         else:
             msg = "Next hop ip is not present" if not next_hop_ip else (
                 "Ip Address is not present")
             LOG.debug(msg)
             return None, None, msg
 
-    def get_vrf_context_ref(self, f5_entity_mem, vrf_config, entity_string,
-                            entity_name, cloud):
+    def get_vrf_context_ref(self, f5_entity_mem, vrf_config,
+                            entity_string, entity_name, cloud):
         """
         Searches for vrf context refs in converted pool config
         :param f5_entity_mem: f5 entity or object like pool
         :param vrf_config: converted vrf config
         :param entity_string: entity string
         :param entity_name: name of f5 entity
         :param cloud: name of the cloud
         :return: returns list of vrf refs assigned to entity in avi config
         """
         vrf_ref = None
-        f5_entity_mem = ':' in f5_entity_mem and f5_entity_mem.split(':')[0] \
-                        or f5_entity_mem if f5_entity_mem else None
-        vrf = 'vrf-' + f5_entity_mem.split('%')[1] \
-            if f5_entity_mem and '%' in f5_entity_mem else None
+        f5_entity_mem = ":" in f5_entity_mem and f5_entity_mem.split(
+            ":")[0] or f5_entity_mem if f5_entity_mem else None
+        vrf = "vrf-" + \
+            f5_entity_mem.split(
+                "%")[1] if f5_entity_mem and "%" in f5_entity_mem else None
         vrf_obj = [obj for obj in vrf_config if vrf and obj["name"] == vrf]
         if vrf_obj:
             vrf_ref = self.get_object_ref(
-                vrf_obj[0]['name'], 'vrfcontext', cloud_name=cloud)
+                vrf_obj[0]["name"], "vrfcontext", cloud_name=cloud)
         else:
-            LOG.warning("VRF not found for %s %s" % (entity_string,
-                                                     entity_name))
+            LOG.warning(
+                "VRF not found for %s %s",
+                entity_string, entity_name)
         return vrf_ref
 
     def net_to_static_route(self, f5_config, avi_config):
         """
         This method converts the net route to static routes and updates the
         VrfContext objects
         :param f5_config: parsed f5 config
         :param avi_config: converted config in avi
         :return:
         """
-        net_config = f5_config.get('route', {})
+        net_config = f5_config.get("route", {})
         avi_vrf = avi_config["VrfContext"]
         # Convert net static route to vrf static route
         for key, route in net_config.items():
-            LOG.debug("Starting conversion from net route to static for '%s'"
-                      % key)
+            LOG.debug(
+                "Starting conversion from net route to static for '%s'",
+                key)
             static_route, vrf, msg = self.update_static_route(route)
             if static_route:
                 for obj in avi_vrf:
-                    if obj['name'] == vrf or (not vrf and obj['name'] ==
-                       'global'):
-                        if obj.get('static_routes'):
-                            rid = max(
-                                [i['route_id'] for i in obj['static_routes']])
-                            static_route['route_id'] = rid + 1
-                            obj['static_routes'].append(static_route)
+                    if obj["name"] == vrf or (
+                            not vrf and obj["name"] == "global"):
+                        if obj.get("static_routes"):
+                            rid = max([i["route_id"]
+                                      for i in obj["static_routes"]])
+                            static_route["route_id"] = rid + 1
+                            obj["static_routes"].append(static_route)
                         else:
-                            obj['static_routes'] = [static_route]
-                LOG.debug("Conversion completed for route '%s'" % key)
-                self.add_conv_status(
-                    'route', None, key,
-                    {'status': conv_const.STATUS_SUCCESSFUL},
-                    [{'route': static_route}]
-                )
+                            obj["static_routes"] = [static_route]
+                LOG.debug("Conversion completed for route '%s'", key)
+                self.add_conv_status("route",
+                                     None,
+                                     key,
+                                     {"status": conv_const.STATUS_SUCCESSFUL},
+                                     [{"route": static_route}])
             else:
-                LOG.debug("Conversion unsuccessful for route '%s'" % key)
-                self.add_conv_status('route', None, key,
-                                     {'status': conv_const.STATUS_SKIPPED}, msg)
+                LOG.debug("Conversion unsuccessful for route '%s'", key)
+                self.add_conv_status(
+                    "route", None, key, {
+                        "status": conv_const.STATUS_SKIPPED}, msg)
 
     def update_monitor_ssl_ref(self, avi_dict, merge_obj_dict, sysdict):
         """
         This method updates the first ssl profile reference from merge
         perspective in monitors, which get attached at the time of creation
         :param avi_dict: avi configuration dict
         :param merge_obj_dict: dict having merge objects
         :param sysdict: system object dicts
         :return:
         """
-        for obj in avi_dict['HealthMonitor']:
-            obj_ref = obj.get('https_monitor', {}).get('ssl_attributes',
-                                                       {}).get(
-                'ssl_profile_ref')
+        for obj in avi_dict["HealthMonitor"]:
+            obj_ref = obj.get(
+                "https_monitor",
+                {}).get(
+                "ssl_attributes",
+                {}).get("ssl_profile_ref")
             if obj_ref:
                 name = self.get_name(obj_ref)
-                if name in merge_obj_dict['ssl_profile']:
-                    updated_name = merge_obj_dict['ssl_profile'][name]
-                    prof = [ob for ob in (sysdict['SSLProfile'] + avi_dict[
-                        'SSLProfile']) if ob['name'] == updated_name]
-                    tenant = self.get_name(prof[0]['tenant_ref'])
+                if name in merge_obj_dict["ssl_profile"]:
+                    updated_name = merge_obj_dict["ssl_profile"][name]
+                    prof = [
+                        ob for ob in (
+                            sysdict["SSLProfile"] +
+                            avi_dict["SSLProfile"]) if ob["name"] == updated_name]
+                    tenant = self.get_name(prof[0]["tenant_ref"])
                     type_cons = conv_const.OBJECT_TYPE_SSL_PROFILE
-                    obj['https_monitor']['ssl_attributes']['ssl_profile_ref'] =\
-                        self.get_object_ref(updated_name, type_cons, tenant)
+                    obj["https_monitor"]["ssl_attributes"]["ssl_profile_ref"] = self.get_object_ref(
+                        updated_name, type_cons, tenant)
 
     def update_app_profile(self, aviconfig, sys_dict):
         """
         This method updates the application profile to http when there are
         multiple services to a L4 app VS in which one of them is ssl enabled
         :param aviconfig: avi config dict
         :param sys_dict: system config dict
         :return:
         """
-        for vs_obj in aviconfig['VirtualService']:
-            if vs_obj.get('services') and len(vs_obj['services']) > 1 and \
-                    vs_obj.get('application_profile_ref'):
-                app_profile = self.get_name(vs_obj['application_profile_ref'])
-                app_profile_obj = [app for app in sys_dict[
-                        'ApplicationProfile'] + aviconfig['ApplicationProfile']
-                                   if app['name'] == app_profile]
-                if app_profile_obj and app_profile_obj[0]['type'] == \
-                        'APPLICATION_PROFILE_TYPE_L4':
-                    for service in vs_obj['services']:
-                        if service['enable_ssl']:
-                            vs_obj['application_profile_ref'] = \
-                                self.get_object_ref(
-                                'System-HTTP',
-                                conv_const.OBJECT_TYPE_APPLICATION_PROFILE)
-                            LOG.debug('Changed the application profile '
-                                      'reference from L4 to System-HTTP')
-                            if vs_obj.get('network_profile_ref'):
+        for vs_obj in aviconfig["VirtualService"]:
+            if vs_obj.get("services") and len(
+                    vs_obj["services"]) > 1 and vs_obj.get("application_profile_ref"):
+                app_profile = self.get_name(vs_obj["application_profile_ref"])
+                app_profile_obj = [
+                    app for app in sys_dict["ApplicationProfile"] +
+                    aviconfig["ApplicationProfile"] if app["name"] == app_profile]
+                if app_profile_obj and app_profile_obj[0]["type"] == "APPLICATION_PROFILE_TYPE_L4":
+                    for service in vs_obj["services"]:
+                        if service["enable_ssl"]:
+                            vs_obj["application_profile_ref"] = self.get_object_ref(
+                                "System-HTTP", conv_const.OBJECT_TYPE_APPLICATION_PROFILE
+                            )
+                            LOG.debug(
+                                "Changed the application profile "
+                                "reference from L4 to System-HTTP")
+                            if vs_obj.get("network_profile_ref"):
                                 self.update_nw_profile(
                                     vs_obj, sys_dict, aviconfig)
                             break
 
     def update_nw_profile(self, vs_obj, sys_dict, aviconfig):
-        nw_profile = self.get_name(vs_obj['network_profile_ref'])
-        nw_profile_obj = [nw for nw in sys_dict['NetworkProfile'] +
-                          aviconfig['NetworkProfile'] if nw['name'] ==
-                          nw_profile]
-        if nw_profile_obj and nw_profile_obj[0]['profile']['type'] != \
-                'PROTOCOL_TYPE_TCP_PROXY':
+        nw_profile = self.get_name(vs_obj["network_profile_ref"])
+        nw_profile_obj = [
+            nw for nw in sys_dict["NetworkProfile"] +
+            aviconfig["NetworkProfile"] if nw["name"] == nw_profile]
+        if nw_profile_obj and nw_profile_obj[0]["profile"]["type"] != "PROTOCOL_TYPE_TCP_PROXY":
             LOG.debug(
-                'Changed the network profile reference from %s to '
-                'TCP-Proxy for VS %s' % (nw_profile_obj[0]['profile']['type'],
-                                         vs_obj['name']))
-            vs_obj['network_profile_ref'] = self.get_object_ref(
-                'System-TCP-Proxy', conv_const.OBJECT_TYPE_NETWORK_PROFILE)
+                "Changed the network profile reference from %s to "
+                "TCP-Proxy for VS %s", nw_profile_obj[0]
+                ["profile"]["type"], vs_obj["name"]
+            )
+            vs_obj["network_profile_ref"] = self.get_object_ref(
+                "System-TCP-Proxy", conv_const.OBJECT_TYPE_NETWORK_PROFILE)
 
     def set_pool_group_vrf(self, pool_ref, vrf_ref, avi_config):
         """
         This method will set vrf_ref for all pools in poolgroup
         :param pool_ref: pool group name
         :param vrf_ref: vrf ref of VS
         :param avi_config: avi config json
         :return:
         """
-        pg_obj = [poolgrp for poolgrp in avi_config['PoolGroup'] if
-                  poolgrp['name'] == pool_ref]
+        pg_obj = [poolgrp for poolgrp in avi_config["PoolGroup"]
+                  if poolgrp["name"] == pool_ref]
         if pg_obj:
-            for member in pg_obj[0]['members']:
-                poolname = self.get_name(member.get('pool_ref'))
+            for member in pg_obj[0]["members"]:
+                poolname = self.get_name(member.get("pool_ref"))
                 self.set_pool_vrf(poolname, vrf_ref, avi_config)
 
     def set_pool_vrf(self, pool_ref, vrf_ref, avi_config):
         """
         This method will set vrf_ref for pool
         :param pool_ref: pool name
         :param vrf_ref: vrf ref of VS
         :param avi_config: avi config json
         :return:
         """
-        pool_obj = [pool for pool in avi_config['Pool'] if pool['name'] ==
-                    pool_ref]
+        pool_obj = [pool for pool in avi_config["Pool"]
+                    if pool["name"] == pool_ref]
         if pool_obj:
-            pool_obj[0]['vrf_ref'] = vrf_ref
+            pool_obj[0]["vrf_ref"] = vrf_ref
             LOG.debug("Added vrf ref to the pool %s", pool_ref)
 
-    def clone_http_policy_set(self, policy, vs_name, avi_config, tenant_name,
-                              cloud_name):
+    def clone_http_policy_set(self, policy, vs_name,
+                              avi_config, tenant_name, cloud_name):
         """
         This function clones policy which is shared with more than one vs
         :param policy: name of policy
         :param vs_name: vs name
         :param avi_config: avi config dict
         :param tenant_name: tenant
         :param cloud_name: cloud
         :return: cloned policy object
         """
 
-        policy_name = policy['name']
+        policy_name = policy["name"]
         clone_policy = copy.deepcopy(policy)
-        LOG.debug("cloning policy %s" % clone_policy)
-        if 'http_request_policy' in clone_policy:
-            for rule in clone_policy['http_request_policy']['rules']:
-                if 'switching_action' in rule:
-                    if rule['switching_action'].get('pool_group_ref'):
+        LOG.debug("cloning policy %s", clone_policy)
+        if "http_request_policy" in clone_policy:
+            for rule in clone_policy["http_request_policy"]["rules"]:
+                if "switching_action" in rule:
+                    if rule["switching_action"].get("pool_group_ref"):
                         pool_group_ref = self.get_name(
-                            rule['switching_action']['pool_group_ref'])
+                            rule["switching_action"]["pool_group_ref"])
                         pool_group_ref = self.clone_pool_group(
-                            pool_group_ref, policy_name, avi_config, False,
-                            tenant_name, cloud_name)
+                            pool_group_ref, policy_name, avi_config, False, tenant_name, cloud_name)
                         if pool_group_ref:
                             updated_pool_group_ref = self.get_object_ref(
-                                pool_group_ref,
-                                conv_const.OBJECT_TYPE_POOL_GROUP,
-                                tenant_name, cloud_name)
-                            rule['switching_action']['pool_group_ref'] = \
-                                updated_pool_group_ref
-                    elif rule['switching_action'].get('pool_ref'):
+                                pool_group_ref, conv_const.OBJECT_TYPE_POOL_GROUP, tenant_name, cloud_name)
+                            rule["switching_action"]["pool_group_ref"] = updated_pool_group_ref
+                    elif rule["switching_action"].get("pool_ref"):
                         pool_ref = self.get_name(
-                            rule['switching_action']['pool_ref'])
+                            rule["switching_action"]["pool_ref"])
                         if pool_ref:
                             updated_pool_ref = self.get_object_ref(
-                                pool_ref, conv_const.OBJECT_TYPE_POOL,
-                                tenant_name, cloud_name)
-                            rule['switching_action']['pool_ref'] = \
-                                updated_pool_ref
+                                pool_ref, conv_const.OBJECT_TYPE_POOL, tenant_name, cloud_name)
+                            rule["switching_action"]["pool_ref"] = updated_pool_ref
         clone_policy['name'] += '-%s-clone' % vs_name
         return clone_policy
 
-    def get_skipped_pool(self, avi_config, pool_name, pool_csv_rows,
-                         csv_writer_dict_list, vs_ref, profile_csv_list,
-                         skipped_setting):
+    def get_skipped_pool(
+            self,
+            avi_config,
+            pool_name,
+            pool_csv_rows,
+            csv_writer_dict_list,
+            vs_ref,
+            profile_csv_list,
+            skipped_setting):
         """
         This method get the skipped list for pool by going over the
         references attached to it
         :param avi_config: Converted Avi configuration
         :param pool_name: name of the pool
         :param pool_csv_rows:
         :param csv_writer_dict_list: Result report dict
@@ -1987,211 +2135,216 @@
         :param profile_csv_list:
         :param skipped_setting: User defined skipped settings
         :return: skipped setting for pool
         """
         pool_skipped_setting = {}
         skipped_list = self.get_pool_skipped(pool_csv_rows, pool_name, vs_ref)
         pool_object = [pool for pool in avi_config["Pool"]
-                       if pool['name'] == pool_name]
+                       if pool["name"] == pool_name]
         if skipped_list:
-            pool_skipped_setting['pool_name'] = pool_name
-            pool_skipped_setting['pool_skipped_list'] = skipped_list
+            pool_skipped_setting["pool_name"] = pool_name
+            pool_skipped_setting["pool_skipped_list"] = skipped_list
         if pool_object:
-            if 'health_monitor_refs' in pool_object[0]:
+            if "health_monitor_refs" in pool_object[0]:
                 health_monitor_skipped_setting = []
-                for health_monitor_ref in pool_object[0]['health_monitor_refs']:
+                for health_monitor_ref in pool_object[0]["health_monitor_refs"]:
                     health_monitor_ref = self.get_name(health_monitor_ref)
                     monitor_csv_object = self.get_csv_object_list(
-                        csv_writer_dict_list, ['monitor'])
+                        csv_writer_dict_list, ["monitor"])
                     skipped_list = self.get_csv_skipped_list(
-                        monitor_csv_object, health_monitor_ref, vs_ref,
-                        field_key='health_monitor')
+                        monitor_csv_object, health_monitor_ref, vs_ref, field_key="health_monitor")
                     if skipped_list:
                         health_monitor_skipped_setting.append(
-                            {'health_monitor_name': health_monitor_ref,
-                             'monitor_skipped_list': skipped_list})
+                            {"health_monitor_name": health_monitor_ref,
+                                "monitor_skipped_list": skipped_list}
+                        )
                 if health_monitor_skipped_setting:
-                    pool_skipped_setting['pool_name'] = pool_name
-                    pool_skipped_setting['health_monitor'] = \
-                        health_monitor_skipped_setting
-            if 'ssl_key_and_certificate_ref' in pool_object[0] and \
-                    pool_object[0]['ssl_key_and_certificate_ref']:
+                    pool_skipped_setting["pool_name"] = pool_name
+                    pool_skipped_setting["health_monitor"] = health_monitor_skipped_setting
+            if "ssl_key_and_certificate_ref" in pool_object[
+                    0] and pool_object[0]["ssl_key_and_certificate_ref"]:
                 ssl_key_cert = self.get_name(
-                    pool_object[0]['ssl_key_and_certificate_ref'])
+                    pool_object[0]["ssl_key_and_certificate_ref"])
                 sslkc_skip = self.get_csv_skipped_list(
-                    profile_csv_list, ssl_key_cert, vs_ref,
-                    field_key='ssl_cert_key')
+                    profile_csv_list, ssl_key_cert, vs_ref, field_key="ssl_cert_key")
                 if sslkc_skip:
-                    pool_skipped_setting['pool_name'] = pool_name
-                    pool_skipped_setting['ssl_key_and_certificate'] = sslkc_skip
+                    pool_skipped_setting["pool_name"] = pool_name
+                    pool_skipped_setting["ssl_key_and_certificate"] = sslkc_skip
 
-            if 'ssl_profile_ref' in pool_object[0] and \
-                    pool_object[0]['ssl_profile_ref']:
+            if "ssl_profile_ref" in pool_object[0] and pool_object[0]["ssl_profile_ref"]:
                 name, skipped = self.get_ssl_profile_skipped(
-                    profile_csv_list, pool_object[0]['ssl_profile_ref'], vs_ref)
+                    profile_csv_list, pool_object[0]["ssl_profile_ref"], vs_ref)
                 if skipped:
-                    pool_skipped_setting['pool_name'] = pool_name
-                    pool_skipped_setting['ssl profile'] = {}
-                    pool_skipped_setting['ssl profile']['name'] = name
-                    pool_skipped_setting['ssl profile'][
-                        'skipped_list'] = skipped
+                    pool_skipped_setting["pool_name"] = pool_name
+                    pool_skipped_setting["ssl profile"] = {}
+                    pool_skipped_setting["ssl profile"]["name"] = name
+                    pool_skipped_setting["ssl profile"]["skipped_list"] = skipped
 
-            if 'application_persistence_profile_ref' in pool_object[0] and \
-                    pool_object[0]['application_persistence_profile_ref']:
+            if "application_persistence_profile_ref" in pool_object[
+                    0] and pool_object[0]["application_persistence_profile_ref"]:
                 name, skipped = self.get_app_persistence_profile_skipped(
                     csv_writer_dict_list, pool_object[0], vs_ref)
                 if skipped:
-                    pool_skipped_setting['pool_name'] = pool_name
-                    pool_skipped_setting['Application Persistence profile'] = {}
-                    pool_skipped_setting['Application Persistence profile'][
-                        'name'] = name
-                    pool_skipped_setting['Application Persistence profile'][
-                        'skipped_list'] = skipped
+                    pool_skipped_setting["pool_name"] = pool_name
+                    pool_skipped_setting["Application Persistence profile"] = {
+                    }
+                    pool_skipped_setting["Application Persistence profile"]["name"] = name
+                    pool_skipped_setting["Application Persistence profile"]["skipped_list"] = skipped
 
             if pool_skipped_setting:
-                skipped_setting['pools'].append(pool_skipped_setting)
+                skipped_setting["pools"].append(pool_skipped_setting)
 
-    def get_skip_pools_policy(self, policy_set_name, http_req, avi_config,
-                              pool_csv_rows, vs_ref, profile_csv_list,
-                              skipped_setting):
-        if http_req['switching_action'].get('pool_group_ref'):
-            pool_group_name = self.get_name(http_req['switching_action']
-                                            ['pool_group_ref'])
+    def get_skip_pools_policy(
+            self,
+            policy_set_name,
+            http_req,
+            avi_config,
+            pool_csv_rows,
+            vs_ref,
+            profile_csv_list,
+            skipped_setting):
+        if http_req["switching_action"].get("pool_group_ref"):
+            pool_group_name = self.get_name(
+                http_req["switching_action"]["pool_group_ref"])
             pool_group_skipped_settings = self.get_pool_skipped_list(
-                avi_config, pool_group_name, pool_csv_rows,
-                csv_writer_dict_list, vs_ref, profile_csv_list)
+                avi_config,
+                pool_group_name,
+                pool_csv_rows,
+                csv_writer_dict_list,
+                vs_ref,
+                profile_csv_list)
             if pool_group_skipped_settings:
-                if 'Httppolicy' not in skipped_setting:
-                    skipped_setting['Httppolicy'] = {}
-                    skipped_setting['Httppolicy']['name'] = policy_set_name
-                skipped_setting['Httppolicy']['Pool Group'] =\
-                    pool_group_skipped_settings
-        elif http_req['switching_action'].get('pool_ref'):
-            pool_name = self.get_name(http_req['switching_action']['pool_ref'])
-            pool_skipped_settings = {'pools': []}
-            self.get_skipped_pool(avi_config, pool_name, pool_csv_rows,
-                                  csv_writer_dict_list, vs_ref,
-                                  profile_csv_list, pool_skipped_settings)
-            if pool_skipped_settings['pools']:
-                if 'Httppolicy' not in skipped_setting:
-                    skipped_setting['Httppolicy'] = {}
-                    skipped_setting['Httppolicy']['name'] = policy_set_name
-                skipped_setting['Httppolicy']['Pool'] = pool_skipped_settings
+                if "Httppolicy" not in skipped_setting:
+                    skipped_setting["Httppolicy"] = {}
+                    skipped_setting["Httppolicy"]["name"] = policy_set_name
+                skipped_setting["Httppolicy"]["Pool Group"] = pool_group_skipped_settings
+        elif http_req["switching_action"].get("pool_ref"):
+            pool_name = self.get_name(http_req["switching_action"]["pool_ref"])
+            pool_skipped_settings = {"pools": []}
+            self.get_skipped_pool(
+                avi_config,
+                pool_name,
+                pool_csv_rows,
+                csv_writer_dict_list,
+                vs_ref,
+                profile_csv_list,
+                pool_skipped_settings)
+            if pool_skipped_settings["pools"]:
+                if "Httppolicy" not in skipped_setting:
+                    skipped_setting["Httppolicy"] = {}
+                    skipped_setting["Httppolicy"]["name"] = policy_set_name
+                skipped_setting["Httppolicy"]["Pool"] = pool_skipped_settings
 
     def remove_pool_group_vrf(self, pool_ref, avi_config):
         """
         This method will remove vrf_ref for all pools in poolgroup
         :param pool_ref: pool group name
         :param avi_config: avi config json
         :return:
         """
-        pg_obj = [poolgrp for poolgrp in avi_config['PoolGroup'] if
-                  poolgrp['name'] == pool_ref]
+        pg_obj = [poolgrp for poolgrp in avi_config["PoolGroup"]
+                  if poolgrp["name"] == pool_ref]
         if pg_obj:
-            for member in pg_obj[0]['members']:
-                poolname = self.get_name(member.get('pool_ref'))
+            for member in pg_obj[0]["members"]:
+                poolname = self.get_name(member.get("pool_ref"))
                 self.remove_pool_vrf(poolname, avi_config)
 
     def remove_pool_vrf(self, pool_ref, avi_config):
         """
         This method will remove vrf_ref for pool
         :param pool_ref: pool name
         :param avi_config: avi config json
         :return:
         """
-        pool_obj = [pool for pool in avi_config['Pool'] if pool['name'] ==
-                    pool_ref]
-        if pool_obj and pool_obj[0].get('vrf_ref'):
-            pool_obj[0].pop('vrf_ref')
+        pool_obj = [pool for pool in avi_config["Pool"]
+                    if pool["name"] == pool_ref]
+        if pool_obj and pool_obj[0].get("vrf_ref"):
+            pool_obj[0].pop("vrf_ref")
             LOG.debug("Removed vrf ref from the pool %s", pool_ref)
 
     def update_network_profile(self, aviconfig, sys_dict):
         """
         This method updates the network profile to TCP PROXY when VS has HTTP
         application profile
         :param aviconfig: avi config dict
         :param sys_dict: system config dict
         :return:
         """
-        for vs_obj in aviconfig['VirtualService']:
-            if vs_obj.get('application_profile_ref'):
-                app_profile = self.get_name(vs_obj['application_profile_ref'])
-                app_profile_obj = [app for app in sys_dict['ApplicationProfile']
-                                   + aviconfig['ApplicationProfile']
-                                   if app['name'] == app_profile]
+        for vs_obj in aviconfig["VirtualService"]:
+            if vs_obj.get("application_profile_ref"):
+                app_profile = self.get_name(vs_obj["application_profile_ref"])
+                app_profile_obj = [
+                    app for app in sys_dict["ApplicationProfile"] +
+                    aviconfig["ApplicationProfile"] if app["name"] == app_profile]
                 if app_profile_obj and (
-                        app_profile_obj[0]['type'] ==
-                        'APPLICATION_PROFILE_TYPE_HTTP' or app_profile_obj[
-                        0]['name'] == 'System-HTTP'):
-                    if vs_obj.get('network_profile_ref'):
-                        nw_profile = self.get_name(vs_obj[
-                                                       'network_profile_ref'])
-                        nw_profile_obj = [nw for nw in sys_dict[
-                                          'NetworkProfile'] + aviconfig[
-                                          'NetworkProfile'] if
-                                          nw['name'] == nw_profile]
+                        app_profile_obj[0]["type"] ==
+                        "APPLICATION_PROFILE_TYPE_HTTP" or app_profile_obj[0]["name"] == "System-HTTP"):
+                    if vs_obj.get("network_profile_ref"):
+                        nw_profile = self.get_name(
+                            vs_obj["network_profile_ref"])
+                        nw_profile_obj = [
+                            nw for nw in sys_dict["NetworkProfile"] +
+                            aviconfig["NetworkProfile"] if nw["name"] == nw_profile]
                         if nw_profile_obj and (
-                                nw_profile_obj[0]['profile']['type']
-                                != 'PROTOCOL_TYPE_TCP_PROXY'):
+                                nw_profile_obj[0]["profile"]["type"] != "PROTOCOL_TYPE_TCP_PROXY"):
                             LOG.debug(
-                                'Changed the network profile reference from %s '
-                                'to TCP-Proxy as VS %s has HTTP profile',
-                                nw_profile_obj[0]['profile']['type'],
-                                vs_obj['name'])
-                            vs_obj['network_profile_ref'] = \
-                                self.get_object_ref(
-                                    'System-TCP-Proxy',
-                                    conv_const.OBJECT_TYPE_NETWORK_PROFILE)
+                                "Changed the network profile reference from %s "
+                                "to TCP-Proxy as VS %s has HTTP profile",
+                                nw_profile_obj[0]["profile"]["type"],
+                                vs_obj["name"],
+                            )
+                            vs_obj["network_profile_ref"] = self.get_object_ref(
+                                "System-TCP-Proxy", conv_const.OBJECT_TYPE_NETWORK_PROFILE)
 
     def correct_vs_ref(self, avi_config):
         """
         This method corrects the reference of VS to different objects
         :param avi_config: avi configuration dict
         :return:
         """
         global csv_writer_dict_list
         avi_graph = self.make_graph(avi_config)
-        csv_dict_sub = [row for row in csv_writer_dict_list if row[
-                        'F5 type'] != 'virtual' and row['Status'] in
-                        (conv_const.STATUS_PARTIAL,
-                         conv_const.STATUS_SUCCESSFUL)]
+        csv_dict_sub = [
+            row for row in csv_writer_dict_list
+            if row["F5 type"] != "virtual" and
+            row["Status"] in (conv_const.STATUS_PARTIAL, conv_const.STATUS_SUCCESSFUL)]
         for dict_row in csv_dict_sub:
-            obj = dict_row['Avi Object']
+            obj = dict_row["Avi Object"]
             vs = []
-            if obj.startswith('{'):
+            if obj.startswith("{"):
                 obj = eval(obj)
                 for key in obj:
                     for objs in obj[key]:
                         self.add_vs_ref(objs, avi_graph, vs)
-            elif obj.startswith('['):
+            elif obj.startswith("["):
                 obj = eval(obj)
                 for objs in obj:
                     for key in objs:
                         objval = objs[key]
                         self.add_vs_ref(objval, avi_graph, vs)
             if vs:
-                dict_row['VS Reference'] = str(list(set(vs)))
+                dict_row["VS Reference"] = str(list(set(vs)))
             else:
-                dict_row['VS Reference'] = conv_const.STATUS_NOT_IN_USE
+                dict_row["VS Reference"] = conv_const.STATUS_NOT_IN_USE
 
     def add_vs_ref(self, obj, avi_graph, vs):
         """
         Helper method for adding vs ref
         :param obj: object
         :param avi_graph: avi graph
         :param vs: VS list
         :return:
         """
         tmplist = []
 
-        if isinstance(obj, str) and obj.startswith('Duplicate of'):
+        if isinstance(obj, str) and obj.startswith("Duplicate of"):
             obj_name = None
-            LOG.debug("Object has merged: %s" % obj)
+            LOG.debug("Object has merged: %s", obj)
         else:
-            obj_name = obj.get('name', obj.get('hostname'))
+            obj_name = obj.get("name", obj.get("hostname"))
         if obj_name:
             if avi_graph.has_node(obj_name):
                 LOG.debug("Checked predecessor for %s", obj_name)
                 predecessor = list(avi_graph.predecessors(obj_name))
                 if predecessor:
                     self.get_predecessor(predecessor, avi_graph, vs, tmplist)
             else:
@@ -2210,69 +2363,74 @@
         if len(predecessor) > 1:
             for node in predecessor:
                 if node in tmplist:
                     continue
                 nodelist = [node]
                 self.get_predecessor(nodelist, avi_graph, vs, tmplist)
         elif len(predecessor):
-            node_obj = [nod for nod in list(avi_graph.nodes().data()) if
-                        nod[0] == predecessor[0]]
-            if node_obj and (node_obj[0][1]['type'] == 'VS' or 'VS' in node_obj[
-              0][1]['type']):
+            node_obj = [
+                nod for nod in list(
+                    avi_graph.nodes(
+                        data=True)) if nod[0] == predecessor[0]]
+            if node_obj and (node_obj[0][1]["type"] ==
+                             "VS" or "VS" in node_obj[0][1]["type"]):
                 LOG.debug("Predecessor %s found", predecessor[0])
                 vs.extend(predecessor)
             else:
                 tmplist.extend(predecessor)
                 LOG.debug("Checked predecessor for %s", predecessor[0])
                 nodelist = list(avi_graph.predecessors(predecessor[0]))
                 self.get_predecessor(nodelist, avi_graph, vs, tmplist)
         else:
             LOG.debug("No more predecessor")
 
-    def convert_irules(self, vs_ds_rules, rule_config, avi_config, prefix,
-                       vs_name, tenant, reuse_http_policy):
-        vs_ds = list()
-        req_policies = list()
+    def convert_irules(self, vs_ds_rules, rule_config,
+                       avi_config, prefix, vs_name, tenant, reuse_http_policy):
+        vs_ds = []
+        req_policies = []
         nw_policy = None
         mapped_rules = []
         converted_rules = []
 
-        LOG.debug("Converting for irules %s for vs %s" % (vs_ds_rules, vs_name))
+        LOG.debug(
+            "Converting for irules %s for vs %s",
+            vs_ds_rules, vs_name)
 
         for rule_mapping in rule_config:
-            mapped_rules.append(rule_mapping['rule_name'])
+            mapped_rules.append(rule_mapping["rule_name"])
 
         for index, rule in enumerate(vs_ds_rules):
             rule_mapping = None
             if rule in mapped_rules:
-                rule_mapping = [obj for obj in rule_config if
-                                obj['rule_name'] == rule][0]
-            if rule_mapping and rule_mapping['type'] == 'VSDataScriptSet':
-                if 'avi_config' in rule_mapping:
-                    ds_config = copy.deepcopy(rule_mapping['avi_config'])
+                rule_mapping = [
+                    obj for obj in rule_config if obj["rule_name"] == rule][0]
+            if rule_mapping and rule_mapping["type"] == "VSDataScriptSet":
+                if "avi_config" in rule_mapping:
+                    ds_config = copy.deepcopy(rule_mapping["avi_config"])
                 else:
                     ds_config = copy.deepcopy(conv_const.PLACE_HOLDER_DS)
                     ds_config['name'] = '%s-%s' % (
                         rule, conv_const.PLACE_HOLDER_STR)
 
-                ds_config['tenant_ref'] = self.get_object_ref(tenant, 'tenant')
+                ds_config["tenant_ref"] = self.get_object_ref(tenant, "tenant")
                 if prefix:
                     ds_config['name'] = '%s-%s' % (prefix, ds_config['name'])
-                existing_ds = [obj for obj in avi_config['VSDataScriptSet']
-                               if obj['name'] == ds_config['name']]
+                existing_ds = [
+                    obj for obj in avi_config["VSDataScriptSet"]
+                    if obj["name"] == ds_config["name"]]
                 if not existing_ds:
-                    avi_config['VSDataScriptSet'].append(ds_config)
-                vs_ds.append(ds_config['name'])
+                    avi_config["VSDataScriptSet"].append(ds_config)
+                vs_ds.append(ds_config["name"])
                 converted_rules.append(rule)
                 LOG.debug(
-                    "iRule %s successfully mapped to %s VSDataScriptSet" %
-                    (rule, ds_config['name']))
-            elif rule_mapping and rule_mapping['type'] == 'HTTPPolicySet':
-                if 'avi_config' in rule_mapping:
-                    policy = copy.deepcopy(rule_mapping['avi_config'])
+                    "iRule %s successfully mapped to %s VSDataScriptSet",
+                    rule, ds_config["name"])
+            elif rule_mapping and rule_mapping["type"] == "HTTPPolicySet":
+                if "avi_config" in rule_mapping:
+                    policy = copy.deepcopy(rule_mapping["avi_config"])
                     if prefix:
                         policy_name = '%s-%s' % (prefix, rule)
                     else:
                         policy_name = '%s' % (rule)
                     if not reuse_http_policy:
                         policy_name = '%s-%s' % (policy_name, vs_name)
                     policy["name"] = policy_name
@@ -2282,33 +2440,32 @@
                         policy_name = '%s-%s' % (prefix, rule)
                     else:
                         policy_name = '%s' % (rule)
                     if not reuse_http_policy:
                         policy_name = '%s-%s' % (policy_name, vs_name)
                     policy["name"] = policy_name
 
-                policy['tenant_ref'] = self.get_object_ref(tenant, 'tenant')
+                policy["tenant_ref"] = self.get_object_ref(tenant, "tenant")
                 if prefix:
                     policy['name'] = '%s-%s' % (prefix, policy['name'])
                 if reuse_http_policy:
-                    policy_obj = [ob for ob in avi_config['HTTPPolicySet'] if ob[
-                        'name'] == policy_name]
+                    policy_obj = [
+                        ob for ob in avi_config["HTTPPolicySet"] if ob["name"] == policy_name]
                     if not policy_obj:
-                        avi_config['HTTPPolicySet'].append(policy)
+                        avi_config["HTTPPolicySet"].append(policy)
                 else:
-                    avi_config['HTTPPolicySet'].append(policy)
-                req_policies.append(policy['name'])
+                    avi_config["HTTPPolicySet"].append(policy)
+                req_policies.append(policy["name"])
                 converted_rules.append(rule)
                 LOG.debug(
-                    "iRule %s successfully mapped to %s HTTPPolicySet" %
-                    (rule, policy['name']))
-            elif rule_mapping and rule_mapping['type'] == \
-                    'NetworkSecurityPolicy':
-                if 'avi_config' in rule_mapping:
-                    policy = copy.deepcopy(rule_mapping['avi_config'])
+                    "iRule %s successfully mapped to %s HTTPPolicySet",
+                    rule, policy["name"])
+            elif rule_mapping and rule_mapping["type"] == "NetworkSecurityPolicy":
+                if "avi_config" in rule_mapping:
+                    policy = copy.deepcopy(rule_mapping["avi_config"])
                     if prefix:
                         policy_name = '%s-%s' % (prefix, rule)
                     else:
                         policy_name = '%s' % (rule)
                     if not reuse_http_policy:
                         policy_name = '%s-%s' % (policy_name, vs_name)
                     policy["name"] = policy_name
@@ -2318,82 +2475,116 @@
                         policy_name = '%s-%s' % (prefix, rule)
                     else:
                         policy_name = '%s' % (rule)
                     if not reuse_http_policy:
                         policy_name = '%s-%s' % (policy_name, vs_name)
                     policy["name"] = policy_name
 
-                policy['tenant_ref'] = self.get_object_ref(tenant, 'tenant')
+                policy["tenant_ref"] = self.get_object_ref(tenant, "tenant")
                 if prefix:
                     policy['name'] = '%s-%s' % (prefix, policy['name'])
                 if reuse_http_policy:
-                    policy_obj = [ob for ob in avi_config['NetworkSecurityPolicy'] if ob[
-                        'name'] == policy_name]
+                    policy_obj = [
+                        ob for ob in avi_config["NetworkSecurityPolicy"]
+                        if ob["name"] == policy_name]
                     if not policy_obj:
-                        avi_config['NetworkSecurityPolicy'].append(policy)
+                        avi_config["NetworkSecurityPolicy"].append(policy)
                 else:
-                    avi_config['NetworkSecurityPolicy'].append(policy)
-                nw_policy = policy['name']
+                    avi_config["NetworkSecurityPolicy"].append(policy)
+                nw_policy = policy["name"]
                 converted_rules.append(rule)
                 LOG.debug(
                     "iRule %s successfully mapped to %s NetworkSecurityPolicy" %
                     (rule, policy['name']))
-            elif (rule_mapping and rule_mapping['type'] ==
-                  'HTTPToHTTPSRedirect') or rule == '_sys_https_redirect':
+            elif (rule_mapping and rule_mapping["type"] == "HTTPToHTTPSRedirect") \
+                    or rule == "_sys_https_redirect":
                 # Added prefix for objects
                 if prefix:
                     policy_name = '%s-%s' % (prefix, rule)
                 else:
                     policy_name = '%s' % (rule)
                 if not reuse_http_policy:
                     policy_name = '%s-%s' % (policy_name, vs_name)
                 policy = copy.deepcopy(conv_const.HTTP_TO_HTTPS_REDIRECT_POL)
                 policy["name"] = policy_name
-                policy['tenant_ref'] = self.get_object_ref(tenant, 'tenant')
+                policy["tenant_ref"] = self.get_object_ref(tenant, "tenant")
                 req_policies.append(policy_name)
                 if reuse_http_policy:
-                    policy_obj = [ob for ob in avi_config['HTTPPolicySet'] if ob[
-                        'name'] == policy_name]
+                    policy_obj = [
+                        ob for ob in avi_config["HTTPPolicySet"] if ob["name"] == policy_name]
                     if not policy_obj:
-                        avi_config['HTTPPolicySet'].append(policy)
+                        avi_config["HTTPPolicySet"].append(policy)
                 else:
-                    avi_config['HTTPPolicySet'].append(policy)
+                    avi_config["HTTPPolicySet"].append(policy)
                 converted_rules.append(rule)
                 LOG.debug(
                     "iRule %s successfully mapped to %s HTTPPolicySet" %
                     (rule, policy['name']))
         return vs_ds, req_policies, nw_policy, converted_rules
 
-    def update_with_default_profile(self, profile_type, profile,
-                                    profile_config, profile_name):
+    def update_with_default_profile(
+            self, profile_type, profile, profile_config, profile_name):
         """
         Profiles can have inheritance used by attribute defaults-from in F5
         configuration this method recursively gets all the attributes from the
         default objects and forms complete object
         :param profile_type: type of profile
         :param profile: currant profile object
         :param profile_config: F5 profile config dict
         :param profile_name: Name of profile
         :return: Complete profile with updated attributes from defaults
         """
-        parent_name = profile.get('defaults-from', None)
+        parent_name = profile.get("defaults-from", None)
         if parent_name and profile_name != parent_name:
-            parent_profile = profile_config.get(profile_type + " " +
-                                                parent_name, None)
+            parent_profile = profile_config.get(
+                profile_type + " " + parent_name, None)
             if parent_profile:
                 parent_profile = self.update_with_default_profile(
                     profile_type, parent_profile, profile_config, parent_name)
                 parent_profile = copy.deepcopy(parent_profile)
                 parent_profile.update(profile)
                 profile = parent_profile
         return profile
 
     def remove_verified_accept_from_network_profile(self, avi_config_dict):
-        for ntwk_profile in avi_config_dict['NetworkProfile']:
-            if ntwk_profile.get('verified-accept'):
-                del(ntwk_profile['verified-accept'])
-
-    def remove_via_host_from_app_profiles(self,avi_config_dict):
-        for app_profile in avi_config_dict['ApplicationProfile']:
-            if app_profile.get('via-host-name'):
-                del(app_profile['via-host-name'])
-                del(app_profile['via-request'])
+        for ntwk_profile in avi_config_dict["NetworkProfile"]:
+            if "verified-accept" in ntwk_profile.keys():
+                del ntwk_profile["verified-accept"]
+
+    def remove_via_host_from_app_profiles(self, avi_config_dict):
+        for app_profile in avi_config_dict["ApplicationProfile"]:
+            if app_profile.get("via-host-name"):
+                del app_profile["via-host-name"]
+                del app_profile["via-request"]
+
+    def remove_vs_names_when_vs_filter_is_provided(
+            self, output_dir="", report_name="", vs_names=""):
+
+        excel_path = output_dir + os.path.sep + "%s-ConversionStatus.xlsx" % \
+                                                 report_name
+        virtual_services = []
+        if vs_names and isinstance(vs_names, str):
+            virtual_services = vs_names.split(",")
+        elif vs_names and isinstance(vs_names, list):
+            virtual_services = vs_names
+
+        wb = load_workbook(excel_path)
+        sh = wb["Status Sheet"]
+
+        for index in range(sh.max_row, 2, -1):
+            if sh.cell(index, 1).value == "virtual" and sh.cell(
+                    index, 3).value not in virtual_services:
+                sh.delete_rows(index)
+
+        wb.save(
+            output_dir + os.path.sep + "%s-ConversionStatus.xlsx" % \
+                                                 report_name)
+
+    def get_protocol_of_vs(self,ntwk_prof_ref,avi_config):
+        protocol ="tcp"
+        if ntwk_prof_ref:
+            prof_name=ntwk_prof_ref.split("name=")[-1]
+            ntwk_prof_config = [
+                np for np in avi_config["NetworkProfile"] if np["name"] == prof_name]
+            if ntwk_prof_config[0]["profile"].get("type")=="PROTOCOL_TYPE_UDP_FAST_PATH":
+                protocol="udp"
+        return protocol
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/converter_constants.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/converter_constants.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-import yaml
 import os
 
+import yaml
+
 DEFAULT_TIMEOUT = 16
 DEFAULT_INTERVAL = 5
 DEFAULT_TIME_UNTIL_UP = 1
 PORT_START = 1
 PORT_END = 65535
 DEFAULT_PORT = 80
 DEFAULT_FAILED_CHECKS = 1
@@ -38,151 +39,129 @@
 SEC_IN_MIN = 60
 MIN_IN_HR = 60
 HR_IN_DAY = 24
 SOURCE_ADDR_TIMEOUT = 180
 MIN_SESSION_TIMEOUT = 60
 MAX_SESSION_TIMEOUT = 1800
 PLACE_HOLDER_STR = "auto_created"
-DEFAULT_CONTENT_TYPE = ['text/html', 'text/xml', 'text/plain',
-                        'application/pdf', 'text/javascript',
-                        'application/javascript', 'application/x-javascript',
-                        'application/xml', 'text/css']
+DEFAULT_CONTENT_TYPE = [
+    "text/html",
+    "text/xml",
+    "text/plain",
+    "application/pdf",
+    "text/javascript",
+    "application/javascript",
+    "application/x-javascript",
+    "application/xml",
+    "text/css",
+]
 
 # Status Constants which are used in CSV/report generation of the conversion
 # run.
-STATUS_SKIPPED = 'SKIPPED'
-STATUS_SUCCESSFUL = 'SUCCESSFUL'
-STATUS_ERROR = 'ERROR'
-STATUS_NOT_APPLICABLE = 'NOT APPLICABLE'  # Its specific netscalar commands
+STATUS_SKIPPED = "SKIPPED"
+STATUS_SUCCESSFUL = "SUCCESSFUL"
+STATUS_ERROR = "ERROR"
+STATUS_NOT_APPLICABLE = "NOT APPLICABLE"  # Its specific netscalar commands
 # which are not applicable in AVI
-STATUS_PARTIAL = 'PARTIAL'
-STATUS_DATASCRIPT = 'DATASCRIPT'
-STATUS_NOT_IN_USE = 'NOT IN USE'
+STATUS_PARTIAL = "PARTIAL"
+STATUS_DATASCRIPT = "DATASCRIPT"
+STATUS_NOT_IN_USE = "NOT IN USE"
 # External status which are not supported Health monitors
-STATUS_EXTERNAL_MONITOR = 'EXTERNAL MONITOR'
-STATUS_MISSING_FILE = 'MISSING FILE'
+STATUS_EXTERNAL_MONITOR = "EXTERNAL MONITOR"
+STATUS_MISSING_FILE = "MISSING FILE"
 # Object type constant which are used in object reference generation
-OBJECT_TYPE_SSL_PROFILE = 'sslprofile'
-OBJECT_TYPE_APPLICATION_PROFILE = 'applicationprofile'
-OBJECT_TYPE_HTTP_POLICY_SET = 'httppolicyset'
-OBJECT_TYPE_POOL_GROUP = 'poolgroup'
-OBJECT_TYPE_POOL = 'pool'
-OBJECT_TYPE_NETWORK_PROFILE = 'networkprofile'
-OBJECT_TYPE_PKI_PROFILE = 'pkiprofile'
-OBJECT_TYPE_SSL_KEY_AND_CERTIFICATE = 'sslkeyandcertificate'
-OBJECT_TYPE_APPLICATION_PERSISTENCE_PROFILE = 'applicationpersistenceprofile'
-OBJECT_TYPE_HEALTH_MONITOR = 'healthmonitor'
-OBJECT_TYPE_VIRTUAL_SERVICE = 'virtualservice'
-OBJECT_TYPE_STRING_GROUP = 'stringgroup'
+OBJECT_TYPE_SSL_PROFILE = "sslprofile"
+OBJECT_TYPE_APPLICATION_PROFILE = "applicationprofile"
+OBJECT_TYPE_HTTP_POLICY_SET = "httppolicyset"
+OBJECT_TYPE_POOL_GROUP = "poolgroup"
+OBJECT_TYPE_POOL = "pool"
+OBJECT_TYPE_NETWORK_PROFILE = "networkprofile"
+OBJECT_TYPE_PKI_PROFILE = "pkiprofile"
+OBJECT_TYPE_SSL_KEY_AND_CERTIFICATE = "sslkeyandcertificate"
+OBJECT_TYPE_APPLICATION_PERSISTENCE_PROFILE = "applicationpersistenceprofile"
+OBJECT_TYPE_HEALTH_MONITOR = "healthmonitor"
+OBJECT_TYPE_VIRTUAL_SERVICE = "virtualservice"
+OBJECT_TYPE_STRING_GROUP = "stringgroup"
 # Complexity status constant
-COMPLEXITY_ADVANCED = 'ADVANCED'
-COMPLEXITY_BASIC = 'BASIC'
+COMPLEXITY_ADVANCED = "ADVANCED"
+COMPLEXITY_BASIC = "BASIC"
 # Not supported constant.
-STATUS_NOT_SUPPORTED = 'NOT SUPPORTED'
-STATUS_LIST = [STATUS_SKIPPED, STATUS_SUCCESSFUL, STATUS_NOT_APPLICABLE,
-               STATUS_ERROR, STATUS_PARTIAL, STATUS_DATASCRIPT]
-HM_CUSTOM_KEY = 'healthmonitor_custom_config'
-RULE_CUSTOM_KEY = 'irule_custom_config'
+STATUS_NOT_SUPPORTED = "NOT SUPPORTED"
+STATUS_LIST = [
+    STATUS_SKIPPED,
+    STATUS_SUCCESSFUL,
+    STATUS_NOT_APPLICABLE,
+    STATUS_ERROR,
+    STATUS_PARTIAL,
+    STATUS_DATASCRIPT]
+HM_CUSTOM_KEY = "healthmonitor_custom_config"
+RULE_CUSTOM_KEY = "irule_custom_config"
 
 PLACE_HOLDER_DS = {
-    'datascript': [
+    "datascript": [
         {
-            'evt': 'VS_DATASCRIPT_EVT_HTTP_REQ',
-            'script': 'if avi.http.get_query("intro", "true") == "hello%20world" then avi.http.add_header("intro", "true") end'
+            "evt": "VS_DATASCRIPT_EVT_HTTP_REQ",
+            "script": 'if avi.http.get_query("intro", "true") == "hello%20world"\
+                then avi.http.add_header("intro", "true") end',
         }
     ]
 }
 
 PLACE_HOLDER_REQ_POLICY = {
-    'http_request_policy': {
-        'rules': [
+    "http_request_policy": {
+        "rules": [
             {
-                'index': 1,
-                'hdr_action': [
-                    {
-                        'action': "HTTP_REPLACE_HDR",
-                        'hdr': {
-                            'name': "placeholder",
-                            'value': {
-                                'val': "placeholder"
-                            }
-                        }
-                    }
-                ],
-                'all_headers': False,
-                'match':
-                {
-                    'hdrs': [
-                        {
-                            'hdr': "placeholder",
-                            'match_criteria': "HDR_EXISTS"
-                        }
-                    ]
-                },
-                'name': "Rule 1"
+                "index": 1,
+                "hdr_action": [{"action": "HTTP_REPLACE_HDR", "hdr":
+                                {"name": "placeholder", "value": {"val": "placeholder"}}}],
+                "all_headers": False,
+                "match": {"hdrs": [{"hdr": "placeholder", "match_criteria": "HDR_EXISTS"}]},
+                "name": "Rule 1",
             }
         ]
     },
-    'is_internal_policy': False
+    "is_internal_policy": False,
 }
 
-PLACE_HOLDER_NW_POLICY = {
-    'rules': [
-        {
-            'index': 1,
-            'enable': True,
-            'name': "Rule 1",
-            'action': "NETWORK_SECURITY_POLICY_ACTION_TYPE_ALLOW",
-            'match': {
-                'client_ip': {
-                    'addrs': [
-                        {
-                            'type': "V4",
-                            'addr': "1.1.1.1"
-                        }
-                    ],
-                    'match_criteria': "IS_IN"
-                }
-            },
-            'log': False
-        }
-    ]
-}
+PLACE_HOLDER_NW_POLICY = {"rules": [{"index": 1,
+                                     "enable": True,
+                                     "name": "Rule 1",
+                                     "action": "NETWORK_SECURITY_POLICY_ACTION_TYPE_ALLOW",
+                                     "match": {"client_ip": {"addrs": [{"type": "V4",
+                                                                        "addr": "1.1.1.1"}],
+                                                             "match_criteria": "IS_IN"}},
+                                     "log": False,
+                                     }]}
 
 HTTP_TO_HTTPS_REDIRECT_POL = {
     "http_request_policy": {
         "rules": [
             {
                 "index": 1,
                 "redirect_action": {
                     "keep_query": True,
-                    "status_code":
-                        "HTTP_REDIRECT_STATUS_CODE_302",
+                    "status_code": "HTTP_REDIRECT_STATUS_CODE_302",
                     "protocol": "HTTPS",
-                    "port": 443
-                },
+                    "port": 443},
                 "enable": True,
                 "name": "HTTP-To-HTTPS-Redirect",
                 "match": {
-                    "protocol": {
-                        "protocols": "HTTP",
-                        "match_criteria": "IS_IN"
-                    }
-                }
-            }
-        ]
-    },
-"is_internal_policy": False
+                        "protocol": {
+                            "protocols": "HTTP",
+                            "match_criteria": "IS_IN"}},
+            }]},
+    "is_internal_policy": False,
 }
 
+
 def init(version):
     """
     This function defines that to initialize constant from yaml file
     :return: None
     """
     global f5_command_status
     with open(os.path.dirname(__file__) + "/command_status.yaml") as stream:
         f5_command_status = yaml.safe_load(stream)
-    if version == '10':
-        return f5_command_status['VERSION_10']
-    else:
-        return f5_command_status['VERSION_11']
+    if version == "10":
+        return f5_command_status["VERSION_10"]
+
+    return f5_command_status["VERSION_11"]
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/datagroup_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/datagroup_converter.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,14 +1,17 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 import logging
+
 import avi.migrationtools.f5_converter.converter_constants as final
-from avi.migrationtools.f5_converter.conversion_util import F5Util
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
+from avi.migrationtools.f5_converter.conversion_util import F5Util
+
 LOG = logging.getLogger(__name__)
 # Creating f5 object for util library.
 conv_utils = F5Util()
 
 
 class DataGroupConfigConv(object):
     @classmethod
@@ -17,218 +20,248 @@
         """
 
         :param version: version of f5 instance
         :param prefix: prefix for objects
         :param object_merge_check: Flag for object merge
         :return:
         """
-        if version == '10':
-            return DataGroupConfigConvV10(prefix, object_merge_check,
-                                          dg_command_status)
-        if version in ['11', '12']:
-            return DataGroupConfigConvV11(prefix, object_merge_check,
-                                          dg_command_status)
+        if version == "10":
+            return DataGroupConfigConvV10(
+                prefix, object_merge_check, dg_command_status)
+        if version in ["11", "12"]:
+            return DataGroupConfigConvV11(
+                prefix, object_merge_check, dg_command_status)
 
     def convert_ip_group(self, name, d_group, avi_config, skipped, tenant):
+        """
+        Args:
+            name : Object name
+            d_group : data group configuration
+            avi_config : passed avi configuration
+            skipped : skipped arguments list
+            tenant :tenant ref
+        """
         pass
 
     def update_conv_status_for_skip(self, dg_type, name, msg):
-        conv_utils.add_status_row("data-group", dg_type, name,
-                                  final.STATUS_NOT_SUPPORTED, msg)
+        '''
+        :param dg_type : data group type
+        :param name : passed name of datagroup
+        :param msg : passed message status
+        '''
+        conv_utils.add_status_row(
+            "data-group",
+            dg_type,
+            name,
+            final.STATUS_NOT_SUPPORTED,
+            msg)
 
-    def update_conversion_status(self, conv_status, dg_type, name,
-                                 data_group):
+    def update_conversion_status(
+            self, conv_status, dg_type, name, data_group, f5_dg_config):
         """
 
         :param conv_status:  state of conversion
         :param dg_type: type of data group
         :param name: name of data group
         :param data_group: dict of data group
         :return:
         """
-        conv_utils.add_conv_status('data-group', dg_type, name, conv_status,
-                                   [{'data-group': data_group}])
-        LOG.debug("Conversion successful for data group: %s" %
-                  name)
+        conv_utils.add_conv_status("data-group",
+                                   dg_type,
+                                   name,
+                                   conv_status,
+                                   [{"data-group": data_group}],
+                                   f5_object=yaml.dump(f5_dg_config))
+        LOG.debug("Conversion successful for data group: %s", name)
 
     def update_conv_status_for_error(self, name, dg_type, key):
         """
 
         :param name:  name of data group
         :param dg_type: type of data group.
         :param key: key for data group
         :return:
         """
         if name:
-            conv_utils.add_status_row("data-group", dg_type, name,
-                                      final.STATUS_ERROR)
+            conv_utils.add_status_row(
+                "data-group", dg_type, name, final.STATUS_ERROR)
         else:
-            conv_utils.add_status_row("data-group", dg_type, key,
-                                      final.STATUS_ERROR)
+            conv_utils.add_status_row(
+                "data-group", dg_type, key, final.STATUS_ERROR)
 
-    def convert(self, f5_config, avi_config, user_ignore, tenant_ref,
-                merge_object_mapping, sys_dict):
+    def convert(self, f5_config, avi_config, user_ignore,
+                tenant_ref, merge_object_mapping, sys_dict):
         """
 
         :param f5_config: parsed f5 config
         :param avi_config: dict of avi config
         :param user_ignore: Ignore config defined by user
         :param tenant_ref: tenant of which output to converted
         :param merge_object_mapping: flag for object merge
         :param sys_dict: baseline profile
         :return:
         """
-        if 'IpAddrGroup' not in avi_config:
-            avi_config['IpAddrGroup'] = []
+        if "IpAddrGroup" not in avi_config:
+            avi_config["IpAddrGroup"] = []
         converted_objs = []
-        f5_datagroup_dict = f5_config.get('data-group', {})
-        user_ignore = user_ignore.get('data-group', {})
+        f5_datagroup_dict = f5_config.get("data-group", {})
+        user_ignore = user_ignore.get("data-group", {})
         # Added variable to get total object count.
         progressbar_count = 0
         total_size = len(f5_datagroup_dict.keys())
         print("Converting Data groups...")
         for key in f5_datagroup_dict.keys():
             progressbar_count += 1
-            data_group_type = None
             name = None
             skipped = []
             # Added call to check the progress.
             msg = "data-group conversion started..."
-            conv_utils.print_progress_bar(progressbar_count, total_size, msg,
-                             prefix='Progress', suffix='')
+            conv_utils.print_progress_bar(
+                progressbar_count,
+                total_size,
+                msg,
+                prefix="Progress",
+                suffix="")
             dg_type = None
             try:
                 tenant, name = conv_utils.get_tenant_ref(key)
                 # dg_scope, name = key.split(" ")
                 # name = name.split('/')[-1]
-                LOG.debug("Converting datagroup: %s" % name)
+                LOG.debug("Converting datagroup: %s", name)
                 dg_config = f5_datagroup_dict[key]
                 if tenant_ref:
                     tenant = tenant_ref
                 if self.prefix:
                     name = '{}-{}'.format(self.prefix, name)
 
-                dg_type = dg_config['type']
-                if dg_type == 'ip':
-                    ip_group = self.convert_ip_group(name, dg_config,
-                                                     avi_config,
-                                                     skipped,
-                                                     tenant)
+                dg_type = dg_config["type"]
+                if dg_type == "ip":
+                    ip_group = self.convert_ip_group(
+                        name, dg_config, avi_config, skipped, tenant)
                 else:
                     msg = 'data-group type not supported skipping ' \
                           'conversion: %s' % name
                     LOG.warning(msg)
                     self.update_conv_status_for_skip(dg_type, name, msg)
                     continue
                 if not ip_group:
                     continue
                 # code to merge Data groups.
                 if self.object_merge_check:
                     conv_utils.update_skip_duplicates(
-                        ip_group, avi_config['IpAddrGroup'], 'ip_group',
-                        converted_objs, name, None, merge_object_mapping,
-                        dg_type, self.prefix, sys_dict['IpAddrGroup'])
+                        ip_group,
+                        avi_config["IpAddrGroup"],
+                        "ip_group",
+                        converted_objs,
+                        name,
+                        None,
+                        merge_object_mapping,
+                        dg_type,
+                        self.prefix,
+                        sys_dict["IpAddrGroup"],
+                    )
                     self.dg_count += 1
                 else:
                     avi_config["IpAddrGroup"].append(ip_group)
 
                 conv_status = conv_utils.get_conv_status(
                     skipped, dict(), dict(), ip_group, user_ignore)
-                self.update_conversion_status(conv_status, dg_type, name,
-                                              ip_group)
-            except:
-                update_count('error')
-                LOG.error("Failed to convert data-group : %s" % key,
-                          exc_info=True)
+                self.update_conversion_status(
+                    conv_status, dg_type, name, ip_group, dg_config)
+            except BaseException:
+                update_count("error")
+                LOG.error(
+                    "Failed to convert data-group : %s",
+                    key, exc_info=True)
                 self.update_conv_status_for_error(name, dg_type, key)
         count = len(avi_config["IpAddrGroup"])
-        LOG.debug("Converted %s ip group" % count)
-        f5_config.pop('data-group', None)
-
+        LOG.debug("Converted %s ip group", count)
+        f5_config.pop("data-group", None)
 
 
 class DataGroupConfigConvV11(DataGroupConfigConv):
+    '''
+    Data group config Conversion
+    '''
+
     def __init__(self, prefix, object_merge_check, dg_command_status):
         """
 
         :param prefix: prefix for object
         :param object_merge_check: flag to merge object
         """
-        self.supported_attr = dg_command_status['Datagroup_supported_attr']
+        self.supported_attr = dg_command_status["Datagroup_supported_attr"]
         # Added prefix for objects
         self.prefix = prefix
         self.object_merge_check = object_merge_check
         self.dg_count = 0
 
-
     def convert_ip_group(self, name, d_group, avi_config, skipped, tenant):
 
         skipped += [attr for attr in d_group.keys()
                     if attr not in self.supported_attr]
         prefixes = []
-        for record in d_group.get('records', []):
+        for record in d_group.get("records", []):
             ip_address = None
             if "%" in record:
-                ip_address = record.split('%')[0]
-                vrf = record.split('%')[1].split('/')[0]
+                ip_address = record.split("%")[0]
+                vrf = record.split("%")[1].split("/")[0]
                 conv_utils.add_vrf(avi_config, vrf, None)
             else:
-                ip_address = record.split('/')[0]
+                ip_address = record.split("/")[0]
             prefix = {
-                'mask': record.split('/')[1],
-                'ip_addr': {
-                    'type':     "V4",
-                    'addr': ip_address
-                }
-            }
+                "mask": record.split("/")[1],
+                "ip_addr": {
+                    "type": "V4",
+                    "addr": ip_address}}
             prefixes.append(prefix)
 
         ip_group = {
-            'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant'),
-            'name': name,
-            'prefixes': prefixes
-        }
+            "tenant_ref": conv_utils.get_object_ref(
+                tenant,
+                "tenant"),
+            "name": name,
+            "prefixes": prefixes}
         return ip_group
 
 
 class DataGroupConfigConvV10(DataGroupConfigConv):
     def __init__(self, prefix, object_merge_check, dg_command_status):
         """
 
         :param prefix: prefix for object
         :param object_merge_check: flag to merge object
         """
-        self.supported_attr = dg_command_status['Datagroup_supported_attr']
+        self.supported_attr = dg_command_status["Datagroup_supported_attr"]
         # Added prefix for objects
         self.prefix = prefix
         self.object_merge_check = object_merge_check
         self.dg_count = 0
 
     def convert_ip_group(self, name, d_group, avi_config, skipped, tenant):
 
         skipped += [attr for attr in d_group.keys()
                     if attr not in self.supported_attr]
         prefixes = []
-        for record in d_group.get('records', []):
+        for record in d_group.get("records", []):
             for ip in record:
                 ip_address = None
                 if "%" in ip:
-                    ip_address = ip.split('%')[0]
-                    vrf = ip.split('%')[1].split('/')[0]
+                    ip_address = ip.split("%")[0]
+                    vrf = ip.split("%")[1].split("/")[0]
                     conv_utils.add_vrf(avi_config, vrf, None)
                 else:
-                    ip_address = ip.split('/')[0]
+                    ip_address = ip.split("/")[0]
                 prefix = {
-                    'mask': ip.split('/')[1],
-                    'ip_addr': {
-                        'type': "V4",
-                        'addr': ip_address
-                    }
-                }
+                    "mask": ip.split("/")[1],
+                    "ip_addr": {
+                        "type": "V4",
+                        "addr": ip_address}}
                 prefixes.append(prefix)
 
         ip_group = {
-            'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant'),
-            'name': name,
-            'prefixes': prefixes
-        }
+            "tenant_ref": conv_utils.get_object_ref(
+                tenant,
+                "tenant"),
+            "name": name,
+            "prefixes": prefixes}
         return ip_group
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_config_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_config_converter.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,57 +1,57 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
+import json
 import logging
-import avi.migrationtools.f5_converter.converter_constants as conv_const
 import os
-import json
 
-from avi.migrationtools.f5_converter.monitor_converter \
-    import MonitorConfigConv
-from avi.migrationtools.f5_converter.persistence_converter \
-    import PersistenceConfigConv
-from avi.migrationtools.f5_converter.pool_converter import PoolConfigConv
-from avi.migrationtools.f5_converter.profile_converter import \
-    ProfileConfigConv, ssl_count
-from avi.migrationtools.f5_converter.vs_converter import VSConfigConv
+import avi.migrationtools.f5_converter.converter_constants as conv_const
+from avi.migrationtools.avi_migration_utils import update_count
 from avi.migrationtools.f5_converter import conversion_util
+from avi.migrationtools.f5_converter.clone_cross_tenant_obj import CloneObjects
 from avi.migrationtools.f5_converter.conversion_util import F5Util
+from avi.migrationtools.f5_converter.datagroup_converter import \
+    DataGroupConfigConv
+from avi.migrationtools.f5_converter.monitor_converter import MonitorConfigConv
+from avi.migrationtools.f5_converter.persistence_converter import \
+    PersistenceConfigConv
 from avi.migrationtools.f5_converter.policy_converter import PolicyConfigConv
-from avi.migrationtools.avi_migration_utils import update_count
-from avi.migrationtools.f5_converter.datagroup_converter import DataGroupConfigConv
-from avi.migrationtools.f5_converter.clone_cross_tenant_obj import CloneObjects
+from avi.migrationtools.f5_converter.pool_converter import PoolConfigConv
+from avi.migrationtools.f5_converter.profile_converter import (
+    ProfileConfigConv, ssl_count)
+from avi.migrationtools.f5_converter.vs_converter import VSConfigConv
 
 LOG = logging.getLogger(__name__)
 csv_writer = None
 # Define Dict of merge_object_mapping to update the merged monitor, profile
 # name of ssl_profile, application_profile, network_profile etc
 merge_object_mapping = {
-    'ssl_profile': {'no': 0},
-    'app_profile': {'no': 0},
-    'network_profile': {'no': 0},
-    'app_per_profile': {'no': 0},
-    'pki_profile': {'no': 0},
-    'health_monitor': {'no': 0},
-    'ssl_cert_key': {'no': 0},
-    'ip_group': {'no': 0}
+    "ssl_profile": {"no": 0},
+    "app_profile": {"no": 0},
+    "network_profile": {"no": 0},
+    "app_per_profile": {"no": 0},
+    "pki_profile": {"no": 0},
+    "health_monitor": {"no": 0},
+    "ssl_cert_key": {"no": 0},
+    "ip_group": {"no": 0},
 }
 
 # Creating f5 object for util library.
 conv_utils = F5Util()
 
 
 def convert(f5_config, output_dir, vs_state, input_dir, version,
             object_merge_check, controller_version, report_name, prefix,
             con_snatpool, user_ignore, profile_path, tenant,
             cloud_name='Default-Cloud', keypassphrase=None,
             vs_level_status=False, vrf=None, segroup=None,
             custom_mappings=None, skip_pki=False, distinct_app_profile=False,
-            reuse_http_policy=False):
-
+            reuse_http_policy=False, skip_disabled_vs=False,
+            migrated_ciphers_dict=None ,migrated_ciphers_group_dict=None ):
     """
     Converts f5 config to avi config pops the config lists for conversion of
     each type from f5 config and remaining marked as skipped in the
     conversion status file
     :param f5_config: dict representation of f5 config from the file
     :param output_dir: Folder path to put output files
     :param vs_state: State of created Avi VS object
@@ -79,125 +79,154 @@
     avi_config_dict = {}
     sys_dict = {}
     partition_vs_mapping = {}
 
     try:
         # load the yaml file attribute in f5_attributes.
         f5_attributes = conv_const.init(version)
-        merge_object_type = ['ApplicationProfile', 'NetworkProfile',
-                             'SSLProfile', 'PKIProfile', 'SSLKeyAndCertificate',
-                             'ApplicationPersistenceProfile', 'HealthMonitor',
-                             'IpAddrGroup']
+        merge_object_type = [
+            "ApplicationProfile",
+            "NetworkProfile",
+            "SSLProfile",
+            "PKIProfile",
+            "SSLKeyAndCertificate",
+            "ApplicationPersistenceProfile",
+            "HealthMonitor",
+            "IpAddrGroup",
+        ]
         for key in merge_object_type:
             sys_dict[key] = []
             avi_config_dict[key] = []
 
         if profile_path and os.path.exists(profile_path):
             with open(profile_path) as data:
                 prof_data = json.load(data)
                 for key in merge_object_type:
                     sys_dict[key] = prof_data.get(key, [])
 
         profile_conv = ProfileConfigConv.get_instance(
-            version, f5_attributes, object_merge_check, prefix, keypassphrase,
-            skip_pki, distinct_app_profile)
-        profile_conv.convert(f5_config, avi_config_dict, input_dir, user_ignore,
-                             tenant, cloud_name, merge_object_mapping, sys_dict)
+            version, f5_attributes, object_merge_check, prefix, keypassphrase, skip_pki,
+            distinct_app_profile)
+        profile_conv.convert(
+            f5_config, avi_config_dict, input_dir, user_ignore, tenant, cloud_name,
+            merge_object_mapping, sys_dict,migrated_ciphers_dict,migrated_ciphers_group_dict)
 
         # Added ssl profile merge flag.
         mon_conv = MonitorConfigConv.get_instance(
             version, f5_attributes, prefix, object_merge_check)
-        mon_conv.convert(f5_config, avi_config_dict, input_dir, user_ignore,
-                         tenant, cloud_name, controller_version,
-                         merge_object_mapping, sys_dict, custom_mappings)
+        mon_conv.convert(
+            f5_config, avi_config_dict, input_dir, user_ignore, tenant, cloud_name,
+            controller_version, merge_object_mapping, sys_dict, custom_mappings,
+        )
 
         pool_conv = PoolConfigConv.get_instance(version, f5_attributes, prefix)
-        pool_conv.convert(f5_config, avi_config_dict, user_ignore, tenant,
-                          cloud_name, merge_object_mapping, sys_dict, vrf,
-                          segroup)
+        pool_conv.convert(
+            f5_config, avi_config_dict, user_ignore, tenant, cloud_name, merge_object_mapping,
+            sys_dict, vrf, segroup,
+        )
 
         persist_conv = PersistenceConfigConv.get_instance(
             version, f5_attributes, prefix, object_merge_check)
-        persist_conv.convert(f5_config, avi_config_dict, user_ignore, tenant,
-                             merge_object_mapping, sys_dict)
-
-        policy_conv = PolicyConfigConv.get_instance(version, f5_attributes, prefix)
-        policy_conv.convert(f5_config, avi_config_dict, tenant)
-
+        persist_conv.convert(
+            f5_config, avi_config_dict, user_ignore, tenant, merge_object_mapping, sys_dict,
+        )
+
+        policy_conv = PolicyConfigConv.get_instance(
+            version, f5_attributes, prefix)
+        policy_conv.convert(f5_config, avi_config_dict, tenant, cloud_name)
         vs_conv = VSConfigConv.get_instance(
-            version, f5_attributes, prefix, con_snatpool, custom_mappings,
-            distinct_app_profile)
+            version, f5_attributes, prefix, con_snatpool, custom_mappings, distinct_app_profile,
+        )
         vs_conv.convert(f5_config, avi_config_dict, vs_state, user_ignore,
                         tenant, cloud_name, controller_version,
                         merge_object_mapping, sys_dict, vrf, segroup,
-                        partition_vs_mapping, reuse_http_policy)
+                        partition_vs_mapping, reuse_http_policy, skip_disabled_vs)
         dg_conv = DataGroupConfigConv.get_instance(
             version, prefix, merge_object_mapping, f5_attributes)
-        dg_conv.convert(f5_config, avi_config_dict, user_ignore,
-                        tenant, merge_object_mapping, sys_dict)
-        #removing verified_accept key from network profile
+        dg_conv.convert(
+            f5_config,
+            avi_config_dict,
+            user_ignore,
+            tenant,
+            merge_object_mapping,
+            sys_dict,
+        )
+        # removing verified_accept key from network profile
         conv_utils.remove_verified_accept_from_network_profile(avi_config_dict)
         # removing via-host info from http profiles
         conv_utils.remove_via_host_from_app_profiles(avi_config_dict)
-        # Updating application profile from L4 to http if service has ssl enable
+        # Updating application profile from L4 to http if service has ssl
+        # enable
         conv_utils.update_app_profile(avi_config_dict, sys_dict)
         # Updated network profile to TCP PROXY if application profile is HTTP
         conv_utils.update_network_profile(avi_config_dict, sys_dict)
 
         # Disabled the net to static route conversion
         # conv_utils.net_to_static_route(f5_config, avi_config_dict)
 
         # Updating the ssl profile ref for monitors with merged name
-        conv_utils.update_monitor_ssl_ref(avi_config_dict, merge_object_mapping,
-                                          sys_dict)
+        conv_utils.update_monitor_ssl_ref(
+            avi_config_dict, merge_object_mapping, sys_dict)
         conv_utils.add_tenants(avi_config_dict)
         conv_utils.cleanup_config(avi_config_dict)
         # Validating the aviconfig after generation
         conv_utils.validation(avi_config_dict)
         # Clone cross tenant references
         test_clone_obj = CloneObjects(avi_config_dict)
         test_clone_obj.find_clone_all()
 
-    except:
-        update_count('warning')
+    except BaseException:
+        update_count("warning")
         LOG.error("Conversion error", exc_info=True)
-    datascript_objs = ['data-group']
+    datascript_objs = ["data-group"]
     # Added support node as not applicable
-    na_list_objs = f5_attributes['na_list_objs']
+    na_list_objs = f5_attributes["na_list_objs"]
     # Marked route as skipped
-    accept_list = ['snatpool', 'route']
+    accept_list = ["snatpool", "route"]
     for f5_type in f5_config.keys():
         f5_obj = f5_config[f5_type]
         for key in f5_obj.keys():
             sub_type = None
-            if ' ' in key:
-                sub_type, key = key.rsplit(' ', 1)
+            if " " in key:
+                sub_type, key = key.rsplit(" ", 1)
             if f5_type in datascript_objs:
-                conv_utils.add_status_row(f5_type, sub_type, key,
-                                          conv_const.STATUS_DATASCRIPT)
+                conv_utils.add_status_row(
+                    f5_type, sub_type, key, conv_const.STATUS_DATASCRIPT)
             elif f5_type in na_list_objs:
-                conv_utils.add_status_row(f5_type, sub_type, key,
-                                          conv_const.STATUS_NOT_APPLICABLE,
-                                          f5_type + " object not applicable")
+                conv_utils.add_status_row(
+                    f5_type,
+                    sub_type,
+                    key,
+                    conv_const.STATUS_NOT_APPLICABLE,
+                    f5_type + " object not applicable",
+                )
             elif f5_type in accept_list:
-                msg = (" skipped because of object "
-                       "associated with this is skipped")
-                conv_utils.add_status_row(f5_type, sub_type, key,
-                                          conv_const.STATUS_SKIPPED,
-                                          f5_type + msg)
+                msg = "skipped because of object associated \
+                with this is skipped"
+
+                conv_utils.add_status_row(
+                    f5_type,
+                    sub_type,
+                    key,
+                    conv_const.STATUS_SKIPPED,
+                    f5_type + msg)
             else:
-                conv_utils.add_status_row(f5_type, sub_type, key,
-                                          conv_const.STATUS_NOT_SUPPORTED)
+                conv_utils.add_status_row(
+                    f5_type, sub_type, key, conv_const.STATUS_NOT_SUPPORTED)
 
     # Add f5 converter status report in xslx report
     conv_utils.add_complete_conv_status(
-        output_dir, avi_config_dict, report_name, vs_level_status)
-    for key in avi_config_dict:
-        if key != 'META':
-            if key == 'VirtualService':
+        output_dir,
+        avi_config_dict,
+        report_name,
+        vs_level_status)
+
+    for key in avi_config_dict.keys():
+        if key != "META":
+            if key == "VirtualService":
                 if vs_level_status:
                     LOG.info('Total Objects of %s : %s (%s full conversions)'
                              % (key, len(avi_config_dict[key]),
                                 conversion_util.fully_migrated))
                     print('Total Objects of %s : %s (%s full conversions)' \
                           % (key, len(avi_config_dict[key]),
                              conversion_util.fully_migrated))
@@ -205,75 +234,72 @@
                     LOG.info('Total Objects of %s : %s'
                              % (key, len(avi_config_dict[key])))
                     print('Total Objects of %s : %s' \
                         % (key, len(avi_config_dict[key])))
 
                 continue
             # Added code to print merged count.
-            elif object_merge_check and key == 'SSLProfile':
-                mergedfile = len(avi_config_dict[key]) - ssl_count['count']
+            if object_merge_check and key == "SSLProfile":
+                mergedfile = len(avi_config_dict[key]) - ssl_count["count"]
                 profile_merged_message = \
                     'Total Objects of %s : %s (%s/%s profile merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedfile),
                      ssl_count['count'])
                 LOG.info(profile_merged_message)
                 print(profile_merged_message)
                 continue
-            elif object_merge_check and key == 'ApplicationProfile':
-                mergedfile = len(avi_config_dict[key]) - \
-                             profile_conv.app_count
+            if object_merge_check and key == "ApplicationProfile":
+                mergedfile = len(avi_config_dict[key]) - profile_conv.app_count
                 profile_merged_message = \
                     'Total Objects of %s : %s (%s/%s profile merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedfile),
                      profile_conv.app_count)
                 LOG.info(profile_merged_message)
                 print(profile_merged_message)
                 continue
-            elif object_merge_check and key == 'NetworkProfile':
-                mergedfile = len(avi_config_dict[key]) - \
-                             profile_conv.net_count
+            if object_merge_check and key == "NetworkProfile":
+                mergedfile = len(avi_config_dict[key]) - profile_conv.net_count
                 profile_merged_message = \
                     'Total Objects of %s : %s (%s/%s profile merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedfile),
                      profile_conv.net_count)
                 LOG.info(profile_merged_message)
                 print(profile_merged_message)
                 continue
-            elif object_merge_check and key == 'HealthMonitor':
+            if object_merge_check and key == "HealthMonitor":
                 mergedmon = len(avi_config_dict[key]) - mon_conv.mon_count
                 monitor_merged_message = \
                     'Total Objects of %s : %s (%s/%s monitor merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedmon),
                      mon_conv.mon_count)
                 LOG.info(monitor_merged_message)
                 print(monitor_merged_message)
                 continue
-            elif object_merge_check and key == 'PKIProfile':
-                mergedfile = len(avi_config_dict[key]) - \
-                             profile_conv.pki_count
+            if object_merge_check and key == "PKIProfile":
+                mergedfile = len(avi_config_dict[key]) - profile_conv.pki_count
                 profile_merged_message = \
                     'Total Objects of %s : %s (%s/%s profile merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedfile),
                      profile_conv.pki_count)
                 LOG.info(profile_merged_message)
                 print(profile_merged_message)
                 continue
-            elif object_merge_check and key == 'ApplicationPersistenceProfile':
-                mergedfile = len(avi_config_dict[key]) - \
-                             persist_conv.app_per_count
+            if object_merge_check and key == "ApplicationPersistenceProfile":
+                mergedfile = len(
+                    avi_config_dict[key]) - persist_conv.app_per_count
                 profile_merged_message = \
                     'Total Objects of %s : %s (%s/%s profile merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedfile),
                      persist_conv.app_per_count)
                 LOG.info(profile_merged_message)
                 print(profile_merged_message)
                 continue
-            elif object_merge_check and key == 'SSLKeyAndCertificate':
-                mergedfile = len(avi_config_dict[key]) - \
-                             profile_conv.certkey_count
+            if object_merge_check and key == "SSLKeyAndCertificate":
+                mergedfile = len(
+                    avi_config_dict[key]) - profile_conv.certkey_count
                 certkey_merged_message = \
                     'Total Objects of %s : %s (%s/%s cert key merged)' % \
                     (key, len(avi_config_dict[key]), abs(mergedfile),
                      profile_conv.certkey_count)
                 LOG.info(certkey_merged_message)
                 print(certkey_merged_message)
                 continue
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_converter.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,87 +4,115 @@
 # ========================================================================
 # Copyright 2021 VMware, Inc.  All rights reserved. VMware Confidential
 # ========================================================================
 ###
 
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
-
-
+from datetime import datetime
 import argparse
 import logging
 import os
 import sys
-
-import yaml
-
+import paramiko
 import avi.migrationtools
 import avi.migrationtools.f5_converter.converter_constants as conv_const
+import yaml
 from avi.migrationtools import avi_rest_lib
 from avi.migrationtools.ansible.ansible_config_converter import \
     AviAnsibleConverterMigration
 from avi.migrationtools.avi_converter import AviConverter
-from avi.migrationtools.avi_migration_utils import get_count, \
-    PasswordPromptAction
+from avi.migrationtools.avi_migration_utils import (PasswordPromptAction,
+                                                    get_count)
 from avi.migrationtools.avi_orphan_object import wipe_out_not_in_use
-from avi.migrationtools.f5_converter import (f5_config_converter,
-                                             f5_parser, scp_util)
+from avi.migrationtools.f5_converter import (f5_config_converter, f5_parser,
+                                             scp_util)
 from avi.migrationtools.f5_converter.conversion_util import F5Util
+from avi.migrationtools.f5_converter.ciphers_converter import CiphersConfigConv
 
 # urllib3.disable_warnings()
 LOG = logging.getLogger(__name__)
-sdk_version = getattr(avi.migrationtools, '__version__', None)
-controller_version = getattr(avi.migrationtools, '__controller_version__', None)
+sdk_version = getattr(avi.migrationtools, "__version__", None)
+controller_version = getattr(
+    avi.migrationtools,
+    "__controller_version__",
+    None)
 
 DEFAULT_SKIP_TYPES = [
-    'SystemConfiguration', 'Network', 'debugcontroller', 'VIMgrVMRuntime',
-    'VIMgrIPSubnetRuntime', 'Alert', 'VIMgrSEVMRuntime', 'VIMgrClusterRuntime',
-    'VIMgrHostRuntime', 'DebugController', 'ServiceEngineGroup',
-    'SeProperties', 'ControllerProperties', 'CloudProperties']
-
-ARG_DEFAULT_VALUE = {'version': False, 'skip_pki': False, 'ansible': False,
-                     'skip_default_file': False,
-                     'controller_version': controller_version,
-                     'option': 'cli-upload', 'distinct_app_profile': False,
-                     'f5_ssh_port': 22, 'reuse_http_policy': False,
-                     'vs_level_status': False, 'cloud_name': 'Default-Cloud',
-                     'convertsnat': False, 'ansible_filter_types': [],
-                     'user': 'admin', 'not_in_use': False,
-                     'vs_state': 'disable', 'f5_config_version': '11',
-                     'ansible_skip_types': ['SystemConfiguration',
-                                            'Network',
-                                            'debugcontroller',
-                                            'VIMgrVMRuntime',
-                                            'VIMgrIPSubnetRuntime',
-                                            'Alert',
-                                            'VIMgrSEVMRuntime',
-                                            'VIMgrClusterRuntime',
-                                            'VIMgrHostRuntime',
-                                            'DebugController',
-                                            'ServiceEngineGroup',
-                                            'SeProperties',
-                                            'ControllerProperties',
-                                            'CloudProperties'],
-                     'input_folder_location': './', 'no_object_merge': True}
+    "SystemConfiguration",
+    "Network",
+    "debugcontroller",
+    "VIMgrVMRuntime",
+    "VIMgrIPSubnetRuntime",
+    "Alert",
+    "VIMgrSEVMRuntime",
+    "VIMgrClusterRuntime",
+    "VIMgrHostRuntime",
+    "DebugController",
+    "ServiceEngineGroup",
+    "SeProperties",
+    "ControllerProperties",
+    "CloudProperties",
+]
+
+ARG_DEFAULT_VALUE = {
+    "version": False,
+    "skip_pki": False,
+    "ansible": False,
+    "skip_default_file": False,
+    "controller_version": controller_version,
+    "option": "cli-upload",
+    "distinct_app_profile": False,
+    "f5_ssh_port": 22,
+    "reuse_http_policy": False,
+    "vs_level_status": False,
+    "cloud_name": "Default-Cloud",
+    "convertsnat": False,
+    "ansible_filter_types": [],
+    "user": "admin",
+    "not_in_use": False,
+    "vs_state": "disable",
+    "f5_config_version": "11",
+    "ansible_skip_types": [
+        "SystemConfiguration",
+        "Network",
+        "debugcontroller",
+        "VIMgrVMRuntime",
+        "VIMgrIPSubnetRuntime",
+        "Alert",
+        "VIMgrSEVMRuntime",
+        "VIMgrClusterRuntime",
+        "VIMgrHostRuntime",
+        "DebugController",
+        "ServiceEngineGroup",
+        "SeProperties",
+        "ControllerProperties",
+        "CloudProperties",
+    ],
+    "input_folder_location": "./",
+    "object_merge": True,
+}
 
 ARG_CHOICES = {
-    'option': ['cli-upload', 'auto-upload'],
-    'vs_state': ['enable', 'disable']
+    "option": ["cli-upload", "auto-upload"],
+    "vs_state": ["enable", "disable"],
 }
 
 
+is_host_present = False
+
+
 class F5Converter(AviConverter):
     def __init__(self, args):
         self.bigip_config_file = args.bigip_config_file
         self.skip_default_file = args.skip_default_file
         self.skip_pki = args.skip_pki
         self.f5_config_version = args.f5_config_version
         self.input_folder_location = args.input_folder_location
-        self.output_file_path = args.output_file_path if args.output_file_path \
-            else 'output'
+        self.output_file_path = args.output_file_path if args.output_file_path else "output"
         self.option = args.option
         self.user = args.user
         self.password = args.password
         self.controller_ip = args.controller_ip
         self.tenant = args.tenant
         self.cloud_name = args.cloud_name
         self.vs_state = args.vs_state
@@ -94,15 +122,15 @@
         self.f5_ssh_user = args.f5_ssh_user
         self.f5_ssh_password = args.f5_ssh_password
         self.f5_ssh_port = args.f5_ssh_port
         self.f5_key_file = args.f5_key_file
         self.ignore_config = args.ignore_config
         self.partition_config = args.partition_config
         self.version = args.version
-        self.object_merge_check = args.no_object_merge
+        self.object_merge_check = args.object_merge
         # config_patch.py args taken into class variable
         self.patch = args.patch
         # vs_filter.py args taken into classs variable
         self.vs_filter = args.vs_filter
         # skip the object while creating ansible playbook
         self.ansible_skip_types = args.ansible_skip_types
         # Create ansible object playbook based on filter types.
@@ -123,195 +151,244 @@
         self.vs_level_status = args.vs_level_status
         # Added args for creating test vips
         self.test_vip = args.test_vip
         # Support for vrf ref and segroup ref
         self.vrf = args.vrf
         self.segroup = args.segroup
         self.reuse_http_policy = args.reuse_http_policy
-
+        self.skip_disabled_vs = args.skip_disabled_vs
         # Created f5 util object.
         self.conversion_util = F5Util()
 
     def print_pip_and_controller_version(self):
         """
         This method print the sdk version and controller version
         :return:
         """
         # Added input parameters to log file
-        params = ' '.join(sys.argv)
+        params = " ".join(sys.argv)
         if self.f5_ssh_password:
-            params = params.replace(self.f5_ssh_password, '******')
+            params = params.replace(self.f5_ssh_password, "******")
         if self.password:
-            params = params.replace(self.password, '******')
-        LOG.info("Input parameters: %s" % params)
+            params = params.replace(self.password, "******")
+        LOG.info("Input parameters: %s", params)
         # Add logger and print avi migrationtool version
-        LOG.info('AVI sdk version: %s Controller Version: %s'
-                 % (sdk_version, self.controller_version))
-        print('AVI sdk version: %s Controller Version: %s' \
-              % (sdk_version, self.controller_version))
+        LOG.info(
+            "AVI sdk version: %s Controller Version: %s",
+            sdk_version,
+            self.controller_version,
+        )
+        print(
+            "AVI sdk version: %s Controller Version: %s",
+            sdk_version,
+            self.controller_version,
+        )
 
     def upload_config_to_controller(self, avi_config):
         """
 
         :param avi_config: conversion of f5 to avi compatible dict.
         :return:
         """
         avi_rest_lib.upload_config_to_controller(
-            avi_config, self.controller_ip, self.user, self.password,
-            self.tenant, self.controller_version)
+            avi_config,
+            self.controller_ip,
+            self.user,
+            self.password,
+            self.tenant,
+            self.controller_version,
+        )
 
     def convert(self):
         if not os.path.exists(self.output_file_path):
             os.mkdir(self.output_file_path)
         self.init_logger_path()
         output_dir = os.path.normpath(self.output_file_path)
         input_dir = os.path.normpath(self.input_folder_location)
         is_download_from_host = False
         if self.f5_host_ip:
-            input_dir = output_dir + os.path.sep + self.f5_host_ip + \
-                os.path.sep + "input"
+            input_dir = output_dir + os.path.sep + self.f5_host_ip + os.path.sep + "input"
             if not os.path.exists(input_dir):
                 os.makedirs(input_dir)
-            output_dir = output_dir + os.path.sep + self.f5_host_ip + \
-                os.path.sep + "output"
+            output_dir = output_dir + os.path.sep + self.f5_host_ip + os.path.sep + "output"
             if not os.path.exists(output_dir):
                 os.makedirs(output_dir)
             is_download_from_host = True
+        is_host_present=is_download_from_host
         user_ignore = {}
+
         # Read the attributes for user ignore val
         if self.ignore_config:
             with open(self.ignore_config) as stream:
                 user_ignore = yaml.safe_load(stream)
         custom_mappings = None
         if self.custom_config:
             with open(self.custom_config) as stream:
                 custom_mappings = yaml.safe_load(stream)
         partitions = []
         # Add logger and print avi f5 converter version
         self.print_pip_and_controller_version()
-        if self.partition_config and type(self.partition_config) == str:
-            partitions = self.partition_config.split(',')
-        elif self.partition_config and type(self.partition_config) == list:
+        if self.partition_config and isinstance(self.partition_config, str):
+            partitions = self.partition_config.split(",")
+        elif self.partition_config and isinstance(self.partition_config, list):
             partitions = self.partition_config
         source_file = None
         if is_download_from_host:
             LOG.debug("Copying files from host")
             print("Copying Files from Host...")
-            scp_util.get_files_from_f5(input_dir, self.f5_host_ip,
-                                       self.f5_ssh_user, self.f5_ssh_password,
-                                       None, self.f5_ssh_port)
+            scp_util.get_files_from_f5(
+                input_dir,
+                self.f5_host_ip,
+                self.f5_ssh_user,
+                self.f5_ssh_password,
+                None,
+                self.f5_ssh_port,
+            )
             LOG.debug("Copied input files")
             source_file = open(input_dir + os.path.sep + "bigip.conf", "r")
             files = os.listdir(input_dir)
-            for f in files:
-                if f.endswith('_bigip.conf'):
-                    partitions.append(input_dir + os.path.sep + f)
+            for file_name in files:
+                if file_name.endswith("_bigip.conf"):
+                    partitions.append(input_dir + os.path.sep + file_name)
         elif self.bigip_config_file:
             source_file = open(self.bigip_config_file, "r")
         if not source_file:
-            print('Not found F5 configuration file')
+            print("Not found F5 configuration file")
             return
         source_str = source_file.read()
         total_size = source_file.tell()
-        LOG.debug('Parsing config file:' + source_file.name)
+        LOG.debug("Parsing config file: %s", source_file.name)
         print("Parsing Input Configuration...")
         f5_config_dict, not_supported_list = f5_parser.parse_config(
             source_str, total_size, self.f5_config_version)
-        LOG.debug('Config file %s parsed successfully' % source_file.name)
+
+
+        if is_download_from_host:
+            cipher_conf_file = open(input_dir + os.path.sep + "cipher.conf", "r")
+            cipher_config_dict=None
+            if cipher_conf_file:
+                cipher_source_str = cipher_conf_file.read()
+                cipher_total_size = cipher_conf_file.tell()
+                cipher_config_dict, cipher_not_supported_list = f5_parser.parse_config(
+                cipher_source_str, cipher_total_size, self.f5_config_version)
+
+        LOG.debug("Config file %s parsed successfully", source_file.name)
         avi_config_dict = None
-        LOG.debug('Parsing defaults files')
-        f5_defaults_dict = self.get_default_config(is_download_from_host,
-                                                   input_dir)
+        LOG.debug("Parsing defaults files")
+        f5_defaults_dict = self.get_default_config(
+            is_download_from_host, input_dir)
         # Added to get not supported parse config
         not_supported_list_partition = []
         if partitions:
             partition_conf = {}
             for partition in partitions:
                 with open(partition, "r") as p_source_file:
                     p_src_str = p_source_file.read()
                     total_size = p_source_file.tell()
-                LOG.debug('Parsing partition config file:' +
-                          p_source_file.name)
+                LOG.debug(
+                    "Parsing partition config file: %s",
+                    p_source_file.name)
                 print("Parsing Partitions Configuration...")
                 partition_dict, not_supported_list = f5_parser.parse_config(
                     p_src_str, total_size, self.f5_config_version)
                 LOG.debug(
-                    'Config file %s parsed successfully' % p_source_file.name)
+                    "Config file %s parsed successfully",
+                    p_source_file.name)
                 # TO get all not supported configuration.
-                not_supported_list_partition = not_supported_list_partition \
-                    + not_supported_list
+                not_supported_list_partition = not_supported_list_partition + not_supported_list
                 self.dict_merge(partition_conf, partition_dict)
             self.dict_merge(partition_conf, f5_config_dict)
             f5_config_dict = partition_conf
         # Added not supported parse config to file
-        merged_not_supported_list = (not_supported_list +
-                                     not_supported_list_partition)
+        merged_not_supported_list = not_supported_list + not_supported_list_partition
         # Added status of all command that are not supported in parsing.
         for command in merged_not_supported_list:
-            d = command.rsplit('/', 1)
-            object_type = d[0].rsplit(' ', 1)
+            d = command.rsplit("/", 1)
+            object_type = d[0].rsplit(" ", 1)
             object_name = '%s/%s' % (object_type[-1], d[-1])
-            self.conversion_util.add_status_row(object_type[0], '', object_name,
-                                                conv_const.STATUS_NOT_SUPPORTED)
-        LOG.debug('Defaults files parsed successfully')
-        LOG.debug('Conversion started')
+            self.conversion_util.add_status_row(
+                object_type[0], "", object_name, conv_const.STATUS_NOT_SUPPORTED)
+        LOG.debug("Defaults files parsed successfully")
+        LOG.debug("Conversion started")
         self.dict_merge(f5_defaults_dict, f5_config_dict)
         f5_config_dict = f5_defaults_dict
         report_name = os.path.splitext(os.path.basename(source_file.name))[0]
-        avi_config_dict, part_mapping = f5_config_converter.convert(
-            f5_config_dict, output_dir, self.vs_state, input_dir,
-            self.f5_config_version, self.object_merge_check,
-            self.controller_version, report_name, self.prefix,
-            self.con_snatpool, user_ignore, self.profile_path,
-            self.tenant, self.cloud_name, self.f5_passphrase_file,
-            self.vs_level_status, self.vrf, self.segroup, custom_mappings,
-            self.skip_pki, self.distinct_app_profile, self.reuse_http_policy)
+        start = datetime.now()
+
+        migrated_ciphers_dict={}
+        migrated_ciphers_group_dict={}
+        if is_download_from_host:
+            cipher_conv = CiphersConfigConv(self.f5_host_ip, self.f5_ssh_password,
+                                            self.f5_ssh_user,self.controller_ip,self.user,
+                                            self.password,self.f5_config_version)
 
+            migrated_ciphers_dict,migrated_ciphers_group_dict=cipher_conv.migrate_ciphers_and_cipher_group(
+                                                            f5_config_dict,cipher_config_dict,self.f5_config_version)
+
+        avi_config_dict, part_mapping = f5_config_converter.convert(
+            f5_config_dict, output_dir, self.vs_state, input_dir, self.f5_config_version,
+            self.object_merge_check, self.controller_version, report_name, self.prefix,
+            self.con_snatpool, user_ignore, self.profile_path, self.tenant, self.cloud_name,
+            self.f5_passphrase_file, self.vs_level_status, self.vrf, self.segroup,
+            custom_mappings, self.skip_pki, self.distinct_app_profile, self.reuse_http_policy,
+            self.skip_disabled_vs,migrated_ciphers_dict=migrated_ciphers_dict,
+            migrated_ciphers_group_dict=migrated_ciphers_group_dict
+        )
+        # validating avi config dict for object length
+        self.trim_object_length(avi_config_dict)
         avi_config = self.process_for_utils(avi_config_dict)
         # Check if flag true then skip not in use object
         if self.not_in_use:
             avi_config = wipe_out_not_in_use(avi_config)
         self.write_output(avi_config, output_dir, '%s-Output.json' %
                           report_name)
+        if self.vs_filter:
+            F5Util().remove_vs_names_when_vs_filter_is_provided(
+                output_dir=output_dir, report_name=report_name, vs_names=self.vs_filter)
         # Call to create ansible playbook if create ansible flag set.
         if self.create_ansible:
             avi_traffic = AviAnsibleConverterMigration(
-                avi_config, output_dir, self.prefix, self.not_in_use,
-                test_vip=self.test_vip, skip_types=self.ansible_skip_types,
-                partitions=part_mapping, controller_version=self.controller_version,
-                filter_types=self.ansible_filter_types)
+                avi_config,
+                output_dir,
+                self.prefix,
+                self.not_in_use,
+                test_vip=self.test_vip,
+                skip_types=self.ansible_skip_types,
+                partitions=part_mapping,
+                controller_version=self.controller_version,
+                filter_types=self.ansible_filter_types,
+            )
             avi_traffic.write_ansible_playbook(
-                self.f5_host_ip, self.f5_ssh_user, self.f5_ssh_password, 'f5')
-        if self.option == 'auto-upload':
+                self.f5_host_ip, self.f5_ssh_user, self.f5_ssh_password, "f5")
+        if self.option == "auto-upload":
             self.upload_config_to_controller(avi_config)
-        print("Total Warning: ", get_count('warning'))
-        print("Total Errors: ", get_count('error'))
+        print("Total Warning: ", get_count("warning"))
+        print("Total Errors: ", get_count("error"))
+
 
     def get_default_config(self, is_download, path):
         """
 
         :param is_download:
         :param path:
         :return:
         """
         f5_defaults_dict = {}
         if is_download:
             print("Copying Files from Host...")
-            with open(path + os.path.sep + "profile_base.conf", "r") as \
-                    profile:
+            with open(path + os.path.sep + "profile_base.conf", "r") as profile:
                 profile_base = profile.read()
                 total_size = profile.tell()
-            with open(path + os.path.sep + "base_monitors.conf", "r") as \
-                    monitor:
+            with open(path + os.path.sep + "base_monitors.conf", "r") as monitor:
                 monitor_base = monitor.read()
                 total_size_mnt = monitor.tell()
             if self.skip_default_file:
-                LOG.warning('Skipped default profile base file : %s\nSkipped '
-                            'default monitor base file : %s'
-                            % (profile.name, monitor.name))
+                LOG.warning(
+                    "Skipped default profile base file : %s\nSkipped "
+                    "default monitor base file : %s", profile.name, monitor.name, )
                 return f5_defaults_dict
             profile_dict, not_supported_list = f5_parser.parse_config(
                 profile_base, total_size, self.f5_config_version)
             monitor_dict, not_supported_list = f5_parser.parse_config(
                 monitor_base, total_size_mnt, self.f5_config_version)
             if int(self.f5_config_version) == 10:
                 default_mon = monitor_dict.get("monitor", {})
@@ -320,110 +397,118 @@
                     default_mon[key.replace("type ", "")] = root_mon[key]
                 monitor_dict["monitor"] = default_mon
                 del monitor_dict["monitorroot"]
             profile_dict.update(monitor_dict)
             f5_defaults_dict = profile_dict
 
         else:
-            if self.f5_config_version == '12':
-                self.f5_config_version = '11'
-            if getattr(sys, 'frozen', False):
+            if self.f5_config_version == "12":
+                self.f5_config_version = "11"
+            if getattr(sys, "frozen", False):
                 # running in a exe bundle
                 dir_path = os.path.abspath(os.path.dirname(__file__))
             else:
                 # Added to get directory path.
                 dir_path = self.conversion_util.get_project_path()
                 dir_path = dir_path + os.path.sep + "f5_converter"
             with open(dir_path + os.path.sep + "f5_v%s_defaults.conf" %
                       self.f5_config_version, "r") as defaults_file:
                 if self.skip_default_file:
                     LOG.warning(
-                        'Skipped default file : %s' % defaults_file.name)
+                        "Skipped default file : %s",
+                        defaults_file.name)
                     return f5_defaults_dict
                 f5_defaults_dict, not_supported_list = f5_parser.parse_config(
-                    defaults_file.read(), defaults_file.tell(),
-                    self.f5_config_version)
+                    defaults_file.read(), defaults_file.tell(), self.f5_config_version)
         return f5_defaults_dict
 
     def dict_merge(self, dct, merge_dct):
         """
         This method merge the two dicts into one.
         :param dct:
         :param merge_dct:
         :return:
         """
-        for k, v in merge_dct.items():
-            if (k in dct and isinstance(dct[k], dict) and
-                    isinstance(merge_dct[k], dict)):
-                self.dict_merge(dct[k], merge_dct[k])
+        for key in merge_dct:
+            if key in dct and isinstance(
+                    dct[key], dict) and isinstance(merge_dct[key], dict):
+                self.dict_merge(dct[key], merge_dct[key])
             else:
-                dct[k] = merge_dct[k]
+                dct[key] = merge_dct[key]
 
 
 def set_default_args(terminal_args):
+    """
+    set default arguments
+    """
     for argument in terminal_args.__dict__:
-        if (argument in ARG_DEFAULT_VALUE and
-                terminal_args.__dict__[argument] is None):
+        if argument in ARG_DEFAULT_VALUE and terminal_args.__dict__[
+                argument] is None:
             terminal_args.__dict__[argument] = ARG_DEFAULT_VALUE[argument]
 
 
 def get_terminal_args(terminal_args):
+    """
+    for getting terminal arguments
+    """
+    if terminal_args.__dict__["ansible_skip_types"]:
+        terminal_args.__dict__["ansible_skip_types"] = terminal_args.__dict__[
+            "ansible_skip_types"].split(",")
+    if terminal_args.__dict__["ansible_filter_types"]:
+        terminal_args.__dict__["ansible_filter_types"] = terminal_args.__dict__[
+            "ansible_filter_types"].split(",")
+    if terminal_args.__dict__["vs_filter"]:
+        terminal_args.__dict__["vs_filter"] = terminal_args.__dict__[
+            "vs_filter"].split(",")
+    if terminal_args.__dict__["partition_config"]:
+        terminal_args.__dict__["partition_config"] = terminal_args.__dict__[
+            "partition_config"].split(",")
 
-    if terminal_args.__dict__['ansible_skip_types']:
-        terminal_args.__dict__['ansible_skip_types'] =\
-            terminal_args.__dict__['ansible_skip_types'].split(",")
-    if terminal_args.__dict__['ansible_filter_types']:
-        terminal_args.__dict__['ansible_filter_types'] =\
-            terminal_args.__dict__['ansible_filter_types'].split(",")
-    if terminal_args.__dict__['vs_filter']:
-        terminal_args.__dict__['vs_filter'] =\
-            terminal_args.__dict__['vs_filter'].split(",")
-    if terminal_args.__dict__['partition_config']:
-        terminal_args.__dict__['partition_config'] =\
-            terminal_args.__dict__['partition_config'].split(",")
-
-    LOG.debug("\n TERMINAL ARGS: %s" % terminal_args)
+    LOG.debug("\n TERMINAL ARGS: %s", terminal_args)
 
     if terminal_args.args_config_file:
         with open(terminal_args.args_config_file) as file:
             global config_file
             config_file = yaml.full_load(file)
             if config_file:
-                LOG.debug("\n CONFIG ARGS: %s" % config_file)
+                LOG.debug("\n CONFIG ARGS: %s", config_file)
                 for terminal_arg in terminal_args.__dict__:
-                    if (terminal_arg not in config_file.keys() and
-                        terminal_args.__dict__[terminal_arg] is None and
-                            terminal_arg in ARG_DEFAULT_VALUE.keys()):
-                        terminal_args.__dict__[terminal_arg] = \
-                            ARG_DEFAULT_VALUE[terminal_arg]
-                    elif (terminal_arg in config_file.keys() and
-                          config_file[terminal_arg] is None and
-                          terminal_args.__dict__[terminal_arg] is None and
-                          terminal_arg in ARG_DEFAULT_VALUE.keys()):
-                        terminal_args.__dict__[terminal_arg] = \
-                            ARG_DEFAULT_VALUE[terminal_arg]
-                    elif (terminal_arg in config_file.keys() and
-                          terminal_arg in ARG_DEFAULT_VALUE.keys()):
-                        if (terminal_args.__dict__[terminal_arg] ==
-                                ARG_DEFAULT_VALUE[terminal_arg] and
-                                not isinstance(terminal_args.__dict__
-                                               [terminal_arg], bool)):
+                    if (
+                        terminal_arg not in config_file.keys()
+                        and terminal_args.__dict__[terminal_arg] is None
+                        and terminal_arg in ARG_DEFAULT_VALUE.keys()
+                    ):
+                        terminal_args.__dict__[
+                            terminal_arg] = ARG_DEFAULT_VALUE[terminal_arg]
+                    elif (
+                        terminal_arg in config_file.keys()
+                        and config_file[terminal_arg] is None
+                        and terminal_args.__dict__[terminal_arg] is None
+                        and terminal_arg in ARG_DEFAULT_VALUE.keys()
+                    ):
+                        terminal_args.__dict__[
+                            terminal_arg] = ARG_DEFAULT_VALUE[terminal_arg]
+                    elif terminal_arg in config_file.keys() and terminal_arg in ARG_DEFAULT_VALUE.keys():
+                        if terminal_args.__dict__[terminal_arg] == ARG_DEFAULT_VALUE[terminal_arg] and not isinstance(
+                                terminal_args.__dict__[terminal_arg], bool):
                             continue
-                        elif (terminal_args.__dict__[terminal_arg] ==
-                              ARG_DEFAULT_VALUE[terminal_arg]):
-                            terminal_args.__dict__[terminal_arg] =\
-                                config_file[terminal_arg]
+                        if terminal_args.__dict__[
+                                terminal_arg] == ARG_DEFAULT_VALUE[terminal_arg]:
+                            terminal_args.__dict__[
+                                terminal_arg] = config_file[terminal_arg]
                         elif terminal_args.__dict__[terminal_arg] is None:
-                            terminal_args.__dict__[terminal_arg] =\
-                                config_file[terminal_arg]
-                    elif (terminal_arg in config_file.keys() and
-                          terminal_arg not in ARG_DEFAULT_VALUE.keys() and
-                          terminal_args.__dict__[terminal_arg] is None):
-                        terminal_args.__dict__[terminal_arg] = \
-                            config_file[terminal_arg]
+                            terminal_args.__dict__[
+                                terminal_arg] = config_file[terminal_arg]
+                    elif (
+                        terminal_arg in config_file.keys()
+                        and terminal_arg not in ARG_DEFAULT_VALUE.keys()
+                        and terminal_args.__dict__[terminal_arg] is None
+                    ):
+                        terminal_args.__dict__[
+                            terminal_arg] = config_file[terminal_arg]
 
                 # Validate argument choice values
                 for argument in ARG_CHOICES.keys():
                     if terminal_args.__dict__[argument] not in ARG_CHOICES[argument]:
                         msg = "%s: error: argument --%s: invalid choice: " \
                               "'%s' (choose from %s)" % (parser.prog, argument,
                                                          terminal_args.__dict__[argument],
@@ -433,308 +518,420 @@
                         exit(1)
             else:
                 set_default_args(terminal_args)
     else:
         set_default_args(terminal_args)
     terminal_args.f5_config_version = str(terminal_args.f5_config_version)
 
-    LOG.debug("\n FINAL ARGS ============== %s" % terminal_args.__dict__)
+    LOG.debug("\n FINAL ARGS ============== %s", terminal_args.__dict__)
     return terminal_args
 
 
 if __name__ == "__main__":
 
-    HELP_STR = '''
+    HELP_STR = """
     Converts F5 Config to Avi config.
 
     Example to convert F5 config file to Avi json config:
         f5_converter.py -f bigip.conf
-    Usecase: 
-        Runs migration tool against local bipip.conf. (bigip.conf doesn't contain certificates and keys. Migration tool will auto-generate place holder ones)
+    Usecase:
+        Runs migration tool against local bipip.conf. (bigip.conf doesn't contain certificates and keys.
+        Migration tool will auto-generate place holder ones)
 
     Example to skip default file in f5:
         f5_converter.py -f bigip.conf --skip_default_file
     Usecase:
         To skip default profile and monitor configuration
 
     Example to f5_config_version
         f5_converter.py -f bigip.conf -v 10
     Usecase:
         Used for specifying the version of LTM you're migrating
 
     Example to download config from f5 host and convert to Avi config:
         f5_converter.py --f5_host_ip 1.1.1.1 --f5_ssh_user username --f5_ssh_password password
-    Usecase: 
+    Usecase:
         Download configuration, certificates, and keys, to create Avi json config
 
     Example to auto upload to controller after conversion:
         f5_converter.py -f bigip.conf -O auto-upload -c 2.2.2.2 -u username -p password -t tenant
-    Usecase: 
-        Run the migration tool, create the Avi config, and upload all in one step
+    Usecase:
+        Run the migration tool, create the Avi config,
+        and upload all in one step
 
     Example to use -s or --vs_state option:
         f5_converter.py -f bigip.conf -s enable
-    Usecase:      
+    Usecase:
         Sets traffic_enabled to true in Virtual Service configuration
 
     Example to use input file for local certs and key
         f5_converter.py -f bigip.conf -l /home/username
-    Usecase: 
-        Creates Avi config mapping local certificates and keys. Local certificate and key names must match names in config to properly map
+    Usecase:
+        Creates Avi config mapping local certificates and keys.
+        Local certificate and key names must match names in config to properly map
         F5 appends digits to the end of the original certificate name
 
     Example to use --controller_version option:
         f5_converter.py -f bigip.conf --controller_version <21.1.4>
     Usecase: To provide the version of controller for getting output in respective controller format.
 
     Example to use ignore config option:
          f5_converter.py -f bigip.conf --ignore_config
-    Usecase: 
-        The attributes mentioned in ignore_config.yaml will appear in ignore column in excel sheet instead of skip. It will need an ignore_config.yaml file in the input directory defined by user
+    Usecase:
+        The attributes mentioned in ignore_config.
+        yaml will appear in ignore column in excel sheet instead of skip.
+        It will need an ignore_config.yaml file in the input directory defined by user
         <Example Format>
             monitor:
               https:
               - 'destination'
               gateway-icmp:
               - 'destination'
               - 'adaptive'
 
     Example to use --partition_config option:
        f5_converter.py -f bigip.conf --partition_config /home/username/abc.txt
-    Usecase: 
-        When auto-download option enable. It will download the files from different f5 partitions with comma separated path provided with partition config option.
+    Usecase:
+        When auto-download option enable.
+        It will download the files from different
+        f5 partitions with comma separated path provided with partition config option.
 
-    Example to use no object merge option:
-        f5_converter.py -f bigip.conf --no_object_merge
-    Usecase: 
-        When we don't need to merge two of the same objects (Multiple objects with matching attributes but different names)
+    Example to use  object merge option:
+        f5_converter.py -f bigip.conf --object_merge
+    Usecase:
+        When we don't need to merge two of the same objects
+        (Multiple objects with matching attributes but different names)
 
     Example to patch the config after conversion:
         f5_converter.py -f bigip.conf --patch test/patch.yaml
         where patch.yaml file contains
         <avi_object example Pool>:
         Pool:
           - match_name: <existing name example p1>
             patch:
               name: <changed name example coolpool>
     Usecase:
-        Use for bulk changes to config. Example: Enabling XFF in application profile or disabling traffic on VS
+        Use for bulk changes to config. Example:
+        Enabling XFF in application profile or disabling traffic on VS
 
     Example to export/migrate list of virtual services
          f5_converter.py -f bigip.conf --vs_filter vs1,vs3,vs5
-    Usecase: 
-        Comma seperated list that is useful for only migrating VSs and their child objects that are in scope
+    Usecase:
+        Comma seperated list that is useful for only migrating VSs
+        and their child objects that are in scope
 
     Example to skip Avi object during playbook creation
-        f5_converter.py -f bigip.conf --ansible --ansible_skip_types DebugController
+        f5_converter.py -f bigip.conf --ansible
+        --ansible_skip_types DebugController
     Usecase:
         Comma separated list of Avi Object types to skip during conversion.
-        Example: DebugController, ServiceEngineGroup will skip debugcontroller and serviceengine objects
+        Example: DebugController, ServiceEngineGroup will
+        skip debugcontroller and serviceengine objects
 
     Example to filter ansible object
-        f5_converter.py -f bigip.conf --ansible --ansible_filter_types virtualservice, pool
+        f5_converter.py -f bigip.conf --ansible
+        --ansible_filter_types virtualservice, pool
     Usecase:
         Comma separated list of Avi Objects types to include during conversion.
-        Example: VirtualService , Pool will do ansible conversion only for Virtualservice and Pool objects
+        Example: VirtualService , Pool will do ansible conversion
+        only for Virtualservice and Pool objects
 
     Example to use ansible option:
         f5_converter.py -f bigip.conf --ansible
-    Usecase: To generate the ansible playbook for the Avi configuration which can be used for upload to controller
+    Usecase: To generate the ansible playbook for the Avi
+    configuration which can be used for upload to controller
 
     Example to add the prefix to Avi object name:
         f5_converter.py -f bigip.conf --prefix abc
-    Usecase: 
-        When two configuration is to be uploaded to same controller then in order to differentiate between the objects that will be uploaded in second time.
+    Usecase:
+        When two configuration is to be uploaded to same controller then in order
+        to differentiate between the objects that will be uploaded in second time.
 
     Example to convert snatpool into individual address
         f5_converter.py -f bigip.conf --convertsnat
-    Usecase: 
+    Usecase:
         Flag to enable Source Network Address Translation in Avi.
 
     Example to use not_in_use option:
         f5_converter.py -f bigip.conf --not_in_use
-    Usecase: 
-        Dangling object which are not referenced by any Avi object will be removed
+    Usecase:
+        Dangling object which are not referenced by any
+        Avi object will be removed
 
     Example to provide baseline json file absolute location:
-        f5_converter.py -f bigip.conf --baseline_profile /home/<'sys_conf.json' or 'bigip-Output.json'>
-    Usecase: 
-        Need to merge objects if there is migration of two f5 instances/box to single controller.
+        f5_converter.py -f bigip.conf --baseline_profile
+        /home/<'sys_conf.json' or 'bigip-Output.json'>
+    Usecase:
+        Need to merge objects if there is migration of two
+        f5 instances/box to single controller.
 
     Example to provide passphrase of encrypted certs and certkey file location
          f5_converter.py -f bigip.conf -l /home/certs/
          --f5_passphrase_file passphrase.yaml
          passphrase.yaml file contains
           <file_name>:<passphrase>
           <file_name2>:<passphrase2>
           Example:
             mcqcim.key: ZcZawJ7ps0AJ+5TMDi7UA==
             avi_key.pem : foobar
     Usecase:
-        To complete an offline migration, you need to call a directory containing certs and keys because the bigip.conf doesn't contain them. If not used, the migration tool will auto create placeholder ones.
+        To complete an offline migration,
+        you need to call a directory containing certs and keys because the
+        bigip.conf doesn't contain them. If not used,
+        the migration tool will auto create placeholder ones.
 
     Example to use vs level status option:
         f5_converter.py -f bigip.conf --vs_level_status
-    Usecase: 
+    Usecase:
         To get the vs level status for enhanced reporting for the Avi objects in excel sheet
 
     Example to use segroup flag
         f5_converter.py -f bigip.conf --segroup segroup_name
     UseCase:
         To add or update segroup reference of vs
 
     Example to use vrf flag
         f5_converter.py -f bipip.conf --vrf vrf_name
-    Usecase: 
+    Usecase:
         Change all the vrf reference in the configuration while conversion
 
     Example to use args config_file
        f5_converter.py --args_config_file ./test/config.yaml
-    Usecase: 
-        To pass the cli params using config.yaml file bigip_config_file: './test/bigip_v11.conf' controller_version: '20.1.4'
+    Usecase:
+        To pass the cli params using config.yaml file bigip_config_file:
+        './test/bigip_v11.conf' controller_version: '20.1.4'
         File located https://github.com/vmware/alb-sdk/blob/eng/python/avi/migrationtools/f5_converter/config.yaml
 
     Example to use reuse http policy flag
         f5_converter.py -f bipip.conf --reuse_http_policy
     Usecase:
         Create http policy once and reuse it with all applicable VSs
 
     Example to use the skip PKI flag
         f5_converter.py -f bipip.conf --skip_pki
     Usecase:
-        --skip_pki flag is used for testing and debugging. Sometimes pki profile is quite big and it takes more time to convert so for testing purpose we use this flag to skip the pki profile
-    '''
+        --skip_pki flag is used for testing and debugging.
+        Sometimes pki profile is quite big and it takes
+        more time to convert so for testing purpose
+        we use this flag to skip the pki profile
+    """
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.RawTextHelpFormatter,
         description=(HELP_STR))
 
     # Create Ansible Script based on Flag
-    parser.add_argument('--ansible',
-                        help='Flag for create ansible files (Create and Delete playbooks)',
-                        action='store_true')
+    parser.add_argument(
+        "--ansible",
+        help="Flag for create ansible files (Create and Delete playbooks)",
+        action="store_false",
+    )
     # Added command line args to take skip type for ansible playbook
-    parser.add_argument('--ansible_skip_types',
-                        help='Comma separated list of Avi Object types to skip '
-                             'during conversion.\n  Example: -s DebugController,'
-                             'ServiceEngineGroup will skip debugcontroller and '
-                             'serviceengine objects')
+    parser.add_argument(
+        "--ansible_skip_types",
+        help="Comma separated list of Avi Object types to skip "
+        "during conversion.\n  Example: -s DebugController,"
+        "ServiceEngineGroup will skip debugcontroller and "
+        "serviceengine objects",
+    )
     # Added command line args to take skip type for ansible playbook
-    parser.add_argument('--ansible_filter_types',
-                        help='Comma separated list of Avi Objects types to '
-                             'include during conversion.\n Example: -f '
-                             'VirtualService, Pool will do ansible conversion '
-                             'only for Virtualservice and Pool objects')
+    parser.add_argument(
+        "--ansible_filter_types",
+        help="Comma separated list of Avi Objects types to "
+        "include during conversion.\n Example: -f "
+        "VirtualService, Pool will do ansible conversion "
+        "only for Virtualservice and Pool objects",
+    )
     # Added args for baseline profile json file
-    parser.add_argument('--baseline_profile', help='Absolute path for json '
-                        'File containing baseline profiles')
-    parser.add_argument('-c', '--controller_ip',
-                        help='Destination controller ip or fqdn for config upload')
-    parser.add_argument('--cloud_name', help='Destination cloud name')
-    parser.add_argument('--controller_version',
-                        help='Target Avi controller version')
+    parser.add_argument(
+        "--baseline_profile",
+        help="Absolute path for json " "File containing baseline profiles",
+    )
+    parser.add_argument(
+        "-c",
+        "--controller_ip",
+        help="Destination controller ip or fqdn for config upload",
+    )
+    parser.add_argument(
+        "--cloud_name",
+        help="Destination cloud name",
+        required=True)
+    parser.add_argument(
+        "--controller_version",
+        help="Target Avi controller version",
+        required=True)
     # Added snatpool conversion option
-    parser.add_argument('--convertsnat',
-                        help='Flag for converting snatpool into '
-                             'individual addresses',
-                        action="store_true")
-    parser.add_argument('--custom_config',
-                        help='iRule/monitor custom mapping yml file path. (File containing converted iRules or health monitors)')
-    parser.add_argument('--distinct_app_profile',  action="store_true",
-                        help="Option to create distinct application profile for"
-                             " each VS even though it is shared in F5 config")
-    parser.add_argument('-f', '--bigip_config_file',
-                        help='Absolute path for F5 config file')
-    parser.add_argument('--f5_host_ip', help='Host ip of f5 instance')
-    parser.add_argument('--f5_key_file',
-                        help='F5 host key file location if key based ' +
-                             'authentication')
-    parser.add_argument('--f5_passphrase_file',
-                        help='F5 key passphrase yaml file path')
-    parser.add_argument('--f5_ssh_user', help='f5 host ssh username')
-    parser.add_argument('--f5_ssh_password', action=PasswordPromptAction,
-                        nargs='?', help='f5 host ssh password if password '
-                                        'based authentication. Input prompt '
-                                        'will appear if no value provided')
-    parser.add_argument('--f5_ssh_port',
-                        help='F5 host ssh port id non default port is used ')
-    parser.add_argument('--ignore_config',
-                        help='Config file to skip specific configuration in conversion')
-
-    parser.add_argument('-l', '--input_folder_location',
-                        help='Location of input files like cert files ' +
-                             'external monitor scripts')
+    parser.add_argument(
+        "--convertsnat",
+        help="Flag for converting snatpool into " "individual addresses",
+        action="store_true",
+    )
+    parser.add_argument(
+        "--custom_config",
+        help="iRule/monitor custom mapping yml file path.\
+            (File containing converted iRules or health monitors)",
+    )
+    parser.add_argument(
+        "--distinct_app_profile",
+        action="store_true",
+        help="Option to create distinct application profile for"
+        " each VS even though it is shared in F5 config",
+    )
+    parser.add_argument(
+        "-f",
+        "--bigip_config_file",
+        help="Absolute path for F5 config file")
+    parser.add_argument("--f5_host_ip", help="Host ip of f5 instance")
+    parser.add_argument(
+        "--f5_key_file",
+        help="F5 host key file location if key based " + "authentication",
+    )
+    parser.add_argument(
+        "--f5_passphrase_file",
+        help="F5 key passphrase yaml file path")
+    parser.add_argument("--f5_ssh_user", help="f5 host ssh username")
+    parser.add_argument(
+        "--f5_ssh_password",
+        action=PasswordPromptAction,
+        nargs="?",
+        help="f5 host ssh password if password "
+        "based authentication. Input prompt "
+        "will appear if no value provided",
+    )
+    parser.add_argument(
+        "--f5_ssh_port",
+        help="F5 host ssh port id non default port is used ")
+    parser.add_argument(
+        "--ignore_config",
+        help="Config file to skip specific configuration in conversion",
+    )
+
+    parser.add_argument(
+        "-l",
+        "--input_folder_location",
+        help="Location of input files like cert files " +
+        "external monitor scripts",
+    )
     # Changed the command line option to more generic term object
-    parser.add_argument('--no_object_merge',
-                        help='Flag for skipping object merge', action='store_false')
+    parser.add_argument(
+        "--object_merge",
+        help="Flag for enabling object merge",
+        action="store_true")
     # Added not in use flag
-    parser.add_argument('--not_in_use',
-                        help='Flag for skipping not in use object',
-                        action="store_true")
-    parser.add_argument('-o', '--output_file_path',
-                        help='Folder path for output files to be created in',
-                        )
-    parser.add_argument('-O', '--option', choices=ARG_CHOICES['option'],
-                        help='Upload option cli-upload genarates Avi config ' +
-                             'file auto upload will upload config to ' +
-                             'controller')
-    parser.add_argument('-p', '--password',
-                        help='Destination controller password for config upload. Input '
-                             'prompt will appear if no value provided')
-    parser.add_argument('--partition_config',
-                        help='Comma separated partition config files')
+    parser.add_argument(
+        "--not_in_use",
+        help="Flag for migrating not in use object",
+        action="store_false",
+    )
+    parser.add_argument(
+        "-o",
+        "--output_file_path",
+        help="Folder path for output files to be created in",
+    )
+    parser.add_argument(
+        "-O",
+        "--option",
+        choices=ARG_CHOICES["option"],
+        help="Upload option cli-upload genarates Avi config " +
+        "file auto upload will upload config to " + "controller",
+    )
+    parser.add_argument(
+        "-p",
+        "--password",
+        help="Destination controller password for config upload. Input "
+        "prompt will appear if no value provided",
+    )
+    parser.add_argument(
+        "--partition_config",
+        help="Comma separated partition config files")
     # Added command line args to execute config_patch file with related Avi
     # json file location and patch location
-    parser.add_argument('--patch', help='Absolute path to patch.yaml file')
+    parser.add_argument("--patch", help="Absolute path to patch.yaml file")
     # Added prefix for objects
-    parser.add_argument('--prefix', help='Prefix for objects')
-    parser.add_argument('-s', '--vs_state', choices=ARG_CHOICES['vs_state'],
-                        help='traffic_enabled state of VS created')
-    parser.add_argument('--segroup',
-                        help='Update the available segroup ref with the custom ref')
-    parser.add_argument('--skip_default_file',
-                        help='Flag for skip default file', action='store_true')
-    parser.add_argument('--skip_pki',
-                        help='Skip migration of PKI profile',
-                        action='store_true')
-    parser.add_argument('-t', '--tenant', help='Destination tenant name')
+    parser.add_argument("--prefix", help="Prefix for objects")
+    parser.add_argument(
+        "-s",
+        "--vs_state",
+        choices=ARG_CHOICES["vs_state"],
+        help="traffic_enabled state of VS created",
+    )
+    parser.add_argument(
+        "--segroup",
+        help="Update the available segroup ref with the custom ref")
+    parser.add_argument(
+        "--skip_default_file",
+        help="Flag for skip default file",
+        action="store_true")
+    parser.add_argument(
+        "--skip_pki",
+        help="Skip migration of PKI profile",
+        action="store_true")
+    parser.add_argument(
+        "-t",
+        "--tenant",
+        help="Destination tenant name",
+        required=True)
     # Adding support for test vip
-    parser.add_argument('--test_vip',
-                        help='Enable test vip for ansible generated file '
-                        'It will replace the original vip '
-                        'Note: The actual ip will vary from input to output'
-                        'use it with caution ')
-    parser.add_argument('-u', '--user',
-                        help='Username on destination controller for config upload')
-    parser.add_argument('-v', '--f5_config_version',
-                        help='Version of f5 config file')
-    parser.add_argument('--version',
-                        help='Print product version and exit',
-                        action='store_true')
-    parser.add_argument('--vrf',
-                        help='Update the available vrf ref with the custom vrf'
-                             'reference')
+    parser.add_argument(
+        "--test_vip",
+        help="Enable test vip for ansible generated file "
+        "It will replace the original vip "
+        "Note: The actual ip will vary from input to output"
+        "use it with caution ",
+    )
+    parser.add_argument(
+        "-u",
+        "--user",
+        help="Username on destination controller for config upload")
+    parser.add_argument(
+        "-v",
+        "--f5_config_version",
+        help="Version of f5 config file")
+    parser.add_argument(
+        "--version",
+        help="Print product version and exit",
+        action="store_true")
+    parser.add_argument(
+        "--vrf",
+        help="Update the available vrf ref with the custom vrf" "reference",
+        required=True,
+    )
     # Added command line args to execute vs_filter.py with vs_name.
-    parser.add_argument('--vs_filter',
-                        help='Comma seperated names of virtualservices. vs1,vs3,vs5\n'
-                        'Note: If patch data is supplied, vs_name should match '
-                        'the new name given in it'
-                        )
-    parser.add_argument('--vs_level_status', action='store_true',
-                        help='Add columns of vs reference and overall skipped '
-                             'settings in status excel sheet')
-    parser.add_argument('--reuse_http_policy', action='store_true',
-                        help='Detect and reuse the HTTP policy that are '
-                             'shared across multiple VS')
+    parser.add_argument(
+        "--vs_filter",
+        help="Comma seperated names of virtualservices. vs1,vs3,vs5\n"
+        "Note: If patch data is supplied, vs_name should match "
+        "the new name given in it",
+    )
+    parser.add_argument(
+        "--vs_level_status",
+        action="store_true",
+        help="Add columns of vs reference and overall skipped "
+        "settings in status excel sheet",
+    )
+    parser.add_argument(
+        "--reuse_http_policy",
+        action="store_true",
+        help="Detect and reuse the HTTP policy that are "
+        "shared across multiple VS",
+    )
     # Config file to override all parameters of this script
-    parser.add_argument('--args_config_file',
-                        help='Config file to specify all the arguments '
-                             'of this script. Argument values provided '
-                             'on terminal take precedence over config file '
-                             'argument values')
+
+    parser.add_argument(
+        "--args_config_file",
+        help="Config file to specify all the arguments "
+        "of this script. Argument values provided "
+        "on terminal take precedence over config file "
+        "argument values",
+    )
+    parser.add_argument(
+        "--skip_disabled_vs",
+        help="Flag for skipping those vs/s which are disabled on f5",
+        action="store_true",
+    )
 
     terminal_args = parser.parse_args()
     args = get_terminal_args(terminal_args)
 
     # print avi f5 converter version
     if args.version:
         print("SDK Version: %s\nController Version: %s" % \
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_parser.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_parser.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,24 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-from pyparsing import *
-import re
 import logging
-import sys
+import re
+
 from avi.migrationtools.f5_converter.conversion_util import F5Util
+from pyparsing import *
 
 LOG = logging.getLogger(__name__)
 # Creating f5 object for util library.
 conversion_util = F5Util()
 
+
 def generate_grammar_v11():
     # define data types that might be in the values
-    unquoted_string = Word(alphanums+"!#$%&'()*+,-./:;<=>?@[\]^_`|~")
+    unquoted_string = Word(alphanums + "!#$%&'()*+,-./:;<=>?@[\\]^_`|~")
     quoted_string = quotedString.setParseAction(removeQuotes)
     ltm = Keyword("ltm")
     gtm = Keyword("gtm")
     apm = Keyword("apm")
     auth = Keyword("auth")
     net = Keyword("net")
     sys = Keyword("sys")
@@ -30,43 +31,46 @@
     BS, LBRACE, RBRACE = map(Suppress, " {}")
     SOL = LineStart().suppress()
     EOL = LineEnd().suppress()
     reserved_words = (ltm | apm | auth | net | sys | gtm).suppress()
 
     ignore = comment
 
-    entity_type = SOL.suppress()+Optional(reserved_words).\
-        suppress() + unquoted_string
-    data = (unquoted_string | quoted_string)
+    entity_type = SOL.suppress() + Optional(reserved_words).suppress() + unquoted_string
+    data = unquoted_string | quoted_string
 
     # define structures
     value = Forward()
     value_object = Forward()
 
     property_name = data
-    monitor_kv = monitor_kw+restOfLine
-    dict_kv = property_name+(~EOL) + Optional(value, default=None)
-    dict_sv = property_name+EOL + Empty()
+    monitor_kv = monitor_kw + restOfLine
+    dict_kv = property_name + (~EOL) + Optional(value, default=None)
+    dict_sv = property_name + EOL + Empty()
     f5_property = Dict(ZeroOrMore(Group(monitor_kv | dict_kv | dict_sv)))
-    entity_details = (originalTextFor(ZeroOrMore(unquoted_string)))
-    entity = Group(entity_type+Group(entity_details +
-                                     LBRACE + (f5_property | BS) + RBRACE))
+    entity_details = originalTextFor(ZeroOrMore(unquoted_string))
+    entity = Group(entity_type + Group(entity_details +
+                   LBRACE + (f5_property | BS) + RBRACE))
     entities = OneOrMore(entity)
 
     value_object << ((LBRACE + f5_property + RBRACE) | empty_object)
-    value << (value_object | originalTextFor(data + OneOrMore(and_kw+data)) |
-              data)
+    value << (
+        value_object | originalTextFor(
+            data +
+            OneOrMore(
+                and_kw +
+                data)) | data)
 
     data_set = entities.ignore(ignore)
     return data_set
 
 
 def generate_grammar_v10():
     # define data types that might be in the values
-    unquoted_string = Word(alphanums+"!#$%&'()*+,-./:;<=>?@[\]^_`|~")
+    unquoted_string = Word(alphanums + "!#$%&'()*+,-./:;<=>?@[\\]^_`|~")
     quoted_string = quotedString.setParseAction(removeQuotes)
     ltm = Keyword("ltm")
     apm = Keyword("apm")
     auth = Keyword("auth")
     net = Keyword("net")
     sys = Keyword("sys")
     opt_kw = Keyword("options")
@@ -75,60 +79,72 @@
     profiles_kw = Keyword("profiles")
     session_kw = Keyword("session")
     mode_kw = Keyword("mode")
     lb_method_kw = Keyword("lb method")
     v_addr_kw = Keyword("virtual address")
     ip_forward_kw = Keyword("ip forward")
     l2_forward_kw = Keyword("l2 forward")
-    is_ro_kw = Keyword('is read only')
+    is_ro_kw = Keyword("is read only")
     cookie_mode_kw = Keyword("cookie mode")
-    defaults_from_kw = Keyword('defaults from')
+    defaults_from_kw = Keyword("defaults from")
     ct_include_kw = Keyword("compress content type include")
     ct_exclude_kw = Keyword("compress content type exclude")
     empty_object = Keyword("{ }")
 
-    disable_kw = Keyword('disable')
+    disable_kw = Keyword("disable")
 
     common = Suppress("/Common/")
     comment = Suppress("#") + Suppress(restOfLine)
     BS, LBRACE, RBRACE = map(Suppress, " {}")
     LBRACE_KW = Keyword("{")
     EOL = LineEnd().suppress()
     SOL = LineStart().suppress()
     reserved_words = (ltm | apm | auth | net | sys).suppress()
 
-    sw_key = (disable_kw)
+    sw_key = disable_kw
 
-    ignore = (common | comment)
+    ignore = common | comment
 
-    entity_type = SOL.suppress()+Optional(reserved_words).\
-        suppress() + (v_addr_kw | unquoted_string)
-    data = (unquoted_string | quoted_string)
-
-    key_exceptions = (opt_kw | profiles_kw | monitor_kw | session_kw | mode_kw |
-                      lb_method_kw | ip_forward_kw | l2_forward_kw |
-                      ct_include_kw | ct_exclude_kw | members_kw |
-                      cookie_mode_kw | is_ro_kw)
+    entity_type = SOL.suppress() + Optional(reserved_words).suppress() + \
+        (v_addr_kw | unquoted_string)
+    data = unquoted_string | quoted_string
+
+    key_exceptions = (
+        opt_kw
+        | profiles_kw
+        | monitor_kw
+        | session_kw
+        | mode_kw
+        | lb_method_kw
+        | ip_forward_kw
+        | l2_forward_kw
+        | ct_include_kw
+        | ct_exclude_kw
+        | members_kw
+        | cookie_mode_kw
+        | is_ro_kw
+    )
 
     # define structures
     value = Forward()
     value_object = Forward()
-    multi_word_key = originalTextFor(OneOrMore((~key_exceptions)+data+(~EOL)))
-    property_name = (multi_word_key | key_exceptions | data+(~EOL))
-    dict_kv = (property_name + Optional(value, default=None))
-    dict_sv = (data+EOL + Empty())
+    multi_word_key = originalTextFor(
+        OneOrMore((~key_exceptions) + data + (~EOL)))
+    property_name = multi_word_key | key_exceptions | data + (~EOL)
+    dict_kv = property_name + Optional(value, default=None)
+    dict_sv = data + EOL + Empty()
     f5_property = Dict(ZeroOrMore(Group(dict_kv | dict_sv)))
-    entity_details = (originalTextFor(ZeroOrMore(unquoted_string)))
-    entity = Group(entity_type+Group(
-        entity_details + LBRACE + (f5_property | BS) + RBRACE))
+    entity_details = originalTextFor(ZeroOrMore(unquoted_string))
+    entity = Group(entity_type + Group(entity_details +
+                   LBRACE + (f5_property | BS) + RBRACE))
     entities = OneOrMore(entity)
 
     value_object << ((LBRACE + f5_property + RBRACE) | empty_object)
-    value << (value_object | originalTextFor(data + restOfLine + (~LBRACE_KW)) |
-              data)
+    value << (value_object | originalTextFor(
+        data + restOfLine + (~LBRACE_KW)) | data)
 
     data_set = entities.ignore(ignore)
     return data_set
 
 
 def parse_config(source_str, total_size, version=11):
     """
@@ -140,51 +156,56 @@
     grammar = get_grammar_by_version(version)
     result = []
     skipped_list = []
     not_supported_list = []
     last_end = 0
     source_str = source_str.replace("\t", "    ")
     source_str = source_str.replace("user-defined ", "user-defined_")
-    source_str = re.sub(" (min) (\d) (of)","", source_str)
+    source_str = re.sub(" (min) (\\d) (of)", "", source_str)
     for tokens, start, end in grammar.scanString(source_str):
-        result = result+tokens.asList()
+        result = result + tokens.asList()
         if last_end != 0:
             if start - 3 > last_end:
-                skipped_info = {"start": last_end, "end": start,
-                                "str_start":
-                                    source_str[last_end:last_end+10]+"...",
-                                "str_end": "..."+source_str[start-10:start]}
+                skipped_info = {
+                    "start": last_end,
+                    "end": start,
+                    "str_start": source_str[last_end: last_end + 10] + "...",
+                    "str_end": "..." + source_str[start - 10: start],
+                }
                 skipped_str = source_str[last_end:start]
                 # Added checks to get not supported configuration
-                skip_obj_list = ZeroOrMore(originalTextFor(SkipTo('{')) +
-                                           nestedExpr('{', '}').suppress()
-                                           ).parseString(skipped_str).asList()
+                skip_obj_list = ZeroOrMore(
+                    originalTextFor(
+                        SkipTo("{")) +
+                    nestedExpr(
+                        "{",
+                        "}").suppress()).parseString(skipped_str).asList()
                 # list for not supported commands.
                 for skipconfig in skip_obj_list:
-                    skipconfig = str(skipconfig.replace('}', ''))
-                    if skipconfig.strip(' ').startswith(
-                            ('security', 'ltm', 'wam', 'sys', 'waf', 'asm',
-                             'apm')):
+                    skipconfig = str(skipconfig.replace("}", ""))
+                    if skipconfig.strip(" ").startswith(
+                            ("security", "ltm", "wam", "sys", "waf", "asm", "apm")):
                         not_supported_list.append(skipconfig)
                 skipped_list.append(skipped_info)
         last_end = end
         # Added call to check progress for parsing.
         msg = "Parsing configuration..."
         if end <= total_size:
-            conversion_util.print_progress_bar(end, total_size, msg, prefix='Progress',
-                               suffix='')
+            conversion_util.print_progress_bar(
+                end, total_size, msg, prefix="Progress", suffix="")
         else:
-            conversion_util.print_progress_bar(total_size, total_size, msg, prefix='Progress',
-                             suffix='')
+            conversion_util.print_progress_bar(
+                total_size, total_size, msg, prefix="Progress", suffix="")
     if last_end < total_size:
-        conversion_util.print_progress_bar(total_size - 1, total_size, None, prefix='Progress',
-                       suffix='')
+        conversion_util.print_progress_bar(
+            total_size - 1, total_size, None, prefix="Progress", suffix="")
     for skipped in skipped_list:
-        LOG.warn("Skipped for parse unmatched from offset:%s to offset:%s" %
-                 (skipped["start"], skipped["end"]))
+        LOG.warning(
+            "Skipped for parse unmatched from offset:%s to offset:%s",
+            skipped["start"], skipped["end"])
     result_dict = convert_to_dict(result)
     LOG.debug("Parsing complete...")
     return result_dict, not_supported_list
 
 
 def get_grammar_by_version(version):
     grammar = None
@@ -193,15 +214,14 @@
     elif int(version) in [11, 12]:
         grammar = generate_grammar_v11()
     return grammar
 
 
 def convert_to_dict(result):
     result_dict = {}
-    total_size = len(result)
     for item in result:
         # determine the key and value to be inserted into the dict
         key = None
         dict_val = None
         if isinstance(item, list):
             try:
                 key = item[0].strip()
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_v10_defaults.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_v10_defaults.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/f5_v11_defaults.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/f5_v11_defaults.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/monitor_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/monitor_converter.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,202 +1,246 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 import copy
 import logging
 import os
+
 import avi.migrationtools.f5_converter.converter_constants as conv_const
-from pkg_resources import parse_version
-from avi.migrationtools.f5_converter.profile_converter import ssl_count
-from avi.migrationtools.f5_converter.conversion_util import F5Util
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
+from avi.migrationtools.f5_converter.conversion_util import F5Util
+from avi.migrationtools.f5_converter.profile_converter import ssl_count
+from pkg_resources import parse_version
 
 LOG = logging.getLogger(__name__)
 # Creating f5 object for util library.
 conv_utils = F5Util()
 
 
 class MonitorConfigConv(object):
+    '''
+    Monitor Conversions
+    '''
+
     @classmethod
     def get_instance(cls, version, f5_monitor_atributes, prefix,
                      object_merge_check):
         """
 
         :param version: version of f5 instance
         :param f5_monitor_atributes: f5 monitor attributes from yaml file.
         :param prefix:  prefix for objects
         :param object_merge_check: Flag for object merge
         :return:
         """
-        if version == '10':
+        if version == "10":
             return MonitorConfigConvV10(f5_monitor_atributes, prefix,
                                         object_merge_check)
-        if version in ['11', '12']:
+        if version in ["11", "12"]:
             return MonitorConfigConvV11(f5_monitor_atributes, prefix,
                                         object_merge_check)
 
     def get_defaults(self, monitor_config, key):
         pass
 
     def get_name_type(self, f5_monitor, key):
+        '''
+        Method for getting name type
+        '''
         pass
 
     def get_default_monitor(self, monitor_type, monitor_config):
+        '''
+        Method for default monitor
+        '''
         pass
 
     def convert_http(self, monitor_dict, f5_monitor, skipped):
+        '''
+        param: passed monitor config dict
+        param: f5 monitor configuration
+        param: skipped  attributes list
+        '''
         pass
 
     def convert_https(self, monitor_dict, f5_monitor, skipped, avi_config,
                       tenant, input_dir, cloud_name, controller_version,
                       merge_object_mapping, sys_dict):
         pass
 
     def convert_dns(self, monitor_dict, f5_monitor, skipped):
         pass
 
     def convert_tcp(self, monitor_dict, f5_monitor, skipped, type):
         pass
 
     def convert_udp(self, monitor_dict, f5_monitor, skipped):
+        '''
+        convert udp
+        '''
         pass
 
     def convert_icmp(self, monitor_dict, f5_monitor, skipped):
+        """
+        convert icmp
+        """
         pass
 
     def convert_external(self, monitor_dict, f5_monitor, skipped, input_dir,
                          name):
+        """
+        param: monitor_dict : parsed monitor dict of f5 config
+        param :f5_monitor : parsed dict of f5 config
+        param:skipped : skipped list
+        param:input_dir : location of input certs and key
+        param:name : name of object
+        """
         pass
 
     def update_request_for_avi(self, send, is_http):
+        """
+        update request for avi
+        """
         if not send:
             return None
-        send = send.replace('\\\\', '\\')
-        send = send.replace('"', '')
-        if send == 'none':
+        send = send.replace("\\\\", "\\")
+        send = send.replace('"', "")
+        if send == "none":
             send = None
-        if is_http and send and 'HTTP' not in send:
-            send = send.replace('\\r\\n', ' HTTP/1.1\\r\\n', 1)
-        if is_http and send and 'BigIP' in send:
-            send = send.replace("BigIP","avi1.0")
+        if is_http and send and "HTTP" not in send:
+            send = send.replace("\\r\\n", " HTTP/1.1\\r\\n", 1)
+        if is_http and send and "BigIP" in send:
+            send = send.replace("BigIP", "avi1.0")
         return send
 
-    def create_sslprofile(self, monitor_dict, f5_monitor, avi_config,
-                           tenant, cloud_name, merge_object_mapping, sys_dict):
+    def create_sslprofile(self, monitor_dict, f5_monitor, avi_config, tenant,
+                          cloud_name, merge_object_mapping, sys_dict):
         """
 
         :param monitor_dict: parsed monitor dict of f5 config
         :param f5_monitor: parsed dict of f5 config
         :param avi_config: dict for conversion to avi config
         :param tenant: tenant for which config need to be converted
         :param input_dir: location of input certs and key
         :param cloud_name: cloud name for which config need to be converted
         :param controller_version: controller version of avi
         :return:
         """
         # Condition to create ssl profile.
         converted_objs = []
-        cipher = f5_monitor.get('cipherlist', None)
-        cipher = cipher.replace('\"', '') if cipher is not None else None
-        ssl_profile = dict()
+        cipher = f5_monitor.get("cipherlist", None)
+        cipher = cipher.replace('"', "") if cipher is not None else None
+        ssl_profile = {}
         ssl_profile["accepted_versions"] = [
-            {"type": "SSL_VERSION_TLS1"},
-            {"type": "SSL_VERSION_TLS1_1"},
-            {"type": "SSL_VERSION_TLS1_2"}
+            {
+                "type": "SSL_VERSION_TLS1"
+            },
+            {
+                "type": "SSL_VERSION_TLS1_1"
+            },
+            {
+                "type": "SSL_VERSION_TLS1_2"
+            },
         ]
         # Removed '-sslprofile' suffix from name
-        ssl_profile['name'] = monitor_dict['name']
-        ssl_profile['tenant_ref'] = conv_utils.get_object_ref(
-            tenant, 'tenant')
-        ssl_profile['accepted_ciphers'] = cipher
+        ssl_profile["name"] = monitor_dict["name"]
+        ssl_profile["tenant_ref"] = conv_utils.get_object_ref(tenant, "tenant")
+        ssl_profile["accepted_ciphers"] = cipher
         if self.object_merge_check:
             conv_utils.update_skip_duplicates(
                 ssl_profile, avi_config['SSLProfile'], 'ssl_profile',
-                converted_objs, ssl_profile['name'], None, merge_object_mapping,
-                None, self.prefix, sys_dict['SSLProfile'])
+                converted_objs, ssl_profile['name'], None,
+                merge_object_mapping, None, self.prefix,
+                sys_dict['SSLProfile'])
             ssl_count['count'] += 1
         else:
-            avi_config['SSLProfile'].append(ssl_profile)
-        sname = [ob for ob in sys_dict['SSLProfile'] if ob['name'] ==
-                merge_object_mapping['ssl_profile'].get(ssl_profile['name'])] \
-                or [sname for sname in avi_config['SSLProfile'] if (
-                sname['name'] == ssl_profile['name'] or ssl_profile[
-                'name'] in sname.get('dup_of', []))]
-        ref = conv_utils.get_object_ref(
-            sname[0]['name'], "sslprofile", tenant, cloud_name)
-        monitor_dict["https_monitor"]['ssl_attributes'][
-            'ssl_profile_ref'] = ref
-
-    def create_sslkeyandcert(self, monitor_dict, f5_monitor, avi_config, tenant,
-                             input_dir, cloud_name, merge_object_mapping,
-                             sys_dict):
+            avi_config["SSLProfile"].append(ssl_profile)
+        sname = [
+            ob for ob in sys_dict["SSLProfile"] if ob["name"] ==
+            merge_object_mapping["ssl_profile"].get(ssl_profile["name"])
+        ] or [
+            sname for sname in avi_config["SSLProfile"]
+            if (sname["name"] == ssl_profile["name"]
+                or ssl_profile["name"] in sname.get("dup_of", []))
+        ]
+        ref = conv_utils.get_object_ref(sname[0]["name"], "sslprofile", tenant,
+                                        cloud_name)
+        monitor_dict["https_monitor"]["ssl_attributes"][
+            "ssl_profile_ref"] = ref
+
+    def create_sslkeyandcert(self, monitor_dict, f5_monitor, avi_config,
+                             tenant, input_dir, cloud_name,
+                             merge_object_mapping, sys_dict):
         """
 
         :param monitor_dict: parsed monitor dict of f5 config
         :param f5_monitor: parsed dict of f5 config
         :param avi_config: dict for conversion to avi config
         :param tenant: tenant for which config need to be converted
         :param input_dir: location of input certs and key
         :param cloud_name: cloud name for which config need to be converted
         :param merge_object_mapping: flag for merging objects
         :param sys_dict: baseline profile dict
         :return:
         """
         # Condition create  sslkeyandcert.
         converted_objs = []
-        key_file_name = f5_monitor.get('key', None)
-        cert_file_name = f5_monitor.get('cert', None)
+        key_file_name = f5_monitor.get("key", None)
+        cert_file_name = f5_monitor.get("cert", None)
         folder_path = input_dir + os.path.sep
         key = None
         if key_file_name:
             key = conv_utils.upload_file(folder_path + key_file_name)
         cert = None
         if cert_file_name:
             cert = conv_utils.upload_file(folder_path + cert_file_name)
-        name = monitor_dict['name']
+        name = monitor_dict["name"]
         if not key or not cert:
             key, cert = conv_utils.create_self_signed_cert()
             name = '%s-%s' % (monitor_dict['name'],
                               conv_const.PLACE_HOLDER_STR)
             LOG.warning(
                 'Create self cerificate and key for : %s' % key_file_name)
         ssl_kc_obj = None
         if key and cert:
             cert = {"certificate": cert}
             ssl_kc_obj = {
                 'name': name,
-                'tenant_ref': conv_utils.get_object_ref(tenant,
-                                                        'tenant'),
+                'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant'),
                 'key': key,
                 'certificate': cert,
                 'key_passphrase': '',
                 'type': 'SSL_CERTIFICATE_TYPE_VIRTUALSERVICE'
             }
         # Added condition for merging sslkeyandcert
         if ssl_kc_obj and conv_const.PLACE_HOLDER_STR not in ssl_kc_obj['name']:
-            conv_utils.update_skip_duplicates(ssl_kc_obj,
-                avi_config['SSLKeyAndCertificate'], 'ssl_cert_key',
-                converted_objs, name, None, merge_object_mapping,
-                None, self.prefix, sys_dict['SSLKeyAndCertificate'])
+            conv_utils.update_skip_duplicates(
+                ssl_kc_obj, avi_config['SSLKeyAndCertificate'], 'ssl_cert_key',
+                converted_objs, name, None, merge_object_mapping, None,
+                self.prefix, sys_dict['SSLKeyAndCertificate'])
         else:
-            avi_config['SSLKeyAndCertificate'].append(ssl_kc_obj)
+            avi_config["SSLKeyAndCertificate"].append(ssl_kc_obj)
         ssl_key_cert_list = avi_config.get("SSLKeyAndCertificate", [])
-        key_cert = [ob for ob in sys_dict['SSLKeyAndCertificate'] if
-                   ob['name'] == merge_object_mapping['ssl_cert_key'].get(
-                   name)] or [obj for obj in ssl_key_cert_list if(
-                   obj['name'] == name or obj['name'] == '%s-%s' % (
-                   name, conv_const.PLACE_HOLDER_STR)
-                   or name in obj.get("dup_of", []))]
+        key_cert = [
+            ob for ob in sys_dict['SSLKeyAndCertificate']
+            if ob['name'] == merge_object_mapping['ssl_cert_key'].get(name)
+        ] or [
+            obj for obj in ssl_key_cert_list
+            if (obj['name'] == name or obj['name'] == '%s-%s' %
+                (name, conv_const.PLACE_HOLDER_STR)
+                or name in obj.get("dup_of", []))
+        ]
         if key_cert:
-            name = key_cert[0]['name']
-        ref = conv_utils.get_object_ref(
-             name, "sslkeyandcertificate", tenant, cloud_name)
-        monitor_dict["https_monitor"]['ssl_attributes'][
-             'ssl_key_and_certificate_ref'] = ref
-        LOG.info('Added new SSL key and certificate for %s' % name)
+            name = key_cert[0]["name"]
+        ref = conv_utils.get_object_ref(name, "sslkeyandcertificate", tenant,
+                                        cloud_name)
+        monitor_dict["https_monitor"]["ssl_attributes"][
+            "ssl_key_and_certificate_ref"] = ref
+        LOG.info("Added new SSL key and certificate for %s", name)
 
     def convert(self, f5_config, avi_config, input_dir, user_ignore, tenant,
                 cloud_name, controller_version, merge_object_mapping, sys_dict,
                 custom_mappings=None):
         """
 
         :param f5_config:  parsed f5 config dict
@@ -210,125 +254,128 @@
         :param sys_dict: baseline profile.
         :param custom_mappings: custom mappings to overwrite monitor config.
         :return:
         """
         LOG.debug("Converting health monitors")
         print("Converting Monitors...")
         converted_objs = []
-        m_user_ignore = user_ignore.get('monitor', {})
+        m_user_ignore = user_ignore.get("monitor", {})
         monitor_config = f5_config.pop("monitor", {})
         # Added varibles to  get total count of object.
         total_size = len(monitor_config.keys())
         progressbar_count = 0
-        custom_config = custom_mappings.get(
-            conv_const.HM_CUSTOM_KEY, dict()
-        ) if custom_mappings else dict()
+        custom_config = (custom_mappings.get(conv_const.HM_CUSTOM_KEY, {})
+                         if custom_mappings else {})
         for key in monitor_config.keys():
             progressbar_count += 1
             # Added call to check progress.
             msg = "Monitor conversion started..."
-            conv_utils.print_progress_bar(progressbar_count, total_size, msg,
-                               prefix='Progress', suffix='')
+            conv_utils.print_progress_bar(progressbar_count,
+                                          total_size,
+                                          msg,
+                                          prefix="Progress",
+                                          suffix="")
             f5_monitor = monitor_config[key]
             if not f5_monitor:
                 if " " in key:
                     m_type, name = key.split(" ")
                 else:
                     m_type = None
                     name = key
                 msg = "Empty config for monitor: %s " % name
                 LOG.warn(msg)
-                conv_utils.add_status_row('monitor', m_type, name,
+                conv_utils.add_status_row("monitor", m_type, name,
                                           conv_const.STATUS_SKIPPED, msg)
                 continue
             f5_monitor = self.get_defaults(monitor_config, key)
             monitor_type, name = self.get_name_type(f5_monitor, key)
-            if '/' in monitor_type:
-                monitor_type = monitor_type.split('/')[-1]
+            if "/" in monitor_type:
+                monitor_type = monitor_type.split("/")[-1]
             m_tenant, m_name = conv_utils.get_tenant_ref(name)
             # Check if custom cofig present for this HM
-            r_hm = [obj for obj in custom_config if
-                            obj['monitor_name'] == m_name]
+            r_hm = [
+                obj for obj in custom_config if obj["monitor_name"] == m_name
+            ]
             if r_hm:
                 LOG.debug(
-                    "Found custom config for %s replacing with custom config"
-                    % m_name)
+                    "Found custom config for %s replacing with custom config",
+                    m_name)
                 r_hm = r_hm[0]
-                avi_monitor = r_hm['avi_config']
+                avi_monitor = r_hm["avi_config"]
                 # Added prefix for objects
                 if self.prefix:
                     avi_monitor['name'] = self.prefix + '-' + m_name
                 else:
-                    avi_monitor['name'] = m_name
+                    avi_monitor["name"] = m_name
                 if tenant:
                     m_tenant = tenant
-                avi_monitor['tenant_ref'] = conv_utils.get_object_ref(
-                    m_tenant, 'tenant')
+                avi_monitor["tenant_ref"] = conv_utils.get_object_ref(
+                    m_tenant, "tenant")
                 avi_config["HealthMonitor"].append(avi_monitor)
                 conv_utils.add_conv_status(
                     'monitor', monitor_type, m_name, {
                         'status': conv_const.STATUS_SUCCESSFUL
-                    }, [{'health_monitor': avi_monitor}])
+                    }, [{'health_monitor': avi_monitor}], yaml.dump(f5_monitor))
                 continue
             # Added prefix for objects
             if self.prefix:
-                name = self.prefix + '-' + name
+                name = self.prefix + "-" + name
             try:
-                LOG.debug("Converting monitor: %s" % name)
+                LOG.debug("Converting monitor: %s", name)
                 if monitor_type not in self.supported_types:
                     avi_monitor = self.convert_monitor(
                         f5_monitor, key, monitor_config, input_dir,
-                        m_user_ignore,
-                        tenant, avi_config, cloud_name, controller_version,
-                        merge_object_mapping, sys_dict)
+                        m_user_ignore, tenant, avi_config, cloud_name,
+                        controller_version, merge_object_mapping, sys_dict)
                     if not avi_monitor:
                         continue
                     avi_monitor['name'] = '%s-%s' % (
                         avi_monitor['name'], conv_const.PLACE_HOLDER_STR)
+
                     avi_monitor["type"] = "HEALTH_MONITOR_EXTERNAL"
                     ext_monitor = {
                         "command_code": "",
                     }
                     avi_monitor["external_monitor"] = ext_monitor
-                    avi_config['HealthMonitor'].append(avi_monitor)
+                    avi_config["HealthMonitor"].append(avi_monitor)
                     msg = "Monitor type {} not supported, created placeholder " \
                           "external monitor {}".format(monitor_type,
                                                        avi_monitor['name'])
                     LOG.warn(msg)
                     conv_utils.add_status_row(
-                        'monitor', monitor_type, name,
+                        "monitor", monitor_type, name,
                         conv_const.STATUS_EXTERNAL_MONITOR, msg)
                     continue
                 avi_monitor = self.convert_monitor(
                     f5_monitor, key, monitor_config, input_dir, m_user_ignore,
                     tenant, avi_config, cloud_name, controller_version,
                     merge_object_mapping, sys_dict)
                 if not avi_monitor:
                     continue
                 # code to merge health monitor.
                 if self.object_merge_check:
-                    conv_utils.update_skip_duplicates(avi_monitor,
-                        avi_config['HealthMonitor'], 'health_monitor',
-                            converted_objs, name, None, merge_object_mapping,
-                                            monitor_type, self.prefix,
-                                                      sys_dict['HealthMonitor'])
+                    conv_utils.update_skip_duplicates(
+                        avi_monitor, avi_config['HealthMonitor'],
+                        'health_monitor', converted_objs, name, None,
+                        merge_object_mapping, monitor_type, self.prefix,
+                        sys_dict['HealthMonitor'])
                     self.mon_count += 1
                 else:
                     avi_config["HealthMonitor"].append(avi_monitor)
-                LOG.debug("Conversion successful for monitor: %s" % name)
-            except:
-                update_count('error')
-                LOG.error("Failed to convert monitor: %s" % key, exc_info=True)
+                LOG.debug("Conversion successful for monitor: %s", name)
+            except BaseException:
+                update_count("error")
+                LOG.error("Failed to convert monitor: %s", key, exc_info=True)
                 if name:
-                    conv_utils.add_status_row('monitor', monitor_type, name,
+                    conv_utils.add_status_row("monitor", monitor_type, name,
                                               conv_const.STATUS_ERROR)
                 else:
-                    conv_utils.add_status_row('monitor', key, key,
+                    conv_utils.add_status_row("monitor", key, key,
                                               conv_const.STATUS_ERROR)
-        LOG.debug("Converted %s health monitors" %
+        LOG.debug("Converted %s health monitors",
                   len(avi_config["HealthMonitor"]))
 
     def convert_monitor(self, f5_monitor, key, monitor_config, input_dir,
                         user_ignore, tenant_ref, avi_config, cloud_name,
                         controller_version, merge_object_mapping, sys_dict):
         """
 
@@ -341,62 +388,65 @@
         :param cloud_name: cloud name of which output to be converted
         :param controller_version: controller version
         :param merge_object_mapping: flag for merge objects
         :param sys_dict: baseline profile
         :return: monitor_dict
         """
         monitor_type, name = self.get_name_type(f5_monitor, key)
-        if '/' in monitor_type:
-            monitor_type = monitor_type.split('/')[-1]
-        skipped = [val for val in f5_monitor.keys()
-                   if val not in self.supported_attributes]
+        if "/" in monitor_type:
+            monitor_type = monitor_type.split("/")[-1]
+        skipped = [
+            val for val in f5_monitor.keys()
+            if val not in self.supported_attributes
+        ]
         indirect = copy.deepcopy(self.indirect_mappings)
         timeout = int(f5_monitor.get("timeout", conv_const.DEFAULT_TIMEOUT))
         # Supporting value 'auto' and changing it to default value for interval
         interval = str(f5_monitor.get("interval", conv_const.DEFAULT_INTERVAL))
-        interval = int(interval) if interval.isdigit() else \
-                    conv_const.DEFAULT_INTERVAL
-        time_until_up = int(f5_monitor.get(self.tup,
-                                           conv_const.DEFAULT_TIME_UNTIL_UP))
+        interval = int(
+            interval) if interval.isdigit() else conv_const.DEFAULT_INTERVAL
+        time_until_up = int(
+            f5_monitor.get(self.tup, conv_const.DEFAULT_TIME_UNTIL_UP))
         # Fixed Successful interval and failed checks, also averting
         # DivisionByZero error
-        failed_checks = int(timeout/interval) if interval else 0
+        failed_checks = int(timeout / interval) if interval else 0
         successful_checks = conv_const.DEFAULT_FAILED_CHECKS
         if time_until_up > 0:
-            successful_checks = int(time_until_up/interval) if interval else 0
-            successful_checks = 1 \
-                if successful_checks == 0 else successful_checks
+            successful_checks = int(time_until_up /
+                                    interval) if interval else 0
+            successful_checks = 1 if successful_checks == 0 else successful_checks
 
         description = f5_monitor.get("description", None)
-        monitor_dict = dict()
+        monitor_dict = {}
         tenant, name = conv_utils.get_tenant_ref(name)
         # Added prefix for objects
         if self.prefix:
-            name = self.prefix + '-' + name
+            name = self.prefix + "-" + name
         if tenant_ref:
             tenant = tenant_ref
-        monitor_dict['tenant_ref'] = conv_utils.get_object_ref(tenant, 'tenant')
+        monitor_dict["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
         monitor_dict["name"] = name
-        monitor_dict["receive_timeout"] = interval-1 if interval else 0
+        monitor_dict["receive_timeout"] = interval - 1 if interval else 0
         monitor_dict["failed_checks"] = failed_checks
         monitor_dict["send_interval"] = interval
         monitor_dict["successful_checks"] = successful_checks
 
         if description:
             monitor_dict["description"] = description
         # transparent : Only flag if destination or port are set, else ignore
-        transparent = f5_monitor.get("transparent", 'disabled')
-        transparent = False if transparent == 'disabled' else True
-        destination = f5_monitor.get(self.dest_key, '*:*')
-        if destination in ['*', '*:0']:
-            destination = '*:*'
+        transparent = f5_monitor.get("transparent", "disabled")
+        transparent = False if transparent == "disabled" else True
+        destination = f5_monitor.get(self.dest_key, "*:*")
+        if destination in ["*", "*:0"]:
+            destination = "*:*"
             f5_monitor[self.dest_key] = destination
-        if not transparent or destination == '*:*':
-            if 'transparent' in skipped:
-                indirect.append('transparent')
+        if not transparent or destination == "*:*":
+            if "transparent" in skipped:
+                indirect.append("transparent")
         ignore_for_defaults = {}
         defaults = self.get_default_monitor(monitor_type, monitor_config)
         if defaults:
             ignore_for_defaults = copy.deepcopy(defaults)
         ignore_for_defaults.update(self.ignore)
         u_ignore = []
         na_list = []
@@ -404,28 +454,29 @@
             u_ignore = user_ignore.get("http", [])
             na_list = self.na_http
             skipped = self.convert_http(monitor_dict, f5_monitor, skipped)
         elif monitor_type == "https":
             na_list = self.na_https
             u_ignore = user_ignore.get("https", [])
             skipped = self.convert_https(monitor_dict, f5_monitor, skipped,
-                      avi_config, tenant, input_dir, cloud_name,
-                      controller_version, merge_object_mapping, sys_dict)
+                                         avi_config, tenant, input_dir,
+                                         cloud_name, controller_version,
+                                         merge_object_mapping, sys_dict)
         elif monitor_type == "dns":
             na_list = self.na_dns
             u_ignore = user_ignore.get("dns", [])
-            if f5_monitor.get('qname', None) and (not f5_monitor.get(
-                    'qname') == 'none'):
+            if f5_monitor.get(
+                    "qname", None) and (not f5_monitor.get("qname") == "none"):
                 skipped = self.convert_dns(monitor_dict, f5_monitor, skipped)
-                ignore_for_defaults.update({'qtype': 'a'})
+                ignore_for_defaults.update({"qtype": "a"})
             else:
                 msg = ('No value for mandatory field query_name, skipped '
                        'DNS Monitor %s' % key)
                 LOG.warning(msg)
-                conv_utils.add_status_row('monitor', monitor_type, name,
+                conv_utils.add_status_row("monitor", monitor_type, name,
                                           conv_const.STATUS_SKIPPED, msg)
                 return None
         elif monitor_type in ["tcp", "tcp_half_open", "tcp-half-open"]:
             na_list = self.na_tcp
             u_ignore = user_ignore.get("tcp", [])
             skipped = self.convert_tcp(monitor_dict, f5_monitor, skipped,
                                        monitor_type)
@@ -440,62 +491,64 @@
             u_ignore += user_ignore.get("gateway_icmp", [])
             skipped = self.convert_icmp(monitor_dict, f5_monitor, skipped)
         elif monitor_type == "external":
             na_list = self.na_external
             u_ignore = user_ignore.get("external", [])
             skipped = self.convert_external(monitor_dict, f5_monitor, skipped,
                                             input_dir, name)
-        if monitor_dict.get('error', False):
+        if monitor_dict.get("error", False):
             return []
-        conv_status = conv_utils.get_conv_status(
-            skipped, indirect, ignore_for_defaults, f5_monitor,
-            u_ignore, na_list)
+        conv_status = conv_utils.get_conv_status(skipped, indirect,
+                                                 ignore_for_defaults,
+                                                 f5_monitor, u_ignore, na_list)
 
         conv_utils.add_conv_status('monitor', monitor_type, name, conv_status,
-                                   [{'health_monitor': monitor_dict}])
+                                   [{
+                                       'health_monitor': monitor_dict
+                                   }], yaml.dump(f5_monitor))
         return monitor_dict
 
 
 class MonitorConfigConvV11(MonitorConfigConv):
+
     def __init__(self, f5_monitor_attributes, prefix, object_merge_check):
         """
 
         :param f5_monitor_attributes: f5 monitor attributes from yaml file.
         :param prefix: prefix for objects
         :param object_merge_check: flag for merge objects
         """
-        self.supported_types = f5_monitor_attributes['Monitor_Supported_Types']
+        self.supported_types = f5_monitor_attributes["Monitor_Supported_Types"]
         self.tup = "time-until-up"
-        self.supported_attributes = \
-            f5_monitor_attributes['Monitor_Supported_Attributes']
-        self.indirect_mappings = \
-            f5_monitor_attributes['Monitor_Indirect_Mappings']
-        self.ignore = f5_monitor_attributes['Monitor_Ignore']
+        self.supported_attributes = f5_monitor_attributes[
+            "Monitor_Supported_Attributes"]
+        self.indirect_mappings = f5_monitor_attributes[
+            "Monitor_Indirect_Mappings"]
+        self.ignore = f5_monitor_attributes["Monitor_Ignore"]
         self.dest_key = "destination"
-        self.na_http = f5_monitor_attributes['Monitor_Na_Http']
-        self.na_https = f5_monitor_attributes['Monitor_Na_Https']
-        self.na_dns = f5_monitor_attributes['Monitor_Na_Dns']
-        self.na_tcp = f5_monitor_attributes['Monitor_Na_Tcp']
-        self.na_udp = f5_monitor_attributes['Monitor_Na_Udp']
-        self.na_icmp = f5_monitor_attributes['Monitor_Na_Icmp']
-        self.na_external = f5_monitor_attributes['Monitor_Na_External']
-        self.http_attr = f5_monitor_attributes['Monitor_http_attr']
-        self.https_attr = f5_monitor_attributes['Monitor_https_attr']
-        self.dns_attr = f5_monitor_attributes['Monitor_dns_attr']
-        self.tcp_attr = f5_monitor_attributes['Monitor_tcp_attr']
-        self.udp_attr = f5_monitor_attributes['Monitor_udp_attr']
-        self.ext_attr = f5_monitor_attributes['Monitor_ext_attr']
+        self.na_http = f5_monitor_attributes["Monitor_Na_Http"]
+        self.na_https = f5_monitor_attributes["Monitor_Na_Https"]
+        self.na_dns = f5_monitor_attributes["Monitor_Na_Dns"]
+        self.na_tcp = f5_monitor_attributes["Monitor_Na_Tcp"]
+        self.na_udp = f5_monitor_attributes["Monitor_Na_Udp"]
+        self.na_icmp = f5_monitor_attributes["Monitor_Na_Icmp"]
+        self.na_external = f5_monitor_attributes["Monitor_Na_External"]
+        self.http_attr = f5_monitor_attributes["Monitor_http_attr"]
+        self.https_attr = f5_monitor_attributes["Monitor_https_attr"]
+        self.dns_attr = f5_monitor_attributes["Monitor_dns_attr"]
+        self.tcp_attr = f5_monitor_attributes["Monitor_tcp_attr"]
+        self.udp_attr = f5_monitor_attributes["Monitor_udp_attr"]
+        self.ext_attr = f5_monitor_attributes["Monitor_ext_attr"]
         # Added prefix for objects
         self.prefix = prefix
         self.object_merge_check = object_merge_check
         self.mon_count = 0
 
     def get_default_monitor(self, monitor_type, monitor_config):
         """
-
         :param monitor_type:  type of monitor
         :param monitor_config: parsed f5 monitor dict
         :return:
         """
         default_name = "%s %s" % (monitor_type, monitor_type)
         return monitor_config.get(default_name, {})
 
@@ -506,19 +559,19 @@
         :param key: object name
         :return:
         """
         f5_monitor = monitor_config[key]
         logging.debug("f5_monitor "+key)
         monitor_type, monitor_name = key.split(" ")
         parent_name = f5_monitor.get("defaults-from", None)
-        parent_name = None if parent_name == 'none' else \
-                        conv_utils.get_tenant_ref(parent_name)[1] if \
-                        parent_name is not None else parent_name
+        parent_name = (None if parent_name == "none" else
+                       conv_utils.get_tenant_ref(parent_name)[1]
+                       if parent_name is not None else parent_name)
         if parent_name and monitor_name != parent_name:
-            key = monitor_type+" "+parent_name
+            key = monitor_type + " " + parent_name
             parent_monitor = monitor_config.get(key, None)
             if parent_monitor:
                 parent_monitor = self.get_defaults(monitor_config, key)
                 copy_p_mon = copy.deepcopy(parent_monitor)
                 copy_p_mon.update(f5_monitor)
                 f5_monitor = copy_p_mon
         return f5_monitor
@@ -531,37 +584,38 @@
 
         :param monitor_dict: dict for converted avi config
         :param f5_monitor: parsed f5 monitor dict
         :param skipped: skipped list
         :return: skipped
         """
         skipped = [key for key in skipped if key not in self.http_attr]
-        send = f5_monitor.get('send', 'HEAD / HTTP/1.0')
+        send = f5_monitor.get("send", "HEAD / HTTP/1.0")
         send = self.update_request_for_avi(send, True)
         monitor_dict["type"] = "HEALTH_MONITOR_HTTP"
         monitor_dict["http_monitor"] = {
             "exact_http_request": True,
             "http_request": send,
-            "http_response_code": ["HTTP_2XX", "HTTP_3XX"]}
+            "http_response_code": ["HTTP_2XX", "HTTP_3XX"],
+        }
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
+        if "." in destination:
+            dest_str = destination.split(".")
         # F5 version 11 have destination as port added code.
         # if * is there then ignore it else add to port.
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
-        if dest_str[0] != '*':
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         # Added mapping for http_response.
         maintenance_resp, http_rsp = self.get_maintenance_response(f5_monitor)
         if maintenance_resp:
-            monitor_dict["http_monitor"]["maintenance_response"] = \
-                                                                maintenance_resp
+            monitor_dict["http_monitor"][
+                "maintenance_response"] = maintenance_resp
         monitor_dict["http_monitor"]["http_response"] = http_rsp
         return skipped
 
     def convert_https(self, monitor_dict, f5_monitor, skipped, avi_config,
                       tenant_ref, input_dir, cloud_name, controller_version,
                       merge_object_mapping, sys_dict):
         """
@@ -575,96 +629,98 @@
         :param cloud_name: cloud which used for converted output
         :param controller_version: controller version of avi
         :param merge_object_mapping: flag for object merge
         :param sys_dict: baseline profile dict
         :return:
         """
         skipped = [key for key in skipped if key not in self.https_attr]
-        send = f5_monitor.get('send', 'HEAD / HTTP/1.0')
+        send = f5_monitor.get("send", "HEAD / HTTP/1.0")
         send = self.update_request_for_avi(send, True)
         monitor_dict["type"] = "HEALTH_MONITOR_HTTPS"
         monitor_dict["https_monitor"] = {
             "exact_http_request": True,
             "http_request": send,
-            "http_response_code": ["HTTP_2XX", "HTTP_3XX"]}
-        monitor_dict["https_monitor"]['ssl_attributes'] = dict()
-        if parse_version(controller_version) >= parse_version('17.1'):
+            "http_response_code": ["HTTP_2XX", "HTTP_3XX"],
+        }
+        monitor_dict["https_monitor"]["ssl_attributes"] = {}
+        if parse_version(controller_version) >= parse_version("17.1"):
             # Added code to handle ssl attribute.
             # Removed ssl cert key ref from monitor's ssl attribute
-            # cipherlist and ssl-profile were present in config then it should use ssl-profile as priority
-            if f5_monitor.get('cipherlist', None) or f5_monitor.get('ssl-profile', None):
-                if f5_monitor.get('ssl-profile', None):
-                    _, ssl_ref = conv_utils.get_tenant_ref(f5_monitor['ssl-profile'])
-                    monitor_dict["https_monitor"]['ssl_attributes'][
-                        'ssl_profile_ref'] = conv_utils.get_object_ref(
-                                                ssl_ref,
-                                                conv_const.OBJECT_TYPE_SSL_PROFILE,
-                                                tenant_ref)
+            # cipherlist and ssl-profile were present in config then it should
+            # use ssl-profile as priority
+            if (f5_monitor.get("cipherlist", None) and  (not f5_monitor.get("cipherlist") == "none"))\
+                or (f5_monitor.get("ssl-profile", None) and (not f5_monitor.get("ssl-profile"))):
+                if f5_monitor.get("ssl-profile", None):
+                    _, ssl_ref = conv_utils.get_tenant_ref(
+                        f5_monitor["ssl-profile"])
+                    monitor_dict["https_monitor"]["ssl_attributes"][
+                        "ssl_profile_ref"] = conv_utils.get_object_ref(
+                            ssl_ref, conv_const.OBJECT_TYPE_SSL_PROFILE,
+                            tenant_ref)
                 else:
-                    self.create_sslprofile(monitor_dict, f5_monitor, avi_config,
-                               tenant_ref, cloud_name, merge_object_mapping,
-                                       sys_dict)
+                    self.create_sslprofile(monitor_dict, f5_monitor,
+                                           avi_config, tenant_ref, cloud_name,
+                                           merge_object_mapping, sys_dict)
             else:
-                monitor_dict["https_monitor"]['ssl_attributes'][
-                    'ssl_profile_ref'] = conv_utils.get_object_ref(
-                                         'System-Standard',
-                                         conv_const.OBJECT_TYPE_SSL_PROFILE,
-                                                                    tenant_ref)
+                monitor_dict["https_monitor"]["ssl_attributes"][
+                    "ssl_profile_ref"] = conv_utils.get_object_ref(
+                        "System-Standard", conv_const.OBJECT_TYPE_SSL_PROFILE,
+                        tenant_ref)
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         # F5 version 11 have destination as port added code.
         # if * is there then ignore it else add to port.
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         # Added mapping for http_response.
-        maintenance_resp,http_rsp = self.get_maintenance_response(f5_monitor)
+        maintenance_resp, http_rsp = self.get_maintenance_response(f5_monitor)
         if maintenance_resp:
-            monitor_dict["https_monitor"]["maintenance_response"] = \
-                                                                maintenance_resp
+            monitor_dict["https_monitor"][
+                "maintenance_response"] = maintenance_resp
         monitor_dict["https_monitor"]["http_response"] = http_rsp
         return skipped
 
     def convert_dns(self, monitor_dict, f5_monitor, skipped):
         """
 
         :param monitor_dict: converted monitor dict
         :param f5_monitor:  parsed f5 dict
         :param skipped: skipped list for monitor
         :return: skipped
         """
         skipped = [key for key in skipped if key not in self.dns_attr]
         accept_rcode = f5_monitor.get("accept-rcode", None)
-        dns_monitor = dict()
+        dns_monitor = {}
         if accept_rcode and accept_rcode == "no-error":
             rcode = "RCODE_NO_ERROR"
         else:
             rcode = "RCODE_ANYTHING"
         qtype = f5_monitor.get("answer-contains", None)
         if qtype:
-            if qtype == 'query-type':
-                qtype = 'DNS_QUERY_TYPE'
-            elif qtype == 'any-type':
-                qtype = 'DNS_ANY_TYPE'
-            elif qtype == 'anything':
-                qtype = 'DNS_ANY_THING'
+            if qtype == "query-type":
+                qtype = "DNS_QUERY_TYPE"
+            elif qtype == "any-type":
+                qtype = "DNS_ANY_TYPE"
+            elif qtype == "anything":
+                qtype = "DNS_ANY_THING"
             dns_monitor["qtype"] = qtype
         monitor_dict["type"] = "HEALTH_MONITOR_DNS"
         dns_monitor["rcode"] = rcode
         dns_monitor["query_name"] = f5_monitor.get("qname", None)
         monitor_dict["dns_monitor"] = dns_monitor
         # Added mapping for http_response.
         maintenance_resp, http_rsp = self.get_maintenance_response(f5_monitor)
         if maintenance_resp:
-            monitor_dict["dns_monitor"]["maintenance_response"] = \
-                                                                maintenance_resp
+            monitor_dict["dns_monitor"][
+                "maintenance_response"] = maintenance_resp
         monitor_dict["dns_monitor"]["http_response"] = http_rsp
         return skipped
 
     def convert_tcp(self, monitor_dict, f5_monitor, skipped, type):
         """
 
         :param monitor_dict: converted monitor dict
@@ -675,25 +731,25 @@
         """
         skipped = [key for key in skipped if key not in self.tcp_attr]
         # F5 version 11 have destination as port added code.
         # if * is there then ignore it else add to port.
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         monitor_dict["type"] = "HEALTH_MONITOR_TCP"
         request = f5_monitor.get("send", None)
         request = self.update_request_for_avi(request, False)
         response = f5_monitor.get("recv", None)
-        if response == 'none':
+        if response == "none":
             response = None
         tcp_monitor = None
         if request or response:
             tcp_monitor = {"tcp_request": request, "tcp_response": response}
             monitor_dict["tcp_monitor"] = tcp_monitor
         # Added mapping for http_response.
         maintenance_resp, http_rsp = self.get_maintenance_response(f5_monitor)
@@ -702,49 +758,49 @@
                 tcp_monitor["maintenance_response"] = maintenance_resp
             tcp_monitor["tcp_response"] = http_rsp
         else:
             tcp_monitor = {"tcp_response": http_rsp}
             if maintenance_resp:
                 tcp_monitor["maintenance_response"] = maintenance_resp
             monitor_dict["tcp_monitor"] = tcp_monitor
-        if type == 'tcp-half-open':
+        if type == "tcp-half-open":
             if tcp_monitor:
                 tcp_monitor["tcp_half_open"] = True
             else:
                 tcp_monitor = {"tcp_half_open": True}
                 monitor_dict["tcp_monitor"] = tcp_monitor
 
         return skipped
 
     def convert_udp(self, monitor_dict, f5_monitor, skipped):
         """
 
-           :param monitor_dict: converted monitor dict
-           :param f5_monitor: parsed f5 config monitor dict
-           :param skipped: skipped list for monitor
-           :param type:  type of monitor
-           :return: skipped
+        :param monitor_dict: converted monitor dict
+        :param f5_monitor: parsed f5 config monitor dict
+        :param skipped: skipped list for monitor
+        :param type:  type of monitor
+        :return: skipped
         """
         skipped = [key for key in skipped if key not in self.udp_attr]
         # F5 version 11 have destination as port added code.
         # if * is there then ignore it else add to port.
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         monitor_dict["type"] = "HEALTH_MONITOR_UDP"
         request = f5_monitor.get("send", None)
         request = self.update_request_for_avi(request, False)
         response = f5_monitor.get("recv", None)
-        if response == 'none':
+        if response == "none":
             response = None
         udp_monitor = None
         if request or response:
             udp_monitor = {"udp_request": request, "udp_response": response}
             monitor_dict["udp_monitor"] = udp_monitor
         # Added mapping for http_response.
         maintenance_resp, http_rsp = self.get_maintenance_response(f5_monitor)
@@ -765,141 +821,150 @@
         :param f5_monitor: parsed f5 config monitor dict
         :param skipped: skipped list for monitor
         :return: skipped
         """
         monitor_dict["type"] = "HEALTH_MONITOR_PING"
         return skipped
 
-    def convert_external(self, monitor_dict, f5_monitor, skipped,
-                         input_dir, name):
+    def convert_external(self, monitor_dict, f5_monitor, skipped, input_dir,
+                         name):
         """
         :param monitor_dict: converted monitor dict
         :param f5_monitor: parsed f5 config monitor dict
         :param skipped: skipped list for monitor
         :param input_dir: location of cert and key
         :return: skipped
         """
         skipped = [key for key in skipped if key not in self.ext_attr]
         monitor_dict["type"] = "HEALTH_MONITOR_EXTERNAL"
-        cmd_code = f5_monitor.get("run", 'none')
+        cmd_code = f5_monitor.get("run", "none")
         user_defined_vars = ""
         for m_key in f5_monitor.keys():
-            if 'user-defined_' in m_key:
+            if "user-defined_" in m_key:
                 var_value = f5_monitor[m_key]
-                var_key = m_key.replace('user-defined_', '')
+                var_key = m_key.replace("user-defined_", "")
                 skipped.remove(m_key)
                 user_defined_vars += '%s=%s,' % (var_key, var_value)
         user_defined_vars = user_defined_vars[:-1]
-        cmd_code = None if cmd_code == 'none' else cmd_code
+        cmd_code = None if cmd_code == "none" else cmd_code
         if cmd_code:
-            cmd_code = conv_utils.upload_file(
-                input_dir + os.path.sep + cmd_code)
+            cmd_code = conv_utils.upload_file(input_dir + os.path.sep +
+                                              cmd_code)
         else:
-            LOG.warn("Skipped monitor: %s for no value in run attribute" % name)
+            LOG.warning("Skipped monitor: %s for no value in run attribute", name)
             conv_utils.add_status_row("monitor", "external", name,
                                       conv_const.STATUS_MISSING_FILE)
-            monitor_dict['error'] = True
+            monitor_dict["error"] = True
             return None
         if cmd_code:
             ext_monitor = {
                 "command_code": cmd_code,
                 "command_parameters": f5_monitor.get("args", None),
-                "command_variables": user_defined_vars
+                "command_variables": user_defined_vars,
             }
             monitor_dict["external_monitor"] = ext_monitor
         else:
-            LOG.warn("MISSING File: %s" % name)
+            LOG.warning("MISSING File: %s", name)
             conv_utils.add_status_row("monitor", "external", name,
                                       conv_const.STATUS_MISSING_FILE)
-            monitor_dict['error'] = True
+            monitor_dict["error"] = True
             return None
         return skipped
 
     def get_maintenance_response(self, f5_monitor):
         """
         Returns avi maintenance response value from F5 monitor object
         :param f5_monitor: F5 monitor object
         :return: Avi monitor maintenance response value
         """
         # Addded mapping for http_response.
-        maintenance_response = ''
-        http_response = ''
-        if "reverse" in f5_monitor and f5_monitor["reverse"] != 'disabled':
-            maintenance_response = f5_monitor.get("recv", '')
-            http_response = f5_monitor.get('recv disable', f5_monitor.get(
-                                'recv-disable', ''))
+        maintenance_response = ""
+        http_response = ""
+        if "reverse" in f5_monitor and f5_monitor["reverse"] != "disabled":
+            maintenance_response = f5_monitor.get("recv", "")
+            http_response = f5_monitor.get("recv disable",
+                                           f5_monitor.get("recv-disable", ""))
         else:
-            http_response = f5_monitor.get("recv", '')
-            maintenance_response = f5_monitor.get('recv disable',
-                                            f5_monitor.get('recv-disable', ''))
+            http_response = f5_monitor.get("recv", "")
+            maintenance_response = f5_monitor.get(
+                "recv disable", f5_monitor.get("recv-disable", ""))
         if maintenance_response:
-            maintenance_response = \
-                maintenance_response.replace('\"', '').strip()
+            maintenance_response = maintenance_response.replace('"',
+                                                                "").strip()
         if http_response:
-            http_response = \
-                http_response.replace('\"', '').strip()
-        if maintenance_response == 'none':
+            http_response = http_response.replace('"', "").strip()
+        if maintenance_response == "none":
             maintenance_response = None
-        if http_response == 'none':
-            http_response = ''
+        if http_response == "none":
+            http_response = ""
         return maintenance_response, http_response
 
 
 class MonitorConfigConvV10(MonitorConfigConv):
 
     def __init__(self, f5_monitor_attributes, prefix, object_merge_check):
         """
 
-       :param f5_monitor_attributes: f5 monitor attributes from yaml file.
-       :param prefix: prefix for objects
-       :param object_merge_check: flag for merge objects
+        :param f5_monitor_attributes: f5 monitor attributes from yaml file.
+        :param prefix: prefix for objects
+        :param object_merge_check: flag for merge objects
         """
-        self.supported_types = f5_monitor_attributes['Monitor_Supported_Types']
+        self.supported_types = f5_monitor_attributes["Monitor_Supported_Types"]
         self.tup = "time until up"
-        self.supported_attributes =\
-            f5_monitor_attributes['Monitor_Supported_Attributes']
-        self.indirect_mappings = \
-            f5_monitor_attributes['Monitor_Indirect_Mappings']
-        self.ignore = f5_monitor_attributes['Monitor_Ignore']
+        self.supported_attributes = f5_monitor_attributes[
+            "Monitor_Supported_Attributes"]
+        self.indirect_mappings = f5_monitor_attributes[
+            "Monitor_Indirect_Mappings"]
+        self.ignore = f5_monitor_attributes["Monitor_Ignore"]
         self.dest_key = "dest"
-        self.na_http = f5_monitor_attributes['Monitor_Na_Http']
-        self.na_https = f5_monitor_attributes['Monitor_Na_Https']
-        self.na_dns =  f5_monitor_attributes['Monitor_Na_Dns']
-        self.na_tcp = f5_monitor_attributes['Monitor_Na_Tcp']
-        self.na_udp = f5_monitor_attributes['Monitor_Na_Udp']
-        self.na_icmp = f5_monitor_attributes['Monitor_Na_Icmp']
-        self.na_external = f5_monitor_attributes['Monitor_Na_External']
-        self.http_attr = f5_monitor_attributes['Monitor_http_attr']
-        self.https_attr = f5_monitor_attributes['Monitor_https_attr']
-        self.tcp_attr = f5_monitor_attributes['Monitor_tcp_attr']
-        self. udp_attr = f5_monitor_attributes['Monitor_udp_attr']
-        self.ext_attr = f5_monitor_attributes['Monitor_ext_attr']
+        self.na_http = f5_monitor_attributes["Monitor_Na_Http"]
+        self.na_https = f5_monitor_attributes["Monitor_Na_Https"]
+        self.na_dns = f5_monitor_attributes["Monitor_Na_Dns"]
+        self.na_tcp = f5_monitor_attributes["Monitor_Na_Tcp"]
+        self.na_udp = f5_monitor_attributes["Monitor_Na_Udp"]
+        self.na_icmp = f5_monitor_attributes["Monitor_Na_Icmp"]
+        self.na_external = f5_monitor_attributes["Monitor_Na_External"]
+        self.http_attr = f5_monitor_attributes["Monitor_http_attr"]
+        self.https_attr = f5_monitor_attributes["Monitor_https_attr"]
+        self.tcp_attr = f5_monitor_attributes["Monitor_tcp_attr"]
+        self.udp_attr = f5_monitor_attributes["Monitor_udp_attr"]
+        self.ext_attr = f5_monitor_attributes["Monitor_ext_attr"]
         # Added prefix for objects
         self.prefix = prefix
         self.object_merge_check = object_merge_check
         self.mon_count = 0
 
     def get_name_type(self, f5_monitor, key):
+        """
+        :param f5_monitor: parsed f5 monitor dict
+        :param key: object name
+        :return:
+        """
         return f5_monitor.get("type"), key
 
     def get_default_monitor(self, monitor_type, monitor_config):
+        """
+        :param monitor_config :parsed monitor config dict
+        :param monitor_type: object type
+        :return:
+        """
         return monitor_config.get(monitor_type, {})
 
     def get_defaults(self, monitor_config, key):
         """
 
         :param monitor_config: parsed monitor config dict
         :param key: object name
         :return:
         """
         f5_monitor = monitor_config[key]
         parent_name = f5_monitor.get("defaults from", None)
-        parent_name = None if parent_name == 'none' else \
-                        conv_utils.get_tenant_ref(parent_name)[1] if \
-                        parent_name is not None else parent_name
+        parent_name = (None if parent_name == "none" else
+                       conv_utils.get_tenant_ref(parent_name)[1]
+                       if parent_name is not None else parent_name)
         if parent_name and key != parent_name:
             parent_monitor = monitor_config.get(parent_name, None)
             if parent_monitor:
                 parent_monitor = self.get_defaults(monitor_config, parent_name)
                 parent_monitor = copy.deepcopy(parent_monitor)
                 parent_monitor.update(f5_monitor)
                 f5_monitor = parent_monitor
@@ -920,41 +985,41 @@
         :param input_dir: location of cert and key
         :param cloud_name: cloud which used for converted output
         :param controller_version: controller version of avi
         :param merge_object_mapping: flag for object merge
         :param sys_dict: baseline profile dict
         :return:
         """
-        ignore_list = ['adaptive']
+        ignore_list = ["adaptive"]
         http_attr = self.http_attr + ignore_list
         skipped = [key for key in skipped if key not in http_attr]
-        send = f5_monitor.get('send', 'HEAD / HTTP/1.0')
+        send = f5_monitor.get("send", "HEAD / HTTP/1.0")
         send = self.update_request_for_avi(send, False)
         monitor_dict["type"] = "HEALTH_MONITOR_HTTP"
         monitor_dict["http_monitor"] = {
             "exact_http_request": True,
             "http_request": send,
-            "http_response_code": ["HTTP_2XX", "HTTP_3XX"]
+            "http_response_code": ["HTTP_2XX", "HTTP_3XX"],
         }
         # F5 version 10 have dest as port added code.
         # if * is there then ignore it else add to port.
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . is appear with port ex: *.80
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         # Added mapping for http_response.
         maintenance_resp, http_resp = self.get_maintenance_response(f5_monitor)
         if maintenance_resp:
-            monitor_dict["http_monitor"]["maintenance_response"] = \
-                                                                maintenance_resp
+            monitor_dict["http_monitor"][
+                "maintenance_response"] = maintenance_resp
         monitor_dict["http_monitor"]["http_response"] = http_resp
         return skipped
 
     def convert_https(self, monitor_dict, f5_monitor, skipped,
                       avi_config, tenant, input_dir, cloud_name,
                       controller_version, merge_object_mapping, sys_dict):
         """
@@ -967,55 +1032,60 @@
         :param input_dir: location of cert and key
         :param cloud_name: cloud which used for converted output
         :param controller_version: controller version of avi
         :param merge_object_mapping: flag for object merge
         :param sys_dict: baseline profile dict
         :return:
         """
-        ignore_list = ['compatibility']
+        ignore_list = ["compatibility"]
         https_attr = ignore_list + self.https_attr
         skipped = [key for key in skipped if key not in https_attr]
-        send = f5_monitor.get('send', None)
+        send = f5_monitor.get("send", None)
         send = self.update_request_for_avi(send, False)
         monitor_dict["type"] = "HEALTH_MONITOR_HTTPS"
         monitor_dict["https_monitor"] = {
             "exact_http_request": True,
             "http_request": send,
-            "http_response_code": ["HTTP_2XX", "HTTP_3XX"]
+            "http_response_code": ["HTTP_2XX", "HTTP_3XX"],
         }
         # Added code to handel ssl attribute and certificate.
-        monitor_dict["https_monitor"]['ssl_attributes'] = dict()
-        if parse_version(controller_version) >= parse_version('17.1'):
+        monitor_dict["https_monitor"]["ssl_attributes"] = {}
+        if parse_version(controller_version) >= parse_version("17.1"):
             # Added code to handle ssl attribute
             # Removed ssl cert and key ref to monitor' ssl attribute
             if f5_monitor.get('cipherlist', None):
-                self.create_sslprofile(monitor_dict, f5_monitor, avi_config,
-                            tenant, cloud_name, merge_object_mapping, sys_dict)
+                self.create_sslprofile(
+                    monitor_dict,
+                    f5_monitor,
+                    avi_config,
+                    tenant,
+                    cloud_name,
+                    merge_object_mapping,
+                    sys_dict)
             else:
-                monitor_dict["https_monitor"]['ssl_attributes'][
-                    'ssl_profile_ref'] = conv_utils.get_object_ref(
-                                            'System-Standard',
-                                            conv_const.OBJECT_TYPE_SSL_PROFILE,
-                                            tenant)
+                monitor_dict["https_monitor"]["ssl_attributes"][
+                    "ssl_profile_ref"] = conv_utils.get_object_ref(
+                        "System-Standard", conv_const.OBJECT_TYPE_SSL_PROFILE,
+                        tenant)
         # F5 version 10 have dest as port added code.
         # if * is there then ignore it else add to port.
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         # Added mapping for http_response.
         maintenance_resp, http_resp = self.get_maintenance_response(f5_monitor)
         if maintenance_resp:
-            monitor_dict["https_monitor"]["maintenance_response"] = \
-                                                                maintenance_resp
+            monitor_dict["https_monitor"][
+                "maintenance_response"] = maintenance_resp
         monitor_dict["https_monitor"]["http_response"] = http_resp
         return skipped
 
     def convert_tcp(self, monitor_dict, f5_monitor, skipped, type):
         """
 
         :param monitor_dict: converted monitor dict
@@ -1026,44 +1096,44 @@
         """
         skipped = [key for key in skipped if key not in self.tcp_attr]
         # F5 version 10 have dest as port added code.
         # if * is there then ignore it else add to port.
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         monitor_dict["type"] = "HEALTH_MONITOR_TCP"
         request = f5_monitor.get("send", None)
         request = self.update_request_for_avi(request, False)
         response = f5_monitor.get("recv", None)
         tcp_monitor = None
         if request or response:
-            request = request.replace('\"', '') if request else None
-            response = response.replace('\"', '') if response else None
-            if response == 'none':
+            request = request.replace('"', "") if request else None
+            response = response.replace('"', "") if response else None
+            if response == "none":
                 response = None
             tcp_monitor = {"tcp_request": request, "tcp_response": response}
             monitor_dict["tcp_monitor"] = tcp_monitor
         # Added mapping for http_response.
         maintenance_resp, http_rsp = self.get_maintenance_response(f5_monitor)
         if tcp_monitor:
             if maintenance_resp:
                 tcp_monitor["maintenance_response"] = maintenance_resp
             tcp_monitor["http_response"] = http_rsp
         else:
             tcp_monitor = {"http_response": http_rsp}
             if maintenance_resp:
                 tcp_monitor["maintenance_response"] = maintenance_resp
             monitor_dict["tcp_monitor"] = tcp_monitor
-        if type == 'tcp_half_open':
+        if type == "tcp_half_open":
             if tcp_monitor:
                 tcp_monitor["tcp_half_open"] = True
             else:
                 tcp_monitor = {"tcp_half_open": True}
                 monitor_dict["tcp_monitor"] = tcp_monitor
         return skipped
 
@@ -1078,29 +1148,29 @@
         """
         skipped = [key for key in skipped if key not in self.udp_attr]
         # F5 version 10 have dest as port added code.
         # if * is there then ignore it else add to port.
         destination = f5_monitor.get(self.dest_key, "*:*")
         dest_str = destination.split(":")
         # some config . appear with port. ex '*.80'
-        if '.' in destination:
-            dest_str = destination.split('.')
-        if dest_str[0] != '*':
+        if "." in destination:
+            dest_str = destination.split(".")
+        if dest_str[0] != "*":
             skipped.append(self.dest_key)
         if dest_str[1].isdigit():
             monitor_dict["monitor_port"] = dest_str[1]
         monitor_dict["type"] = "HEALTH_MONITOR_UDP"
         request = f5_monitor.get("send", None)
         request = self.update_request_for_avi(request, False)
         response = f5_monitor.get("recv", None)
         udp_monitor = None
         if request or response:
-            request = request.replace('\"', '') if request else None
-            response = response.replace('\"', '') if response else None
-            if response == 'none':
+            request = request.replace('"', "") if request else None
+            response = response.replace('"', "") if response else None
+            if response == "none":
                 response = None
             udp_monitor = {"udp_request": request, "udp_response": response}
             monitor_dict["udp_monitor"] = udp_monitor
         # Added mapping for http_response.
         maintenance_resp, http_resp = self.get_maintenance_response(f5_monitor)
         if udp_monitor:
             if maintenance_resp:
@@ -1121,83 +1191,80 @@
         :param skipped: skipped list for monitor
         :param type:  type of monitor
         :return: skipped
         """
         monitor_dict["type"] = "HEALTH_MONITOR_PING"
         return skipped
 
-    def convert_external(self, monitor_dict, f5_monitor, skipped,
-                         input_dir, name):
+    def convert_external(self, monitor_dict, f5_monitor, skipped, input_dir,
+                         name):
         """
-           :param monitor_dict: converted monitor dict
-           :param f5_monitor: parsed f5 config monitor dict
-           :param skipped: skipped list for monitor
-           :param input_dir: location of cert and key
-           :return: skipped
+        :param monitor_dict: converted monitor dict
+        :param f5_monitor: parsed f5 config monitor dict
+        :param skipped: skipped list for monitor
+        :param input_dir: location of cert and key
+        :return: skipped
         """
         script_vars = ""
         for key in f5_monitor.keys():
-            if key not in ('args', 'run') and '\"' in f5_monitor[key]:
+            if key not in ("args", "run") and '"' in f5_monitor[key]:
                 self.ext_attr.append(key)
-                param_value = f5_monitor[key].replace('\"', '')
+                param_value = f5_monitor[key].replace('"', "")
                 script_vars += "%s=%s," % (key, param_value)
         if script_vars:
             script_vars = script_vars[:-1]
         skipped = [key for key in skipped if key not in self.ext_attr]
         cmd_code = f5_monitor.get("run", None)
         cmd_params = f5_monitor.get("args", None)
-        cmd_code = cmd_code.replace('\"', '') if cmd_code else None
-        cmd_params = cmd_params.replace('\"', '') if cmd_params else None
+        cmd_code = cmd_code.replace('"', "") if cmd_code else None
+        cmd_params = cmd_params.replace('"', "") if cmd_params else None
         if cmd_code:
-            cmd_code = conv_utils.upload_file(
-                input_dir + os.path.sep + cmd_code)
+            cmd_code = conv_utils.upload_file(input_dir + os.path.sep +
+                                              cmd_code)
         else:
-            LOG.warn("Skipped monitor: %s for no value in run attribute" % name)
+            LOG.warning("Skipped monitor: %s for no value in run attribute", name)
             conv_utils.add_status_row("monitor", "external", name,
                                       conv_const.STATUS_MISSING_FILE)
-            monitor_dict['error'] = True
+            monitor_dict["error"] = True
             return None
         monitor_dict["type"] = "HEALTH_MONITOR_EXTERNAL"
         if cmd_code:
             ext_monitor = {
                 "command_code": cmd_code,
                 "command_parameters": cmd_params,
-                "command_variables": script_vars
+                "command_variables": script_vars,
             }
             monitor_dict["external_monitor"] = ext_monitor
         else:
-            LOG.warn("MISSING File: %s" % name)
+            LOG.warning("MISSING File: %s", name)
             conv_utils.add_status_row("monitor", "external", name,
                                       conv_const.STATUS_MISSING_FILE)
-            monitor_dict['error'] = True
+            monitor_dict["error"] = True
             return None
 
         return skipped
 
     def get_maintenance_response(self, f5_monitor):
         """
         Returns avi maintenance response value from F5 monitor object
         :param f5_monitor: F5 monitor object
         :return: Avi monitor maintenance response value
         """
         # Addded mapping for http_response.
-        maintenance_response = ''
-        http_response = ''
+        maintenance_response = ""
+        http_response = ""
         if "reverse" in f5_monitor:
-            maintenance_response = f5_monitor.get("recv", '')
-            http_response = f5_monitor.get('recv disable', '')
+            maintenance_response = f5_monitor.get("recv", "")
+            http_response = f5_monitor.get("recv disable", "")
         else:
-            http_response = f5_monitor.get("recv", '')
-            maintenance_response = f5_monitor.get('recv disable', '')
+            http_response = f5_monitor.get("recv", "")
+            maintenance_response = f5_monitor.get("recv disable", "")
         if maintenance_response:
-            maintenance_response = \
-                maintenance_response.replace('\"', '').strip()
+            maintenance_response = maintenance_response.replace('"',
+                                                                "").strip()
         if http_response:
-            http_response = \
-                http_response.replace('\"', '').strip()
-        if maintenance_response == 'none':
+            http_response = http_response.replace('"', "").strip()
+        if maintenance_response == "none":
             maintenance_response = None
-        if http_response == 'none':
-            http_response = ''
+        if http_response == "none":
+            http_response = ""
         return maintenance_response, http_response
-
-
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/persistence_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/persistence_converter.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,92 +1,119 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 import logging
+
 import avi.migrationtools.f5_converter.converter_constants as final
 import avi.migrationtools.f5_converter.converter_constants as conv_const
-from avi.migrationtools.f5_converter.profile_converter import ProfileConfigConv
-from avi.migrationtools.f5_converter.conversion_util import F5Util
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
+from avi.migrationtools.f5_converter.conversion_util import F5Util
+from avi.migrationtools.f5_converter.profile_converter import ProfileConfigConv
+
 LOG = logging.getLogger(__name__)
 # Creating f5 object for util library.
 conv_utils = F5Util()
 
 
 class PersistenceConfigConv(object):
     @classmethod
-    def get_instance(cls, version, f5_persistence_attributes, prefix,
-                     object_merge_check):
+    def get_instance(cls, version, f5_persistence_attributes,
+                     prefix, object_merge_check):
         """
 
         :param version: version of f5 instance
         :param f5_persistence_attributes: yaml attribute file for object
         :param prefix: prefix for objects
         :param object_merge_check: Flag for object merge
         :return:
         """
-        if version == '10':
-            return PersistenceConfigConvV10(f5_persistence_attributes, prefix,
-                                            object_merge_check)
-        if version in ['11', '12']:
-            return PersistenceConfigConvV11(f5_persistence_attributes, prefix,
-                                            object_merge_check)
+        if version == "10":
+            return PersistenceConfigConvV10(
+                f5_persistence_attributes, prefix, object_merge_check)
+        if version in ["11", "12"]:
+            return PersistenceConfigConvV11(
+                f5_persistence_attributes, prefix, object_merge_check)
 
     def convert_cookie_persistence(self, name, profile):
+        '''
+        Method for converting cookie persistence
+        '''
         pass
 
     def convert_cookie(self, name, profile, skipped, tenant):
+        '''
+        convert cookie
+        '''
         pass
 
     def convert_ssl(self, name, profile, skipped, indirect_mappings, tenant):
+        '''
+        Method for ssl conversion
+        '''
         pass
 
     def convert_source_addr(self, name, profile, skipped, tenant):
+        '''
+        Method for converting source address
+        '''
         pass
 
-    def update_conversion_status(self, conv_status, persist_mode, name,
-                                 persist_profile):
+    def update_conversion_status(
+            self,
+            conv_status,
+            persist_mode,
+            name,
+            persist_profile,
+            f5_profile):
+        '''
+        Methode to update conversion status
+        '''
         pass
 
     def update_conv_status_for_error(self, name, persist_mode, key):
         pass
 
     def update_conv_status_for_skip(self, persist_mode, name, msg):
         pass
 
-    def convert(self, f5_config, avi_config, user_ignore, tenant_ref,
-                merge_object_mapping, sys_dict):
+    def convert(self, f5_config, avi_config, user_ignore,
+                tenant_ref, merge_object_mapping, sys_dict):
         """
 
         :param f5_config: parsed f5 config
         :param avi_config: dict of avi config
         :param user_ignore: Ignore config defined by user
         :param tenant_ref: tenant of which output to converted
         :param merge_object_mapping: flag for object merge
         :param sys_dict: baseline profile
         :return:
         """
-        avi_config['hash_algorithm'] = []
+        avi_config["hash_algorithm"] = []
         converted_objs = []
-        f5_persistence_dict = f5_config.get('persistence')
-        user_ignore = user_ignore.get('persistence', {})
+        f5_persistence_dict = f5_config.get("persistence")
+        user_ignore = user_ignore.get("persistence", {})
         # Added variable to get total object count.
         progressbar_count = 0
         total_size = len(f5_persistence_dict.keys())
         print("Converting Persistence Profiles...")
         for key in f5_persistence_dict.keys():
             progressbar_count += 1
             persist_mode = None
             name = None
             skipped = []
             # Added call to check the progress.
             msg = "persistence conversion started..."
-            conv_utils.print_progress_bar(progressbar_count, total_size, msg,
-                             prefix='Progress', suffix='')
-            if key == 'global-settings':
+            conv_utils.print_progress_bar(
+                progressbar_count,
+                total_size,
+                msg,
+                prefix="Progress",
+                suffix="")
+            if key == "global-settings":
                 msg = 'persist mode not supported skipping conversion: %s' \
                       % name
                 LOG.warning(msg)
                 self.update_conv_status_for_skip(None, name, msg)
                 continue
             try:
                 persist_mode, name = key.split(" ")
@@ -98,333 +125,340 @@
                 tenant, name = conv_utils.get_tenant_ref(name)
                 if tenant_ref:
                     tenant = tenant_ref
                 if self.prefix:
                     name = '{}-{}'.format(self.prefix, name)
                 # Enabled the cookie support
                 if persist_mode == "cookie":
-                    persist_profile = self.convert_cookie(name, profile,
-                                                          skipped, tenant)
+                    persist_profile = self.convert_cookie(
+                        name, profile, skipped, tenant)
                     if not persist_profile:
                         continue
-                    u_ignore = user_ignore.get('cookie', [])
+                    u_ignore = user_ignore.get("cookie", [])
                 elif persist_mode == "ssl":
                     persist_profile = self.convert_ssl(
                         name, profile, skipped, self.indirect, tenant)
-                    u_ignore = user_ignore.get('ssl', [])
+                    u_ignore = user_ignore.get("ssl", [])
                 elif persist_mode == "source-addr":
                     persist_profile = self.convert_source_addr(
                         name, profile, skipped, tenant)
-                    u_ignore = user_ignore.get('source-addr', [])
+                    u_ignore = user_ignore.get("source-addr", [])
                 elif persist_mode == "hash":
-                    avi_config['hash_algorithm'].append(name)
+                    avi_config["hash_algorithm"].append(name)
                     skipped = profile.keys()
                     LOG.warn('hash-persistence profile %s will be mapped '
                              'indirectly to Pool -> Load Balance  Algorithm'
                              % name)
                     conv_status = {
-                        'status': conv_const.STATUS_PARTIAL,
-                        'skipped': skipped
-                    }
-                    msg = 'Indirectly mapped to Pool -> Load Balance Algorithm'
+                        "status": conv_const.STATUS_PARTIAL,
+                        "skipped": skipped}
+                    msg = "Indirectly mapped to Pool -> Load Balance Algorithm"
                     conv_utils.add_conv_status(
-                        'profile', "hash-persistence", name, conv_status, msg)
+                        "profile", "hash-persistence", name, conv_status, msg)
                     continue
                 else:
                     msg = 'persist mode not supported skipping conversion: %s'\
                            % name
                     LOG.warning(msg)
                     self.update_conv_status_for_skip(persist_mode, name, msg)
                     continue
                 if not persist_profile:
                     continue
                 # code to merge applicaation persistence profile.
                 if self.object_merge_check:
-                    conv_utils.update_skip_duplicates(persist_profile,
-                                    avi_config['ApplicationPersistenceProfile'],
-                                    'app_per_profile', converted_objs, name,
-                                    None, merge_object_mapping, persist_mode,
-                         self.prefix, sys_dict['ApplicationPersistenceProfile'])
+                    conv_utils.update_skip_duplicates(
+                        persist_profile,
+                        avi_config["ApplicationPersistenceProfile"],
+                        "app_per_profile",
+                        converted_objs,
+                        name,
+                        None,
+                        merge_object_mapping,
+                        persist_mode,
+                        self.prefix,
+                        sys_dict["ApplicationPersistenceProfile"],
+                    )
                     self.app_per_count += 1
                 else:
                     avi_config["ApplicationPersistenceProfile"].append(
                         persist_profile)
 
                 ignore_for_defaults = {"app-service": "none", "mask": "none"}
                 conv_status = conv_utils.get_conv_status(
-                    skipped, self.indirect, ignore_for_defaults,
-                    profile, u_ignore)
-                self.update_conversion_status(conv_status, persist_mode,
-                                              name, persist_profile)
-            except:
-                update_count('error')
+                    skipped, self.indirect, ignore_for_defaults, profile, u_ignore)
+                self.update_conversion_status(
+                    conv_status, persist_mode, name, persist_profile, profile)
+            except BaseException:
+                update_count("error")
                 LOG.error("Failed to convert persistance profile : %s" % key,
                           exc_info=True)
                 self.update_conv_status_for_error(name, persist_mode, key)
         count = len(avi_config["ApplicationPersistenceProfile"])
-        LOG.debug("Converted %s persistence profiles" % count)
-        f5_config.pop('persistence')
+        LOG.debug("Converted %s persistence profiles", count)
+        f5_config.pop("persistence")
 
     def convert_timeout(self, timeout):
         """
 
         :param timeout: timeout
         :return: timeout
         """
-        if ':' in str(timeout):
-            expiration = timeout.split(':')
+        if ":" in str(timeout):
+            expiration = timeout.split(":")
             expiration.reverse()
             timeout = 0
             i = 0
             for val in expiration:
                 val = int(val)
                 if i == 0:
-                    timeout = int(val/final.SEC_IN_MIN)
+                    timeout = int(val / final.SEC_IN_MIN)
                 elif i == 1:
                     timeout += val
                 elif i == 2:
-                    timeout += (val*final.MIN_IN_HR)
+                    timeout += val * final.MIN_IN_HR
                 elif i == 3:
-                    timeout += (val*final.MIN_IN_HR*final.HR_IN_DAY)
+                    timeout += val * final.MIN_IN_HR * final.HR_IN_DAY
                 i += 1
         else:
             timeout = 1 if int(timeout) == 0 else timeout
         return timeout
 
 
 class PersistenceConfigConvV11(PersistenceConfigConv):
     def __init__(self, f5_persistence_attributes, prefix, object_merge_check):
         """
 
         :param f5_persistence_attributes: yaml file for f5 attributes
         :param prefix: prefix for object
         :param object_merge_check: flag to merge object
         """
-        self.indirect = f5_persistence_attributes['Persistence_indirect']
-        self.supported_attr = f5_persistence_attributes['Persistence_supported_attr']
-        self.supported_attr_convert = f5_persistence_attributes['Persistence_' \
-                                            'supported_attr_' \
-                                            'convert_source_addr']
+        self.indirect = f5_persistence_attributes["Persistence_indirect"]
+        self.supported_attr = f5_persistence_attributes["Persistence_supported_attr"]
+        self.supported_attr_convert = f5_persistence_attributes["Persistence_"
+                                                                "supported_attr_"
+                                                                "convert_source_addr"]
         # Added prefix for objects
         self.prefix = prefix
         self.object_merge_check = object_merge_check
         self.app_per_count = 0
 
     def convert_cookie(self, name, profile, skipped, tenant):
         """
 
         :param name: name of cookie
         :param profile: f5 profile attributes
         :param skipped: skipped list for profile
         :param tenant: Tenant for which output to be converted
         :return:persist_profile
         """
-        method = profile.get('method', 'insert')
-        if not method == 'insert':
+        method = profile.get("method", "insert")
+        if not method == "insert":
             msg = "Skipped cookie method not supported for profile '%s' " % name
             LOG.warn(msg)
-            conv_utils.add_status_row('persistence', 'cookie', name,
-                                      final.STATUS_SKIPPED, msg)
+            conv_utils.add_status_row(
+                "persistence", "cookie", name, final.STATUS_SKIPPED, msg)
             return None
-        ignore_lst = ['always-send']
+        ignore_lst = ["always-send"]
         parent_obj = super(PersistenceConfigConvV11, self)
         self.supported_attr += ignore_lst
         skipped += [attr for attr in profile.keys()
                     if attr not in self.supported_attr]
         cookie_name = profile.get("cookie-name")
         # Set cookie name to default value from avi if not given
-        if not cookie_name or cookie_name == 'none':
-            cookie_name = 'AVI_COOKIE'
-        timeout = profile.get("expiration", '1')
+        if not cookie_name or cookie_name == "none":
+            cookie_name = "AVI_COOKIE"
+        timeout = profile.get("expiration", "1")
         timeout = parent_obj.convert_timeout(timeout)
         persist_profile = {
             "name": name,
             "http_cookie_persistence_profile": {
                 "cookie_name": cookie_name,
-                "timeout": timeout
-            },
+                "timeout": timeout},
             "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
             "persistence_type": "PERSISTENCE_TYPE_HTTP_COOKIE",
         }
-        persist_profile['tenant_ref'] = conv_utils.get_object_ref(
-            tenant, 'tenant')
+        persist_profile["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
 
         return persist_profile
 
     def convert_ssl(self, name, profile, skipped, indirect_mappings, tenant):
         """
 
         :param name: name of ssl profile
         :param profile: f5 profile attribute
         :param skipped: skipped list for profile
         :param indirect_mappings: list of indirect mapping
         :param tenant: Tenant for which output to be converted
         :return:
         """
-        supported_attr = ['defaults-from']
+        supported_attr = ["defaults-from"]
         skipped += [attr for attr in profile.keys()
                     if attr not in supported_attr]
         indirect_mappings.append("timeout")
         persist_profile = {
             "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
             "persistence_type": "PERSISTENCE_TYPE_TLS",
-            "name": name
-        }
-        persist_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            "name": name}
+        persist_profile["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
         return persist_profile
 
     def convert_source_addr(self, name, profile, skipped, tenant):
         """
 
         :param name:  name of profile
         :param profile: f5 profile attributes
         :param skipped: skipped list for avi
         :param tenant: Tenant for which output to be converted
         :return: persist_profile
         """
         supported_attr = self.supported_attr_convert
-        ignore_lst = ['map-proxies']
+        ignore_lst = ["map-proxies"]
         supported_attr += ignore_lst
         skipped += [attr for attr in profile.keys()
                     if attr not in supported_attr]
         timeout = profile.get("timeout", final.SOURCE_ADDR_TIMEOUT)
-        timeout = 0 if timeout == 'indefinite' else timeout
+        timeout = 0 if timeout == "indefinite" else timeout
         if int(timeout) > 0:
-            timeout = int(timeout)/final.SEC_IN_MIN
+            timeout = int(timeout) / final.SEC_IN_MIN
         persist_profile = {
             "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
             "persistence_type": "PERSISTENCE_TYPE_CLIENT_IP_ADDRESS",
-            "ip_persistence_profile": {
-                "ip_persistent_timeout": timeout
-            },
-            "name": name
+            "ip_persistence_profile": {"ip_persistent_timeout": timeout},
+            "name": name,
         }
-        persist_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+        persist_profile["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
         return persist_profile
 
-    def update_conversion_status(self, conv_status, persist_mode, name,
-                                 persist_profile):
+    def update_conversion_status(
+            self,
+            conv_status,
+            persist_mode,
+            name,
+            persist_profile,
+            f5_profile):
         """
 
         :param conv_status:  state of conversion
         :param persist_mode: type of profile
         :param name: name of persistance profile
         :param persist_profile: dict of persist profile
         :return:
         """
-        conv_utils.add_conv_status('persistence', persist_mode, name,
-                                   conv_status,
-                                   [{'app_per_profile': persist_profile}])
-        LOG.debug("Conversion successful for persistence profile: %s" %
-                  name)
+        conv_utils.add_conv_status("persistence", persist_mode, name, conv_status, [
+            {"app_per_profile": persist_profile}], f5_object=yaml.dump(f5_profile))
+        LOG.debug("Conversion successful for persistence profile: %s", name)
 
     def update_conv_status_for_error(self, name, persist_mode, key):
         """
 
         :param name:  name of profile
         :param persist_mode: type of profile.
         :param key: key for profile
         :return:
         """
         if name:
-            conv_utils.add_status_row("persistence", persist_mode, name,
-                                      final.STATUS_ERROR)
+            conv_utils.add_status_row(
+                "persistence", persist_mode, name, final.STATUS_ERROR)
         else:
-            conv_utils.add_status_row("persistence", key, key,
-                                      final.STATUS_ERROR)
+            conv_utils.add_status_row(
+                "persistence", key, key, final.STATUS_ERROR)
 
     def update_conv_status_for_skip(self, persist_mode, name, msg):
-        conv_utils.add_status_row("persistence", persist_mode, name,
-                                  final.STATUS_SKIPPED, msg)
+        conv_utils.add_status_row(
+            "persistence",
+            persist_mode,
+            name,
+            final.STATUS_SKIPPED,
+            msg)
 
 
 class PersistenceConfigConvV10(PersistenceConfigConv):
     def __init__(self, f5_persistence_attributes, prefix, object_merge_check):
         """
 
         :param f5_persistence_attributes:  f5 persistence attributes
         :param prefix: prefix for objects
         :param object_merge_check: flag to merge object
         """
-        self.indirect = f5_persistence_attributes['Persistence_indirect']
-        self.supported_attr = \
-            f5_persistence_attributes['Persistence_supported_attr']
+        self.indirect = f5_persistence_attributes["Persistence_indirect"]
+        self.supported_attr = f5_persistence_attributes["Persistence_supported_attr"]
         self.supported_attr_conver = f5_persistence_attributes[
-            'Persistence_supported_attr_convert_source_addr']
+            "Persistence_supported_attr_convert_source_addr"]
         # Added prefix for objects
         self.prefix = prefix
         self.object_merge_check = object_merge_check
         self.app_per_count = 0
 
     def convert_cookie(self, name, profile, skipped, tenant):
         """
 
         :param name: name of cookie
         :param profile: f5 profile attributes
         :param skipped: skipped list for profile
         :param tenant: Tenant for which output to be converted
         :return:persist_profile
         """
-        method = profile.get('cookie mode', 'insert')
-        if not method == 'insert':
-            LOG.warn("Skipped cookie method not supported for profile '%s' "
-                     % name)
-            conv_utils.add_conv_status('persistence', 'cookie', name, 'skipped')
+        method = profile.get("cookie mode", "insert")
+        if not method == "insert":
+            LOG.warning(
+                "Skipped cookie method not supported for profile '%s' ",
+                name)
+            conv_utils.add_conv_status(
+                "persistence", "cookie", name, "skipped")
             return None
         skipped += [attr for attr in profile.keys()
-                   if attr not in self.supported_attr]
+                    if attr not in self.supported_attr]
         cookie_name = profile.get("cookie name")
         # Set cookie name to default value from avi if not given
-        if not cookie_name or cookie_name == 'none':
-            cookie_name = 'AVI_COOKIE'
-        timeout = profile.get("cookie expiration", '1')
-        if timeout == 'immediate':
-            timeout = '0'
+        if not cookie_name or cookie_name == "none":
+            cookie_name = "AVI_COOKIE"
+        timeout = profile.get("cookie expiration", "1")
+        if timeout == "immediate":
+            timeout = "0"
         parent_obj = super(PersistenceConfigConvV10, self)
-        if 'd ' in timeout:
-            timeout = timeout.replace('d ', ':')
-        elif 'd' in timeout:
-            timeout = timeout.replace('d', '')
+        if "d " in timeout:
+            timeout = timeout.replace("d ", ":")
+        elif "d" in timeout:
+            timeout = timeout.replace("d", "")
         timeout = parent_obj.convert_timeout(timeout)
         persist_profile = {
             "name": name,
             "http_cookie_persistence_profile": {
                 "cookie_name": cookie_name,
-                "timeout": timeout
-            },
+                "timeout": timeout},
             "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
             "persistence_type": "PERSISTENCE_TYPE_HTTP_COOKIE",
         }
-        persist_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+        persist_profile["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
         return persist_profile
 
     def convert_ssl(self, name, profile, skipped, indirect, tenant):
         """
 
         :param name: name of ssl profile
         :param profile: f5 profile attribute
         :param skipped: skipped list for profile
         :param indirect_mappings: list of indirect mapping
         :param tenant: Tenant for which output to be converted
         :return:
         """
-        supported_attr = ["mode", 'defaults-from']
+        supported_attr = ["mode", "defaults-from"]
         skipped += [attr for attr in profile.keys()
                     if attr not in supported_attr]
         indirect.append("timeout")
         persist_profile = {
             "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
             "persistence_type": "PERSISTENCE_TYPE_TLS",
-            "name": name
-        }
-        persist_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            "name": name}
+        persist_profile["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
         return persist_profile
 
     def convert_source_addr(self, name, profile, skipped, tenant):
         """
 
         :param name:  name of profile
         :param profile: f5 profile attributes
@@ -434,60 +468,66 @@
         """
         supported_attr = self.supported_attr_conver
 
         skipped += [attr for attr in profile.keys()
                     if attr not in supported_attr]
         timeout = profile.get("timeout", final.SOURCE_ADDR_TIMEOUT)
         if int(timeout) > 0:
-            timeout = int(timeout)/final.SEC_IN_MIN
+            timeout = int(timeout) / final.SEC_IN_MIN
         persist_profile = {
-          "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
-          "persistence_type": "PERSISTENCE_TYPE_CLIENT_IP_ADDRESS",
-          "ip_persistence_profile": {
-            "ip_persistent_timeout": timeout
-          },
-          "name": name
+            "server_hm_down_recovery": "HM_DOWN_PICK_NEW_SERVER",
+            "persistence_type": "PERSISTENCE_TYPE_CLIENT_IP_ADDRESS",
+            "ip_persistence_profile": {"ip_persistent_timeout": timeout},
+            "name": name,
         }
-        persist_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+        persist_profile["tenant_ref"] = conv_utils.get_object_ref(
+            tenant, "tenant")
         return persist_profile
 
-    def update_conversion_status(self, conv_status, persist_mode, name,
-                                 persist_profile):
+    def update_conversion_status(
+            self,
+            conv_status,
+            persist_mode,
+            name,
+            persist_profile,
+            f5_profile):
         """
 
         :param conv_status:  state of conversion
         :param persist_mode: type of profile
         :param name: name of persistance profile
         :param persist_profile: dict of persist profile
         :return:
         """
-        conv_utils.add_conv_status('persistence', 'persist', name, conv_status,
-                                   [{'app_per_profile': persist_profile}])
-        LOG.debug("Conversion successful for persistence profile: %s" %
-                  name)
+        conv_utils.add_conv_status("persistence", "persist", name, conv_status, [
+            {"app_per_profile": persist_profile}], f5_object=yaml.dump(f5_profile))
+        LOG.debug("Conversion successful for persistence profile: %s", name)
 
     def update_conv_status_for_error(self, name, persist_mode, key):
         """
 
         :param name:  name of profile
         :param persist_mode: type of profile.
         :param key: key for profile
         :return:
         """
         if name:
-            conv_utils.add_status_row("persistence", 'persist', name,
-                                      final.STATUS_ERROR)
+            conv_utils.add_status_row(
+                "persistence", "persist", name, final.STATUS_ERROR)
         else:
-            conv_utils.add_status_row("persistence", 'persist', key,
-                                      final.STATUS_ERROR)
+            conv_utils.add_status_row(
+                "persistence", "persist", key, final.STATUS_ERROR)
 
     def update_conv_status_for_skip(self, persist_mode, name, msg):
         """
 
         :param persist_mode: type of profile.
         :param name: name of profile.
         :param msg: status message
         :return:
         """
-        conv_utils.add_status_row("persistence", 'persist', name,
-                                  final.STATUS_SKIPPED, msg)
+        conv_utils.add_status_row(
+            "persistence",
+            "persist",
+            name,
+            final.STATUS_SKIPPED,
+            msg)
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/policy_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/policy_converter.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,42 +1,48 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 import logging
+
 import avi.migrationtools.f5_converter.converter_constants as final
-from avi.migrationtools.f5_converter.conversion_util import F5Util
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
+from avi.migrationtools.f5_converter.conversion_util import F5Util
 
 LOG = logging.getLogger(__name__)
 
 # Creating f5 object for util library.
 conv_utils = F5Util()
 
-parameters_dict = {'starts-with': 'BEGINS_WITH', 'equals': 'EQUALS',
-                   'contains': 'CONTAINS', 'ends-with': 'ENDS_WITH',
-                   'not': 'DOES_NOT_'}
+parameters_dict = {
+    "starts-with": "BEGINS_WITH",
+    "equals": "EQUALS",
+    "contains": "CONTAINS",
+    "ends-with": "ENDS_WITH",
+    "not": "DOES_NOT_"}
 used_pools = {}
+http_to_https_policy_rule = []
 
 
 class PolicyConfigConv(object):
     @classmethod
     def get_instance(cls, version, f5_profile_attributes, prefix):
         """
 
         :param version: version of f5 instance
         :param f5_monitor_atributes: f5 monitor attributes from yaml file.
         :param prefix:  prefix for objects
         :return:
         """
-        if version == '10':
+        if version == "10":
             return PolicyConfigConvV10(prefix, f5_profile_attributes)
-        if version in ['11', '12']:
+        if version in ["11", "12"]:
             return PolicyConfigConvV11(prefix, f5_profile_attributes)
 
-    def convert(self, f5_config, avi_config, tenant_ref):
+    def convert(self, f5_config, avi_config, tenant_ref, cloud_name):
         """
         Main method for conversion of policy
         :param f5_config: parsed f5 config dict
         :param avi_config: dict for conversion to avi config
         :param tenant_ref: tenant of which config to be converted
         :return:
         """
@@ -46,122 +52,139 @@
             try:
                 LOG.debug("Conversion started for the policy %s", each_policy)
                 tenant, policy_name = conv_utils.get_tenant_ref(each_policy)
                 if tenant_ref:
                     tenant = tenant_ref
                 if self.prefix:
                     policy_name = '%s-%s' % (self.prefix, policy_name)
-                httppolicy = dict()
+                httppolicy = {}
                 config = policy_config[each_policy]
-                skip = self.create_rules(config, httppolicy, avi_config,
-                                         policy_name)
-                if httppolicy.get('http_request_policy', httppolicy.get(
-                        'http_response_policy')):
-                    httppolicy['name'] = policy_name
-                    httppolicy['tenant_ref'] = conv_utils.get_object_ref(tenant,
-                                                                       'tenant')
+                skip = self.create_rules(
+                    config,
+                    httppolicy,
+                    avi_config,
+                    policy_name,
+                    cloud_name,
+                    tenant)
+                if httppolicy.get("http_request_policy",
+                                  httppolicy.get("http_response_policy")):
+                    httppolicy["name"] = policy_name
+                    httppolicy["tenant_ref"] = conv_utils.get_object_ref(
+                        tenant, "tenant")
                     httppolicy["is_internal_policy"] = False
-                    avi_config['HTTPPolicySet'].append(httppolicy)
+                    avi_config["HTTPPolicySet"].append(httppolicy)
                     if isinstance(skip, dict):
                         if skip:
-                            na_list = [val for val in skip if val in self.na_list]
-                            conv_status = {'skipped': [skip],
-                                           'status': final.STATUS_PARTIAL,
-                                           'na_list': na_list
-                                           }
+                            na_list = [
+                                val for val in skip if val in self.na_list]
+                            conv_status = {
+                                "skipped": [skip],
+                                "status": final.STATUS_PARTIAL,
+                                "na_list": na_list}
                         else:
-                            conv_status = {'status': final.STATUS_SUCCESSFUL}
+                            conv_status = {"status": final.STATUS_SUCCESSFUL}
                     indirect = self.indirect
-                    conv_status['indirect'] = indirect
-                    conv_utils.add_conv_status('policy', None, each_policy,
-                                               conv_status,
-                                               [{'policy_set': httppolicy}])
+                    conv_status["indirect"] = indirect
+                    conv_utils.add_conv_status("policy", None, each_policy, conv_status, [
+                        {"policy_set": httppolicy}], f5_object=yaml.dump(config))
                 else:
-                    conv_utils.add_conv_status("policy", None, each_policy,
-                                         {'status': final.STATUS_SKIPPED}, skip)
-                    LOG.debug('Skipping:Conversion unsuccessful for the policy'
-                              ' %s', each_policy)
-            except:
-                update_count('error')
-                LOG.error("Error in conversion of policy %s" % each_policy,
-                          exc_info=True)
+                    conv_utils.add_conv_status(
+                        "policy", None, each_policy, {
+                            "status": final.STATUS_SKIPPED}, skip)
+                    LOG.debug(
+                        "Skipping:Conversion unsuccessful for the policy"
+                        " %s", each_policy)
+            except BaseException:
+                update_count("error")
+                LOG.error(
+                    "Error in conversion of policy %s",
+                    each_policy, exc_info=True)
 
     def create_rules(self, config, httppolicy, avi_config,
-                     policy_name):
+                     policy_name, cloud_name, tenant):
         """
         This method create rules for each policy
         :param config: f5 policy config dict
         :param httppolicy: httppolicy dict
         :param avi_config: dict for avi conversion
         :param policy_name: name of policy
         :return: skip elements for rule or message
         """
-        if 'rules' in config and not config['rules'] == 'none':
-            skip_rule = dict()
-            for index, each_rule in enumerate(config['rules']):
-                if config['rules'][each_rule].get('conditions') and config[
-                  'rules'][each_rule].get('actions'):
+        if "rules" in config and not config["rules"] == "none":
+            skip_rule = {}
+            for index, each_rule in enumerate(config["rules"]):
+                if config["rules"][each_rule].get(
+                        "conditions") and config["rules"][each_rule].get("actions"):
                     rule_name = '%s-%s-%s' % (policy_name, each_rule,
                                               str(index + 1))
-                    rule_dict = {'name': rule_name, 'enable': True,
-                                   'index': index + 1}
-                    match_rule = config['rules'][each_rule]['conditions']
+                    rule_dict = {
+                        "name": rule_name,
+                        "enable": True,
+                        "index": index + 1}
+                    match_rule = config["rules"][each_rule]["conditions"]
                     pol_type, match, skip_match = self.create_match_rule(
                         match_rule, avi_config, rule_name, each_rule)
                     if not match:
                         msg = 'All match conditions not supported for rule {}' \
                               ' in policy {}'.format(each_rule, policy_name)
                         LOG.debug(msg)
                         skip_rule[each_rule] = msg
                         continue
-                    else:
-                        LOG.debug('Rule match successfully converted for rule '
-                                  '%s in policy %s', each_rule, policy_name)
-                    action_rule = config['rules'][each_rule]['actions']
+
+                    LOG.debug(
+                        "Rule match successfully converted for rule "
+                        "%s in policy %s", each_rule, policy_name)
+                    action_rule = config["rules"][each_rule]["actions"]
                     actions, skip_action, log = self.create_action_rule(
-                                action_rule, avi_config, each_rule, policy_name)
+                        action_rule, avi_config, each_rule, policy_name, cloud_name, tenant)
                     if not actions:
                         msg = 'All actions not supported for rule {} in ' \
                               'policy {}'.format(each_rule, policy_name)
+
                         LOG.debug(msg)
                         skip_rule[each_rule] = msg
                         continue
-                    else:
-                        LOG.debug('Rule action successfully converted for rule '
-                                  '%s in policy %s', each_rule, policy_name)
-                    rule_dict.update({'match': match})
+
+                    LOG.debug(
+                        "Rule action successfully converted for rule "
+                        "%s in policy %s", each_rule, policy_name)
+                    rule_dict.update({"match": match})
                     for act in actions:
                         rule_dict.update(act)
                     if log:
                         rule_dict.update(log)
                     if pol_type:
-                        if not httppolicy.get('http_' + pol_type + '_policy'):
-                            httppolicy['http_' + pol_type + '_policy'] = dict()
-                            httppolicy['http_' + pol_type + '_policy'][
-                                'rules'] = []
-                        httppolicy['http_' + pol_type + '_policy'][
-                            'rules'].append(rule_dict)
+                        if not httppolicy.get("http_" + pol_type + "_policy"):
+                            httppolicy["http_" + pol_type + "_policy"] = dict()
+                            httppolicy["http_" + pol_type +
+                                       "_policy"]["rules"] = []
+                        httppolicy["http_" + pol_type +
+                                   "_policy"]["rules"].append(rule_dict)
                         skipped = skip_match + skip_action
                         if skipped:
                             skip_rule[each_rule] = skipped
-                elif config['rules'][each_rule].get('conditions'):
+                elif config["rules"][each_rule].get("conditions"):
                     msg = 'Skipping rule:No action found for rule {} in ' \
                             'policy {}'.format(each_rule, policy_name)
+
                     LOG.debug(msg)
                     skip_rule[each_rule] = msg
-                elif config['rules'][each_rule].get('actions'):
+                elif config["rules"][each_rule].get("actions"):
                     msg = 'Skipping rule:No match condition found for rule ' \
                               '{} in policy {}'.format(each_rule, policy_name)
                     LOG.debug(msg)
                     skip_rule[each_rule] = msg
                 else:
                     msg = 'Skipping rule:Match conditions and actions are ' \
                               'missing for policy {}'.format(policy_name)
+
                     LOG.debug(msg)
                     skip_rule[each_rule] = msg
+                if each_rule == "http_to_https_policy_rule":
+                    http_to_https_policy_rule.append(policy_name)
             return skip_rule
         else:
             msg = 'No rule found for policy {}'.format(policy_name)
             LOG.debug(msg)
             return msg
 
     def create_match_rule(self, match_dict, avi_config, rule_name, each_rule):
@@ -172,1003 +195,1029 @@
         :param rule_name: name of rule
         :param each_rule: rule for policy
         :return: policy type, match dict and skip elements
         """
         pol_type = None
         match = {}
         skip_match = []
-        LOG.debug('Started making match for rule %s', each_rule)
+        LOG.debug("Started making match for rule %s", each_rule)
         for each_index in match_dict:
             result = match_dict[each_index]
             op = None
             skip_parameter, skip_selector, skip_op, skip_event = [], [], [], []
-            if 'geoip' in result:
-                op = 'geoip'
-                if 'response' in result:
-                    pol_type = 'response'
-                elif 'ssl-client-hello' in result:
-                    skip_event.append('ssl-client-hello')
-                    LOG.debug("Event 'ssl-client-hello' not supported for "
-                              "operand %s", op)
-                    continue
-                elif 'ssl-server-handshake' in result:
-                    skip_event.append('ssl-server-handshake')
-                    LOG.debug("Event 'ssl-server-handshake' not supported for "
-                              "operand %s", op)
-                    continue
-                elif 'ssl-sever-hello' in result:
-                    skip_event.append('ssl-sever-hello')
-                    LOG.debug("Event 'ssl-sever-hello' not supported for "
-                              "operand %s", op)
+            if "geoip" in result:
+                op = "geoip"
+                if "response" in result:
+                    pol_type = "response"
+                elif "ssl-client-hello" in result:
+                    skip_event.append("ssl-client-hello")
+                    LOG.debug(
+                        "Event 'ssl-client-hello' not supported for "
+                        "operand %s", op)
+                    continue
+                elif "ssl-server-handshake" in result:
+                    skip_event.append("ssl-server-handshake")
+                    LOG.debug(
+                        "Event 'ssl-server-handshake' not supported for "
+                        "operand %s", op)
+                    continue
+                elif "ssl-sever-hello" in result:
+                    skip_event.append("ssl-sever-hello")
+                    LOG.debug(
+                        "Event 'ssl-sever-hello' not supported for "
+                        "operand %s", op)
                     continue
                 else:
-                    pol_type = 'request'
-                if 'country-code' in result:
-                    if 'starts-with' not in result and 'contains' not in \
-                            result and 'ends-with' not in result:
-                        if 'values' not in result:
-                            LOG.debug('Match rule is incomplete, values are '
-                                      'mandatory for operand %s', op)
+                    pol_type = "request"
+                if "country-code" in result:
+                    if "starts-with" not in result and "contains" not in result \
+                            and "ends-with" not in result:
+                        if "values" not in result:
+                            LOG.debug(
+                                "Match rule is incomplete, values are "
+                                "mandatory for operand %s", op)
                             continue
                         client_ip = {
-                            'group_refs': [],
-                            'match_criteria': 'IS_NOT_IN' if 'not' in result
-                                                else 'IS_IN'
-                        }
-                        if 'Internal' in result:
-                            client_ip['group_refs'].append(
-                                        conv_utils.get_object_ref('Internal',
-                                                      'ipaddrgroup'))
-                        if 'local' in result:
-                            skip_parameter.append('local')
+                            "group_refs": [],
+                            "match_criteria": "IS_NOT_IN" if "not" in result else "IS_IN"}
+                        if "Internal" in result:
+                            client_ip["group_refs"].append(
+                                conv_utils.get_object_ref("Internal", "ipaddrgroup"))
+                        if "local" in result:
+                            skip_parameter.append("local")
                         ipgrp_name = 'ipaddrgroup%s-%s' % (rule_name,
                                                       str(each_index))
                         ip_addr_group = {
-                            'name': ipgrp_name,
-                            'tenant_ref': conv_utils.get_object_ref(
-                                 'admin', 'tenant'),
-                            'country_codes': list(result['values'].keys())
-                        }
+                            "name": ipgrp_name, "tenant_ref": conv_utils.get_object_ref(
+                                "admin", "tenant"), "country_codes": list(
+                                result["values"].keys()), }
 
-                        if 'IpAddrGroup' not in avi_config:
-                            avi_config['IpAddrGroup'] = []
-                        avi_config['IpAddrGroup'].append(ip_addr_group)
-                        client_ip['group_refs'].append(
-                            conv_utils.get_object_ref(ipgrp_name,
-                                                      'ipaddrgroup'))
-                        match['client_ip'] = client_ip
-                    else:
-                        if 'starts-with' in result:
-                            skip_op.append('starts-with')
-                        elif 'contains' in result:
-                            skip_op.append('contains')
-                        elif 'ends-with' in result:
-                            skip_op.append('ends-with')
-                        if 'case-sensitive' in result:
-                            skip_op.append('case-sensitive')
-                        if 'missing' in result:
-                            skip_op.append('missing')
+                        if "IpAddrGroup" not in avi_config:
+                            avi_config["IpAddrGroup"] = []
+                        avi_config["IpAddrGroup"].append(ip_addr_group)
+                        client_ip["group_refs"].append(
+                            conv_utils.get_object_ref(
+                                ipgrp_name, "ipaddrgroup"))
+                        match["client_ip"] = client_ip
+                    else:
+                        if "starts-with" in result:
+                            skip_op.append("starts-with")
+                        elif "contains" in result:
+                            skip_op.append("contains")
+                        elif "ends-with" in result:
+                            skip_op.append("ends-with")
+                        if "case-sensitive" in result:
+                            skip_op.append("case-sensitive")
+                        if "missing" in result:
+                            skip_op.append("missing")
                         if skip_op:
-                            LOG.debug("Condition '%s' not supported for operand"
-                                      " %s", str(skip_op), op)
+                            LOG.debug(
+                                "Condition '%s' not supported for operand"
+                                " %s", str(skip_op), op)
                 else:
-                    if 'continent' in result:
-                        skip_selector.append('continent')
-                    elif 'country-name' in result:
-                        skip_selector.append('country-name')
-                    elif 'isp' in result:
-                        skip_selector.append('isp')
-                    elif 'organization' in result:
-                        skip_selector.append('organization')
-                    elif 'region-code' in result:
-                        skip_selector.append('region-code')
-                    elif 'region-name' in result:
-                        skip_selector.append('region-name')
+                    if "continent" in result:
+                        skip_selector.append("continent")
+                    elif "country-name" in result:
+                        skip_selector.append("country-name")
+                    elif "isp" in result:
+                        skip_selector.append("isp")
+                    elif "organization" in result:
+                        skip_selector.append("organization")
+                    elif "region-code" in result:
+                        skip_selector.append("region-code")
+                    elif "region-name" in result:
+                        skip_selector.append("region-name")
                     if skip_selector:
-                        LOG.debug("Selector '%s' not supported for operand %s",
-                                  str(skip_selector), op)
-            elif 'http-cookie' in result:
-                op = 'http-cookie'
-                pol_type = 'response' if 'response' in result else 'request'
+                        LOG.debug(
+                            "Selector '%s' not supported for operand %s",
+                            str(skip_selector),
+                            op)
+            elif "http-cookie" in result:
+                op = "http-cookie"
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'name' not in result or 'values' not in result:
-                    LOG.debug('Match rule is incomplete, Name and values are '
-                              'mandatory for operand %s', op)
-                    continue
-                if 'missing' in result:
-                    skip_op.append('missing')
-                    LOG.debug("Condition 'missing' not supported for operand %s"
-                              , op)
-                if len(result['values']) > 1:
-                    LOG.debug('More than one value can not be used for op %s, '
-                              'using the any one', op)
+                if "name" not in result or "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, Name and values are "
+                        "mandatory for operand %s", op)
+                    continue
+                if "missing" in result:
+                    skip_op.append("missing")
+                    LOG.debug(
+                        "Condition 'missing' not supported for operand %s", op)
+                if len(result["values"]) > 1:
+                    LOG.debug(
+                        "More than one value can not be used for op %s, "
+                        "using the any one", op)
                 cookie = {
-                    "match_case": 'SENSITIVE' if 'case-sensitive' in result
-                                    else 'INSENSITIVE',
-                    "name": result['name'],
-                    "value": list(result['values'].keys())[0],
-                    "match_criteria": ''
+                    "match_case": "SENSITIVE" if "case-sensitive" in result else "INSENSITIVE",
+                    "name": result["name"],
+                    "value": list(
+                        result["values"].keys())[0],
+                    "match_criteria": "",
                 }
 
-                match_criteria = [key for key in result if key in
-                                  parameters_dict]
+                match_criteria = [
+                    key for key in result if key in parameters_dict]
                 if len(match_criteria) > 1:
-                    cookie['match_criteria'] = 'HDR_%s%s' % (parameters_dict[
-                        match_criteria[0]], (parameters_dict[match_criteria[
-                        1]].replace('S','')))
+                    cookie["match_criteria"] = "HDR_%s%s" % (
+                        parameters_dict[match_criteria[0]],
+                        (parameters_dict[match_criteria[1]].replace("S", "")),
+                    )
                 elif len(match_criteria):
-                    if 'not' in match_criteria:
+                    if "not" in match_criteria:
                         cookie['match_criteria'] = 'HDR_%sEQUAL' % \
                                               parameters_dict[match_criteria[0]]
                     else:
                         cookie['match_criteria'] = 'HDR_%s' % parameters_dict[
                                                               match_criteria[0]]
                 else:
-                    cookie['match_criteria'] = 'HDR_EQUALS'
-                match['cookie'] = cookie
-            elif 'http-header' in result:
-                op = 'http-header'
-                pol_type = 'response' if 'response' in result else 'request'
+                    cookie["match_criteria"] = "HDR_EQUALS"
+                match["cookie"] = cookie
+            elif "http-header" in result:
+                op = "http-header"
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'name' not in result or 'values' not in result:
-                    LOG.debug('Match rule is incomplete, Name and values are '
-                              'mandatory for operand %s', op)
-                    continue
-                if 'missing' in result:
-                    skip_op.append('missing')
-                    LOG.debug("Condition 'missing' not supported for operand %s"
-                              , op)
+                if "name" not in result or "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, Name and values are "
+                        "mandatory for operand %s", op)
+                    continue
+                if "missing" in result:
+                    skip_op.append("missing")
+                    LOG.debug(
+                        "Condition 'missing' not supported for operand %s", op)
                 header = {
-                    "match_case": 'SENSITIVE' if 'case-sensitive' in result
-                                    else 'INSENSITIVE',
-                    "hdr": result['name'],
-                    "value": list(result['values'].keys()),
-                    "match_criteria": ''
+                    "match_case": "SENSITIVE" if "case-sensitive" in result else "INSENSITIVE",
+                    "hdr": result["name"],
+                    "value": list(
+                        result["values"].keys()),
+                    "match_criteria": "",
                 }
-                match_criteria = [key for key in result if key in
-                                  parameters_dict]
+                match_criteria = [
+                    key for key in result if key in parameters_dict]
                 if len(match_criteria) > 1:
-                    header['match_criteria'] = 'HDR_%s%s' % (parameters_dict[
-                        match_criteria[0]], (parameters_dict[
-                        match_criteria[1]].replace('S', '')))
+                    header["match_criteria"] = "HDR_%s%s" % (
+                        parameters_dict[match_criteria[0]],
+                        (parameters_dict[match_criteria[1]].replace("S", "")),
+                    )
                 elif len(match_criteria):
-                    if 'not' in match_criteria:
+                    if "not" in match_criteria:
                         header['match_criteria'] = 'HDR_%sEQUAL' % \
                                               parameters_dict[match_criteria[0]]
                     else:
                         header['match_criteria'] = 'HDR_%s' % parameters_dict[
                                                               match_criteria[0]]
                 else:
-                    header['match_criteria'] = 'HDR_EQUALS'
-                if 'hdrs' not in match:
-                    match['hdrs']=[]
-                match['hdrs'].append(header)
-            elif 'http-host' in result:
-                op = 'http-host'
-                if 'values' not in result:
-                    LOG.debug('Match rule is incomplete, Values are '
-                              'mandatory for op %s', op)
+                    header["match_criteria"] = "HDR_EQUALS"
+                if "hdrs" not in match:
+                    match["hdrs"] = []
+                match["hdrs"].append(header)
+            elif "http-host" in result:
+                op = "http-host"
+                if "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, Values are "
+                        "mandatory for op %s", op)
                     continue
-                pol_type = 'response' if 'response' in result else 'request'
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'missing' in result:
-                    skip_op.append('missing')
-                    LOG.debug("Condition 'missing' not supported for "
-                              "operand %s", op)
-                if 'port' not in result:
+                if "missing" in result:
+                    skip_op.append("missing")
+                    LOG.debug(
+                        "Condition 'missing' not supported for "
+                        "operand %s", op)
+                if "port" not in result:
                     host_header = {
-                        "match_case": 'SENSITIVE' if 'case-sensitive' in result
-                                        else 'INSENSITIVE',
-                        "value": list(result['values'].keys()),
-                        "match_criteria": ''
+                        "match_case": "SENSITIVE" if "case-sensitive" in result else "INSENSITIVE",
+                        "value": list(
+                            result["values"].keys()),
+                        "match_criteria": "",
                     }
-                    match_criteria = [key for key in result if key in
-                                      parameters_dict]
+                    match_criteria = [
+                        key for key in result if key in parameters_dict]
                     if len(match_criteria) > 1:
-                        host_header['match_criteria'] = 'HDR_%s%s' % (
-                           parameters_dict[match_criteria[0]], (
-                           parameters_dict[match_criteria[1]].replace('S', '')))
+                        host_header["match_criteria"] = "HDR_%s%s" % (
+                            parameters_dict[match_criteria[0]],
+                            (parameters_dict[match_criteria[1]].replace(
+                                "S", "")),
+                        )
                     elif len(match_criteria):
-                        if 'not' in match_criteria:
+                        if "not" in match_criteria:
                             host_header['match_criteria'] = 'HDR_%sEQUAL' % \
                                               parameters_dict[match_criteria[0]]
                         else:
                             host_header['match_criteria'] = 'HDR_%s' % \
                                               parameters_dict[match_criteria[0]]
                     else:
-                        host_header['match_criteria'] = 'HDR_EQUALS'
+                        host_header["match_criteria"] = "HDR_EQUALS"
                     match["host_hdr"] = host_header
                 else:
-                    if 'less' not in result and 'greater' not in result and \
-                      'less-or-equal' not in result and 'greater-or-equal' \
-                      not in result:
+                    if (
+                        "less" not in result
+                        and "greater" not in result
+                        and "less-or-equal" not in result
+                        and "greater-or-equal" not in result
+                    ):
                         service_port = {
-                            'ports': list(result['values'].keys()),
-                            'match_criteria': 'IS_NOT_IN' if 'not' in result
-                                                else 'IS_IN'
+                            "ports": list(
+                                result["values"].keys()),
+                            "match_criteria": "IS_NOT_IN" if "not" in result else "IS_IN",
                         }
                         match["vs_port"] = service_port
                     else:
-                        if 'less' in result:
-                            skip_op.append('less')
-                        elif 'greater' in result:
-                            skip_op.append('greater')
-                        elif 'less-or-equal' in result:
-                            skip_op.append('less-or-equal')
-                        elif 'greater-or-equal' in result:
-                            skip_op.append('greater-or-equal')
-                        if 'case-sensitive' in result:
-                            skip_op.append('case-sensitive')
+                        if "less" in result:
+                            skip_op.append("less")
+                        elif "greater" in result:
+                            skip_op.append("greater")
+                        elif "less-or-equal" in result:
+                            skip_op.append("less-or-equal")
+                        elif "greater-or-equal" in result:
+                            skip_op.append("greater-or-equal")
+                        if "case-sensitive" in result:
+                            skip_op.append("case-sensitive")
                         if skip_op:
-                            LOG.debug("Condition '%s' not supported for "
-                                      "parameter 'port' in operand"
-                                      " %s", str(skip_op), op)
-            elif 'http-method' in result:
-                op = 'http-method'
-                if 'values' not in result:
-                    LOG.debug('Match rule is incomplete, Values are '
-                              'mandatory for op %s', op)
+                            LOG.debug(
+                                "Condition '%s' not supported for "
+                                "parameter 'port' in operand"
+                                " %s", str(skip_op), op)
+            elif "http-method" in result:
+                op = "http-method"
+                if "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, Values are "
+                        "mandatory for op %s", op)
                     continue
-                pol_type = 'response' if 'response' in result else 'request'
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'starts-with' not in result and 'contains' not in \
-                            result and 'ends-with' not in result:
-                    avi_method = ['OPTIONS', 'PUT', 'HEAD', 'DELETE', 'GET',
-                                  'POST', 'TRACE', 'options', 'put', 'head',
-                                  'get', 'delete', 'post', 'trace']
-                    invalid = [True if val not in avi_method else False for
-                               val in list(result['values'].keys())]
+                if "starts-with" not in result and "contains" not in result \
+                        and "ends-with" not in result:
+                    avi_method = [
+                        "OPTIONS", "PUT", "HEAD",
+                        "DELETE", "GET", "POST",
+                        "TRACE", "options", "put",
+                        "head", "get", "delete",
+                        "post", "trace",
+                    ]
+                    invalid = [
+                        True if val not in avi_method else False for val in list(
+                            result["values"].keys())]
                     if all(invalid):
-                        LOG.debug('All methods %s are invalid', str(result[
-                                                            'values'].keys()))
+                        LOG.debug(
+                            "All methods %s are invalid", str(
+                                result["values"].keys()))
                         continue
-                    else:
-                        valid = [val for val in list(result['values'].keys()) if
-                                 val in avi_method]
-                        LOG.debug('Only these %s methods are valid', str(valid))
+
+                    valid = [
+                        val for val in list(
+                            result["values"].keys()) if val in avi_method]
+                    LOG.debug(
+                        "Only these %s methods are valid", str(valid))
                     method = {
-                        'methods': ['HTTP_METHOD_%s' % val.upper() for val in
-                                    valid],
-                        'match_criteria': 'IS_NOT_IN' if 'not' in result
-                                            else 'IS_IN'
+                        "methods": [
+                            "HTTP_METHOD_%s" %
+                            val.upper() for val in valid],
+                        "match_criteria": "IS_NOT_IN" if "not" in result else "IS_IN",
                     }
-                    match['method'] = method
+                    match["method"] = method
                 else:
-                    if 'starts-with' in result:
-                        skip_op.append('starts-with')
-                    elif 'contains' in result:
-                        skip_op.append('contains')
-                    elif 'ends-with' in result:
-                        skip_op.append('ends-with')
-                    if 'case-sensitive' in result:
-                        skip_op.append('case-sensitive')
-                    if 'missing' in result:
-                        skip_op.append('missing')
+                    if "starts-with" in result:
+                        skip_op.append("starts-with")
+                    elif "contains" in result:
+                        skip_op.append("contains")
+                    elif "ends-with" in result:
+                        skip_op.append("ends-with")
+                    if "case-sensitive" in result:
+                        skip_op.append("case-sensitive")
+                    if "missing" in result:
+                        skip_op.append("missing")
                     if skip_op:
-                        LOG.debug("Condition '%s' not supported for operand"
-                                  " %s", str(skip_op), op)
-            elif 'http-referer' in result:
-                op = 'http-referer'
-                pol_type = 'response' if 'response' in result else 'request'
+                        LOG.debug(
+                            "Condition '%s' not supported for operand"
+                            " %s", str(skip_op), op)
+            elif "http-referer" in result:
+                op = "http-referer"
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'values' not in result:
-                    LOG.debug('Match rule is incomplete, values are '
-                              'mandatory for operand %s', op)
-                    continue
-                if 'missing' in result:
-                    skip_op.append('missing')
-                    LOG.debug("Condition 'missing' not supported for operand %s"
-                              , op)
+                if "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, values are "
+                        "mandatory for operand %s", op)
+                    continue
+                if "missing" in result:
+                    skip_op.append("missing")
+                    LOG.debug(
+                        "Condition 'missing' not supported for operand %s", op)
                 header = {
-                    "match_case": 'SENSITIVE' if 'case-sensitive' in result
-                                    else 'INSENSITIVE',
-                    "hdr": 'referer',
-                    "value": list(result['values'].keys()),
-                    "match_criteria": ''
+                    "match_case": "SENSITIVE" if "case-sensitive" in result else "INSENSITIVE",
+                    "hdr": "referer",
+                    "value": list(
+                        result["values"].keys()),
+                    "match_criteria": "",
                 }
-                match_criteria = [key for key in result if key in
-                                  parameters_dict]
+                match_criteria = [
+                    key for key in result if key in parameters_dict]
                 if len(match_criteria) > 1:
-                    header['match_criteria'] = 'HDR_%s%s' % (parameters_dict[
-                        match_criteria[0]], (parameters_dict[
-                        match_criteria[1]].replace('S', '')))
+                    header["match_criteria"] = "HDR_%s%s" % (
+                        parameters_dict[match_criteria[0]],
+                        (parameters_dict[match_criteria[1]].replace("S", "")),
+                    )
                 elif len(match_criteria):
-                    if 'not' in match_criteria:
+                    if "not" in match_criteria:
                         header['match_criteria'] = 'HDR_%sEQUAL' % \
                                               parameters_dict[match_criteria[0]]
                     else:
                         header['match_criteria'] = 'HDR_%s' % parameters_dict[
                                                               match_criteria[0]]
                 else:
-                    header['match_criteria'] = 'HDR_EQUALS'
-                if 'hdrs' not in match:
-                    match['hdrs']=[]
-                match['hdrs'].append(header)
-            elif 'http-uri' in result:
-                op = 'http-uri'
-                pol_type = 'response' if 'response' in result else 'request'
+                    header["match_criteria"] = "HDR_EQUALS"
+                if "hdrs" not in match:
+                    match["hdrs"] = []
+                match["hdrs"].append(header)
+            elif "http-uri" in result:
+                op = "http-uri"
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'values' not in result:
-                    LOG.debug('Match rule is incomplete, Values are '
-                              'mandatory for operand %s', op)
-                    continue
-                if 'missing' in result:
-                    skip_op.append('missing')
-                    LOG.debug("Condition 'missing' not supported for operand %s"
-                              , op)
-                if 'path' in result or 'extension' in result:
+                if "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, Values are "
+                        "mandatory for operand %s", op)
+                    continue
+                if "missing" in result:
+                    skip_op.append("missing")
+                    LOG.debug(
+                        "Condition 'missing' not supported for operand %s", op)
+                if "path" in result or "extension" in result:
                     path_query = {
-                        "match_str": list(result['values'].keys()),
-                        "match_criteria": '',
-                        'match_case': 'SENSITIVE' if 'case-sensitive' in result
-                                        else 'INSENSITIVE'
+                        "match_str": list(
+                            result["values"].keys()),
+                        "match_criteria": "",
+                        "match_case": "SENSITIVE" if "case-sensitive" in result else "INSENSITIVE",
                     }
-                    if 'path' in result:
-                        match_criteria = [key for key in result if key in
-                                            parameters_dict.keys()]
+                    if "path" in result:
+                        match_criteria = [
+                            key for key in result if key in parameters_dict.keys()]
                         if len(match_criteria) > 1:
-                            path_query['match_criteria'] = '%s%s' % (
-                               parameters_dict[match_criteria[0]], (
-                               parameters_dict[match_criteria[1]].replace('S',
-                                                                          '')))
+                            path_query["match_criteria"] = "%s%s" % (
+                                parameters_dict[match_criteria[0]],
+                                (parameters_dict[match_criteria[1]].replace(
+                                    "S", "")),
+                            )
                         elif len(match_criteria):
-                            if 'not' in match_criteria:
+                            if "not" in match_criteria:
                                 path_query['match_criteria'] = '%sEQUAL' % \
                                               parameters_dict[match_criteria[0]]
                             else:
                                 path_query['match_criteria'] = '%s' % \
                                               parameters_dict[match_criteria[0]]
                         else:
-                            path_query['match_criteria'] = 'EQUALS'
+                            path_query["match_criteria"] = "EQUALS"
                         match["path"] = path_query
                     else:
-                        if 'starts-with' not in result and 'ends-with' not in \
-                          result and 'contains' not in result:
-                            path_query["match_criteria"] = 'DOES_NOT_END_WITH' \
-                                    if 'not' in result else 'ENDS_WITH'
+                        if "starts-with" not in result and "ends-with" not in result and \
+                                "contains" not in result:
+                            path_query["match_criteria"] = "DOES_NOT_END_WITH" \
+                                if "not" in result else "ENDS_WITH"
                             match["path"] = path_query
                         else:
-                            if 'starts-with' in result:
-                                skip_op.append('starts-with')
-                            elif 'contains' in result:
-                                skip_op.append('contains')
-                            elif 'ends-with' in result:
-                                skip_op.append('ends-with')
+                            if "starts-with" in result:
+                                skip_op.append("starts-with")
+                            elif "contains" in result:
+                                skip_op.append("contains")
+                            elif "ends-with" in result:
+                                skip_op.append("ends-with")
                             if skip_op:
                                 LOG.debug(
                                     "Condition '%s' not supported for operand"
                                     " %s", str(skip_op), op)
-                elif 'port' in result:
-                    if 'case-sensitive' in result:
-                        skip_op.append('case-sensitive')
-                        LOG.debug("Condition 'case-sensitive' not supported for"
-                                  " operand %s with selector 'port'", op)
-                    if 'less' not in result and 'greater' not in result and \
-                      'less-or-equal' not in result and 'greater-or-equal' \
-                      not in result:
+                elif "port" in result:
+                    if "case-sensitive" in result:
+                        skip_op.append("case-sensitive")
+                        LOG.debug(
+                            "Condition 'case-sensitive' not supported for"
+                            " operand %s with selector 'port'", op)
+                    if (
+                        "less" not in result
+                        and "greater" not in result
+                        and "less-or-equal" not in result
+                        and "greater-or-equal" not in result
+                    ):
                         service_port = {
-                            'ports': list(result['values'].keys()),
-                            'match_criteria': 'IS_NOT_IN' if 'not' in result
-                                                else 'IS_IN'
+                            "ports": list(
+                                result["values"].keys()),
+                            "match_criteria": "IS_NOT_IN" if "not" in result else "IS_IN",
                         }
                         match["vs_port"] = service_port
                     else:
-                        if 'less' in result:
-                            skip_op.append('less')
-                        elif 'greater' in result:
-                            skip_op.append('greater')
-                        elif 'less-or-equal' in result:
-                            skip_op.append('less-or-equal')
-                        elif 'greater-or-equal' in result:
-                            skip_op.append('greater-or-equal')
+                        if "less" in result:
+                            skip_op.append("less")
+                        elif "greater" in result:
+                            skip_op.append("greater")
+                        elif "less-or-equal" in result:
+                            skip_op.append("less-or-equal")
+                        elif "greater-or-equal" in result:
+                            skip_op.append("greater-or-equal")
                         if skip_op:
                             LOG.debug(
                                 "Condition '%s' not supported for operand"
                                 " %s", str(skip_op), op)
-                elif 'scheme' in result:
-                    if 'not' not in result and 'starts-with' not in result and \
-                      'ends-with' not in result and 'contains' not in result:
-                        avi_protocol = ['HTTP', 'HTTPS']
-                        invalid = [True if val not in avi_protocol else
-                                   False for val in list(result['values'].keys())]
+                elif "scheme" in result:
+                    if "not" not in result and "starts-with" not in result and \
+                            "ends-with" not in result and "contains" not in result:
+                        avi_protocol = ["HTTP", "HTTPS"]
+                        invalid = [
+                            True if val not in avi_protocol else False for val in list(
+                                result["values"].keys())]
                         if all(invalid):
-                            LOG.debug('All protocols %s are invalid',
-                                      str(list(result['values'].keys())))
+                            LOG.debug("All protocols %s are invalid",
+                                      str(list(result["values"].keys())))
                             continue
-                        else:
-                            valid = [val for val in list(result['values'].keys())
-                                     if val in avi_protocol]
-                            LOG.debug('Only these protocols %s are valid',
-                                      str(avi_protocol))
+
+                        valid = [
+                            val for val in list(
+                                result["values"].keys()) if val in avi_protocol]
+                        LOG.debug(
+                            "Only these protocols %s are valid",
+                            str(avi_protocol))
                         if len(valid) > 1:
-                            LOG.debug("Only one value is supported at a "
-                                      "time for 'protocol' in operand %s, "
-                                      "taking any one", op)
+                            LOG.debug(
+                                "Only one value is supported at a "
+                                "time for 'protocol' in operand %s, "
+                                "taking any one", op)
                         protocol = {
-                            'protocols': valid[0],
-                            'match_criteria': 'IS_IN'
-                        }
-                        match['protocol'] = protocol
-                    else:
-                        if 'starts-with' in result:
-                            skip_op.append('starts-with')
-                        elif 'contains' in result:
-                            skip_op.append('contains')
-                        elif 'ends-with' in result:
-                            skip_op.append('ends-with')
-                        if 'not' in result:
-                            skip_op.append('not')
+                            "protocols": valid[0],
+                            "match_criteria": "IS_IN"}
+                        match["protocol"] = protocol
+                    else:
+                        if "starts-with" in result:
+                            skip_op.append("starts-with")
+                        elif "contains" in result:
+                            skip_op.append("contains")
+                        elif "ends-with" in result:
+                            skip_op.append("ends-with")
+                        if "not" in result:
+                            skip_op.append("not")
                         if skip_op:
-                            LOG.debug("Condition '%s' not supported for operand"
-                                      " %s", str(skip_op), op)
-                elif 'query-parameters' in result or 'query-string' in result:
+                            LOG.debug(
+                                "Condition '%s' not supported for operand"
+                                " %s", str(skip_op), op)
+                elif "query-parameters" in result or "query-string" in result:
                     query = {
-                        'match_case': 'SENSITIVE' if 'case-sensitive' in result
-                                        else 'INSENSITIVE',
-                        'string_group_refs': [],
-                        'match_criteria': "QUERY_MATCH_CONTAINS"
+                        "match_case": "SENSITIVE" if "case-sensitive" in result else "INSENSITIVE",
+                        "string_group_refs": [],
+                        "match_criteria": "QUERY_MATCH_CONTAINS",
                     }
-                    if 'contains' in result:
+                    if "contains" in result:
                         strgrp_name = 'stringgroup%s-%s' % (rule_name,
                                                            str(each_index))
-                        string_group = {'name': strgrp_name,
-                                        'tenant_ref':
-                                             conv_utils.get_object_ref(
-                                                 'admin', 'tenant'),
-                                        'kv': None,
-                                        'type': ''
-                        }
-                        if 'query-parameters' in result:
-                            if 'name' not in result:
-                                LOG.debug('Match rule is incomplete, values are'
-                                      ' mandatory for operand %s with selector '
-                                      'query-parameter', op)
+                        string_group = {
+                            "name": strgrp_name, "tenant_ref": conv_utils.get_object_ref(
+                                "admin", "tenant"), "kv": None, "type": "", }
+                        if "query-parameters" in result:
+                            if "name" not in result:
+                                LOG.debug(
+                                    "Match rule is incomplete, values are"
+                                    " mandatory for operand %s with selector "
+                                    "query-parameter", op)
                                 continue
-                            string_group['kv'] = [{'key': result['name'],
-                                                   'value': result[
-                                                       'values'].keys()[0]}]
-                            string_group['type'] = 'SG_TYPE_KEYVAL'
-                            query['string_group_refs'].append(
-                                conv_utils.get_object_ref(strgrp_name,
-                                            final.OBJECT_TYPE_STRING_GROUP))
-                            match['query'] = query
+                            string_group["kv"] = [
+                                {"key": result["name"],
+                                 "value": result["values"].keys()[0]}]
+                            string_group["type"] = "SG_TYPE_KEYVAL"
+                            query["string_group_refs"].append(
+                                conv_utils.get_object_ref(
+                                    strgrp_name, final.OBJECT_TYPE_STRING_GROUP))
+                            match["query"] = query
                         else:
-                            string_group['kv'] = list({'key': val} for val in
-                                                      list(result['values'].keys()))
-                            string_group['type'] = 'SG_TYPE_STRING'
-                            query['string_group_refs'].append(
-                                conv_utils.get_object_ref(strgrp_name,
-                                            final.OBJECT_TYPE_STRING_GROUP))
-                            match['query'] = query
-                        if string_group['kv']:
-                            if 'StringGroup' not in avi_config:
-                                avi_config['StringGroup'] = []
-                            avi_config['StringGroup'].append(string_group)
-                    else:
-                        if 'starts-with' in result:
-                            skip_op.append('starts-with')
-                        elif 'ends-with' in result:
-                            skip_op.append('ends-with')
+                            string_group["kv"] = list(
+                                {"key": val} for val in list(result["values"].keys()))
+                            string_group["type"] = "SG_TYPE_STRING"
+                            query["string_group_refs"].append(
+                                conv_utils.get_object_ref(
+                                    strgrp_name, final.OBJECT_TYPE_STRING_GROUP))
+                            match["query"] = query
+                        if string_group["kv"]:
+                            if "StringGroup" not in avi_config:
+                                avi_config["StringGroup"] = []
+                            avi_config["StringGroup"].append(string_group)
+                    else:
+                        if "starts-with" in result:
+                            skip_op.append("starts-with")
+                        elif "ends-with" in result:
+                            skip_op.append("ends-with")
                         else:
-                            skip_op.append('equals')
-                        if 'not' in result:
-                            skip_op.append('not')
+                            skip_op.append("equals")
+                        if "not" in result:
+                            skip_op.append("not")
                         if skip_op:
-                            LOG.debug("Condition '%s' not supported for operand"
-                                      " %s", str(skip_op), op)
+                            LOG.debug(
+                                "Condition '%s' not supported for operand"
+                                " %s", str(skip_op), op)
                 else:
-                    if 'host' in result:
-                        skip_selector.append('host')
-                    elif 'path-segment' in result:
-                        skip_selector.append('path-segment')
-                    elif 'unamed-query-parameter' in result:
-                        skip_selector.append('unamed-query-parameter')
+                    if "host" in result:
+                        skip_selector.append("host")
+                    elif "path-segment" in result:
+                        skip_selector.append("path-segment")
+                    elif "unamed-query-parameter" in result:
+                        skip_selector.append("unamed-query-parameter")
                     else:
-                        skip_selector.append('all')
+                        skip_selector.append("all")
                     if skip_selector:
-                        LOG.debug("Selector '%s' not supported for operand %s",
-                            str(skip_selector), op)
-            elif 'http-version' in result:
-                op = 'http-version'
-                pol_type = 'response' if 'response' in result else 'request'
+                        LOG.debug(
+                            "Selector '%s' not supported for operand %s",
+                            str(skip_selector),
+                            op)
+            elif "http-version" in result:
+                op = "http-version"
+                pol_type = "response" if "response" in result else "request"
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'values' not in result:
-                    LOG.debug('Match rule is incomplete, values are '
-                              'mandatory for operand %s', op)
-                    continue
-                if 'case-sensitive' in result:
-                    skip_op.append('case-sensitive')
-                if 'missing' in result:
-                    skip_op.append('missing')
-                if 'starts-with' not in result and 'contains' not in \
-                        result and 'ends-with' not in result:
-                    if 'major' not in result and 'minor' not in result and \
-                            'protocol' not in result:
-                        avi_version = ['ZERO_NINE', 'ONE_ZERO', 'ONE_ONE',
-                                       'zero_nine', 'one_zero', 'one_one']
-                        invalid = [True if val not in avi_version else False for
-                                   val in list(result['values'].keys())]
+                if "values" not in result:
+                    LOG.debug(
+                        "Match rule is incomplete, values are "
+                        "mandatory for operand %s", op)
+                    continue
+                if "case-sensitive" in result:
+                    skip_op.append("case-sensitive")
+                if "missing" in result:
+                    skip_op.append("missing")
+                if "starts-with" not in result and "contains" not in result and \
+                        "ends-with" not in result:
+                    if "major" not in result and "minor" not in result and \
+                            "protocol" not in result:
+                        avi_version = [
+                            "ZERO_NINE",
+                            "ONE_ZERO",
+                            "ONE_ONE",
+                            "zero_nine",
+                            "one_zero",
+                            "one_one"]
+                        invalid = [
+                            True if val not in avi_version else False for val in list(
+                                result["values"].keys())]
                         if all(invalid):
-                            LOG.debug('All versions %s are invalid', str(result[
-                                                              'values'].keys()))
+                            LOG.debug(
+                                "All versions %s are invalid", str(
+                                    result["values"].keys()))
                             continue
-                        else:
-                            valid = [val for val in list(result['values'].keys())
-                                     if val in avi_version]
-                            LOG.debug('Only these %s versions are valid',
-                                      str(valid))
+
+                        valid = [
+                            val for val in list(
+                                result["values"].keys()) if val in avi_version]
+                        LOG.debug(
+                            "Only these %s versions are valid", str(valid))
                         version = {
-                            'versions': [val.upper() for val in valid],
-                            'match_criteria': 'IS_NOT_IN' if 'not' in result
-                                                else 'IS_IN'
+                            "versions": [
+                                val.upper() for val in valid],
+                            "match_criteria": "IS_NOT_IN" if "not" in result else "IS_IN",
                         }
-                        match['version'] = version
-                    elif 'protocol' in result:
-                        if 'not' not in result:
-                            avi_protocol = ['HTTP', 'HTTPS']
-                            invalid = [True if val not in avi_protocol else
-                                       False for val in list(result['values'].keys())]
+                        match["version"] = version
+                    elif "protocol" in result:
+                        if "not" not in result:
+                            avi_protocol = ["HTTP", "HTTPS"]
+                            invalid = [
+                                True if val not in avi_protocol else False for val in list(
+                                    result["values"].keys())]
                             if all(invalid):
-                                LOG.debug('All protocols %s are invalid',
-                                          str(list(result['values'].keys())))
+                                LOG.debug(
+                                    "All protocols %s are invalid", str(
+                                        list(
+                                            result["values"].keys())))
                                 continue
-                            else:
-                                valid = [val for val in list(result['values'].keys())
-                                         if val in avi_protocol]
-                                LOG.debug('Only these protocols %s are valid',
-                                          str(avi_protocol))
+
+                            valid = [
+                                val for val in list(
+                                    result["values"].keys()) if val in avi_protocol]
+                            LOG.debug(
+                                "Only these protocols %s are valid", str(avi_protocol))
                             if len(valid) > 1:
-                                LOG.debug("Only one value is supported at a "
-                                          "time for 'protocol' in operand %s, "
-                                          "taking any one", op)
+                                LOG.debug(
+                                    "Only one value is supported at a "
+                                    "time for 'protocol' in operand %s, "
+                                    "taking any one", op)
                             protocol = {
-                                'protocols': valid[0],
-                                'match_criteria': 'IS_IN'
-                            }
-                            match['protocol'] = protocol
+                                "protocols": valid[0],
+                                "match_criteria": "IS_IN"}
+                            match["protocol"] = protocol
                         else:
-                            skip_op.append('not')
-                            LOG.debug("Condition 'not' not supported for "
-                                      "'protocol' in operand %s", op)
+                            skip_op.append("not")
+                            LOG.debug(
+                                "Condition 'not' not supported for "
+                                "'protocol' in operand %s", op)
                     else:
-                        if 'major' in result:
-                            skip_selector.append('major')
-                        elif 'minor' in result:
-                            skip_selector.append('minor')
+                        if "major" in result:
+                            skip_selector.append("major")
+                        elif "minor" in result:
+                            skip_selector.append("minor")
                         if skip_selector:
                             LOG.debug(
                                 "Selector '%s' not supported for operand %s",
-                                str(skip_selector), op)
+                                str(skip_selector),
+                                op)
                 else:
-                    if 'starts-with' in result:
-                        skip_op.append('starts-with')
-                    elif 'contains' in result:
-                        skip_op.append('contains')
-                    elif 'ends-with' in result:
-                        skip_op.append('ends-with')
+                    if "starts-with" in result:
+                        skip_op.append("starts-with")
+                    elif "contains" in result:
+                        skip_op.append("contains")
+                    elif "ends-with" in result:
+                        skip_op.append("ends-with")
                     if skip_op:
-                        LOG.debug("Condition '%s' not supported for operand"
-                                  " %s", str(skip_op), op)
-            elif 'http-status' in result:
-                op = 'http-status'
-                pol_type = 'response' if 'response' in result else None
+                        LOG.debug(
+                            "Condition '%s' not supported for operand"
+                            " %s", str(skip_op), op)
+            elif "http-status" in result:
+                op = "http-status"
+                pol_type = "response" if "response" in result else None
                 if not pol_type:
-                    LOG.debug('Event not supported for operand %s', op)
+                    LOG.debug("Event not supported for operand %s", op)
                     continue
-                if 'code' in result:
-                    if 'less' not in result and 'greater' not in result and \
-                      'less-or-equal' not in result and 'greater-or-equal' \
-                      not in result:
-                        if 'values' not in result:
-                            LOG.debug('Match rule is incomplete, Values are '
-                                      'mandatory for operand %s', op)
+                if "code" in result:
+                    if (
+                        "less" not in result
+                        and "greater" not in result
+                        and "less-or-equal" not in result
+                        and "greater-or-equal" not in result
+                    ):
+                        if "values" not in result:
+                            LOG.debug(
+                                "Match rule is incomplete, Values are "
+                                "mandatory for operand %s", op)
                             continue
                         status = {
-                            'match_criteria': 'IS_NOT_IN' if 'not' in result
-                                                else 'IS_IN'
-                        }
-                        status_code = [val for val in result[
-                                            'values'].keys() if '-' not in val]
+                            "match_criteria": "IS_NOT_IN" if "not" in result else "IS_IN"}
+                        status_code = [
+                            val for val in result["values"].keys() if "-" not in val]
                         if status_code:
-                            status['status_codes'] = status_code
-                        ranges = [{'begin': stat_code.split('-')[0], 'end':
-                                  stat_code.split('-')[1]} for stat_code in
-                                 list(result['values'].keys()) if '-' in stat_code]
+                            status["status_codes"] = status_code
+                        ranges = [
+                            {"begin": stat_code.split(
+                                "-")[0], "end": stat_code.split("-")[1]}
+                            for stat_code in list(result["values"].keys())
+                            if "-" in stat_code
+                        ]
                         if ranges:
-                            status['ranges'] = ranges
-                        match['status'] = status
+                            status["ranges"] = ranges
+                        match["status"] = status
                     else:
-                        if 'less' in result:
-                            skip_op.append('less')
-                        elif 'greater' in result:
-                            skip_op.append('greater')
-                        elif 'less-or-equal' in result:
-                            skip_op.append('less-or-equal')
-                        elif 'greater-or-equal' in result:
-                            skip_op.append('greater-or-equal')
-                        if 'case-sensitive' in result:
-                            skip_op.append('case-sensitive')
-                        if 'missing' in result:
-                            skip_op.append('missing')
+                        if "less" in result:
+                            skip_op.append("less")
+                        elif "greater" in result:
+                            skip_op.append("greater")
+                        elif "less-or-equal" in result:
+                            skip_op.append("less-or-equal")
+                        elif "greater-or-equal" in result:
+                            skip_op.append("greater-or-equal")
+                        if "case-sensitive" in result:
+                            skip_op.append("case-sensitive")
+                        if "missing" in result:
+                            skip_op.append("missing")
                         if skip_op:
-                            LOG.debug("Condition '%s' not supported for "
-                                      "operand %s", str(skip_op), op)
+                            LOG.debug(
+                                "Condition '%s' not supported for "
+                                "operand %s", str(skip_op), op)
                 else:
-                    if 'text' in result:
-                        skip_selector.append('text')
+                    if "text" in result:
+                        skip_selector.append("text")
                     else:
-                        skip_selector.append('all')
+                        skip_selector.append("all")
                     if skip_selector:
-                        LOG.debug("Selector %s not supported for operand %s",
-                                  str(skip_selector), op)
+                        LOG.debug(
+                            "Selector %s not supported for operand %s",
+                            str(skip_selector),
+                            op)
             else:
-                LOG.debug('Rule match %s not supported for rule %s',
-                          str(result), each_rule)
+                LOG.debug(
+                    "Rule match %s not supported for rule %s",
+                    str(result),
+                    each_rule)
             if op:
                 skip_set = {op: {}}
                 if skip_selector:
-                    skip_set[op]['selector'] = skip_selector
+                    skip_set[op]["selector"] = skip_selector
                 if skip_parameter:
-                    skip_set[op]['parameter'] = skip_parameter
+                    skip_set[op]["parameter"] = skip_parameter
                 if skip_op:
-                    skip_set[op]['condn_op'] = skip_op
+                    skip_set[op]["condn_op"] = skip_op
                 if skip_event:
-                    skip_set[op]['event'] = skip_event
+                    skip_set[op]["event"] = skip_event
                 if skip_set[op]:
                     skip_match.append(skip_set)
         return pol_type, match, skip_match
 
-    def create_action_rule(self, action_dict, avi_config, each_rule,
-                           policy_name):
+    def create_action_rule(self, action_dict, avi_config,
+                           each_rule, policy_name, cloud_name, tenant):
         """
         This method create action dict for each rule
         :param action_dict: f5 action dict
         :param avi_config: dict for avi conversion
         :param each_rule: rule for policy
         :param policy_name: name of http policy
         :return: action list, skip list for action and log action dict
         """
         action_list = []
         skip_actions = []
         log_dict = None
-        LOG.debug('Started making action for rule %s', each_rule)
+        LOG.debug("Started making action for rule %s", each_rule)
         for each_index in action_dict:
-            if [act for act in action_list if act.get('redirect_action')]:
-                LOG.debug("Rule '%s' has 'redirect_action' hence, can't have "
-                          "any other action", each_rule)
+            if [act for act in action_list if act.get("redirect_action")]:
+                LOG.debug(
+                    "Rule '%s' has 'redirect_action' hence, can't have "
+                    "any other action", each_rule)
                 return
             action = None
             target = None
             skip_event, skip_target = [], []
             skip_action, skip_parameter = [], []
             result = action_dict[each_index]
-            pol_type = 'response' if 'response' in result else 'request'
-            if 'forward' in result:
-                target = 'forward'
-                if 'select' in result:
-                    if 'pool' in result:
+            pol_type = "response" if "response" in result else "request"
+            if "forward" in result:
+                target = "forward"
+                if "select" in result:
+                    if "pool" in result:
                         action = {
-                            'switching_action': {
-                                'status_code':
-                                    'HTTP_LOCAL_RESPONSE_STATUS_CODE_200'
-                            }
-                        }
+                            "switching_action": {
+                                "status_code": "HTTP_LOCAL_RESPONSE_STATUS_CODE_200"}}
                         p_tenant, poolname = conv_utils.get_tenant_ref(
-                            result['pool'])
+                            result["pool"])
+                        if tenant:
+                            p_tenant = tenant
                         if self.prefix:
                             poolname = '%s-%s' % (self.prefix, poolname)
-                        poolobj = [obj for obj in avi_config['Pool'] if
-                                   poolname == obj['name'] and
-                                   conv_utils.get_name(obj[
-                                   'tenant_ref']) == p_tenant]
+                        poolobj = [
+                            obj
+                            for obj in avi_config["Pool"]
+                            if poolname == obj["name"] and conv_utils.get_name(obj["tenant_ref"]) == p_tenant
+                        ]
                         if poolobj:
                             pool_ref = conv_utils.get_object_ref(
-                                poolobj[0]['name'], 'pool', tenant=p_tenant)
-                            action['switching_action']['action'] = \
-                                'HTTP_SWITCHING_SELECT_POOL'
-                            action['switching_action']['pool_ref'] = pool_ref
+                                poolobj[0]["name"], "pool", tenant=p_tenant, cloud_name=cloud_name)
+                            action["switching_action"]["action"] = "HTTP_SWITCHING_SELECT_POOL"
+                            action["switching_action"]["pool_ref"] = pool_ref
 
                             if pool_ref not in used_pools:
                                 used_pools[pool_ref] = set([policy_name])
                             else:
                                 used_pools[pool_ref].add(policy_name)
                         else:
-                            pgobj = [ob for ob in avi_config['PoolGroup']
-                                     if poolname == ob['name'] and
-                                     conv_utils.get_name(obj[
-                                     'tenant_ref']) == p_tenant]
+                            pgobj = [
+                                ob
+                                for ob in avi_config["PoolGroup"]
+                                if poolname == ob["name"] and conv_utils.get_name(ob["tenant_ref"]) == p_tenant
+                            ]
                             if pgobj:
                                 pg_ref = conv_utils.get_object_ref(
-                                    pgobj[0]['name'], 'poolgroup',
-                                    tenant=p_tenant)
-                                action['switching_action']['action'] = \
-                                    'HTTP_SWITCHING_SELECT_POOLGROUP'
-                                action['switching_action']['pool_group_ref'] = \
-                                    pg_ref
+                                    pgobj[0]["name"],
+                                    "poolgroup", tenant=p_tenant, cloud_name=cloud_name)
+                                action["switching_action"]["action"] = "HTTP_SWITCHING_SELECT_POOLGROUP"
+                                action["switching_action"]["pool_group_ref"] = pg_ref
                                 if pg_ref not in used_pools:
                                     used_pools[pg_ref] = set([policy_name])
                                 else:
                                     used_pools[pg_ref].add(policy_name)
                             else:
-                                LOG.debug("No pool/poolgroup '%s' found",
-                                          poolname)
+                                LOG.debug(
+                                    "No pool/poolgroup '%s' found", poolname)
                                 continue
                     else:
-                        if 'clone-pool' in result:
-                            skip_parameter.append('clone-pool')
-                        elif 'member' in result:
-                            skip_parameter.append('member')
-                        elif 'nexthop' in result:
-                            skip_parameter.append('nexthop')
-                        elif 'node' in result:
-                            skip_parameter.append('node')
-                        elif 'rateclass' in result:
-                            skip_parameter.append('rateclass')
-                        elif 'snat' in result:
-                            skip_parameter.append('snat')
-                        elif 'snatpool'  in result:
-                            skip_parameter.append('snatpool')
-                        elif 'virtualserver'  in result:
-                            skip_parameter.append('virtualserver')
-                        elif 'vlan'  in result:
-                            skip_parameter.append('vlan')
-                        elif 'vlan_id'  in result:
-                            skip_parameter.append('vlan_id')
+                        if "clone-pool" in result:
+                            skip_parameter.append("clone-pool")
+                        elif "member" in result:
+                            skip_parameter.append("member")
+                        elif "nexthop" in result:
+                            skip_parameter.append("nexthop")
+                        elif "node" in result:
+                            skip_parameter.append("node")
+                        elif "rateclass" in result:
+                            skip_parameter.append("rateclass")
+                        elif "snat" in result:
+                            skip_parameter.append("snat")
+                        elif "snatpool" in result:
+                            skip_parameter.append("snatpool")
+                        elif "virtualserver" in result:
+                            skip_parameter.append("virtualserver")
+                        elif "vlan" in result:
+                            skip_parameter.append("vlan")
+                        elif "vlan_id" in result:
+                            skip_parameter.append("vlan_id")
                         if skip_parameter:
-                            LOG.debug('Parameter %s not supported for target '
-                                      '%s', str(skip_parameter), target)
+                            LOG.debug(
+                                "Parameter %s not supported for target "
+                                "%s", str(skip_parameter), target)
                 else:
-                    if 'reset' in result:
-                        skip_action.append('reset')
-                        LOG.debug("Action 'reset' not supported for target %s",
-                                  target)
-            elif 'http' in result:
-                target = 'http'
-                if pol_type == 'request':
-                    if 'enable' in result:
+                    if "reset" in result:
+                        skip_action.append("reset")
+                        LOG.debug(
+                            "Action 'reset' not supported for target %s", target)
+            elif "http" in result:
+                target = "http"
+                if pol_type == "request":
+                    if "enable" in result:
                         action = {
-                            'redirect_action': {
-                                'keep_query': True,
-                                'status_code': 'HTTP_REDIRECT_STATUS_CODE_302',
-                                'protocol': 'HTTP',
-                                'port': 80
+                            "redirect_action": {
+                                "keep_query": True,
+                                "status_code": "HTTP_REDIRECT_STATUS_CODE_302",
+                                "protocol": "HTTP",
+                                "port": 80,
                             }
                         }
                     else:
-                        skip_action.append('disable')
-                        LOG.debug("Action 'disable' not supported for target "
-                                  "%s", target)
+                        skip_action.append("disable")
+                        LOG.debug(
+                            "Action 'disable' not supported for target "
+                            "%s", target)
                 else:
-                    skip_event.append('response')
-                    LOG.debug("Event 'response' not supported for target %s",
-                              target)
-            elif 'http-header' in result:
-                target = 'http-header'
-                if 'name' not in result:
-                    LOG.debug("Mandatory parameter 'name' is missing for "
-                              "target %s in rule %s", target, each_rule)
-                    continue
-                action = {
-                    'hdr_action': [
-                        {
-                            'action': '',
-                            'hdr': {
-                                        'name': result['name']
-                            }
-                        }
-                    ]
-                }
-                if 'remove' in result:
-                    action['hdr_action'][0]['action'] = 'HTTP_REMOVE_HDR'
-                elif 'replace' in result:
-                    if 'value' not in result:
-                        LOG.debug("Mandatory parameter 'value' is missing for "
-                                  "target %s in rule %s", target, each_rule)
+                    skip_event.append("response")
+                    LOG.debug(
+                        "Event 'response' not supported for target %s", target)
+            elif "http-header" in result:
+                target = "http-header"
+                if "name" not in result:
+                    LOG.debug(
+                        "Mandatory parameter 'name' is missing for "
+                        "target %s in rule %s", target, each_rule)
+                    continue
+                action = {"hdr_action": [
+                    {"action": "", "hdr": {"name": result["name"]}}]}
+                if "remove" in result:
+                    action["hdr_action"][0]["action"] = "HTTP_REMOVE_HDR"
+                elif "replace" in result:
+                    if "value" not in result:
+                        LOG.debug(
+                            "Mandatory parameter 'value' is missing for "
+                            "target %s in rule %s", target, each_rule)
                         continue
-                    action['hdr_action'][0]['action'] = 'HTTP_REPLACE_HDR'
-                    action['hdr_action'][0]['hdr']['value'] = {}
-                    action['hdr_action'][0]['hdr']['value']['val'] = result[
-                                                                        'value']
-                elif 'insert' in result:
-                    if 'value' not in result:
-                        LOG.debug("Mandatory parameter 'value' is missing for "
-                                  "target %s in rule %s", target, each_rule)
+                    action["hdr_action"][0]["action"] = "HTTP_REPLACE_HDR"
+                    action["hdr_action"][0]["hdr"]["value"] = {}
+                    action["hdr_action"][0]["hdr"]["value"]["val"] = result["value"]
+                elif "insert" in result:
+                    if "value" not in result:
+                        LOG.debug(
+                            "Mandatory parameter 'value' is missing for "
+                            "target %s in rule %s", target, each_rule)
                         continue
-                    action['hdr_action'][0]['action'] = 'HTTP_ADD_HDR'
-                    action['hdr_action'][0]['hdr']['value'] = {}
-                    action['hdr_action'][0]['hdr']['value']['val'] = result[
-                                                                        'value']
+                    action["hdr_action"][0]["action"] = "HTTP_ADD_HDR"
+                    action["hdr_action"][0]["hdr"]["value"] = {}
+                    action["hdr_action"][0]["hdr"]["value"]["val"] = result["value"]
                 else:
                     skip_target.append(target)
                     LOG.debug("Action not supported for target %s", target)
-            elif 'http-reply' in result:
-                target = 'http-reply'
-                if pol_type == 'request':
-                    if 'redirect' in result:
-                        if 'location' in result:
+            elif "http-reply" in result:
+                target = "http-reply"
+                if pol_type == "request":
+                    if "redirect" in result:
+                        if "location" in result:
                             action = {
-                                'redirect_action': {
-                                   'keep_query': True,
-                                   'path': {
-                                       'tokens': [
-                                           {
-                                               'str_value': result['location'],
-                                               'type': 'URI_TOKEN_TYPE_STRING'
-                                           }
-
-                                       ],
-                                       'type': "URI_PARAM_TYPE_TOKENIZED"
-                                   },
-                                   'protocol': "HTTP",
-                                   'port': 80,
-                                   'status_code':
-                                       "HTTP_REDIRECT_STATUS_CODE_302"
+                                "redirect_action": {
+                                    "keep_query": True,
+                                    "path": {
+                                        "tokens": [{"str_value": result["location"], "type": "URI_TOKEN_TYPE_STRING"}],
+                                        "type": "URI_PARAM_TYPE_TOKENIZED",
+                                    },
+                                    "protocol": "HTTP",
+                                    "port": 80,
+                                    "status_code": "HTTP_REDIRECT_STATUS_CODE_302",
                                 }
                             }
                         else:
-                            LOG.debug("Mandatory parameter 'location' is "
-                                      "missing for target %s in rule %s",
-                                      target, each_rule)
+                            LOG.debug(
+                                "Mandatory parameter 'location' is "
+                                "missing for target %s in rule %s", target, each_rule)
                     else:
                         LOG.debug("Action not supported for target %s", target)
                 else:
-                    skip_event.append('response')
-                    LOG.debug("Event 'response' not supported for target "
-                              "'%s' in rule %s", target, each_rule)
-            elif 'http-host' in result:
-                target = 'http-host'
-                if 'value' not in result:
-                    LOG.debug("Mandatory parameter 'value' is missing for "
-                              "target %s in rule %s", target, each_rule)
-                    continue
-                if 'replace' in result:
-                    action = {
-                        'hdr_action': [
-                            {
-                                'action': 'HTTP_REPLACE_HDR',
-                                'hdr': {
-                                            'name': 'host',
-                                            'value': {'val': result['value']}
-                                }
-                            }
-                        ]
-                    }
+                    skip_event.append("response")
+                    LOG.debug(
+                        "Event 'response' not supported for target "
+                        "'%s' in rule %s", target, each_rule)
+            elif "http-host" in result:
+                target = "http-host"
+                if "value" not in result:
+                    LOG.debug(
+                        "Mandatory parameter 'value' is missing for "
+                        "target %s in rule %s", target, each_rule)
+                    continue
+                if "replace" in result:
+                    action = {"hdr_action": [{"action": "HTTP_REPLACE_HDR", "hdr": {
+                        "name": "host", "value": {"val": result["value"]}}}]}
                 else:
                     skip_target.append(target)
                     LOG.debug("Action not supported for target %s", target)
-            elif 'http-referer' in result:
-                target = 'http-referer'
-                action = {
-                    'hdr_action': [
-                        {
-                            'action': '',
-                            'hdr': {
-                                        'name': 'referer'
-                            }
-                        }
-                    ]
-                }
-                if 'remove' in result:
-                    action['hdr_action'][0]['action'] = 'HTTP_REMOVE_HDR'
-                elif 'replace' in result:
-                    if 'value' not in result:
-                        LOG.debug("Mandatory parameter 'value' is missing for "
-                                  "target %s in rule %s", target, each_rule)
+            elif "http-referer" in result:
+                target = "http-referer"
+                action = {"hdr_action": [
+                    {"action": "", "hdr": {"name": "referer"}}]}
+                if "remove" in result:
+                    action["hdr_action"][0]["action"] = "HTTP_REMOVE_HDR"
+                elif "replace" in result:
+                    if "value" not in result:
+                        LOG.debug(
+                            "Mandatory parameter 'value' is missing for "
+                            "target %s in rule %s", target, each_rule)
                         continue
-                    action['hdr_action'][0]['action'] = 'HTTP_REPLACE_HDR'
-                    action['hdr_action'][0]['hdr']['value'] = {}
-                    action['hdr_action'][0]['hdr']['value']['val'] = result[
-                                                                        'value']
-                elif 'insert' in result:
-                    if 'value' not in result:
-                        LOG.debug("Mandatory parameter 'value' is missing for "
-                                  "target %s in rule %s", target, each_rule)
+                    action["hdr_action"][0]["action"] = "HTTP_REPLACE_HDR"
+                    action["hdr_action"][0]["hdr"]["value"] = {}
+                    action["hdr_action"][0]["hdr"]["value"]["val"] = result["value"]
+                elif "insert" in result:
+                    if "value" not in result:
+                        LOG.debug(
+                            "Mandatory parameter 'value' is missing for "
+                            "target %s in rule %s", target, each_rule)
                         continue
-                    action['hdr_action'][0]['action'] = 'HTTP_ADD_HDR'
-                    action['hdr_action'][0]['hdr']['value'] = {}
-                    action['hdr_action'][0]['hdr']['value']['val'] = result[
-                                                                        'value']
+                    action["hdr_action"][0]["action"] = "HTTP_ADD_HDR"
+                    action["hdr_action"][0]["hdr"]["value"] = {}
+                    action["hdr_action"][0]["hdr"]["value"]["val"] = result["value"]
                 else:
                     skip_target.append(target)
                     LOG.debug("Action not supported for target %s", target)
-            elif 'http-uri' in result:
-                target = 'http-uri'
-                if 'value' not in result:
-                    LOG.debug("Mandatory parameter 'value' is missing for "
-                              "target %s in rule %s", target, each_rule)
+            elif "http-uri" in result:
+                target = "http-uri"
+                if "value" not in result:
+                    LOG.debug(
+                        "Mandatory parameter 'value' is missing for "
+                        "target %s in rule %s", target, each_rule)
                     continue
-                if 'replace' in result:
-                    if 'path' in result:
+                if "replace" in result:
+                    if "path" in result:
                         action = {
-                            'rewrite_url_action': {
-                                'path': {
-                                    'tokens': [
-                                        {
-                                            'str_value': result['value'],
-                                            'type': "URI_TOKEN_TYPE_STRING"
-                                        }
-                                    ],
-                                    'type': "URI_PARAM_TYPE_TOKENIZED"
+                            "rewrite_url_action": {
+                                "path": {
+                                    "tokens": [{"str_value": result["value"], "type": "URI_TOKEN_TYPE_STRING"}],
+                                    "type": "URI_PARAM_TYPE_TOKENIZED",
                                 },
-                                'query': {
-                                    'keep_query': True
-                                }
+                                "query": {"keep_query": True},
                             }
                         }
-                    elif 'query-string' in result:
+                    elif "query-string" in result:
                         action = {
-                            'rewrite_url_action': {
-                                'query': {
-                                    'keep_query': True,
-                                    'add_string': result['value']
-                                }
-                            }
-                        }
+                            "rewrite_url_action": {
+                                "query": {
+                                    "keep_query": True,
+                                    "add_string": result["value"]}}}
                     else:
-                        if 'name' in result:
-                            skip_parameter.append('name')
+                        if "name" in result:
+                            skip_parameter.append("name")
                         if skip_parameter:
-                            LOG.debug('Parameter %s not supported for target '
-                                      '%s', str(skip_parameter), target)
+                            LOG.debug(
+                                "Parameter %s not supported for target "
+                                "%s", str(skip_parameter), target)
                 else:
                     skip_target.append(target)
                     LOG.debug("Action not supported for target %s", target)
-            elif 'log' in result:
-                target = 'log'
-                if pol_type == 'request':
-                    log_dict = {
-                        'log': True,
-                        'all_headers': False
-                    }
+            elif "log" in result:
+                target = "log"
+                if pol_type == "request":
+                    log_dict = {"log": True, "all_headers": False}
                 else:
-                    skip_event.append('response')
-                    LOG.debug("Event 'response' not supported for target %s",
-                              target)
-            elif 'l7dos' in result:
-                target = 'l7dos'
+                    skip_event.append("response")
+                    LOG.debug(
+                        "Event 'response' not supported for target %s", target)
+            elif "l7dos" in result:
+                target = "l7dos"
                 skip_target.append(target)
                 LOG.debug("Datascript can be used for action %s", str(result))
             else:
-                LOG.debug('Rule action %s not supported for rule %s',
-                          str(result), each_rule)
+                LOG.debug(
+                    "Rule action %s not supported for rule %s",
+                    str(result),
+                    each_rule)
             if target:
                 sk_set = {target: {}}
                 if skip_action:
-                    sk_set[target]['action'] = skip_action
+                    sk_set[target]["action"] = skip_action
                 if skip_event:
-                    sk_set[target]['event'] = skip_event
+                    sk_set[target]["event"] = skip_event
                 if skip_parameter:
-                    sk_set[target]['parameter'] = skip_parameter
+                    sk_set[target]["parameter"] = skip_parameter
                 if skip_target:
-                    sk_set[target]['target'] = skip_target
+                    sk_set[target]["target"] = skip_target
                 if sk_set[target]:
                     skip_actions.append(sk_set)
             if action:
                 action_list.append(action)
         return action_list, skip_actions, log_dict
 
 
 class PolicyConfigConvV11(PolicyConfigConv):
     def __init__(self, prefix, f5_profile_attributes):
         self.prefix = prefix
-        self.na_list = f5_profile_attributes['Policy_na_attr']
-        self.indirect = f5_profile_attributes['Policy_indirect_attr']
+        self.na_list = f5_profile_attributes["Policy_na_attr"]
+        self.indirect = f5_profile_attributes["Policy_indirect_attr"]
+
 
 class PolicyConfigConvV10(PolicyConfigConv):
-    def __init__(self, prefix , f5_profile_attributes):
+    def __init__(self, prefix, f5_profile_attributes):
         self.prefix = prefix
-        self.na_list = f5_profile_attributes['Policy_na_attr']
-        self.indirect = f5_profile_attributes['Policy_indirect_attr']
+        self.na_list = f5_profile_attributes["Policy_na_attr"]
+        self.indirect = f5_profile_attributes["Policy_indirect_attr"]
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/pool_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/pool_converter.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,116 +1,146 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-import logging
 import copy
+import logging
 import re
+
 import avi.migrationtools.f5_converter.converter_constants as conv_const
-from avi.migrationtools.f5_converter.conversion_util import F5Util
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
+from avi.migrationtools.f5_converter.conversion_util import F5Util
+
 LOG = logging.getLogger(__name__)
 # Creating f5 object for util library.
 conv_utils = F5Util()
 
+
 class PoolConfigConv(object):
     @classmethod
     def get_instance(cls, version, f5_pool_attributes, prefix):
         """
 
         :param version:  f5 version
         :param f5_pool_attributes: location of yaml file for supported
         attributes
         :param prefix: prefix for objects
         :return:
         """
-        if version == '10':
+        if version == "10":
             return PoolConfigConvV10(f5_pool_attributes, prefix)
-        if version in ['11', '12']:
+        if version in ["11", "12"]:
             return PoolConfigConvV11(f5_pool_attributes, prefix)
 
-    def convert_pool(self, pool_name, f5_config, avi_config, user_ignore,
-                     tenant_ref, cloud_ref, merge_object_mapping, sys_dict,
-                     vrf=None, segroup=None):
+    def convert_pool(
+            self,
+            pool_name,
+            f5_config,
+            avi_config,
+            user_ignore,
+            tenant_ref,
+            cloud_ref,
+            merge_object_mapping,
+            sys_dict,
+            vrf=None,
+            segroup=None):
+        '''
+        Method for converting pool
+        '''
         pass
 
-    def convert(self, f5_config, avi_config, user_ignore, tenant_ref,
-                cloud_name, merge_object_mapping, sys_dict, vrf=None,
-                segroup=None):
+    def convert(
+            self,
+            f5_config,
+            avi_config,
+            user_ignore,
+            tenant_ref,
+            cloud_name,
+            merge_object_mapping,
+            sys_dict,
+            vrf=None,
+            segroup=None):
         """
 
         :param f5_config: parsed f5 config dict
         :param avi_config: dict for avi conversion
         :param user_ignore: Ignore config defined by user
         :param tenant_ref: tenant for which config need to be converted
         :param cloud_name: cloud for which config need to be converted
         :param merge_object_mapping: flag for merge object
         :param sys_dict: baseline profile dict
         :return:
         """
         pool_list = []
-        pool_config = f5_config.get('pool', {})
-        user_ignore = user_ignore.get('pool', {})
-        avi_config['VrfContext'] = []
-        avi_config['PoolGroup'] = []
-        avi_config['PriorityLabels'] = {}
+        pool_config = f5_config.get("pool", {})
+        user_ignore = user_ignore.get("pool", {})
+        avi_config["VrfContext"] = []
+        avi_config["PoolGroup"] = []
+        avi_config["PriorityLabels"] = {}
         # Initialize Global vrf context object
         vrf_context = {
-            "name": 'global',
+            "name": "global",
             "system_default": True,
-            "tenant_ref": conv_utils.get_object_ref('admin', 'tenant'),
-            "cloud_ref": conv_utils.get_object_ref(cloud_name, 'cloud'),
-            "static_routes": []
+            "tenant_ref": conv_utils.get_object_ref("admin", "tenant"),
+            "cloud_ref": conv_utils.get_object_ref(cloud_name, "cloud"),
+            "static_routes": [],
         }
-        avi_config['VrfContext'].append(vrf_context)
+        avi_config["VrfContext"].append(vrf_context)
         total_size = len(pool_config.keys())
         # Added variable to get total object count.
         progressbar_count = 0
         print("Converting Pools...")
         for pool_name in pool_config.keys():
             progressbar_count += 1
-            LOG.debug("Converting Pool: %s" % pool_name)
+            LOG.debug("Converting Pool: %s", pool_name)
             f5_pool = pool_config[pool_name]
             if not f5_pool:
                 msg = "Empty pool skipped for conversion :%s" % pool_name
                 LOG.debug(msg)
-                conv_utils.add_status_row('pool', None, pool_name,
-                                          conv_const.STATUS_SKIPPED, msg)
+                conv_utils.add_status_row(
+                    "pool", None, pool_name, conv_const.STATUS_SKIPPED, msg)
                 continue
-            if 'gateway-failsafe-device' in f5_pool:
+            if "gateway-failsafe-device" in f5_pool:
                 msg = ("Not supported gateway-failsafe-device, pool skipped "
                           "for conversion :%s" % pool_name)
                 LOG.debug(msg)
-                conv_utils.add_status_row('pool', None, pool_name,
-                                          conv_const.STATUS_SKIPPED, msg)
+                conv_utils.add_status_row(
+                    "pool", None, pool_name, conv_const.STATUS_SKIPPED, msg)
                 continue
             try:
                 converted_objs = self.convert_pool(
-                    pool_name, f5_config, avi_config, user_ignore, tenant_ref,
-                    cloud_name, merge_object_mapping, sys_dict, vrf, segroup)
-                pool_list += converted_objs['pools']
-                if 'pg_obj' in converted_objs:
-                    avi_config['PoolGroup'].extend(converted_objs['pg_obj'])
-                LOG.debug("Conversion successful for Pool: %s" % pool_name)
-            except:
-                update_count('error')
-                LOG.error("Failed to convert pool: %s" % pool_name,
-                          exc_info=True)
-                conv_utils.add_status_row('pool', None, pool_name,
-                                          conv_const.STATUS_ERROR)
+                    pool_name, f5_config, avi_config,
+                    user_ignore, tenant_ref, cloud_name,
+                    merge_object_mapping, sys_dict, vrf,
+                    segroup)
+                pool_list += converted_objs["pools"]
+                if "pg_obj" in converted_objs:
+                    avi_config["PoolGroup"].extend(converted_objs["pg_obj"])
+                LOG.debug("Conversion successful for Pool: %s", pool_name)
+            except BaseException:
+                update_count("error")
+                LOG.error(
+                    "Failed to convert pool: %s",
+                    pool_name, exc_info=True)
+                conv_utils.add_status_row(
+                    "pool", None, pool_name, conv_const.STATUS_ERROR)
             # Added call to check progress.
             msg = "Pool and PoolGroup conversion started..."
-            conv_utils.print_progress_bar(progressbar_count, total_size, msg,
-                             prefix='Progress', suffix='')
-        avi_config['Pool'] = pool_list
-        LOG.debug("Converted %s pools" % len(pool_list))
-        f5_config.pop('pool', {})
-
-    def get_monitor_refs(self, monitor_names, monitor_config_list, pool_name,
-                         tenant_ref, merge_object_mapping, sys_mon):
+            conv_utils.print_progress_bar(
+                progressbar_count,
+                total_size,
+                msg,
+                prefix="Progress",
+                suffix="")
+        avi_config["Pool"] = pool_list
+        LOG.debug("Converted %s pools", len(pool_list))
+        f5_config.pop("pool", {})
 
+    def get_monitor_refs(self, monitor_names, monitor_config_list,
+                         pool_name, tenant_ref, merge_object_mapping, sys_mon):
         """
 
         :param monitor_names:  name of monitor
         :param monitor_config_list: parsed dict of monitor_config_list
         :param pool_name: name of pool
         :param tenant_ref: tenant which need to be converted
         :param merge_object_mapping: flag for object merge
@@ -119,39 +149,41 @@
         """
         skipped_monitors = []
         monitors = monitor_names.split(" ")
         monitor_refs = []
         garbage_val = ["and", "all", "min", "of", "{", "}", "none"]
         for monitor in monitors:
             monitor = monitor.strip()
-            if not monitor or monitor in garbage_val or \
-                    monitor.isdigit():
+            if not monitor or monitor in garbage_val or monitor.isdigit():
                 continue
-            if self.prefix:
-                monitor = '%s-%s' % (self.prefix, monitor)
 
             tenant, monitor = conv_utils.get_tenant_ref(monitor)
-            monitor_obj = [ob for ob in sys_mon if ob['name'] ==
-                          merge_object_mapping['health_monitor'].get(monitor)] \
-                          or [obj for obj in monitor_config_list if (
-                          obj["name"] == monitor or monitor in
-                          obj.get("dup_of", []))]
+            if self.prefix:
+                monitor = '%s-%s' % (self.prefix, monitor)
+            monitor_obj = [ob for ob in sys_mon if ob["name"] ==
+                           merge_object_mapping["health_monitor"].get(monitor)]\
+                or [obj for obj in monitor_config_list if (
+                    obj["name"] == monitor or monitor in obj.get(
+                        "dup_of", []))]
             if monitor_obj:
-                tenant = conv_utils.get_name(
-                    monitor_obj[0]['tenant_ref'])
-                monitor_refs.append(conv_utils.get_object_ref(monitor_obj[0]['name'],
-                                                              'healthmonitor', tenant=tenant))
+                tenant = conv_utils.get_name(monitor_obj[0]["tenant_ref"])
+                monitor_refs.append(
+                    conv_utils.get_object_ref(
+                        monitor_obj[0]["name"],
+                        "healthmonitor",
+                        tenant=tenant))
             else:
-                LOG.warning("Monitor not found: %s for pool %s" %
-                            (monitor, pool_name))
+                LOG.warning(
+                    "Monitor not found: %s for pool %s",
+                    monitor, pool_name)
                 skipped_monitors.append(monitor)
         return skipped_monitors, monitor_refs
 
-    def create_pool_object(self, name, desc, servers, pd_action, algo,
-                           ramp_time, limits, tenant_ref, cloud_ref):
+    def create_pool_object(self, name, desc, servers, pd_action,
+                           algo, ramp_time, limits, tenant_ref, cloud_ref):
         """
 
         :param name: name of pool
         :param desc:  description of pool
         :param servers: servers list in pool
         :param pd_action: action on avi pool
         :param algo: algorithm used for pool
@@ -160,608 +192,680 @@
         :return: pool_obj
         """
         tenant, name = conv_utils.get_tenant_ref(name)
         # Added prefix for objects
         if self.prefix:
             name = self.prefix + '-' + name
         pool_obj = {
-            'name': name,
-            'description': desc,
-            'servers': servers,
-            'fail_action': pd_action,
-            'lb_algorithm': algo,
-            'cloud_ref': conv_utils.get_object_ref(cloud_ref, 'cloud')
+            "name": name,
+            "description": desc,
+            "servers": servers,
+            "fail_action": pd_action,
+            "lb_algorithm": algo,
+            "cloud_ref": conv_utils.get_object_ref(cloud_ref, "cloud"),
         }
 
         if any(server["port"] == "" for server in servers):
             pool_obj.update({"use_service_port": "true"})
         if tenant_ref:
             tenant = tenant_ref
-        pool_obj['tenant_ref'] = conv_utils.get_object_ref(tenant, 'tenant')
+        pool_obj["tenant_ref"] = conv_utils.get_object_ref(tenant, "tenant")
         if ramp_time:
-            pool_obj['connection_ramp_duration'] = ramp_time
-        if limits.get('connection_limit', 0) > 0:
-            pool_obj['max_concurrent_connections_per_server'] = \
-                limits['connection_limit']
+            pool_obj["connection_ramp_duration"] = ramp_time
+        if limits.get("connection_limit", 0) > 0:
+            pool_obj["max_concurrent_connections_per_server"] = limits["connection_limit"]
         return pool_obj
 
     def check_for_pool_group(self, servers):
         """
         Check if the priority group for the server exist
         :param servers: List of servers to check server priority
         :return: if priority exist returns true and priority wise
         dict of servers
         """
         is_pool_group = False
         for server in servers:
-            if 'priority' in server:
+            if "priority" in server:
                 is_pool_group = True
                 break
         if not is_pool_group:
             return is_pool_group, None
-        pg_dict = dict()
+        pg_dict = {}
         for server in servers:
-            priority = server.get('priority', None)
+            priority = server.get("priority", None)
             if not priority:
                 is_pool_group = False
                 break
-            else:
-                del server['priority']
+
+            del server["priority"]
             priority_list = pg_dict.get(priority, [])
             priority_list.append(server)
             pg_dict[priority] = priority_list
         return is_pool_group, pg_dict
 
     def add_status(self, name, skipped_attr, member_skipped, skipped_monitors,
-                   converted_objs, user_ignore, skipped_servers):
+                   converted_objs, user_ignore, skipped_servers, f5_pool):
         skipped = []
-        conv_status = dict()
-        conv_status['user_ignore'] = []
+        conv_status = {}
+        conv_status["user_ignore"] = []
         if skipped_attr:
-            p_ignore = user_ignore.get('pool', [])
-            conv_status['user_ignore'] = [val for val in skipped_attr
-                                          if val in p_ignore]
-            skipped_attr = [attr for attr in skipped_attr
-                            if attr not in p_ignore]
+            p_ignore = user_ignore.get("pool", [])
+            conv_status["user_ignore"] = [
+                val for val in skipped_attr if val in p_ignore]
+            skipped_attr = [
+                attr for attr in skipped_attr if attr not in p_ignore]
             if skipped_attr:
                 skipped.append(skipped_attr)
         if member_skipped:
-            m_ignore = user_ignore.get('members', [])
+            m_ignore = user_ignore.get("members", [])
             if m_ignore:
                 ms_new = []
                 um_list = []
                 for obj in member_skipped:
-                    um_skipped = dict()
-                    um_skipped[obj.keys()[0]] = \
-                        [val for val in obj[obj.keys()[0]] if val in m_ignore]
+                    um_skipped = {}
+                    um_skipped[obj.keys()[0]] = [
+                        val for val in obj[obj.keys()[0]] if val in m_ignore]
                     temp = [val for val in obj[obj.keys()[0]]
                             if val not in m_ignore]
                     if um_skipped[um_skipped.keys()[0]]:
                         um_list.append(um_skipped)
                     if temp:
                         ms_new.append({obj.keys()[0]: temp})
-                conv_status['user_ignore'].append(um_list)
+                conv_status["user_ignore"].append(um_list)
                 if ms_new:
                     skipped.append(ms_new)
             else:
                 skipped.append(member_skipped)
 
-        if skipped_monitors and not user_ignore.get('monitor', None):
+        if skipped_monitors and not user_ignore.get("monitor", None):
             skipped.append({"monitor": skipped_monitors})
         if skipped_servers:
             skipped.append({"server": skipped_servers})
-        conv_status['skipped'] = skipped
+        conv_status["skipped"] = skipped
         status = conv_const.STATUS_SUCCESSFUL
         if skipped:
             status = conv_const.STATUS_PARTIAL
-        conv_status['status'] = status
+        conv_status["status"] = status
 
-        conv_utils.add_conv_status('pool', None, name, conv_status,
-                                   converted_objs)
+        conv_utils.add_conv_status(
+            "pool",
+            None,
+            name,
+            conv_status,
+            converted_objs,
+            yaml.dump(f5_pool))
 
-    def convert_for_pg(self, pg_dict, pool_obj, name, tenant, avi_config,
-                       cloud_ref):
+    def convert_for_pg(self, pg_dict, pool_obj, name,
+                       tenant, avi_config, cloud_ref):
         """
         Creates a pool group object
         :param pg_dict: priority wise sorted dict of pools
         :param pool_obj: Converted f5 pool object
         :param name: name of the pool
         :param tenant: tenant name for tenant reference
         :param avi_config: Avi config to add temporary labels
         :return:
         """
         pg_members = []
         pools = []
         for priority in pg_dict:
             priority_pool = copy.deepcopy(pool_obj)
-            priority_pool['servers'] = pg_dict[priority]
+            priority_pool["servers"] = pg_dict[priority]
             priority_pool_ref = '%s-%s' % (name, priority)
             # Added prefix for objects
             if self.prefix:
                 priority_pool_ref = self.prefix + '-' + priority_pool_ref
-            priority_pool['name'] = priority_pool_ref
+            priority_pool["name"] = priority_pool_ref
             pools.append(priority_pool)
             if priority_pool_ref:
                 member = {
-                    'pool_ref': conv_utils.get_object_ref(
-                        priority_pool_ref, 'pool', tenant=tenant,
+                    "pool_ref": conv_utils.get_object_ref(
+                        priority_pool_ref,
+                        "pool",
+                        tenant=tenant,
                         cloud_name=cloud_ref),
-                    'priority_label': priority
+                    "priority_label": priority,
                 }
                 pg_members.append(member)
         # Added prefix for objects
         if self.prefix:
             name = self.prefix + "-" + name
         pg_obj = {
-            'name': name,
-            'members': pg_members,
-            'cloud_ref': conv_utils.get_object_ref(cloud_ref, 'cloud')
-        }
+            "name": name,
+            "members": pg_members,
+            "cloud_ref": conv_utils.get_object_ref(
+                cloud_ref,
+                "cloud")}
 
-        pg_obj['tenant_ref'] = conv_utils.get_object_ref(tenant, 'tenant')
-        converted_objs = {
-            'pools': pools,
-            'pg_obj': [pg_obj]
-        }
+        pg_obj["tenant_ref"] = conv_utils.get_object_ref(tenant, "tenant")
+        converted_objs = {"pools": pools, "pg_obj": [pg_obj]}
         return converted_objs
 
 
 class PoolConfigConvV11(PoolConfigConv):
+    '''
+    Pool convertersion for v11 version
+    '''
+
     def __init__(self, f5_pool_attributes, prefix):
         """
 
         :param f5_pool_attributes: f5 pool attributes from yaml file
         :param prefix: prefix for objects
         """
-        self.supported_attr = f5_pool_attributes['Pool_supported_attr']
-        self.supported_attributes = f5_pool_attributes[
-            'Pool_supported_attr_convert_servers_config']
-        self.ignore_for_val = f5_pool_attributes['Pool_ignore_val']
+        self.supported_attr = f5_pool_attributes["Pool_supported_attr"]
+        self.supported_attributes = f5_pool_attributes["Pool_supported_attr_convert_servers_config"]
         # Added prefix for objects
         self.prefix = prefix
 
-    def convert_pool(self, pool_name, f5_config, avi_config, user_ignore,
-                     tenant_ref, cloud_ref, merge_object_mapping, sys_dict,
-                     vrf=None, segroup=None):
+    def convert_pool(
+            self,
+            pool_name,
+            f5_config,
+            avi_config,
+            user_ignore,
+            tenant_ref,
+            cloud_ref,
+            merge_object_mapping,
+            sys_dict,
+            vrf=None,
+            segroup=None):
         """
 
         :param pool_name: name of the pool
         :param f5_config: parsed f5 config dict
         :param avi_config: dict for avi conversion
         :param user_ignore: Ignore config defined by user
         :param tenant_ref: tenant of which output to  converted
         :param cloud_ref: cloud of which output to converted
         :param merge_object_mapping: flag for merge object
         :param sys_dict: baseline dict
         :return:
         """
         converted_objs = {}
         nodes = f5_config.get("node", {})
-        f5_pool = f5_config['pool'][pool_name]
-        monitor_config = avi_config['HealthMonitor']
-        servers, member_skipped_config, limits, skipped_servers = \
-            self.convert_servers_config(f5_pool.get("members", {}), nodes,
-                                        avi_config, cloud_ref)
+        f5_pool = f5_config["pool"][pool_name]
+        monitor_config = avi_config["HealthMonitor"]
+        servers, member_skipped_config, limits, skipped_servers = self.convert_servers_config(
+            f5_pool.get("members", {}), nodes, avi_config, cloud_ref)
         sd_action = f5_pool.get("service-down-action", "")
         pd_action = conv_utils.get_avi_pool_down_action(sd_action)
         lb_method = f5_pool.get("load-balancing-mode", None)
         lb_algorithm = self.get_avi_lb_algorithm(lb_method)
-        desc = f5_pool.get('description', None)
-        ramp_time = f5_pool.get('slow-ramp-time', None)
-        pool_obj = super(PoolConfigConvV11, self).create_pool_object(
-            pool_name, desc, servers, pd_action, lb_algorithm, ramp_time,
-            limits, tenant_ref, cloud_ref)
+        desc = f5_pool.get("description", None)
+        ramp_time = f5_pool.get("slow-ramp-time", None)
+        pool_obj = super(
+            PoolConfigConvV11,
+            self).create_pool_object(
+            pool_name,
+            desc,
+            servers,
+            pd_action,
+            lb_algorithm,
+            ramp_time,
+            limits,
+            tenant_ref,
+            cloud_ref)
         # if length of servers > 400 take only 400 servers
         status_flag = False
         if len(servers) > 400:
             servers = servers[0:400]
             status_flag = True
         tenant, name = conv_utils.get_tenant_ref(pool_name)
         tenant_name = tenant
         if tenant_ref:
             tenant = tenant_ref
-        num_retries = f5_pool.get('reselect-tries', None)
+        num_retries = f5_pool.get("reselect-tries", None)
         if num_retries:
             server_reselect = {
                 "retry_nonidempotent": False,
                 "svr_resp_code": {
-                    "resp_code_block": ["HTTP_RSP_4XX", "HTTP_RSP_5XX"]
-                },
+                    "resp_code_block": [
+                        "HTTP_RSP_4XX",
+                        "HTTP_RSP_5XX"]},
                 "num_retries": num_retries,
-                "enabled": True
+                "enabled": True,
             }
-            pool_obj['server_reselect'] = server_reselect
+            pool_obj["server_reselect"] = server_reselect
         monitor_names = f5_pool.get("monitor", None)
         skipped_monitors = []
         if monitor_names:
-            skipped_monitors, monitor_refs = super(
-                PoolConfigConvV11, self).get_monitor_refs(
-                monitor_names, monitor_config, pool_name, tenant,
-                merge_object_mapping, sys_dict['HealthMonitor'])
+            skipped_monitors, monitor_refs = super(PoolConfigConvV11, self).get_monitor_refs(
+                monitor_names, monitor_config, pool_name, tenant, merge_object_mapping, sys_dict[
+                    "HealthMonitor"]
+            )
             pool_obj["health_monitor_refs"] = list(set(monitor_refs))
         # Adding vrf context ref to pool obj
-        vrf_config = avi_config['VrfContext']
-        members = f5_pool.get('members')
-        address = (isinstance(members, dict) and members.get(list(members.keys())[
-                  0]) and isinstance(members[list(members.keys())[0]], dict)) and \
-                  members[list(members.keys())[0]].get('address') or isinstance(
-                  members, str) and members.split(' ')[0] or None if members \
-                  else None
+        vrf_config = avi_config["VrfContext"]
+        members = f5_pool.get("members")
+        address = (
+            (isinstance(members, dict) and members.get(list(members.keys())
+             [0]) and isinstance(members[list(members.keys())[0]], dict))
+            and members[list(members.keys())[0]].get("address")
+            or isinstance(members, str)
+            and members.split(" ")[0]
+            or None
+            if members
+            else None
+        )
         if vrf:
-            vrf_ref = conv_utils.get_object_ref(vrf, 'vrfcontext',
-                                                tenant=tenant_name,
-                                                cloud_name=cloud_ref)
+            vrf_ref = conv_utils.get_object_ref(
+                vrf, "vrfcontext", tenant=tenant_name, cloud_name=cloud_ref)
         else:
-            vrf_ref = conv_utils.get_vrf_context_ref(address, vrf_config, 'pool',
-                                                 pool_name, cloud_ref)
+            vrf_ref = conv_utils.get_vrf_context_ref(
+                address, vrf_config, "pool", pool_name, cloud_ref)
         if not vrf_ref:
-            vrf_ref = conv_utils.get_object_ref("global", 'vrfcontext',
-                                                tenant=tenant_name,
-                                                cloud_name=cloud_ref)
+            vrf_ref = conv_utils.get_object_ref(
+                "global", "vrfcontext", tenant=tenant_name, cloud_name=cloud_ref)
         if vrf_ref:
             pool_obj["vrf_ref"] = vrf_ref
 
-        skipped_attr = [key for key in f5_pool.keys() if
-                        key not in self.supported_attr]
-        for attr in self.ignore_for_val:
-            ignore_val = self.ignore_for_val[attr]
-            actual_val = f5_pool.get(attr, None)
-            if not actual_val:
-                continue
-            if isinstance(ignore_val, str) and actual_val == ignore_val:
-                skipped_attr.remove(attr)
-            elif isinstance(ignore_val, list) and actual_val in ignore_val:
-                skipped_attr.remove(attr)
-        is_pg, pg_dict = self.check_for_pool_group(servers)
+        skipped_attr = [
+            key for key in f5_pool.keys() if key not in self.supported_attr]
+        is_pg = False
+        pg_dict = None
+        if f5_pool.get("min-active-members"):
+            is_pg, pg_dict = self.check_for_pool_group(servers)
         if is_pg:
             converted_objs = self.convert_for_pg(
                 pg_dict, pool_obj, name, tenant, avi_config, cloud_ref)
         else:
-            converted_objs['pools'] = [pool_obj]
+            converted_objs["pools"] = [pool_obj]
         # Flag to make status partial for pool.
         if status_flag:
-            skipped_attr.append('Skipped: length of servers more than 400')
-        super(PoolConfigConvV11, self).add_status(
-            pool_name, skipped_attr, member_skipped_config, skipped_monitors,
-            converted_objs, user_ignore, skipped_servers)
+            skipped_attr.append("Skipped: length of servers more than 400")
+        super(
+            PoolConfigConvV11,
+            self).add_status(
+            pool_name,
+            skipped_attr,
+            member_skipped_config,
+            skipped_monitors,
+            converted_objs,
+            user_ignore,
+            skipped_servers,
+            f5_pool)
 
         return converted_objs
 
     def get_avi_lb_algorithm(self, f5_algorithm):
         """
         Converts f5 LB algorithm to equivalent avi LB algorithm
         :param f5_algorithm: f5 algorithm name
         :return: Avi LB algorithm enum value
         """
         avi_algorithm = None
         if not f5_algorithm or f5_algorithm in ["ratio-node", "ratio-member"]:
             avi_algorithm = "LB_ALGORITHM_ROUND_ROBIN"
-        elif f5_algorithm in ["least-connections-member",
-                              "least-connections-node", "least-sessions",
-                              "weighted-least-connections-member",
-                              "ratio-least-connections-member",
-                              "ratio-least-connections-node",
-                              "weighted-least-connections-node"]:
+        elif f5_algorithm in [
+            "least-connections-member",
+            "least-connections-node",
+            "least-sessions",
+            "weighted-least-connections-member",
+            "ratio-least-connections-member",
+            "ratio-least-connections-node",
+            "weighted-least-connections-node",
+        ]:
             avi_algorithm = "LB_ALGORITHM_LEAST_CONNECTIONS"
         elif f5_algorithm in ["fastest-node", "fastest-app-response"]:
             avi_algorithm = "LB_ALGORITHM_FASTEST_RESPONSE"
-        elif f5_algorithm in ["dynamic-ratio-node", "observed-member",
-                              "predictive-node", "dynamic-ratio-member",
-                              "predictive-member", "observed-node"]:
+        elif f5_algorithm in [
+            "dynamic-ratio-node",
+            "observed-member",
+            "predictive-node",
+            "dynamic-ratio-member",
+            "predictive-member",
+            "observed-node",
+        ]:
             avi_algorithm = "LB_ALGORITHM_LEAST_LOAD"
         return avi_algorithm
 
-    def convert_servers_config(self, servers_config, nodes, avi_config,
-                               cloud_ref):
+    def convert_servers_config(
+            self, servers_config, nodes, avi_config, cloud_ref):
         """
         Converts the config of servers in the pool
         :param servers_config: F5 servers config for particular pool
         :param nodes: F5 node config to resolve IP of the server
         :return: List of Avi server configs
         """
         server_list = []
         skipped_list = []
         rate_limit = []
         connection_limit = []
         server_skipped = []
         for server_name in servers_config.keys():
             hostname = None
             server = servers_config[server_name]
-            parts = server_name.split(':')
+            parts = server_name.split(":")
             node = nodes.get(parts[0], None)
             if node and node.get("address"):
-                hostname = parts[0].split('/')[-1]
-                if '%' in node["address"]:
-                    ip_addr, vrf = node["address"].split('%')
+                hostname = parts[0].split("/")[-1]
+                if "%" in node["address"]:
+                    ip_addr, vrf = node["address"].split("%")
                     conv_utils.add_vrf(avi_config, vrf, cloud_ref)
                 else:
                     ip_addr = node["address"]
             else:
-                if '%' in parts[0]:
-                    ip_addr, vrf = parts[0].split('%')
+                if "%" in parts[0]:
+                    ip_addr, vrf = parts[0].split("%")
                     conv_utils.add_vrf(avi_config, vrf, cloud_ref)
                 else:
                     ip_addr = parts[0]
-            description = server.get('description', '')
+            description = server.get("description", "")
             port = parts[1] if len(parts) == 2 else conv_const.DEFAULT_PORT
             orig_port = port
             if not port.isdigit():
                 port = conv_utils.get_port_by_protocol(port)
             if not port:
-                LOG.warning("Skipped: Server %s with ip %s has" % (server_name,
-                            ip_addr) + ((" non protocol port %s" % orig_port)
-                            if orig_port else " no port"))
+                LOG.warning(
+                    "Skipped: Server %s with ip %s has",
+                    server_name, ip_addr
+                    + ((" non protocol port %s",
+                        orig_port) if orig_port else " no port")
+                )
                 server_skipped.append(server_name)
                 continue
-            if port == '0':
+            if port == "0":
                 port = ""
             enabled = True
-            state = server.get("state", 'enabled')
-            session = server.get("session", 'enabled')
-            if state == "user-down" or session == 'user-disabled':
+            state = server.get("state", "enabled")
+            session = server.get("session", "enabled")
+            if state == "user-down" or session == "user-disabled":
                 enabled = False
-            priority = server.get('priority-group', None)
+            priority = server.get("priority-group", None)
 
             ip_addr = ip_addr.strip()
-            matches = re.findall('^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$',
-                                 ip_addr)
+            matches = re.findall(
+                "^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$", ip_addr)
             if not matches:
-                LOG.warning('Avi does not support IPv6. Replace 1.1.1.1 '
-                            'ipv4 for : %s' % ip_addr)
-                ip_addr = '1.1.1.1'
+                LOG.warning(
+                    "Avi does not support IPv6. Replace 1.1.1.1 "
+                    "ipv4 for : %s",
+                    ip_addr)
+                ip_addr = "1.1.1.1"
 
             server_obj = {
-                'ip': {
-                    'addr': ip_addr,
-                    'type': 'V4'
-                },
-                'enabled': enabled,
-                'description': description,
-                'port': port
-            }
+                "ip": {
+                    "addr": ip_addr,
+                    "type": "V4"},
+                "enabled": enabled,
+                "description": description,
+                "port": port}
 
             if hostname:
-                server_obj['hostname'] = hostname
+                server_obj["hostname"] = hostname
 
             if priority:
-                server_obj['priority'] = priority
+                server_obj["priority"] = priority
             ratio = server.get("ratio", None)
             if ratio:
                 server_obj["ratio"] = ratio
-            r_lim = int(server.get("rate-limit", '0'))
+            r_lim = int(server.get("rate-limit", "0"))
             if r_lim > 0:
                 rate_limit.append(r_lim)
-            c_lim = int(server.get("connection-limit", '0'))
+            c_lim = int(server.get("connection-limit", "0"))
             if c_lim > 0:
                 connection_limit.append(c_lim)
             server_obj_list = [
-                s for s in server_list if s['ip']['addr'] ==
-                server_obj['ip']['addr'] and
-                ('port' in s and 'port' in server_obj)and
-                (s['port'] == server_obj['port'])]
+                s
+                for s in server_list
+                if s["ip"]["addr"] == server_obj["ip"]["addr"]
+                and ("port" in s and "port" in server_obj)
+                and (s["port"] == server_obj["port"])
+            ]
             if server_obj_list:
-                LOG.warning('Skipped duplicate server %s' % ip_addr)
+                LOG.warning("Skipped duplicate server %s", ip_addr)
                 continue
 
             server_list.append(server_obj)
-            skipped = [key for key in server.keys()
-                       if key not in self.supported_attributes]
+            skipped = [key for key in server.keys(
+            ) if key not in self.supported_attributes]
             if skipped:
                 skipped_list.append({server_name: skipped})
-        limits = dict()
+        limits = {}
         if rate_limit:
-            limits['rate_limit'] = min(rate_limit)
+            limits["rate_limit"] = min(rate_limit)
         if connection_limit:
-            limits['connection_limit'] = min(connection_limit)
+            limits["connection_limit"] = min(connection_limit)
         return server_list, skipped_list, limits, server_skipped
 
 
 class PoolConfigConvV10(PoolConfigConv):
+    '''
+    Pool conversion for v10 version
+    '''
+
     def __init__(self, f5_pool_attributes, prefix):
         """
 
         :param f5_pool_attributes: f5 pool attributes from yaml file
         :param prefix: prefix for objects
         """
-        self.supported_attr = f5_pool_attributes['Pool_supported_attr_1']
-        self.supported_attributes = f5_pool_attributes['Pool_supported_attr_2']
-        self.ignore_for_val = f5_pool_attributes['Pool_ignore_val']
+        self.supported_attr = f5_pool_attributes["Pool_supported_attr_1"]
+        self.supported_attributes = f5_pool_attributes["Pool_supported_attr_2"]
         # Added prefix for objects
         self.prefix = prefix
 
-    def convert_pool(self, pool_name, f5_config, avi_config, user_ignore,
-                     tenant_ref, cloud_ref, merge_object_mapping, sys_dict,
-                     vrf=None, segroup=None):
-
+    def convert_pool(
+            self,
+            pool_name,
+            f5_config,
+            avi_config,
+            user_ignore,
+            tenant_ref,
+            cloud_ref,
+            merge_object_mapping,
+            sys_dict,
+            vrf=None,
+            segroup=None):
         """
-       :param pool_name: name of the pool
-       :param f5_config: parsed f5 config dict
-       :param avi_config: dict for avi conversion
-       :param user_ignore: Ignore config defined by user
-       :param tenant_ref: tenant of which output to  converted
-       :param cloud_ref: cloud of which output to converted
-       :param merge_object_mapping: flag for merge object
-       :param sys_dict: baseline dict
-       :return:
+        :param pool_name: name of the pool
+        :param f5_config: parsed f5 config dict
+        :param avi_config: dict for avi conversion
+        :param user_ignore: Ignore config defined by user
+        :param tenant_ref: tenant of which output to  converted
+        :param cloud_ref: cloud of which output to converted
+        :param merge_object_mapping: flag for merge object
+        :param sys_dict: baseline dict
+        :return:
         """
         nodes = f5_config.pop("node", {})
-        f5_pool = f5_config['pool'][pool_name]
-        monitor_config = avi_config['HealthMonitor']
-        servers, member_skipped_config, limits, skipped_servers = \
-            self.convert_servers_config(f5_pool.get("members", {}), nodes,
-                                        avi_config, cloud_ref)
+        f5_pool = f5_config["pool"][pool_name]
+        monitor_config = avi_config["HealthMonitor"]
+        servers, member_skipped_config, limits, skipped_servers = self.convert_servers_config(
+            f5_pool.get("members", {}), nodes, avi_config, cloud_ref)
         sd_action = f5_pool.get("action on svcdown", "")
         pd_action = conv_utils.get_avi_pool_down_action(sd_action)
         lb_method = f5_pool.get("lb method", None)
         lb_algorithm = self.get_avi_lb_algorithm(lb_method)
-        desc = f5_pool.get('description', None)
-        ramp_time = f5_pool.get('slow ramp time', None)
+        desc = f5_pool.get("description", None)
+        ramp_time = f5_pool.get("slow ramp time", None)
         # if length of servers > 400 take only 400 servers.
         status_flag = False
         if len(servers) > 400:
             servers = servers[0:400]
             status_flag = True
-        pool_obj = super(PoolConfigConvV10, self).create_pool_object(
-            pool_name, desc, servers, pd_action, lb_algorithm, ramp_time,
-            limits, tenant_ref, cloud_ref)
+        pool_obj = super(
+            PoolConfigConvV10,
+            self).create_pool_object(
+            pool_name,
+            desc,
+            servers,
+            pd_action,
+            lb_algorithm,
+            ramp_time,
+            limits,
+            tenant_ref,
+            cloud_ref)
         monitor_names = f5_pool.get("monitor", None)
         skipped_monitors = []
         if monitor_names:
             skipped_monitors, monitor_refs = super(
                 PoolConfigConvV10, self).get_monitor_refs(
-                monitor_names, monitor_config, pool_name, tenant_ref,
-                merge_object_mapping, sys_dict['HealthMonitor'])
+                monitor_names, monitor_config, pool_name, tenant_ref, merge_object_mapping,
+                sys_dict["HealthMonitor"])
             pool_obj["health_monitor_refs"] = list(set(monitor_refs))
         # Adding vrf context ref to pool obj
-        vrf_config = avi_config['VrfContext']
-        members = f5_pool.get('members')
-        address = (isinstance(members, dict) and members.get(list(members.keys())[
-                  0]) and isinstance(members[list(members.keys())[0]], dict)) and \
-                  members[list(members.keys())[0]].get('address') or isinstance(
-                  members, str) and members.split(' ')[0] or None if members \
-                  else None
+        vrf_config = avi_config["VrfContext"]
+        members = f5_pool.get("members")
+        address = (
+            (isinstance(members, dict) and members.get(list(members.keys())
+             [0]) and isinstance(members[list(members.keys())[0]], dict))
+            and members[list(members.keys())[0]].get("address")
+            or isinstance(members, str)
+            and members.split(" ")[0]
+            or None
+            if members
+            else None
+        )
         if vrf:
-            vrf_ref = conv_utils.get_object_ref(vrf, 'vrfcontext',
-                                                tenant=tenant_ref,
-                                                cloud_name=cloud_ref)
+            vrf_ref = conv_utils.get_object_ref(
+                vrf, "vrfcontext", tenant=tenant_ref, cloud_name=cloud_ref)
         else:
-            vrf_ref = conv_utils.get_vrf_context_ref(address, vrf_config, 'pool',
-                                                    pool_name, cloud_ref)
+            vrf_ref = conv_utils.get_vrf_context_ref(
+                address, vrf_config, "pool", pool_name, cloud_ref)
 
         if vrf_ref:
             pool_obj["vrf_ref"] = vrf_ref
-        num_retries = f5_pool.get('reselect tries', None)
+        num_retries = f5_pool.get("reselect tries", None)
         if num_retries:
             server_reselect = {
                 "retry_nonidempotent": False,
                 "svr_resp_code": {
-                    "resp_code_block": ["HTTP_RSP_4XX", "HTTP_RSP_5XX"]
-                },
+                    "resp_code_block": [
+                        "HTTP_RSP_4XX",
+                        "HTTP_RSP_5XX"]},
                 "num_retries": num_retries,
-                "enabled": True
+                "enabled": True,
             }
-            pool_obj['server_reselect'] = server_reselect
+            pool_obj["server_reselect"] = server_reselect
 
-        skipped_attr = [key for key in f5_pool.keys() if
-                        key not in self.supported_attr]
-        for attr in self.ignore_for_val:
-            ignore_val = self.ignore_for_val[attr]
-            actual_val = f5_pool.get(attr, None)
-            if not actual_val:
-                continue
-            if isinstance(ignore_val, str) and actual_val == ignore_val:
-                skipped_attr.remove(attr)
-            elif isinstance(ignore_val, list) and actual_val in ignore_val:
-                skipped_attr.remove(attr)
-        is_pg, pg_dict = self.check_for_pool_group(servers)
-        converted_objs = dict()
+        skipped_attr = [
+            key for key in f5_pool.keys() if key not in self.supported_attr]
+        is_pg = False
+        pg_dict = None
+        if f5_pool.get("min-active-members"):
+            is_pg, pg_dict = self.check_for_pool_group(servers)
+        converted_objs = {}
         tenant, name = conv_utils.get_tenant_ref(pool_name)
         if is_pg:
-            converted_objs = self.convert_for_pg(pg_dict,
-                                                 pool_obj, name,
-                                                 tenant, avi_config, cloud_ref)
+            converted_objs = self.convert_for_pg(
+                pg_dict, pool_obj, name, tenant, avi_config, cloud_ref)
         else:
-            converted_objs['pools'] = [pool_obj]
+            converted_objs["pools"] = [pool_obj]
         # Flag to make status partial for pool.
         if status_flag:
-            skipped_attr.append('Skipped: length of servers more than 400')
-        super(PoolConfigConvV10, self).add_status(
-            pool_name, skipped_attr, member_skipped_config, skipped_monitors,
-            converted_objs, user_ignore, skipped_servers)
+            skipped_attr.append("Skipped: length of servers more than 400")
+        super(
+            PoolConfigConvV10,
+            self).add_status(
+            pool_name,
+            skipped_attr,
+            member_skipped_config,
+            skipped_monitors,
+            converted_objs,
+            user_ignore,
+            skipped_servers,
+            f5_pool)
         return converted_objs
 
     def get_avi_lb_algorithm(self, f5_algorithm):
         """
         Converts f5 LB algorithm to equivalent avi LB algorithm
         :param f5_algorithm: f5 algorithm name
         :return: Avi LB algorithm enum value
         """
         avi_algorithm = None
         if not f5_algorithm or f5_algorithm in ["ratio", "member ratio"]:
             avi_algorithm = "LB_ALGORITHM_ROUND_ROBIN"
-        elif f5_algorithm in ["member least conn", "least conn", "l3 addr",
-                              "weighted least conn member", "least sessions",
-                              "weighted least conn node addr"]:
+        elif f5_algorithm in [
+            "member least conn",
+            "least conn",
+            "l3 addr",
+            "weighted least conn member",
+            "least sessions",
+            "weighted least conn node addr",
+        ]:
             avi_algorithm = "LB_ALGORITHM_LEAST_CONNECTIONS"
         elif f5_algorithm in ["fastest", "fastest app resp"]:
             avi_algorithm = "LB_ALGORITHM_FASTEST_RESPONSE"
         elif f5_algorithm in ["dynamic ratio", "member observed", "predictive",
-                              "member predictive", "observed",
-                              "member dynamic ratio"]:
+                              "member predictive", "observed", "member dynamic ratio"]:
             avi_algorithm = "LB_ALGORITHM_LEAST_LOAD"
         return avi_algorithm
 
-    def convert_servers_config(self, servers_config, nodes, avi_config,
-                               cloud_ref):
+    def convert_servers_config(
+            self, servers_config, nodes, avi_config, cloud_ref):
         """
         Converts the config of servers in the pool
         :param servers_config: F5 servers config for particular pool
         :return: List of Avi server configs
         """
         server_list = []
         skipped_list = []
         connection_limit = []
         server_skipped = []
         if isinstance(servers_config, str):
-            servers_config = {servers_config.split(' ')[0]: None}
+            servers_config = {servers_config.split(" ")[0]: None}
         for server_name in servers_config.keys():
             skipped = None
             server = servers_config[server_name]
-            parts = server_name.split(':')
+            parts = server_name.split(":")
             node = nodes.get(parts[0], None)
-            if node and '%' in node.get("address", ''):
-                ip_addr, vrf = node["address"].split('%')
+            if node and "%" in node.get("address", ""):
+                ip_addr, vrf = node["address"].split("%")
                 conv_utils.add_vrf(avi_config, vrf, cloud_ref)
             else:
-                if '%' in parts[0]:
-                    ip_addr, vrf = parts[0].split('%')
+                if "%" in parts[0]:
+                    ip_addr, vrf = parts[0].split("%")
                     conv_utils.add_vrf(avi_config, vrf, cloud_ref)
                 else:
                     ip_addr = parts[0]
             port = parts[1] if len(parts) == 2 else conv_const.DEFAULT_PORT
             orig_port = port
             if not port.isdigit():
                 port = conv_utils.get_port_by_protocol(port)
             if not port:
-                LOG.warning("Skipped: Server %s with ip %s has" % (server_name,
-                            ip_addr) + ((" non protocol port %s" % orig_port)
-                            if orig_port else " no port"))
+                LOG.warning(
+                    "Skipped: Server %s with ip %s has",
+                    server_name, ip_addr
+                    + ((" non protocol port %s",
+                        orig_port) if orig_port else " no port")
+                )
                 server_skipped.append(server_name)
                 continue
             enabled = True
-            state = 'enabled'
+            state = "enabled"
             ratio = None
             description = None
             priority = None
             if server:
-                state = server.get("session", 'enabled')
-                skipped = [key for key in server.keys()
-                           if key not in self.supported_attributes]
+                state = server.get("session", "enabled")
+                skipped = [key for key in server.keys(
+                ) if key not in self.supported_attributes]
                 ratio = server.get("ratio", None)
-                description = server.get('description', None)
-                if state == "user disabled" or 'down' in server.keys():
+                description = server.get("description", None)
+                if state == "user disabled" or "down" in server.keys():
                     enabled = False
-                c_lim = int(server.get("limit", '0'))
+                c_lim = int(server.get("limit", "0"))
                 if c_lim > 0:
                     connection_limit.append(c_lim)
-                priority = server.get('priority', None)
+                priority = server.get("priority", None)
             server_obj = {
-                'ip': {
-                    'addr': ip_addr,
-                    'type': 'V4'
-                },
-                'enabled': enabled,
-                'description': description,
-                'port': port
-            }
+                "ip": {
+                    "addr": ip_addr,
+                    "type": "V4"},
+                "enabled": enabled,
+                "description": description,
+                "port": port}
 
             if priority:
-                server_obj['priority'] = priority
+                server_obj["priority"] = priority
             if ratio:
                 server_obj["ratio"] = ratio
             server_list.append(server_obj)
             if skipped:
                 skipped_list.append({server_name: skipped})
-        limits = dict()
+        limits = {}
         if connection_limit:
-            limits['connection_limit'] = min(connection_limit)
+            limits["connection_limit"] = min(connection_limit)
         return server_list, skipped_list, limits, server_skipped
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/profile_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/profile_converter.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,87 +1,94 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 import copy
 import logging
 import os
-import yaml
+
 import avi.migrationtools.f5_converter.converter_constants as final
-from avi.migrationtools.f5_converter.conversion_util import F5Util
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
-
+from avi.migrationtools.f5_converter.conversion_util import F5Util
 LOG = logging.getLogger(__name__)
-ssl_count = {'count': 0}
+ssl_count = {"count": 0}
 # Creating f5 object for util library.
 conv_utils = F5Util()
-
+ssl_profile_with_sni_parent = []
+ssl_profile_with_sni_child = {}
 
 class ProfileConfigConv(object):
+    '''
+    Profile Conversion Class
+    '''
     @classmethod
-    def get_instance(cls, version, f5_profile_attributes,
-                     object_merge_check, prefix, keypassphrase, skip_pki=False,
-                     distinct_app_profile=False):
+    def get_instance(
+        cls, version, f5_profile_attributes, object_merge_check, prefix,
+        keypassphrase, skip_pki=False, distinct_app_profile=False
+    ):
         """
 
         :param version:  version of f5 instance
         :param f5_profile_attributes: yaml attribute file for object
         :param object_merge_check: Flag for object merge
         :param prefix: prefix for objects
         :param keypassphrase: path of keypassphrase
         :param skip_pki: PKI profile migration needs to be skipped
         :param distinct_app_profile: Merge duplicates needs to be slipped
         :return: object of respective f5 version object.
         """
-        f5_profile_attributes = f5_profile_attributes
-        if version == '10':
+        if version == "10":
             return ProfileConfigConvV10(
                 f5_profile_attributes, object_merge_check, prefix,
                 keypassphrase, skip_pki, distinct_app_profile)
-        if version in ['11', '12']:
+        if version in ["11", "12"]:
             return ProfileConfigConvV11(
                 f5_profile_attributes, object_merge_check, prefix,
                 keypassphrase, skip_pki, distinct_app_profile)
 
     default_key = None
 
-    ciphers = 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-' \
-              'ECDSA-AES256-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-' \
-              'AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:AES128-GCM-SHA256:' \
-              'AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:' \
-              'AES256-SHA:DES-CBC3-SHA'
+    ciphers = (
+        "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-"
+        "ECDSA-AES256-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-"
+        "AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:AES128-GCM-SHA256:"
+        "AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:"
+        "AES256-SHA:DES-CBC3-SHA"
+    )
 
     def convert_profile(self, profile, key, f5_config, profile_config,
                         avi_config, input_dir, user_ignore, tenant_ref,
                         key_and_cert_mapping_list, merge_object_mapping,
-                        sys_dict):
+                        sys_dict,migrated_cipher,migrated_cipher_group):
         pass
 
     def convert(self, f5_config, avi_config, input_dir, user_ignore,
-                tenant_ref, cloud_ref, merge_object_mapping, sys_dict):
+                tenant_ref, cloud_ref, merge_object_mapping, sys_dict
+                ,migrated_cipher,migrated_cipher_group):
         """
 
         :param f5_config:  parsed f5 config dict.
         :param avi_config: avi config dict for converted avi conversion.
         :param input_dir: Location of cert and external monitor script files
         :param user_ignore: Ignore config defined by user
         :param tenant_ref: tenant ref for avi objects
         :param cloud_ref: cloud ref for avi objects
         :param merge_object_mapping: merged object dict for merging objects
         :param sys_dict: baseline objects
         :return:
         """
         profile_config = f5_config.get("profile", {})
         avi_config["StringGroup"] = []
-        avi_config['HTTPPolicySet'] = []
-        avi_config['OneConnect'] = []
+        avi_config["HTTPPolicySet"] = []
+        avi_config["OneConnect"] = []
         key_and_cert_mapping_list = []
         persistence = f5_config.get("persistence", None)
         if not persistence:
-            f5_config['persistence'] = {}
-        avi_config['UnsupportedProfiles'] = []
+            f5_config["persistence"] = {}
+        avi_config["UnsupportedProfiles"] = []
         print("\nConverting Profiles ...")
         # Added variable to get total object count.
         progressbar_count = 0
         total_size = len(profile_config.keys())
         for key in profile_config.keys():
             progressbar_count += 1
             profile_type = None
@@ -91,90 +98,118 @@
                 tenant, name = conv_utils.get_tenant_ref(name)
                 if tenant_ref:
                     tenant = tenant_ref
                 if profile_type not in self.supported_types:
                     msg = ("Skipped not supported profile: %s of type: %s"
                            % (name, profile_type))
                     LOG.warning(msg)
-                    conv_utils.add_status_row('profile', profile_type, name,
-                                              final.STATUS_SKIPPED, msg)
-                    avi_config['UnsupportedProfiles'].append(name)
+                    conv_utils.add_status_row(
+                        "profile", profile_type, name, final.STATUS_SKIPPED, msg)
+                    avi_config["UnsupportedProfiles"].append(name)
                     continue
                 # Added prefix for objects
                 if self.prefix:
                     name = self.prefix + '-' + name
-                LOG.debug("Converting profile: %s" % name)
+                LOG.debug("Converting profile: %s", name)
                 profile = profile_config[key]
                 if not profile:
-                    LOG.warn('Empty config for profile %s Skipping the config'
-                             % name)
+                    LOG.warning(
+                        "Empty config for profile %s Skipping the config",
+                        name)
                     conv_utils.add_status_row(
                         'profile', profile_type, name,
                         final.STATUS_NOT_APPLICABLE, 'Empty config')
                     continue
                 # print key, profile
                 profile = self.update_with_default_profile(
                     profile_type, profile, profile_config, name)
-                u_ignore = user_ignore.get('profile', {})
+                u_ignore = user_ignore.get("profile", {})
                 self.convert_profile(
                     profile, key, f5_config, profile_config, avi_config,
                     input_dir, u_ignore, tenant, key_and_cert_mapping_list,
-                    merge_object_mapping, sys_dict)
-                LOG.debug("Conversion successful for profile: %s" % name)
-            except:
-                update_count('error')
-                LOG.error("Failed to convert profile: %s" % key, exc_info=True)
+                    merge_object_mapping, sys_dict,migrated_cipher,migrated_cipher_group)
+                LOG.debug("Conversion successful for profile: %s", name)
+
+            except BaseException:
+                update_count("error")
+                LOG.error("Failed to convert profile: %s", key, exc_info=True)
                 if name:
-                    conv_utils.add_status_row('profile', profile_type, name,
-                                              final.STATUS_ERROR)
+                    conv_utils.add_status_row(
+                        "profile", profile_type, name, final.STATUS_ERROR)
                 else:
-                    conv_utils.add_status_row('profile', key, key,
-                                              final.STATUS_ERROR)
+                    conv_utils.add_status_row(
+                        "profile", key, key, final.STATUS_ERROR)
             # Added call to check progress.
             msg = "Profile conversion started..."
-            conv_utils.print_progress_bar(progressbar_count, total_size, msg,
-                                          prefix='Progress', suffix='')
+            conv_utils.print_progress_bar(
+                progressbar_count,
+                total_size,
+                msg,
+                prefix="Progress",
+                suffix="")
         count = len(avi_config["SSLProfile"])
         count += len(avi_config["PKIProfile"])
         count += len(avi_config["ApplicationProfile"])
         count += len(avi_config["NetworkProfile"])
-        LOG.debug("Converted %s profiles" % count)
+        LOG.debug("Converted %s profiles", count)
         f5_config.pop("profile")
         del key_and_cert_mapping_list
 
-    def update_with_default_profile(self, profile_type, profile,
-                                    profile_config, profile_name):
+        if len(merge_object_mapping.get("ssl_profile")) > 1:
+
+            for ssl_index, ssl_parent in enumerate(
+                    ssl_profile_with_sni_parent):
+                merged_ssl_parent = merge_object_mapping["ssl_profile"].get(
+                    ssl_parent)
+                ssl_profile_with_sni_parent[ssl_index] = merged_ssl_parent
+
+            temp_ssl_child = dict((merge_object_mapping["ssl_profile"].get(
+                k), v) for k, v in ssl_profile_with_sni_child.items())
+            ssl_profile_with_sni_child.update(temp_ssl_child)
+
+    def update_with_default_profile(
+            self, profile_type, profile, profile_config, profile_name):
         """
         Profiles can have inheritance used by attribute defaults-from in F5
         configuration this method recursively gets all the attributes from the
         default objects and forms complete object
         :param profile_type: type of profile
         :param profile: currant profile object
         :param profile_config: F5 profile config dict
         :param profile_name: Name of profile
         :return: Complete profile with updated attributes from defaults
         """
         parent_name = profile.get(self.default_key, None)
-        if parent_name and '/' in parent_name:
-            parent_name = parent_name.split('/')[-1]
+        if parent_name and "/" in parent_name:
+            parent_name = parent_name.split("/")[-1]
         if parent_name and profile_name != parent_name:
-            parent_profile = profile_config.get(profile_type + " " +
-                                                parent_name, None)
+            parent_profile = profile_config.get(
+                profile_type + " " + parent_name, None)
             if parent_profile:
                 parent_profile = self.update_with_default_profile(
                     profile_type, parent_profile, profile_config, parent_name)
                 parent_profile = copy.deepcopy(parent_profile)
                 parent_profile.update(profile)
                 profile = parent_profile
         return profile
 
-    def update_key_cert_obj(self, name, key_file_name, cert_file_name,
-                            input_dir, tenant, avi_config, converted_objs,
-                            default_profile_name, key_and_cert_mapping_list,
-                            merge_object_mapping, sys_dict):
+    def update_key_cert_obj(
+            self,
+            name,
+            key_file_name,
+            cert_file_name,
+            input_dir,
+            tenant,
+            avi_config,
+            profile,
+            converted_objs,
+            default_profile_name,
+            key_and_cert_mapping_list,
+            merge_object_mapping,
+            sys_dict):
         """
         This method create the certs if certificate not present at location
         it create placeholder certificate.
         :param name: name of certificate.
         :param key_file_name: name of keyfile of cert
         :param cert_file_name: name of cert file
         :param input_dir: location of cert and key
@@ -184,103 +219,117 @@
         :param default_profile_name: name of default profile name.
         :param key_and_cert_mapping_list: list of key and cert
         :param merge_object_mapping: merged object dict for merging objects
         :param sys_dict: baseline objects
         :return:
         """
 
-        cert_name = [cert['name'] for cert in key_and_cert_mapping_list if
-                     cert['key_file_name'] == key_file_name and
-                     cert['cert_file_name'] == cert_file_name]
+        cert_name = [
+            cert["name"]
+            for cert in key_and_cert_mapping_list
+            if cert["key_file_name"] == key_file_name and cert["cert_file_name"] == cert_file_name
+        ]
 
         if cert_name:
             LOG.warning(
-                'SSL key and Certificate is already exist for %s and %s is %s' %
-                (key_file_name, cert_file_name, cert_name[0]))
+                "SSL key and Certificate is already exist for %s and %s is %s",
+                key_file_name, cert_file_name, cert_name[0])
             return
         folder_path = input_dir + os.path.sep
         key = None
         cert = None
         if key_file_name and cert_file_name:
             # Removed / from key_file_name to get name of file.
-            if '/' in key_file_name:
-                key_file_name = key_file_name.split('/')[-1]
+            if "/" in key_file_name:
+                key_file_name = key_file_name.split("/")[-1]
             # Removed / from cert_file_name to get name of file.
-            if '/' in cert_file_name:
-                cert_file_name = cert_file_name.split('/')[-1]
+            if "/" in cert_file_name:
+                cert_file_name = cert_file_name.split("/")[-1]
             key = conv_utils.upload_file(folder_path + key_file_name)
             cert = conv_utils.upload_file(folder_path + cert_file_name)
 
         is_key_protected = False
         if key:
             # Check kay is passphrase protected or not
             is_key_protected = conv_utils.is_certificate_key_protected(
                 input_dir + os.path.sep + key_file_name)
 
         if cert and key:
             # Flag to check expiry date of certificate. if expired then
             # create placeholder certificate.
-            if not conv_utils.check_certificate_expiry(input_dir,
-                                                       cert_file_name):
+            if not conv_utils.check_certificate_expiry(
+                    input_dir, cert_file_name):
                 cert, key = None, None
 
         key_passphrase = None
         # Get the key passphrase for key_file
         if is_key_protected and self.f5_passphrase_keys:
             key_passphrase = self.f5_passphrase_keys.get(key_file_name, None)
 
         if is_key_protected and not key_passphrase:
             key = None
 
         if not key or not cert:
             key, cert = conv_utils.create_self_signed_cert()
             name = '%s-%s' % (name, final.PLACE_HOLDER_STR)
-            LOG.warning('Create self cerificate and key for : %s' % name)
+            LOG.warning("Create self cerificate and key for : %s", name)
 
         ssl_kc_obj = None
-        if tenant == None:
-            tenant = 'admin'
+        if tenant is None:
+            tenant = "admin"
         if key and cert:
-            cert = {"certificate": cert if type(cert) == str else cert.decode()}
+            cert = {
+                "certificate": cert if isinstance(
+                    cert, str) else cert.decode()}
             ssl_kc_obj = {
-                'name': name,
-                'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant'),
-                'key': key if type(key) == str else key.decode(),
-                'certificate': cert,
-                'type': 'SSL_CERTIFICATE_TYPE_VIRTUALSERVICE'
+                "name": name,
+                "tenant_ref": conv_utils.get_object_ref(tenant, "tenant"),
+                "key": key if isinstance(key, str) else key.decode(),
+                "certificate": cert,
+                "type": "SSL_CERTIFICATE_TYPE_VIRTUALSERVICE",
             }
+        if profile.get("ocsp-stapling") == "enabled":
+            ssl_kc_obj["enable_ocsp_stapling"] = True
         if key_passphrase:
-            ssl_kc_obj['key_passphrase'] = key_passphrase
+            ssl_kc_obj["key_passphrase"] = key_passphrase
         if ssl_kc_obj:
-            cert_obj = {'key_file_name': key_file_name,
-                        'cert_file_name': cert_file_name,
-                        'name': name
-                        }
+            cert_obj = {
+                "key_file_name": key_file_name,
+                "cert_file_name": cert_file_name,
+                "name": name}
             key_and_cert_mapping_list.append(cert_obj)
-            LOG.info('Added new SSL key and certificate for %s' % name)
+            LOG.info("Added new SSL key and certificate for %s", name)
 
         if ssl_kc_obj:
             if self.object_merge_check:
-                if final.PLACE_HOLDER_STR not in ssl_kc_obj['name']:
-                    conv_utils.update_skip_duplicates(ssl_kc_obj,
-                                                      avi_config['SSLKeyAndCertificate'], 'ssl_cert_key',
-                                                      converted_objs, name, default_profile_name,
-                                                      merge_object_mapping, None, self.prefix, sys_dict[
-                                                          'SSLKeyAndCertificate'])
+                if final.PLACE_HOLDER_STR not in ssl_kc_obj["name"]:
+                    conv_utils.update_skip_duplicates(
+                        ssl_kc_obj,
+                        avi_config["SSLKeyAndCertificate"],
+                        "ssl_cert_key",
+                        converted_objs,
+                        name,
+                        default_profile_name,
+                        merge_object_mapping,
+                        None,
+                        self.prefix,
+                        sys_dict["SSLKeyAndCertificate"],
+                    )
                 else:
-                    converted_objs.append({'ssl_cert_key': ssl_kc_obj})
-                    avi_config['SSLKeyAndCertificate'].append(ssl_kc_obj)
+                    converted_objs.append({"ssl_cert_key": ssl_kc_obj})
+                    avi_config["SSLKeyAndCertificate"].append(ssl_kc_obj)
                 self.certkey_count += 1
             else:
-                converted_objs.append({'ssl_cert_key': ssl_kc_obj})
-                avi_config['SSLKeyAndCertificate'].append(ssl_kc_obj)
+                converted_objs.append({"ssl_cert_key": ssl_kc_obj})
+                avi_config["SSLKeyAndCertificate"].append(ssl_kc_obj)
 
-    def update_ca_cert_obj(self, name, ca_cert_file_name, input_dir, tenant,
-                           avi_config, converted_objs, merge_object_mapping,
-                           sys_dict):
+    def update_ca_cert_obj(
+        self, name, ca_cert_file_name, input_dir, tenant, avi_config,
+        profile, converted_objs, merge_object_mapping, sys_dict
+    ):
         """
         This method create the certs if certificate not present at location
         it create placeholder certificate.
         :param name: name of certificate.
         :param key_file_name: name of keyfile of cert
         :param cert_file_name: name of cert file
         :param input_dir: location of cert and key
@@ -290,151 +339,155 @@
         :param default_profile_name: name of default profile name.
         :param key_and_cert_mapping_list: list of key and cert
         :param merge_object_mapping: merged object dict for merging objects
         :param sys_dict: baseline objects
         :return:
         """
 
-        cert_name = [cert['name'] for cert in avi_config['SSLKeyAndCertificate']
-                     if cert['name'] == name and
-                     cert['type'] == 'SSL_CERTIFICATE_TYPE_CA']
+        cert_name = [
+            cert["name"]
+            for cert in avi_config["SSLKeyAndCertificate"]
+            if cert["name"] == name and cert["type"] == "SSL_CERTIFICATE_TYPE_CA"
+        ]
 
         if cert_name:
             LOG.warning(
-                'SSL ca cert is already exist for %s is %s' % (
-                    ca_cert_file_name, cert_name[0]))
+                "SSL ca cert is already exist for %s is %s",
+                ca_cert_file_name, cert_name[0])
             return
         folder_path = input_dir + os.path.sep
         ca_cert = None
         # Removed / from cert_file_name to get name of file.
         if ca_cert_file_name:
-            if '/' in ca_cert_file_name:
-                ca_cert_file_name = ca_cert_file_name.split('/')[-1]
-            if ':' in ca_cert_file_name:
-                ca_cert_file_name = ca_cert_file_name.split(':')[-1]
+            if "/" in ca_cert_file_name:
+                ca_cert_file_name = ca_cert_file_name.split("/")[-1]
+            if ":" in ca_cert_file_name:
+                ca_cert_file_name = ca_cert_file_name.split(":")[-1]
             ca_cert = conv_utils.upload_file(folder_path + ca_cert_file_name)
 
         if ca_cert:
             if not conv_utils.check_certificate_expiry(
                     input_dir, ca_cert_file_name):
                 ca_cert = None
 
         if not ca_cert:
             key, ca_cert = conv_utils.create_self_signed_cert()
             name = '%s-%s' % (name, final.PLACE_HOLDER_STR)
-            LOG.warning('Create self cerificate and key for : %s' % name)
+            LOG.warning("Create self cerificate and key for : %s", name)
 
         ca_cert_obj = None
         cert_name = name
-        if ca_cert_file_name and '.crt' in ca_cert_file_name:
-            if ':' in ca_cert_file_name:
-                ca_cert_file_name = ca_cert_file_name.split(':')[-1]
+        if ca_cert_file_name and ".crt" in ca_cert_file_name:
+            if ":" in ca_cert_file_name:
+                ca_cert_file_name = ca_cert_file_name.split(":")[-1]
             ca_cert_file_name = '%s.crt' % ca_cert_file_name.split('.crt')[0]
         if not ca_cert_file_name:
             ca_cert_file_name = name
         if ca_cert:
-            cert = {"certificate": ca_cert if type(ca_cert) == str else ca_cert.decode()}
+            cert = {
+                "certificate": ca_cert if isinstance(
+                    ca_cert, str) else ca_cert.decode()}
             ca_cert_obj = {
-                'name': ca_cert_file_name,
-                'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant'),
-                'certificate': cert,
-                'type': 'SSL_CERTIFICATE_TYPE_CA'
+                "name": ca_cert_file_name,
+                "tenant_ref": conv_utils.get_object_ref(tenant, "tenant"),
+                "certificate": cert,
+                "type": "SSL_CERTIFICATE_TYPE_CA",
             }
-            LOG.info('Added new ca certificate for %s' % name)
+            LOG.info("Added new ca certificate for %s", name)
+            if profile.get("ocsp-stapling") == "enabled":
+                ca_cert_obj["enable_ocsp_stapling"] = True
         if ca_cert_obj and self.object_merge_check:
-            if final.PLACE_HOLDER_STR not in ca_cert_obj['name']:
+            if final.PLACE_HOLDER_STR not in ca_cert_obj["name"]:
                 conv_utils.update_skip_duplicates(
                     ca_cert_obj, avi_config['SSLKeyAndCertificate'],
                     'ssl_cert_key', converted_objs, name, None,
                     merge_object_mapping, None, self.prefix,
                     sys_dict['SSLKeyAndCertificate'])
             else:
-                converted_objs.append({'ssl_cert_key': ca_cert_obj})
-                avi_config['SSLKeyAndCertificate'].append(ca_cert_obj)
+                converted_objs.append({"ssl_cert_key": ca_cert_obj})
+                avi_config["SSLKeyAndCertificate"].append(ca_cert_obj)
             self.certkey_count += 1
         else:
-            converted_objs.append({'ssl_cert_key': ca_cert_obj})
-            avi_config['SSLKeyAndCertificate'].append(ca_cert_obj)
+            converted_objs.append({"ssl_cert_key": ca_cert_obj})
+            avi_config["SSLKeyAndCertificate"].append(ca_cert_obj)
 
     def get_enf_skipped(self, enforcement):
-        default_ignore = list()
+        default_ignore = []
         na_list = self.na_enf
-        skipped = [enf for enf in enforcement.keys()
-                   if enf not in self.supported_enf]
+        skipped = [enf for enf in enforcement.keys(
+        ) if enf not in self.supported_enf]
         for key in enforcement:
-            if (key in self.ignore_for_defaults_enf and enforcement[key] ==
-                    self.ignore_for_defaults_enf.get(key, None)):
+            if key in self.ignore_for_defaults_enf and\
+                enforcement[key] == self.ignore_for_defaults_enf.get(
+                    key, None):
                 default_ignore.append(key)
                 skipped.remove(key)
         indirect_enf_attr = self.indirect_enf
-        indirect_enf = [val for val in skipped if
-                        val in indirect_enf_attr]
+        indirect_enf = [val for val in skipped if val in indirect_enf_attr]
         skipped = [attr for attr in skipped if attr not in indirect_enf]
         na_list = [val for val in skipped if val in na_list]
         skipped = [attr for attr in skipped if attr not in na_list]
 
         return skipped, default_ignore, na_list, indirect_enf
 
 
 class ProfileConfigConvV11(ProfileConfigConv):
-    def __init__(self, f5_profile_attributes, object_merge_check, prefix,
-                 keypassphrase, skip_pki, distinct_app_profile):
+    '''
+    Profile Config Conversion V11
+    '''
+
+    def __init__(self, f5_profile_attributes, object_merge_check,
+                 prefix, keypassphrase, skip_pki, distinct_app_profile):
         """
 
         :param f5_profile_attributes: f5 profile attributes from yaml file.
         :param object_merge_check: flag for merging objects
         :param prefix: prefix for objects
         :param keypassphrase: keypassphrase yaml file location
         :param skip_pki: PKI profile migration needs to be skipped
         :param distinct_app_profile: Merge duplicates needs to be slipped
         """
-        self.supported_types = \
-            f5_profile_attributes['Profile_supported_types']
-        self.ignore_for_defaults = \
-            f5_profile_attributes['Profile_ignore_for_defaults']
+        self.supported_types = f5_profile_attributes["Profile_supported_types"]
+        self.ignore_for_defaults = f5_profile_attributes["Profile_ignore_for_defaults"]
         self.default_key = "defaults-from"
-        self.na_ssl = f5_profile_attributes['Profile_na_ssl']
-        self.indirect_ssl = f5_profile_attributes['Profile_indirect_ssl']
-        self.supported_ssl = f5_profile_attributes['Profile_supported_ssl']
-        self.na_http = f5_profile_attributes['Profile_na_http']
-        self.supported_http = f5_profile_attributes['Profile_supported_http']
-        self.indirect_http = f5_profile_attributes['Profile_indirect_http']
-        self.na_dns = f5_profile_attributes['Profile_na_dns']
-        self.supported_dns = f5_profile_attributes['Profile_supported_dns']
-        self.indirect_dns = f5_profile_attributes['Profile_indirect_dns']
-        self.supported_hc = f5_profile_attributes['Profile_supported_hc']
-        self.na_hc = f5_profile_attributes['Profile_na_hc']
-        self.indirect_hc = f5_profile_attributes['Profile_indirect_hc']
-
-        self.supported_wa = f5_profile_attributes['Profile_supported_wa']
-        self.indirect_wa = f5_profile_attributes['Profile_indirect_wa']
-
-        self.supported_l4 = f5_profile_attributes['Profile_supported_l4']
-        self.na_l4 = f5_profile_attributes['profile_na_l4']
-        self.indirect_l4 = f5_profile_attributes['Profile_indirect_l4']
-
-        self.supported_fh = f5_profile_attributes['Profile_supported_fh']
-        self.indirect_fh = f5_profile_attributes['Profile_indirect_fh']
-        self.na_fh = f5_profile_attributes['Profile_na_fh']
-
-        self.supported_tcp = f5_profile_attributes['Profile_supported_tcp']
-        self.indirect_tcp = f5_profile_attributes['Profile_indirect_tcp']
-        self.na_tcp = f5_profile_attributes['Profile_na_tcp']
-        self.supported_udp = f5_profile_attributes['Profile_supported_udp']
-        self.indirect_udp = f5_profile_attributes['Profile_indirect_udp']
-        self.na_udp = f5_profile_attributes['Profile_na_udp']
-        self.supported_oc = f5_profile_attributes['Profile_supported_oc']
-        self.supported_enf = \
-            f5_profile_attributes['Profile_supported_http_enforcement']
-        self.ignore_for_defaults_enf = \
-            f5_profile_attributes['Profile_http_enf_ignore_for_defaults']
-        self.na_enf = \
-            f5_profile_attributes['Profile_na_http_enforcement']
-        self.indirect_enf = \
-            f5_profile_attributes['Profile_indirect_http_enforcement']
+        self.na_ssl = f5_profile_attributes["Profile_na_ssl"]
+        self.indirect_ssl = f5_profile_attributes["Profile_indirect_ssl"]
+        self.supported_ssl = f5_profile_attributes["Profile_supported_ssl"]
+        self.na_http = f5_profile_attributes["Profile_na_http"]
+        self.supported_http = f5_profile_attributes["Profile_supported_http"]
+        self.indirect_http = f5_profile_attributes["Profile_indirect_http"]
+        self.na_dns = f5_profile_attributes["Profile_na_dns"]
+        self.supported_dns = f5_profile_attributes["Profile_supported_dns"]
+        self.indirect_dns = f5_profile_attributes["Profile_indirect_dns"]
+        self.supported_hc = f5_profile_attributes["Profile_supported_hc"]
+        self.na_hc = f5_profile_attributes["Profile_na_hc"]
+        self.indirect_hc = f5_profile_attributes["Profile_indirect_hc"]
+
+        self.supported_wa = f5_profile_attributes["Profile_supported_wa"]
+        self.indirect_wa = f5_profile_attributes["Profile_indirect_wa"]
+
+        self.supported_l4 = f5_profile_attributes["Profile_supported_l4"]
+        self.na_l4 = f5_profile_attributes["profile_na_l4"]
+        self.indirect_l4 = f5_profile_attributes["Profile_indirect_l4"]
+
+        self.supported_fh = f5_profile_attributes["Profile_supported_fh"]
+        self.indirect_fh = f5_profile_attributes["Profile_indirect_fh"]
+        self.na_fh = f5_profile_attributes["Profile_na_fh"]
+
+        self.supported_tcp = f5_profile_attributes["Profile_supported_tcp"]
+        self.indirect_tcp = f5_profile_attributes["Profile_indirect_tcp"]
+        self.na_tcp = f5_profile_attributes["Profile_na_tcp"]
+        self.supported_udp = f5_profile_attributes["Profile_supported_udp"]
+        self.indirect_udp = f5_profile_attributes["Profile_indirect_udp"]
+        self.na_udp = f5_profile_attributes["Profile_na_udp"]
+        self.supported_oc = f5_profile_attributes["Profile_supported_oc"]
+        self.supported_enf = f5_profile_attributes["Profile_supported_http_enforcement"]
+        self.ignore_for_defaults_enf = f5_profile_attributes["Profile_http_enf_ignore_for_defaults"]
+        self.na_enf = f5_profile_attributes["Profile_na_http_enforcement"]
+        self.indirect_enf = f5_profile_attributes["Profile_indirect_http_enforcement"]
         if keypassphrase:
             self.f5_passphrase_keys = yaml.safe_load(open(keypassphrase))
         else:
             self.f5_passphrase_keys = None
         self.object_merge_check = object_merge_check
         # added code to handel count of sslmerge, applicationmerge,
         # networkmerge count, certkey_count
@@ -446,15 +499,15 @@
         self.prefix = prefix
         self.skip_pki = skip_pki
         self.distinct_app_profile = distinct_app_profile
 
     def convert_profile(self, profile, key, f5_config, profile_config,
                         avi_config, input_dir, user_ignore, tenant_ref,
                         key_and_cert_mapping_list, merge_object_mapping,
-                        sys_dict):
+                        sys_dict,migrated_cipher,migrated_cipher_group):
         """
 
         :param profile: parsed dict of profile
         :param key: key which contain combination of profile type and name
         :param f5_config: parsed f5 config dict
         :param profile_config:
         :param avi_config: dict for avi config conversion.
@@ -467,622 +520,676 @@
         :return:
         """
         skipped = profile.keys()
         indirect = []
         converted_objs = []
         na_list = []
         u_ignore = []
+        partially_migrated_profiles=dict()
         parent_cls = super(ProfileConfigConvV11, self)
-        profile_type, name = key.split(' ')
+        profile_type, name = key.split(" ")
         tenant, name = conv_utils.get_tenant_ref(name)
         if tenant_ref:
             tenant = tenant_ref
         default_profile_name = '%s %s' % (profile_type,
                                           profile_type.replace('-', ''))
-        default_ignore = f5_config['profile'].get(default_profile_name, {})
+        default_ignore = f5_config["profile"].get(default_profile_name, {})
         default_ignore.update(self.ignore_for_defaults)
         enf_skip_defaults = None
-        default_profile_name = profile_type.replace('-', '')
+        default_profile_name = profile_type.replace("-", "")
         # Added prefix for objects
         if self.prefix:
             name = '%s-%s' % (self.prefix, name)
             default_profile_name = '%s-%s' % (self.prefix, default_profile_name)
-        if profile_type in ('client-ssl', 'server-ssl'):
+        if profile_type in ("client-ssl", "server-ssl"):
             supported_attr = self.supported_ssl
             na_list = self.na_ssl
             indirect = self.indirect_ssl
-            u_ignore = user_ignore.get('client-ssl', [])
-            u_ignore += user_ignore.get('server-ssl', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
+            u_ignore = user_ignore.get("client-ssl", [])
+            u_ignore += user_ignore.get("server-ssl", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
             original_prof = profile_config.get(key, None)
-            inherit_key = original_prof.get('inherit-certkeychain', 'true')
-            if inherit_key == 'false':
-                profile['cert-key-chain'] = original_prof.get(
+            inherit_key = original_prof.get("inherit-certkeychain", "true")
+            if inherit_key == "false":
+                profile["cert-key-chain"] = original_prof.get(
                     "cert-key-chain", None)
-                profile['key'] = original_prof.get("key", None)
-                profile['cert'] = original_prof.get("cert", None)
+                profile["key"] = original_prof.get("key", None)
+                profile["cert"] = original_prof.get("cert", None)
 
             cert_obj = profile.get("cert-key-chain", None)
             if cert_obj and cert_obj.keys():
                 cert_obj_key = list(cert_obj.keys())[0]
                 key_file = cert_obj.get(cert_obj_key, {}).get("key", None)
                 cert_file = cert_obj.get(cert_obj_key, {}).get("cert", None)
             else:
                 cert_file = profile.get("cert", None)
                 key_file = profile.get("key", None)
-                cert_file = None if cert_file == 'none' else cert_file
-                key_file = None if key_file == 'none' else key_file
+                cert_file = None if cert_file == "none" else cert_file
+                key_file = None if key_file == "none" else key_file
             cert_name = cert_file
             if cert_name:
-                cert_name = cert_name.split('/')[-1]
+                cert_name = cert_name.split("/")[-1]
             else:
                 cert_name = name
             # Added for getting correct file names from cache path in sys file
-            sys_file = f5_config.get('file', {})
+            sys_file = f5_config.get("file", {})
             for file_key in sys_file:
-                file_type, file_name = file_key.split(' ')
-                if file_type in ('ssl-key', 'ssl-cert'):
-                    if file_type == 'ssl-key' and file_name == key_file and \
-                            sys_file[file_key].get('cache-path'):
-                        key_file = sys_file[file_key]['cache-path'].rsplit(
-                            '/', 1)[-1]
-                    elif file_type == 'ssl-cert' and file_name == cert_file \
-                            and sys_file[file_key].get('cache-path'):
-                        cert_file = sys_file[file_key]['cache-path'].rsplit(
-                            '/', 1)[-1]
+                file_type, file_name = file_key.split(" ")
+                if file_type in ("ssl-key", "ssl-cert"):
+                    if file_type == "ssl-key" and file_name == key_file and sys_file[file_key].get(
+                            "cache-path"):
+                        key_file = sys_file[file_key]["cache-path"].rsplit(
+                            "/", 1)[-1]
+                    elif file_type == "ssl-cert" and file_name == cert_file and\
+                            sys_file[file_key].get("cache-path"):
+                        cert_file = sys_file[file_key]["cache-path"].rsplit(
+                            "/", 1)[-1]
             parent_cls.update_key_cert_obj(
                 cert_name, key_file, cert_file, input_dir, tenant_ref,
-                avi_config, converted_objs, default_profile_name,
+                avi_config, profile, converted_objs, default_profile_name,
                 key_and_cert_mapping_list, merge_object_mapping, sys_dict)
             if profile.get('chain', 'none') != 'none':
-                LOG.debug("Migrating root/intermediate cert for %s" % name)
+                LOG.debug("Migrating root/intermediate cert for %s", name)
                 ca_cert_file = None
                 for file_key in sys_file:
-                    file_type, file_name = file_key.split(' ')
-                    if (file_type == 'ssl-cert' and
-                            file_name == profile['chain'] and
-                            sys_file[file_key].get('cache-path')):
-                        ca_cert_file = sys_file[file_key][
-                            'cache-path'].rsplit('/', 1)[-1]
+                    file_type, file_name = file_key.split(" ")
+                    if file_type == "ssl-cert" and file_name == profile["chain"]\
+                            and sys_file[file_key].get("cache-path"):
+                        ca_cert_file = sys_file[file_key]["cache-path"].rsplit(
+                            "/", 1)[-1]
                         break
                 self.update_ca_cert_obj(
-                    name, ca_cert_file, input_dir, tenant, avi_config,
-                    converted_objs, merge_object_mapping,
-                    sys_dict)
-
-            # ciphers = profile.get('ciphers', 'DEFAULT')
-            # ciphers = 'AES:3DES:RC4' if ciphers == 'DEFAULT' else ciphers
-            # ciphers = ciphers.replace(":@SPEED", "")
-            ssl_profile = dict()
-            ssl_profile['name'] = name
-            ssl_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+                    name, ca_cert_file, input_dir, tenant, avi_config, profile,
+                    converted_objs, merge_object_mapping, sys_dict
+                )
+
+
+            accepted_ciphers=self.ciphers
+            unsupported_ciphers=None
+            ciphers = profile.get('ciphers','none')
+            accepted_ciphers = 'AES:3DES:RC4' if ciphers == 'DEFAULT' else accepted_ciphers
+            if ciphers not in ['none']:
+                if migrated_cipher.get(ciphers):
+                    accepted_ciphers=migrated_cipher.get(ciphers).get('mig_cipher')
+                    unsupported_ciphers=migrated_cipher.get(ciphers).get('unsupported_ciphers')
+            else:
+                cipher_group = profile.get('cipher-group')
+                if cipher_group :
+                    cipher_group_name=conv_utils.get_tenant_ref(cipher_group)[1]
+                    if migrated_cipher_group.get(cipher_group_name):
+                        accepted_ciphers=migrated_cipher_group.get(cipher_group_name).get('mig_cipher')
+                        unsupported_ciphers=migrated_cipher_group.get(cipher_group_name).get('unsupported_ciphers')
+
+            if unsupported_ciphers:
+                unsupp_mesg="Profile partially migrated due to presence of unsupported ciphers %s" %unsupported_ciphers
+                partially_migrated_profiles[name]=unsupp_mesg
+                LOG.warning("ssl %s %s" %(name,unsupp_mesg))
+
+            ssl_profile = {}
+            ssl_profile["name"] = name
+            ssl_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             if cert_name:
-                ssl_profile['cert_name'] = cert_name
-            ssl_profile['accepted_ciphers'] = self.ciphers
-            close_notify = profile.get('unclean-shutdown', None)
-            if close_notify and close_notify == 'enabled':
-                ssl_profile['send_close_notify'] = True
+                ssl_profile["cert_name"] = cert_name
+            ssl_profile["accepted_ciphers"] = accepted_ciphers
+            close_notify = profile.get("unclean-shutdown", None)
+            if close_notify and close_notify == "enabled":
+                ssl_profile["send_close_notify"] = True
             else:
-                ssl_profile['send_close_notify'] = False
+                ssl_profile["send_close_notify"] = False
             options = profile.get("options", {})
-            options = {} if options == 'none' else options
+            options = {} if options == "none" else options
             options = list(options.keys()) + list(options.values())
             if None in options:
                 options.remove(None)
             accepted_versions = []
             if "no-tlsv1" not in options:
                 accepted_versions.append({"type": "SSL_VERSION_TLS1"})
             if "no-tlsv1.1" not in options:
                 accepted_versions.append({"type": "SSL_VERSION_TLS1_1"})
             if "no-tlsv1.2" not in options:
                 accepted_versions.append({"type": "SSL_VERSION_TLS1_2"})
             if accepted_versions:
                 ssl_profile["accepted_versions"] = accepted_versions
+            if profile.get("alert-timeout"):
+                alert_timeout=profile.get("alert-timeout")
+                ssl_profile["ssl_session_timeout"] = alert_timeout if alert_timeout not in ['indefinite'] else 86400
+            if profile.get("session-ticket-timeout"):
+                ssl_profile["ssl_session_timeout"] = profile.get(
+                    "session-ticket-timeout")
+
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
                     ssl_profile, avi_config['SSLProfile'], 'ssl_profile',
                     converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['SSLProfile'])
                 ssl_count['count'] += 1
             else:
-                converted_objs.append({'ssl_profile': ssl_profile})
-                avi_config['SSLProfile'].append(ssl_profile)
-            crl_file_name = profile.get('crl-file', None)
-            ca_file_name = profile.get('ca-file', None)
-            if crl_file_name and crl_file_name != 'none':
-                crl_file_name = crl_file_name.replace('\"', '').strip()
+                converted_objs.append({"ssl_profile": ssl_profile})
+                avi_config["SSLProfile"].append(ssl_profile)
+            if profile.get("sni-default") == "true":
+                ssl_profile_with_sni_parent.append(ssl_profile.get("name"))
+            elif profile.get("server-name") != "none":
+                ssl_profile_with_sni_child[ssl_profile.get(
+                    "name")] = profile.get("server-name")
+            crl_file_name = profile.get("crl-file", None)
+            ca_file_name = profile.get("ca-file", None)
+            if ca_file_name is None:
+                ca_file_name = profile.get("client-cert-ca", None)
+            if crl_file_name and crl_file_name != "none":
+                crl_file_name = crl_file_name.replace('"', "").strip()
             else:
                 crl_file_name = None
-            if ca_file_name and ca_file_name != 'none':
-                ca_file_name = ca_file_name.replace('\"', '').strip()
+            if ca_file_name and ca_file_name != "none":
+                ca_file_name = ca_file_name.replace('"', "").strip()
             else:
                 ca_file_name = None
 
             if ca_file_name and not self.skip_pki:
-                pki_profile = dict()
+                pki_profile = {}
                 file_path = input_dir + os.path.sep + ca_file_name
                 pki_profile["name"] = name
-                pki_profile['tenant_ref'] = conv_utils.get_object_ref(
-                    tenant, 'tenant')
-                pc_mode = profile.get('peer-cert-mode', 'ignore')
-                if pc_mode == 'ignore':
-                    pc_mode = 'SSL_CLIENT_CERTIFICATE_NONE'
-                elif pc_mode == 'request':
-                    pc_mode = 'SSL_CLIENT_CERTIFICATE_REQUEST'
-                elif pc_mode == 'require':
-                    pc_mode = 'SSL_CLIENT_CERTIFICATE_REQUIRE'
-                pki_profile['mode'] = pc_mode
+                pki_profile["tenant_ref"] = conv_utils.get_object_ref(
+                    tenant, "tenant")
+                pc_mode = profile.get("peer-cert-mode", "ignore")
+                if pc_mode == "ignore":
+                    pc_mode = "SSL_CLIENT_CERTIFICATE_NONE"
+                elif pc_mode == "request":
+                    pc_mode = "SSL_CLIENT_CERTIFICATE_REQUEST"
+                elif pc_mode == "require":
+                    pc_mode = "SSL_CLIENT_CERTIFICATE_REQUIRE"
+                pki_profile["mode"] = pc_mode
                 error = False
                 ca = conv_utils.upload_file(file_path)
                 if ca:
-                    pki_profile["ca_certs"] = [{'certificate': ca}]
+                    pki_profile["ca_certs"] = [{"certificate": ca}]
                 else:
                     error = True
                 if crl_file_name:
                     file_path = input_dir + os.path.sep + crl_file_name
                     crl = conv_utils.upload_file(file_path)
                     if crl:
-                        pki_profile["crls"] = [{'body': crl}]
+                        pki_profile["crls"] = [{"body": crl}]
                     else:
                         error = True
                 else:
-                    pki_profile['crl_check'] = False
+                    pki_profile["crl_check"] = False
                 if not error:
                     if self.object_merge_check:
-                        conv_utils.update_skip_duplicates(pki_profile,
-                                                          avi_config['PKIProfile'], 'pki_profile',
-                                                          converted_objs, name, default_profile_name,
-                                                          merge_object_mapping, None, self.prefix,
-                                                          sys_dict['PKIProfile'])
+                        conv_utils.update_skip_duplicates(
+                            pki_profile, avi_config['PKIProfile'],
+                            'pki_profile', converted_objs, name, default_profile_name,
+                            merge_object_mapping, None, self.prefix, sys_dict['PKIProfile'])
                         self.pki_count += 1
                     else:
-                        converted_objs.append({'pki_profile': pki_profile})
-                        avi_config['PKIProfile'].append(pki_profile)
-        elif profile_type == 'http':
+                        converted_objs.append({"pki_profile": pki_profile})
+                        avi_config["PKIProfile"].append(pki_profile)
+        elif profile_type == "http":
             supported_attr = self.supported_http
             na_list = self.na_http
-            u_ignore = user_ignore.get('http', [])
+            u_ignore = user_ignore.get("http", [])
             indirect = self.indirect_http
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_HTTP'
-            app_profile['description'] = profile.get('description', None)
-            encpt_cookie = profile.get('encrypt-cookies', 'none')
-            encpt_cookie = False if encpt_cookie == 'none' else True
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_HTTP"
+            app_profile["description"] = profile.get("description", None)
+            encpt_cookie = profile.get("encrypt-cookies", "none")
+            encpt_cookie = encpt_cookie != "none"
             # xff_enabled = profile.get('accept-xff', 'disabled')
             # xff_enabled = False if xff_enabled == 'disabled' else True
-            con_mltplxng = profile.get('oneconnect-transformations',
-                                       'disabled')
-            con_mltplxng = False if con_mltplxng == 'disabled' else True
-            http_profile = dict()
-            insert_xff = profile.get('insert-xforwarded-for', 'disabled')
-            insert_xff = True if insert_xff == 'enabled' else False
-            http_profile['x_forwarded_proto_enabled'] = insert_xff
-            xff_alt_names = profile.get('xff-alternative-names', None)
-            xff_alt_names = None if xff_alt_names == 'none' else xff_alt_names
-            http_profile['xff_alternate_name'] = xff_alt_names
-            http_profile['secure_cookie_enabled'] = encpt_cookie
-            http_profile['xff_enabled'] = insert_xff
-            http_profile['connection_multiplexing_enabled'] = con_mltplxng
-            if profile.get('via-host-name'):
-                app_profile['via-host-name'] = profile.get('via-host-name')
-                app_profile['via-request'] = profile.get('via-request')
-            if not profile.get('redirect-rewrite'):
-                http_profile['hsts_enabled'] = True
-            enforcement = profile.get('enforcement', None)
+            con_mltplxng = profile.get(
+                "oneconnect-transformations", "disabled")
+            con_mltplxng = con_mltplxng != "disabled"
+            http_profile = {}
+            insert_xff = profile.get("insert-xforwarded-for", "disabled")
+            insert_xff = insert_xff == "enabled"
+            http_profile["x_forwarded_proto_enabled"] = insert_xff
+            xff_alt_names = profile.get("xff-alternative-names", None)
+            xff_alt_names = None if xff_alt_names == "none" else xff_alt_names
+            http_profile["xff_alternate_name"] = xff_alt_names
+            http_profile["secure_cookie_enabled"] = encpt_cookie
+            http_profile["xff_enabled"] = insert_xff
+            http_profile["connection_multiplexing_enabled"] = con_mltplxng
+            if profile.get("via-host-name"):
+                app_profile["via-host-name"] = profile.get("via-host-name")
+                app_profile["via-request"] = profile.get("via-request")
+            if not profile.get("redirect-rewrite"):
+                http_profile["hsts_enabled"] = True
+            if profile.get("hsts"):
+                if profile["hsts"].get("mode") == "enabled":
+                    http_profile["hsts_enabled"] = True
+            enforcement = profile.get("enforcement", None)
             if enforcement:
-                header_size = enforcement.get('max-header-size',
-                                              final.DEFAULT_MAX_HEADER)
-                http_profile['client_max_header_size'] = \
-                    int(header_size) / final.BYTES_IN_KB
-                if enforcement.get('max-header-count'):
-                    http_profile['max_header_count'] = enforcement.get('max-header-count')
-                enf_skipped, enf_skip_defaults , enf_na , enf_indirect = self.get_enf_skipped(enforcement)
+                header_size = enforcement.get(
+                    "max-header-size", final.DEFAULT_MAX_HEADER)
+                http_profile["client_max_header_size"] = int(
+                    header_size) / final.BYTES_IN_KB
+                if enforcement.get("max-header-count"):
+                    http_profile["max_header_count"] = enforcement.get(
+                        "max-header-count")
+                enf_skipped, enf_skip_defaults, enf_na, enf_indirect = self.get_enf_skipped(
+                    enforcement)
                 if enf_skipped:
                     skipped.append({"enforcement": enf_skipped})
                 na_list.append({"enforcement": enf_na})
                 indirect.append({"enforcement": enf_indirect})
             app_profile["http_profile"] = http_profile
 
-            header_erase = profile.get('header-erase', None)
-            header_erase = None if header_erase == 'none' else header_erase
+            header_erase = profile.get("header-erase", None)
+            header_erase = None if header_erase == "none" else header_erase
             if header_erase:
-                header_erase = header_erase.replace('\"', '').strip()
-            header_insert = profile.get('header-insert', None)
-            header_insert = None if header_insert == 'none' else header_insert
+                header_erase = header_erase.replace('"', "").strip()
+            header_insert = profile.get("header-insert", None)
+            header_insert = None if header_insert == "none" else header_insert
             if header_insert:
-                header_insert = header_insert.replace('\"', '').strip()
+                header_insert = header_insert.replace('"', "").strip()
 
             if header_erase or header_insert:
                 rules = []
                 rule_index = 1
                 # Added condition of header insert and header erase present then
                 # create common rule with more action.
                 if header_erase and header_insert:
-                    header_erase = header_erase.split(':')[0]
-                    header, val = header_insert.split(':')
+                    header_erase = header_erase.split(":")[0]
+                    header, val = header_insert.split(":")
                     header_erase_rule = conv_utils.create_hdr_erase_rule(
-                        'rule-header-erase', header_erase, rule_index)
+                        "rule-header-erase", header_erase, rule_index)
                     header_insert_rule = conv_utils.create_hdr_insert_rule(
-                        'rule-header-insert', header, val, rule_index)
-                    header_erase_rule['hdr_action'].append(header_insert_rule[
-                                                               'hdr_action'][0])
+                        "rule-header-insert", header, val, rule_index)
+                    header_erase_rule["hdr_action"].append(
+                        header_insert_rule["hdr_action"][0])
                     rules.append(header_erase_rule)
                 elif header_erase:
-                    if ':' in header_erase:
-                        header_erase = header_erase.split(':', 1)[0]
-                    rules.append(conv_utils.create_hdr_erase_rule(
-                        'rule-header-erase', header_erase, rule_index))
+                    if ":" in header_erase:
+                        header_erase = header_erase.split(":", 1)[0]
+                    rules.append(
+                        conv_utils.create_hdr_erase_rule(
+                            "rule-header-erase",
+                            header_erase,
+                            rule_index))
                 elif header_insert:
-                    header, val = header_insert.split(':', 1)
-                    rules.append(conv_utils.create_hdr_insert_rule(
-                        'rule-header-insert', header, val, rule_index))
+                    header, val = header_insert.split(":", 1)
+                    rules.append(
+                        conv_utils.create_hdr_insert_rule(
+                            "rule-header-insert", header, val, rule_index))
                 rule_index += 1
                 policy_name = name + '-HTTP-Policy-Set'
                 policy = {
                     "name": policy_name,
                     "http_request_policy": {
-                        "rules": rules
-                    },
-                    "is_internal_policy": False
-                }
-                policy['tenant_ref'] = conv_utils.get_object_ref(
-                    tenant, 'tenant')
-                avi_config['HTTPPolicySet'].append(policy)
+                        "rules": rules},
+                    "is_internal_policy": False}
+                policy["tenant_ref"] = conv_utils.get_object_ref(
+                    tenant, "tenant")
+                avi_config["HTTPPolicySet"].append(policy)
                 app_profile["HTTPPolicySet"] = policy_name
-                converted_objs.append({'policy_set': policy})
+                converted_objs.append({"policy_set": policy})
 
-                realm = profile.get("basic-auth-realm", 'none')
-                realm = None if realm == 'none' else realm
+                realm = profile.get("basic-auth-realm", "none")
+                realm = None if realm == "none" else realm
                 if realm:
-                    app_profile['realm'] = realm
-                host = profile.get("fallback-host", 'none')
-                host = None if host == 'none' else host
+                    app_profile["realm"] = realm
+                host = profile.get("fallback-host", "none")
+                host = None if host == "none" else host
                 if host:
-                    app_profile['fallback_host'] = host
+                    app_profile["fallback_host"] = host
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
 
-        elif profile_type == 'dns':
+        elif profile_type == "dns":
             supported_attr = self.supported_dns
             na_list = self.na_dns
-            u_ignore = user_ignore.get('dns', [])
+            u_ignore = user_ignore.get("dns", [])
             indirect = self.indirect_dns
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_DNS'
-            app_profile['description'] = profile.get('description', None)
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_DNS"
+            app_profile["description"] = profile.get("description", None)
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
-        elif profile_type == 'web-acceleration':
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
+        elif profile_type == "web-acceleration":
             supported_attr = self.supported_wa
             indirect = self.indirect_wa
-            u_ignore = user_ignore.get('web-acceleration', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_HTTP'
-            app_profile['description'] = profile.get('description', None)
-            cache_config = dict()
-            cache_config['min_object_size'] = profile.get(
-                'cache-object-min-size', final.MIN_CACHE_OBJ_SIZE)
-            cache_config['query_cacheable'] = True
-            cache_config['max_object_size'] = profile.get(
-                'cache-object-max-size', final.MAX_CACHE_OBJ_SIZE)
-            age_header = profile.get('cache-insert-age-header', 'disabled')
-            if age_header == 'enabled':
-                cache_config['age_header'] = True
-            else:
-                cache_config['age_header'] = False
-            cache_config['enabled'] = True
-            cache_config['default_expire'] = \
-                profile.get('cache-max-age', final.DEFAULT_CACHE_MAX_AGE)
-            max_entities = profile.get('cache-max-entries', 0)
-            cache_config['max_cache_size'] = \
-                (int(max_entities) * int(cache_config['max_object_size']))
+            u_ignore = user_ignore.get("web-acceleration", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_HTTP"
+            app_profile["description"] = profile.get("description", None)
+            cache_config = {}
+            cache_config["min_object_size"] = profile.get(
+                "cache-object-min-size", final.MIN_CACHE_OBJ_SIZE)
+            cache_config["query_cacheable"] = True
+            cache_config["max_object_size"] = profile.get(
+                "cache-object-max-size", final.MAX_CACHE_OBJ_SIZE)
+            age_header = profile.get("cache-insert-age-header", "disabled")
+            if age_header == "enabled":
+                cache_config["age_header"] = True
+            else:
+                cache_config["age_header"] = False
+            cache_config["enabled"] = True
+            cache_config["default_expire"] = profile.get(
+                "cache-max-age", final.DEFAULT_CACHE_MAX_AGE)
+            max_entities = profile.get("cache-max-entries", 0)
+            cache_config["max_cache_size"] = int(
+                max_entities) * int(cache_config["max_object_size"])
             exclude_uri = profile.get("cache-uri-exclude", None)
             include_uri = profile.get("cache-uri-include", None)
             if exclude_uri and isinstance(exclude_uri, dict):
-                exclude_uri = list(exclude_uri.keys()) + list(exclude_uri.values())
+                exclude_uri = list(exclude_uri.keys()) + \
+                    list(exclude_uri.values())
                 if None in exclude_uri:
                     exclude_uri.remove(None)
-                cache_config['mime_types_block_lists'] = exclude_uri
+                cache_config["mime_types_block_lists"] = exclude_uri
             if include_uri and isinstance(include_uri, dict):
-                include_uri = list(include_uri.keys()) + list(include_uri.values())
+                include_uri = list(include_uri.keys()) + \
+                    list(include_uri.values())
                 if None in include_uri:
                     include_uri.remove(None)
-                cache_config['mime_types_list'] = include_uri
-            http_profile = dict()
+                cache_config["mime_types_list"] = include_uri
+            http_profile = {}
             http_profile["cache_config"] = cache_config
             app_profile["http_profile"] = http_profile
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
 
-        elif profile_type == 'http-compression':
+        elif profile_type == "http-compression":
             supported_attr = self.supported_hc
-            u_ignore = user_ignore.get('http-compression', [])
+            u_ignore = user_ignore.get("http-compression", [])
             na_list = self.na_hc
             indirect = self.indirect_hc
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_HTTP'
-            app_profile['description'] = profile.get('description', None)
-            compression_profile = dict()
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_HTTP"
+            app_profile["description"] = profile.get("description", None)
+            compression_profile = {}
             compression_profile["type"] = "AUTO_COMPRESSION"
             compression_profile["compression"] = True
             encoding = profile.get("keep-accept-encoding", "disable")
-            if encoding == "disable":
-                encoding = True
-            else:
-                encoding = False
+            encoding = encoding == "disable"
             compression_profile["remove_accept_encoding_header"] = encoding
             content_type = profile.get("content-type-include", "")
             ct_exclude = profile.get("content-type-exclude", "")
-            ct_exclude = None if ct_exclude == 'none' else ct_exclude
-            http_profile = dict()
+            ct_exclude = None if ct_exclude == "none" else ct_exclude
+            http_profile = {}
             if content_type:
-                content_type = list(content_type.keys()) + list(content_type.values())
+                content_type = list(content_type.keys()) + \
+                    list(content_type.values())
             elif ct_exclude:
                 content_type = final.DEFAULT_CONTENT_TYPE
             if ct_exclude:
                 ct_exclude = ct_exclude.keys() + ct_exclude.values()
-                content_type = [ct for ct in content_type
-                                if ct not in ct_exclude]
+                content_type = [
+                    ct for ct in content_type if ct not in ct_exclude]
             if content_type:
                 sg_obj = conv_utils.get_content_string_group(
                     name, content_type, tenant_ref)
-                avi_config['StringGroup'].append(sg_obj)
-                converted_objs.append({'string_group': sg_obj})
+                avi_config["StringGroup"].append(sg_obj)
+                converted_objs.append({"string_group": sg_obj})
                 cc_ref = name + "-content_type"
                 cc_ref = conv_utils.get_object_ref(
-                    cc_ref, 'stringgroup', tenant=tenant)
+                    cc_ref, "stringgroup", tenant=tenant)
                 compression_profile["compressible_content_ref"] = cc_ref
 
             http_profile["compression_profile"] = compression_profile
             app_profile["http_profile"] = http_profile
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
-        elif profile_type == 'fastl4':
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
+        elif profile_type == "fastl4":
             supported_attr = self.supported_l4
             indirect = self.indirect_l4
             na_list = self.na_l4
-            u_ignore = user_ignore.get('fastl4', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            hw_syn_protection = (profile.get("hardware-syn-cookie",
-                                             None) == 'enabled')
-            sw_syn_protection = (profile.get("software-syn-cookie",
-                                             None) == 'enabled')
-            syn_protection = (hw_syn_protection or sw_syn_protection)
+            u_ignore = user_ignore.get("fastl4", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            hw_syn_protection = profile.get(
+                "hardware-syn-cookie", None) == "enabled"
+            sw_syn_protection = profile.get(
+                "software-syn-cookie", None) == "enabled"
+            syn_protection = hw_syn_protection or sw_syn_protection
             timeout = profile.get("idle-timeout", final.MIN_SESSION_TIMEOUT)
             if int(timeout) < 60:
                 timeout = final.MIN_SESSION_TIMEOUT
-                LOG.warn("idle-timeout for profile: %s is less" % name +
-                         " than minimum, changed to Avis minimum value")
+                LOG.warning(
+                    "idle-timeout for profile: %s is less than minimum,\
+                         changed to Avis minimum value", name)
             elif int(timeout) > final.MAX_SESSION_TIMEOUT:
                 timeout = final.MAX_SESSION_TIMEOUT
-                LOG.warn("idle-timeout for profile: %s  is grater" % name +
-                         " than maximum, changed to Avis maximum value")
-            description = profile.get('description', None)
+                LOG.warning("idle-timeout for profile: %s  is grater\
+                         than maximum, changed to Avis maximum value", name)
+            description = profile.get("description", None)
             verified_accept = profile.get("verified-accept")
             ntwk_profile = {
                 "profile": {
                     "tcp_fast_path_profile": {
                         "session_idle_timeout": timeout,
-                        "enable_syn_protection": syn_protection
-                    },
-                    "type": "PROTOCOL_TYPE_TCP_FAST_PATH"
+                        "enable_syn_protection": syn_protection},
+                    "type": "PROTOCOL_TYPE_TCP_FAST_PATH",
                 },
                 "name": name,
-                'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant'),
+                "tenant_ref": conv_utils.get_object_ref(
+                    tenant,
+                    "tenant"),
                 "description": description,
-                'verified-accept': verified_accept
+                "verified-accept": verified_accept,
             }
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_L4'
-            app_profile['description'] = description
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_L4"
+            app_profile["description"] = description
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             explicit_tracking = profile.get("explicit-flow-migration", None)
-            l4_profile = {"rl_profile": {
-                "client_ip_connections_rate_limit": {
-                    "explicit_tracking": (explicit_tracking == 'enabled'),
-                    "action": {
-                        "type": "RL_ACTION_NONE"
+            l4_profile = {
+                "rl_profile": {
+                    "client_ip_connections_rate_limit": {
+                        "explicit_tracking": (explicit_tracking == "enabled"),
+                        "action": {"type": "RL_ACTION_NONE"},
                     }
-                }}
+                }
             }
-            app_profile['dos_rl_profile'] = l4_profile
+            app_profile["dos_rl_profile"] = l4_profile
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
-                    app_profile, avi_config['ApplicationProfile'],
-                    'app_profile', converted_objs, name, default_profile_name,
-                    merge_object_mapping, profile_type, self.prefix,
-                    sys_dict['ApplicationProfile'])
+                    app_profile,
+                    avi_config["ApplicationProfile"],
+                    "app_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["ApplicationProfile"],
+                )
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
             # code to get merge count of network profile.
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
-                    ntwk_profile, avi_config['NetworkProfile'],
-                    'network_profile', converted_objs, name,
-                    default_profile_name, merge_object_mapping, profile_type,
-                    self.prefix, sys_dict['NetworkProfile'])
+                    ntwk_profile,
+                    avi_config["NetworkProfile"],
+                    "network_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["NetworkProfile"],
+                )
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
-        elif profile_type == 'fasthttp':
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
+        elif profile_type == "fasthttp":
             supported_attr = self.supported_fh
             indirect = self.indirect_fh
             na_list = self.na_fh
-            u_ignore = user_ignore.get('fasthttp', [])
-            skipped = [attr for attr in f5_config['profile'][key].keys()
-                       if attr not in supported_attr]
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_HTTP'
-            app_profile['description'] = profile.get('description', None)
-            http_profile = dict()
-            insert_xff = profile.get('insert-xforwarded-for', 'disabled')
-            insert_xff = True if insert_xff == 'enabled' else False
-            http_profile['x_forwarded_proto_enabled'] = insert_xff
-            http_profile['xff_enabled'] = insert_xff
-            header_size = profile.get('max-header-size',
-                                      final.DEFAULT_MAX_HEADER)
-            http_profile['client_max_header_size'] = \
-                int(header_size) / final.BYTES_IN_KB
+            u_ignore = user_ignore.get("fasthttp", [])
+            skipped = [attr for attr in f5_config["profile"]
+                       [key].keys() if attr not in supported_attr]
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_HTTP"
+            app_profile["description"] = profile.get("description", None)
+            http_profile = {}
+            insert_xff = profile.get("insert-xforwarded-for", "disabled")
+            insert_xff = insert_xff == "enabled"
+            http_profile["x_forwarded_proto_enabled"] = insert_xff
+            http_profile["xff_enabled"] = insert_xff
+            header_size = profile.get(
+                "max-header-size", final.DEFAULT_MAX_HEADER)
+            http_profile["client_max_header_size"] = int(
+                header_size) / final.BYTES_IN_KB
             app_profile["http_profile"] = http_profile
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
-            receive_window = profile.get("receive-window-size",
-                                         final.DEFAULT_RECV_WIN)
-            if not (final.MIN_RECV_WIN <= int(receive_window) <=
-                    final.MAX_RECV_WIN):
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
+            receive_window = profile.get(
+                "receive-window-size", final.DEFAULT_RECV_WIN)
+            if not (final.MIN_RECV_WIN <= int(
+                    receive_window) <= final.MAX_RECV_WIN):
                 receive_window = final.DEFAULT_RECV_WIN
             timeout = profile.get("idle-timeout", 0)
             verified_accept = profile.get("verified-accept")
             ntwk_profile = {
                 "profile": {
                     "tcp_proxy_profile": {
                         "receive_window": receive_window,
                         "idle_connection_timeout": timeout,
-                        'automatic': False
-                    },
-                    "type": "PROTOCOL_TYPE_TCP_PROXY"
+                        "automatic": False},
+                    "type": "PROTOCOL_TYPE_TCP_PROXY",
                 },
                 "name": name,
-                'verified-accept': verified_accept
+                "verified-accept": verified_accept,
             }
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
                     ntwk_profile, avi_config['NetworkProfile'],
                     'network_profile', converted_objs, name,
                     default_profile_name, merge_object_mapping, profile_type,
                     self.prefix, sys_dict['NetworkProfile'])
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
 
-        elif profile_type == 'one-connect':
+        elif profile_type == "one-connect":
             supported_attr = self.supported_oc
             indirect = []
-            u_ignore = user_ignore.get('one-connect', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            mask = profile.get('source-mask', 'any')
-            if not mask == 'any':
-                skipped.append('source-mask')
-            converted_objs = \
-                'Maps Indirectly to : HTTP Profile -> Connection Multiplex'
-            LOG.warn('one-connect profile %s will be mapped indirectly to HTTP '
-                     'Profile -> Connection Multiplex of the same VS if '
-                     'oneconnect-transformations is enabled' % name)
-            avi_config['OneConnect'].append(name)
+            u_ignore = user_ignore.get("one-connect", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            mask = profile.get("source-mask", "any")
+            if not mask == "any":
+                skipped.append("source-mask")
+            converted_objs = "Maps Indirectly to : HTTP Profile -> Connection Multiplex"
+            LOG.warning(
+                "one-connect profile %s will be mapped indirectly to HTTP "
+                "Profile -> Connection Multiplex of the same VS if "
+                "oneconnect-transformations is enabled", name
+            )
+            avi_config["OneConnect"].append(name)
 
-        elif profile_type == 'tcp':
+        elif profile_type == "tcp":
             supported_attr = self.supported_tcp
             indirect = self.indirect_tcp
             na_list = self.na_tcp
-            u_ignore = user_ignore.get('tcp', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
+            u_ignore = user_ignore.get("tcp", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
             timeout = profile.get("idle-timeout", 0)
-            nagle = profile.get("nagle", 'disabled')
-            nagle = False if nagle == 'disabled' else True
+            nagle = profile.get("nagle", "disabled")
+            nagle = nagle != "disabled"
             retrans = profile.get("max-retrans", final.MIN_SYN_RETRANS)
-            retrans = final.MIN_SYN_RETRANS if \
-                int(retrans) < final.MIN_SYN_RETRANS else retrans
-            retrans = final.MAX_SYN_RETRANS if \
-                int(retrans) > final.MAX_SYN_RETRANS else retrans
-            syn_retrans = profile.get("syn-max-retrans",
-                                      final.MIN_SYN_RETRANS)
-            syn_retrans = final.MIN_SYN_RETRANS if \
-                int(syn_retrans) < final.MIN_SYN_RETRANS else syn_retrans
-            syn_retrans = final.MAX_SYN_RETRANS if \
-                int(syn_retrans) > final.MAX_SYN_RETRANS else syn_retrans
+            retrans = final.MIN_SYN_RETRANS if int(
+                retrans) < final.MIN_SYN_RETRANS else retrans
+            retrans = final.MAX_SYN_RETRANS if int(
+                retrans) > final.MAX_SYN_RETRANS else retrans
+            syn_retrans = profile.get("syn-max-retrans", final.MIN_SYN_RETRANS)
+            syn_retrans = final.MIN_SYN_RETRANS if int(
+                syn_retrans) < final.MIN_SYN_RETRANS else syn_retrans
+            syn_retrans = final.MAX_SYN_RETRANS if int(
+                syn_retrans) > final.MAX_SYN_RETRANS else syn_retrans
             conn_type = profile.get("time-wait-recycle", "disabled")
-            conn_type = "CLOSE_IDLE" if \
-                conn_type == "disabled" else "KEEP_ALIVE"
+            conn_type = "CLOSE_IDLE" if conn_type == "disabled" else "KEEP_ALIVE"
             delay = profile.get("time-wait-timeout", 0)
-            window = profile.get("receive-window-size",
-                                 (final.MIN_RECV_WIN * final.BYTES_IN_KB))
+            window = profile.get(
+                "receive-window-size",
+                (final.MIN_RECV_WIN * final.BYTES_IN_KB))
             window = int(int(window) / final.BYTES_IN_KB)
             cc_algo = profile.get("congestion-control", "")
             cc_algo = conv_utils.get_cc_algo_val(cc_algo)
             ip_dscp = profile.get("ip-tos-to-client", None)
             verified_accept = profile.get("verified-accept")
             ntwk_profile = {
                 "profile": {
@@ -1091,135 +1198,151 @@
                         "nagles_algorithm": nagle,
                         "max_syn_retransmissions": syn_retrans,
                         "max_retransmissions": retrans,
                         "idle_connection_type": conn_type,
                         "time_wait_delay": delay,
                         "receive_window": window,
                         "cc_algo": cc_algo,
-                        'automatic': False
+                        "automatic": False,
                     },
-                    "type": "PROTOCOL_TYPE_TCP_PROXY"
+                    "type": "PROTOCOL_TYPE_TCP_PROXY",
                 },
                 "name": name,
-                'verified-accept': verified_accept
+                "verified-accept": verified_accept,
             }
             if ip_dscp:
                 is_ip_dscp = True
-                if ip_dscp == 'pass-through':
+                if ip_dscp == "pass-through":
                     ip_dscp = 2147483647
-                elif ip_dscp == 'mimic':
+                elif ip_dscp == "mimic":
                     is_ip_dscp = False
-                    skipped.append('ip-tos-to-client')
+                    skipped.append("ip-tos-to-client")
                 if is_ip_dscp:
-                    ntwk_profile["profile"]["tcp_proxy_profile"]["ip_dscp"] = \
-                        ip_dscp
+                    ntwk_profile["profile"]["tcp_proxy_profile"]["ip_dscp"] = ip_dscp
 
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
-                    ntwk_profile, avi_config['NetworkProfile'],
-                    'network_profile', converted_objs, name,
-                    default_profile_name, merge_object_mapping, profile_type,
-                    self.prefix, sys_dict['NetworkProfile'])
+                    ntwk_profile,
+                    avi_config["NetworkProfile"],
+                    "network_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["NetworkProfile"],
+                )
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
-        elif profile_type == 'udp':
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
+        elif profile_type == "udp":
             supported_attr = self.supported_udp
             indirect = self.indirect_udp
             na_list = self.na_udp
-            u_ignore = user_ignore.get('udp', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            per_pkt = profile.get("datagram-load-balancing", 'disabled')
+            u_ignore = user_ignore.get("udp", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            per_pkt = profile.get("datagram-load-balancing", "disabled")
             timeout = str(profile.get("idle-timeout", 0))
             if not timeout.isdigit():
                 timeout = 0
             ntwk_profile = {
                 "profile": {
                     "type": "PROTOCOL_TYPE_UDP_FAST_PATH",
                     "udp_fast_path_profile": {
-                        "per_pkt_loadbalance": (per_pkt == 'enabled'),
-                        "session_idle_timeout": timeout
-                    }
+                        "per_pkt_loadbalance": (
+                            per_pkt == "enabled"),
+                        "session_idle_timeout": timeout},
                 },
-                "name": name
+                "name": name,
             }
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
                     ntwk_profile, avi_config['NetworkProfile'],
                     'network_profile', converted_objs, name,
                     default_profile_name, merge_object_mapping, profile_type,
                     self.prefix, sys_dict['NetworkProfile'])
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
         conv_status = conv_utils.get_conv_status(
             skipped, indirect, default_ignore, profile, u_ignore, na_list)
         if enf_skip_defaults:
-            conv_status['default_skip'].append(
+            conv_status["default_skip"].append(
                 {"enforcement": enf_skip_defaults})
-        conv_utils.add_conv_status('profile', profile_type, name, conv_status,
-                                   converted_objs)
+        needs_review=None
+        if partially_migrated_profiles.get(name):
+            conv_status['status']='PARTIAL'
+            needs_review=partially_migrated_profiles.get(name)
+
+        conv_utils.add_conv_status(
+            "profile",
+            profile_type,
+            name,
+            conv_status,
+            converted_objs,
+            yaml.dump(profile),
+            needs_review)
 
 
 class ProfileConfigConvV10(ProfileConfigConv):
-    def __init__(self, f5_profile_attributes, object_merge_check, prefix,
-                 keypassphrase, skip_pki, distinct_app_profile):
+    '''
+    Profile config conversion v10
+    '''
+
+    def __init__(self, f5_profile_attributes, object_merge_check,
+                 prefix, keypassphrase, skip_pki, distinct_app_profile):
         """
 
         :param f5_profile_attributes: f5 profile attributes from yaml file.
         :param object_merge_check: flag for merging objects
         :param prefix: prefix for objects
         :param keypassphrase: keypassphrase yaml file location
         :param skip_pki: PKI profile migration needs to be skipped
         :param distinct_app_profile: Merge duplicates needs to be slipped
         """
-        self.supported_types = f5_profile_attributes['Profile_supported_types']
+        self.supported_types = f5_profile_attributes["Profile_supported_types"]
         self.default_key = "defaults from"
-        self.supported_ssl = f5_profile_attributes['Profile_supported_ssl']
-        self.na_ssl = f5_profile_attributes['Profile_na_ssl']
-        self.indirect_ssl = f5_profile_attributes['Profile_indirect_ssl']
-        self.ignore_for_defaults = \
-            f5_profile_attributes['Profile_ignore_for_defaults']
-        self.na_http = f5_profile_attributes['Profile_na_http']
-        self.supported_http = f5_profile_attributes['Profile_supported_http']
-        self.indirect_http = f5_profile_attributes['Profile_indirect_http']
+        self.supported_ssl = f5_profile_attributes["Profile_supported_ssl"]
+        self.na_ssl = f5_profile_attributes["Profile_na_ssl"]
+        self.indirect_ssl = f5_profile_attributes["Profile_indirect_ssl"]
+        self.ignore_for_defaults = f5_profile_attributes["Profile_ignore_for_defaults"]
+        self.na_http = f5_profile_attributes["Profile_na_http"]
+        self.supported_http = f5_profile_attributes["Profile_supported_http"]
+        self.indirect_http = f5_profile_attributes["Profile_indirect_http"]
         self.na_dns = []
-        self.supported_dns = f5_profile_attributes['Profile_supported_dns']
+        self.supported_dns = f5_profile_attributes["Profile_supported_dns"]
         self.indirect_dns = []
-        self.supported_l4 = f5_profile_attributes['Profile_supported_l4']
-        self.indirect_l4 = f5_profile_attributes['Profile_indirect_l4']
-        self.supported_fh = f5_profile_attributes['Profile_supported_fh']
-        self.indirect_fh = f5_profile_attributes['Profile_indirect_fh']
-        self.supported_tcp = f5_profile_attributes['Profile_supported_tcp']
-        self.indirect_tcp = f5_profile_attributes['Profile_indirect_tcp']
-        self.supported_udp = f5_profile_attributes['Profile_supported_udp']
-        self.na_tcp = f5_profile_attributes['Profile_na_tcp']
+        self.supported_l4 = f5_profile_attributes["Profile_supported_l4"]
+        self.indirect_l4 = f5_profile_attributes["Profile_indirect_l4"]
+        self.supported_fh = f5_profile_attributes["Profile_supported_fh"]
+        self.indirect_fh = f5_profile_attributes["Profile_indirect_fh"]
+        self.supported_tcp = f5_profile_attributes["Profile_supported_tcp"]
+        self.indirect_tcp = f5_profile_attributes["Profile_indirect_tcp"]
+        self.supported_udp = f5_profile_attributes["Profile_supported_udp"]
+        self.na_tcp = f5_profile_attributes["Profile_na_tcp"]
         self.indirect_udp = []
-        self.na_udp = f5_profile_attributes['Profile_na_udp']
-        self.supported_oc = f5_profile_attributes['Profile_supported_oc']
+        self.na_udp = f5_profile_attributes["Profile_na_udp"]
+        self.supported_oc = f5_profile_attributes["Profile_supported_oc"]
         self.supported_enf = []
         self.ignore_for_defaults_enf = []
         self.na_enf = []
-        self.supported_enf = \
-            f5_profile_attributes['Profile_supported_http_enforcement']
-        self.ignore_for_defaults_enf = \
-            f5_profile_attributes['Profile_http_enf_ignore_for_defaults']
-        self.na_enf = \
-            f5_profile_attributes['Profile_na_http_enforcement']
-        self.indirect_enf = \
-            f5_profile_attributes['Profile_indirect_http_enforcement']
+        self.supported_enf = f5_profile_attributes["Profile_supported_http_enforcement"]
+        self.ignore_for_defaults_enf = f5_profile_attributes["Profile_http_enf_ignore_for_defaults"]
+        self.na_enf = f5_profile_attributes["Profile_na_http_enforcement"]
+        self.indirect_enf = f5_profile_attributes["Profile_indirect_http_enforcement"]
         if keypassphrase:
             self.f5_passphrase_keys = yaml.safe_load(open(keypassphrase))
         else:
             self.f5_passphrase_keys = None
         self.object_merge_check = object_merge_check
         # code to get count to merge objects
         self.app_count = 0
@@ -1230,15 +1353,15 @@
         self.prefix = prefix
         self.skip_pki = skip_pki
         self.distinct_app_profile = distinct_app_profile
 
     def convert_profile(self, profile, key, f5_config, profile_config,
                         avi_config, input_dir, user_ignore, tenant_ref,
                         key_and_cert_mapping_list, merge_object_mapping,
-                        sys_dict):
+                        sys_dict,migrated_cipher,migrated_cipher_group):
         """
 
         :param profile: parsed dict of profile
         :param key: key which contain combination of profile type and name
         :param f5_config: parsed f5 config dict
         :param profile_config: dict of profile config
         :param avi_config: dict for avi config conversion.
@@ -1251,586 +1374,676 @@
         :return:
         """
         skipped = profile.keys()
         indirect = []
         converted_objs = []
         u_ignore = []
         na_list = []
+        partially_migrated_profiles=dict()
         parent_cls = super(ProfileConfigConvV10, self)
         profile_type, name = key.split(" ")
         default_profile_name = '%s %s' % (profile_type, profile_type)
-        default_ignore = f5_config['profile'].get(default_profile_name, {})
+        default_ignore = f5_config["profile"].get(default_profile_name, {})
         default_ignore.update(self.ignore_for_defaults)
         tenant, name = conv_utils.get_tenant_ref(name)
         if tenant_ref:
             tenant = tenant_ref
         old_name = name
         default_profile_name = profile_type
         # Added prefix for objects
         if self.prefix:
             name = '%s-%s' % (self.prefix, name)
             default_profile_name = '%s-%s' % (self.prefix, default_profile_name)
         if profile_type in ("clientssl", "serverssl"):
             supported_attr = self.supported_ssl
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            u_ignore = user_ignore.get('clientssl', [])
-            u_ignore += user_ignore.get('serverssl', [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            u_ignore = user_ignore.get("clientssl", [])
+            u_ignore += user_ignore.get("serverssl", [])
             na_list = self.na_ssl
             indirect = self.indirect_ssl
             original_prof = profile_config.get('%s %s' % (profile_type,
                                                           old_name), None)
-            inherit_key = original_prof.get('inherit-certkeychain', 'true')
-            if inherit_key == 'false':
-                profile['key'] = original_prof.get("key", None)
-                profile['cert'] = original_prof.get("cert", None)
+            inherit_key = original_prof.get("inherit-certkeychain", "true")
+            if inherit_key == "false":
+                profile["key"] = original_prof.get("key", None)
+                profile["cert"] = original_prof.get("cert", None)
             cert_file = profile.get("cert", None)
             key_file = profile.get("key", None)
-            key_file = None if key_file == 'none' else key_file
-            cert_file = None if cert_file == 'none' else cert_file
+            key_file = None if key_file == "none" else key_file
+            cert_file = None if cert_file == "none" else cert_file
             if key_file and cert_file:
-                key_file = key_file.replace('\"', '')
-                cert_file = cert_file.replace('\"', '')
+                key_file = key_file.replace('"', "")
+                cert_file = cert_file.replace('"', "")
 
             parent_cls.update_key_cert_obj(
-                name, key_file, cert_file, input_dir, tenant_ref, avi_config,
-                converted_objs, default_profile_name, key_and_cert_mapping_list,
-                merge_object_mapping, sys_dict)
-            ssl_profile = dict()
-            ssl_profile['name'] = name
-            ssl_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            ssl_profile['accepted_ciphers'] = self.ciphers
-            close_notify = profile.get('unclean shutdown', None)
-            if close_notify and close_notify == 'enabled':
-                ssl_profile['send_close_notify'] = True
+                name,
+                key_file,
+                cert_file,
+                input_dir,
+                tenant_ref,
+                avi_config,
+                profile,
+                converted_objs,
+                default_profile_name,
+                key_and_cert_mapping_list,
+                merge_object_mapping,
+                sys_dict)
+
+            ssl_profile = {}
+            ssl_profile["name"] = name
+            ssl_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            if profile.get("alert-timeout"):
+                alert_timeout=profile.get("alert-timeout")
+                ssl_profile["ssl_session_timeout"] = alert_timeout if alert_timeout not in ['indefinite'] else 86400
+            if profile.get("ssl-ticket-timeout"):
+                ssl_profile["ssl_session_timeout"] = profile.get(
+                    "ssl-ticket-timeout")
+
+            accepted_ciphers=self.ciphers
+            unsupported_ciphers=None
+            ciphers = profile.get('ciphers','none')
+            accepted_ciphers = 'AES:3DES:RC4' if ciphers == 'DEFAULT' else accepted_ciphers
+            if ciphers not in ['none']:
+                if migrated_cipher.get(ciphers):
+                    accepted_ciphers=migrated_cipher.get(ciphers).get('mig_cipher')
+                    unsupported_ciphers=migrated_cipher.get(ciphers).get('unsupported_ciphers')
+
+            if unsupported_ciphers:
+                unsupp_mesg="Profile partially migrated due to presence of unsupported ciphers %s" %unsupported_ciphers
+                partially_migrated_profiles[name]=unsupp_mesg
+                LOG.warning("ssl %s %s" %(name,unsupp_mesg))
+
+
+            ssl_profile["accepted_ciphers"] = accepted_ciphers
+            close_notify = profile.get("unclean shutdown", None)
+            if close_notify and close_notify == "enabled":
+                ssl_profile["send_close_notify"] = True
             else:
-                ssl_profile['send_close_notify'] = False
+                ssl_profile["send_close_notify"] = False
             options = profile.get("options", "")
             if isinstance(options, dict):
                 opt = []
                 for opt_key in options.keys():
-                    opt.append(opt_key + ' ' + options[opt_key])
+                    opt.append(opt_key + " " + options[opt_key])
                 options = opt
             accepted_versions = []
             if "no tlsv1" not in options:
                 accepted_versions.append({"type": "SSL_VERSION_TLS1"})
             if "no tlsv1.1" not in options:
                 accepted_versions.append({"type": "SSL_VERSION_TLS1_1"})
             if "no tlsv1.2" not in options:
                 accepted_versions.append({"type": "SSL_VERSION_TLS1_2"})
             if accepted_versions:
                 ssl_profile["accepted_versions"] = accepted_versions
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
-                    ssl_profile, avi_config['SSLProfile'], 'ssl_profile',
-                    converted_objs, name, default_profile_name,
-                    merge_object_mapping, profile_type, self.prefix,
-                    sys_dict['SSLProfile'])
-                ssl_count['count'] += 1
-            else:
-                converted_objs.append({'ssl_profile': ssl_profile})
-                avi_config['SSLProfile'].append(ssl_profile)
-            crl_file_name = profile.get('crl file', None)
-            ca_file_name = profile.get('ca file', None)
-            if crl_file_name and crl_file_name != 'none':
-                crl_file_name = crl_file_name.replace('\"', '').strip()
+                    ssl_profile,
+                    avi_config["SSLProfile"],
+                    "ssl_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["SSLProfile"],
+                )
+                ssl_count["count"] += 1
+            else:
+                converted_objs.append({"ssl_profile": ssl_profile})
+                avi_config["SSLProfile"].append(ssl_profile)
+            crl_file_name = profile.get("crl file", None)
+            ca_file_name = profile.get("ca file", None)
+            if crl_file_name and crl_file_name != "none":
+                crl_file_name = crl_file_name.replace('"', "").strip()
             else:
                 crl_file_name = None
-            if ca_file_name and ca_file_name != 'none':
-                ca_file_name = ca_file_name.replace('\"', '').strip()
+            if ca_file_name and ca_file_name != "none":
+                ca_file_name = ca_file_name.replace('"', "").strip()
             else:
                 ca_file_name = None
             if ca_file_name and not self.skip_pki:
-                pki_profile = dict()
+                pki_profile = {}
                 file_path = input_dir + os.path.sep + ca_file_name
                 pki_profile["name"] = name
-                pc_mode = profile.get('peer-cert-mode', 'ignore')
-                if pc_mode == 'ignore':
-                    pc_mode = 'SSL_CLIENT_CERTIFICATE_NONE'
-                elif pc_mode == 'request':
-                    pc_mode = 'SSL_CLIENT_CERTIFICATE_REQUEST'
+                pc_mode = profile.get("peer-cert-mode", "ignore")
+                if pc_mode == "ignore":
+                    pc_mode = "SSL_CLIENT_CERTIFICATE_NONE"
+                elif pc_mode == "request":
+                    pc_mode = "SSL_CLIENT_CERTIFICATE_REQUEST"
                 else:
-                    pc_mode = 'SSL_CLIENT_CERTIFICATE_REQUIRE'
-                pki_profile['mode'] = pc_mode
-                pki_profile['tenant_ref'] = conv_utils.get_object_ref(
-                    tenant, 'tenant')
+                    pc_mode = "SSL_CLIENT_CERTIFICATE_REQUIRE"
+                pki_profile["mode"] = pc_mode
+                pki_profile["tenant_ref"] = conv_utils.get_object_ref(
+                    tenant, "tenant")
                 error = False
                 ca = conv_utils.upload_file(file_path)
                 if ca:
-                    pki_profile["ca_certs"] = [{'certificate': ca}]
+                    pki_profile["ca_certs"] = [{"certificate": ca}]
                 else:
                     error = True
                 if crl_file_name:
                     file_path = input_dir + os.path.sep + crl_file_name
                     crl = conv_utils.upload_file(file_path)
                     if crl:
-                        pki_profile["crls"] = [{'body': crl}]
+                        pki_profile["crls"] = [{"body": crl}]
                     else:
                         error = True
                 else:
-                    pki_profile['crl_check'] = False
+                    pki_profile["crl_check"] = False
                 if not error:
                     if self.object_merge_check:
-                        conv_utils.update_skip_duplicates(pki_profile,
-                                                          avi_config['PKIProfile'], 'pki_profile',
-                                                          converted_objs, name, default_profile_name,
-                                                          merge_object_mapping, None, self.prefix,
-                                                          sys_dict['PKIProfile'])
+                        conv_utils.update_skip_duplicates(
+                            pki_profile, avi_config['PKIProfile'],
+                            'pki_profile', converted_objs, name, default_profile_name,
+                            merge_object_mapping, None, self.prefix, sys_dict['PKIProfile'])
                         self.pki_count += 1
                     else:
-                        converted_objs.append({'pki_profile': pki_profile})
-                        avi_config['PKIProfile'].append(pki_profile)
-        elif profile_type == 'http':
+                        converted_objs.append({"pki_profile": pki_profile})
+                        avi_config["PKIProfile"].append(pki_profile)
+        elif profile_type == "http":
             app_profile, skipped = self.convert_http_profile(
                 profile, name, avi_config, converted_objs, tenant)
-            u_ignore = user_ignore.get('http', [])
+            u_ignore = user_ignore.get("http", [])
             na_list = self.na_http
             indirect = self.indirect_http
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
-        elif profile_type == 'dns':
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
+        elif profile_type == "dns":
             supported_attr = self.supported_dns
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            u_ignore = user_ignore.get('dns', [])
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_DNS'
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            u_ignore = user_ignore.get("dns", [])
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_DNS"
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
                     app_profile, avi_config['ApplicationProfile'],
                     'app_profile', converted_objs, name, default_profile_name,
                     merge_object_mapping, profile_type, self.prefix,
                     sys_dict['ApplicationProfile'])
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
-        elif profile_type == 'fastL4':
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
+        elif profile_type == "fastL4":
             supported_attr = self.supported_l4
             indirect = self.indirect_l4
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            u_ignore = user_ignore.get('fastL4', [])
-            hw_syn_protection = (profile.get("hardware syncookie",
-                                             None) == 'enabled')
-            sw_syn_protection = (profile.get("software syncookie",
-                                             None) == 'enabled')
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            u_ignore = user_ignore.get("fastL4", [])
+            hw_syn_protection = profile.get(
+                "hardware syncookie", None) == "enabled"
+            sw_syn_protection = profile.get(
+                "software syncookie", None) == "enabled"
 
-            syn_protection = (hw_syn_protection or sw_syn_protection)
+            syn_protection = hw_syn_protection or sw_syn_protection
 
-            description = profile.get('description', None)
+            description = profile.get("description", None)
             timeout = profile.get("idle timeout", final.MIN_SESSION_TIMEOUT)
             if int(timeout) < 60:
                 timeout = final.MIN_SESSION_TIMEOUT
-                LOG.warn("idle-timeout for profile: %s is less" % name +
-                         " than minimum, changed to Avis minimum value")
+                LOG.warning(
+                    "idle-timeout for profile: %s is less \
+                    than minimum, changed to Avis minimum value", name)
             elif int(timeout) > final.MAX_SESSION_TIMEOUT:
                 timeout = final.MAX_SESSION_TIMEOUT
-                LOG.warn("idle-timeout for profile: %s  is grater" % name +
-                         " than maximum, changed to Avis maximum value")
+                LOG.warning(
+                    "idle-timeout for profile: %s  is grater \
+                        than maximum, changed to Avis maximum value", name)
             verified_accept = profile.get("verified-accept")
             ntwk_profile = {
                 "profile": {
                     "tcp_fast_path_profile": {
                         "session_idle_timeout": timeout,
-                        "enable_syn_protection": syn_protection
-                    },
-                    "type": "PROTOCOL_TYPE_TCP_FAST_PATH"
+                        "enable_syn_protection": syn_protection},
+                    "type": "PROTOCOL_TYPE_TCP_FAST_PATH",
                 },
                 "name": name,
                 "description": description,
-                "verified-accept": verified_accept
+                "verified-accept": verified_accept,
             }
             app_profile = {
                 "type": "APPLICATION_PROFILE_TYPE_L4",
                 "name": name,
-                "description": description
-            }
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+                "description": description}
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
-                    ntwk_profile, avi_config['NetworkProfile'],
-                    'network_profile', converted_objs, name,
-                    default_profile_name, merge_object_mapping, profile_type,
-                    self.prefix, sys_dict['NetworkProfile'])
+                    ntwk_profile,
+                    avi_config["NetworkProfile"],
+                    "network_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["NetworkProfile"],
+                )
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
                 conv_utils.update_skip_duplicates(
-                    app_profile, avi_config['ApplicationProfile'],
-                    'app_profile', converted_objs, name, default_profile_name,
-                    merge_object_mapping, profile_type, self.prefix,
-                    sys_dict['ApplicationProfile'])
+                    app_profile,
+                    avi_config["ApplicationProfile"],
+                    "app_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["ApplicationProfile"],
+                )
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
 
-        elif profile_type == 'fasthttp':
+        elif profile_type == "fasthttp":
             supported_attr = self.supported_fh
-            u_ignore = user_ignore.get('fasthttp', [])
+            u_ignore = user_ignore.get("fasthttp", [])
             indirect = self.indirect_fh
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            app_profile = dict()
-            app_profile['name'] = name
-            app_profile['type'] = 'APPLICATION_PROFILE_TYPE_HTTP'
-            app_profile['description'] = profile.get('description', None)
-            http_profile = dict()
-            insert_xff = profile.get('insert xforwarded for', 'disabled')
-            insert_xff = True if insert_xff == 'enabled' else False
-            http_profile['x_forwarded_proto_enabled'] = insert_xff
-            http_profile['xff_enabled'] = insert_xff
-            header_size = profile.get('max header size',
-                                      final.DEFAULT_MAX_HEADER)
-            http_profile['client_max_header_size'] = \
-                int(header_size) / final.BYTES_IN_KB
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            app_profile = {}
+            app_profile["name"] = name
+            app_profile["type"] = "APPLICATION_PROFILE_TYPE_HTTP"
+            app_profile["description"] = profile.get("description", None)
+            http_profile = {}
+            insert_xff = profile.get("insert xforwarded for", "disabled")
+            insert_xff = insert_xff == "enabled"
+            http_profile["x_forwarded_proto_enabled"] = insert_xff
+            http_profile["xff_enabled"] = insert_xff
+            header_size = profile.get(
+                "max header size", final.DEFAULT_MAX_HEADER)
+            http_profile["client_max_header_size"] = int(
+                header_size) / final.BYTES_IN_KB
             app_profile["http_profile"] = http_profile
             # code to merge application profile count.
             if self.object_merge_check and not self.distinct_app_profile:
-                conv_utils.update_skip_duplicates \
-                    (app_profile, avi_config['ApplicationProfile'],
-                     'app_profile', converted_objs, name, default_profile_name,
-                     merge_object_mapping, profile_type, self.prefix,
-                     sys_dict['ApplicationProfile'])
+                conv_utils.update_skip_duplicates(
+                    app_profile,
+                    avi_config["ApplicationProfile"],
+                    "app_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["ApplicationProfile"],
+                )
                 self.app_count += 1
             else:
-                converted_objs.append({'app_profile': app_profile})
-                avi_config['ApplicationProfile'].append(app_profile)
+                converted_objs.append({"app_profile": app_profile})
+                avi_config["ApplicationProfile"].append(app_profile)
             timeout = profile.get("idle-timeout", 0)
             verified_accept = profile.get("verified-accept")
             ntwk_profile = {
                 "profile": {
                     "tcp_proxy_profile": {
                         "idle_connection_timeout": timeout,
-                        'automatic': False
-                    },
-                    "type": "PROTOCOL_TYPE_TCP_PROXY"
+                        "automatic": False},
+                    "type": "PROTOCOL_TYPE_TCP_PROXY",
                 },
                 "name": name,
-                "verified-accept": verified_accept
+                "verified-accept": verified_accept,
             }
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            app_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
+            app_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
-                conv_utils.update_skip_duplicates \
-                    (ntwk_profile, avi_config['NetworkProfile'],
-                     'network_profile', converted_objs, name,
-                     default_profile_name, merge_object_mapping,
-                     profile_type, self.prefix, sys_dict['NetworkProfile'])
+                conv_utils.update_skip_duplicates(
+                    ntwk_profile,
+                    avi_config["NetworkProfile"],
+                    "network_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["NetworkProfile"],
+                )
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
 
-        elif profile_type == 'oneconnect':
+        elif profile_type == "oneconnect":
             supported_attr = self.supported_oc
             indirect = []
-            u_ignore = user_ignore.get('oneconnect', [])
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            mask = profile.get('source mask', '0.0.0.0')
-            if not mask == '0.0.0.0':
-                skipped.append('source-mask')
-            converted_objs = \
-                'Maps Indirectly to : HTTP Profile -> Connection Multiplex'
-            LOG.warn('oneconnect profile %s will be mapped indirectly to HTTP '
-                     'Profile -> Connection Multiplex of the same VS if '
-                     'oneconnect-transformations is enabled' % name)
-            avi_config['OneConnect'].append(name)
-        elif profile_type == 'tcp':
-            u_ignore = user_ignore.get('tcp', [])
+            u_ignore = user_ignore.get("oneconnect", [])
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            mask = profile.get("source mask", "0.0.0.0")
+            if not mask == "0.0.0.0":
+                skipped.append("source-mask")
+            converted_objs = "Maps Indirectly to : HTTP Profile -> Connection Multiplex"
+            LOG.warning(
+                "oneconnect profile %s will be mapped indirectly to HTTP "
+                "Profile -> Connection Multiplex of the same VS if "
+                "oneconnect-transformations is enabled", name
+            )
+            avi_config["OneConnect"].append(name)
+        elif profile_type == "tcp":
+            u_ignore = user_ignore.get("tcp", [])
             supported_attr = self.supported_tcp
             indirect = self.indirect_tcp
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
             timeout = profile.get("idle timeout", 0)
-            nagle = profile.get("nagle", 'disabled')
-            nagle = False if nagle == 'disabled' else True
+            nagle = profile.get("nagle", "disabled")
+            nagle = nagle != "disabled"
             retrans = profile.get("max retrans", final.MIN_SYN_RETRANS)
-            retrans = final.MIN_SYN_RETRANS if \
-                int(retrans) < final.MIN_SYN_RETRANS else retrans
-            retrans = final.MAX_SYN_RETRANS if \
-                int(retrans) > final.MAX_SYN_RETRANS else retrans
-            syn_retrans = profile.get("max retrans syn",
-                                      final.MIN_SYN_RETRANS)
-            syn_retrans = final.MIN_SYN_RETRANS \
-                if int(syn_retrans) < final.MIN_SYN_RETRANS else syn_retrans
-            syn_retrans = final.MAX_SYN_RETRANS \
-                if int(syn_retrans) > final.MAX_SYN_RETRANS else syn_retrans
+            retrans = final.MIN_SYN_RETRANS if int(
+                retrans) < final.MIN_SYN_RETRANS else retrans
+            retrans = final.MAX_SYN_RETRANS if int(
+                retrans) > final.MAX_SYN_RETRANS else retrans
+            syn_retrans = profile.get("max retrans syn", final.MIN_SYN_RETRANS)
+            syn_retrans = final.MIN_SYN_RETRANS if int(
+                syn_retrans) < final.MIN_SYN_RETRANS else syn_retrans
+            syn_retrans = final.MAX_SYN_RETRANS if int(
+                syn_retrans) > final.MAX_SYN_RETRANS else syn_retrans
             conn_type = profile.get("time wait recycle", "disabled")
-            conn_type = "CLOSE_IDLE" if \
-                conn_type == "disabled" else "KEEP_ALIVE"
+            conn_type = "CLOSE_IDLE" if conn_type == "disabled" else "KEEP_ALIVE"
             delay = profile.get("time wait", 0)
             window = profile.get("recv window",
                                  (final.MIN_RECV_WIN * final.BYTES_IN_KB))
             window = int(int(window) / final.BYTES_IN_KB)
             cc_algo = profile.get("congestion-control", "")
             cc_algo = conv_utils.get_cc_algo_val(cc_algo)
             ip_dscp = profile.get("ip tos", None)
-            verified_accept=profile.get('verified-accept')
+            verified_accept = profile.get("verified-accept")
             ntwk_profile = {
                 "profile": {
                     "tcp_proxy_profile": {
                         "idle_connection_timeout": timeout,
                         "nagles_algorithm": nagle,
                         "max_syn_retransmissions": syn_retrans,
                         "max_retransmissions": retrans,
                         "idle_connection_type": conn_type,
                         "time_wait_delay": delay,
                         "receive_window": window,
                         "cc_algo": cc_algo,
-                        'automatic': False
+                        "automatic": False,
                     },
-                    "type": "PROTOCOL_TYPE_TCP_PROXY"
+                    "type": "PROTOCOL_TYPE_TCP_PROXY",
                 },
                 "name": name,
-                'verified-accept': verified_accept
+                "verified-accept": verified_accept,
             }
             if ip_dscp:
                 is_ip_dscp = True
-                if ip_dscp == 'pass':
+                if ip_dscp == "pass":
                     ip_dscp = 2147483647
-                elif ip_dscp == 'mimic':
+                elif ip_dscp == "mimic":
                     is_ip_dscp = False
-                    skipped.append('ip tos')
+                    skipped.append("ip tos")
                 if is_ip_dscp:
-                    ntwk_profile["profile"]["tcp_proxy_profile"]["ip_dscp"] = \
-                        ip_dscp
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+                    ntwk_profile["profile"]["tcp_proxy_profile"]["ip_dscp"] = ip_dscp
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
-                conv_utils.update_skip_duplicates \
-                    (ntwk_profile, avi_config['NetworkProfile'],
-                     'network_profile', converted_objs, name,
-                     default_profile_name, merge_object_mapping,
-                     profile_type, self.prefix, sys_dict['NetworkProfile'])
+                conv_utils.update_skip_duplicates(
+                    ntwk_profile,
+                    avi_config["NetworkProfile"],
+                    "network_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["NetworkProfile"],
+                )
 
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
-        elif profile_type == 'udp':
-            u_ignore = user_ignore.get('udp', [])
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
+        elif profile_type == "udp":
+            u_ignore = user_ignore.get("udp", [])
             supported_attr = self.supported_udp
             na_list = self.na_udp
-            skipped = [attr for attr in profile.keys()
-                       if attr not in supported_attr]
-            per_pkt = profile.get("datagram lb", 'disable')
+            skipped = [
+                attr for attr in profile.keys() if attr not in supported_attr]
+            per_pkt = profile.get("datagram lb", "disable")
             timeout = profile.get("idle timeout", 0)
             if not timeout.isdigit():
                 timeout = 0
             ntwk_profile = {
                 "profile": {
                     "type": "PROTOCOL_TYPE_UDP_FAST_PATH",
                     "udp_fast_path_profile": {
-                        "per_pkt_loadbalance": (per_pkt == 'enable'),
-                        "session_idle_timeout": timeout
-                    }
+                        "per_pkt_loadbalance": (
+                            per_pkt == "enable"),
+                        "session_idle_timeout": timeout},
                 },
-                "name": name
+                "name": name,
             }
-            ntwk_profile['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
+            ntwk_profile["tenant_ref"] = conv_utils.get_object_ref(
+                tenant, "tenant")
             # code to get merge count of network profile.
             if self.object_merge_check:
                 conv_utils.update_skip_duplicates(
-                    ntwk_profile, avi_config['NetworkProfile'],
-                    'network_profile', converted_objs, name,
-                    default_profile_name, merge_object_mapping, profile_type,
-                    self.prefix, sys_dict['NetworkProfile'])
+                    ntwk_profile,
+                    avi_config["NetworkProfile"],
+                    "network_profile",
+                    converted_objs,
+                    name,
+                    default_profile_name,
+                    merge_object_mapping,
+                    profile_type,
+                    self.prefix,
+                    sys_dict["NetworkProfile"],
+                )
                 self.net_count += 1
             else:
-                converted_objs.append({'network_profile': ntwk_profile})
-                avi_config['NetworkProfile'].append(ntwk_profile)
-        elif profile_type == 'persist':
-            mode = profile.get("mode").replace(' ', '-')
+                converted_objs.append({"network_profile": ntwk_profile})
+                avi_config["NetworkProfile"].append(ntwk_profile)
+        elif profile_type == "persist":
+            mode = profile.get("mode").replace(" ", "-")
             f5_config["persistence"]['%s %s' % (mode, name)] = profile
             return
 
         conv_status = conv_utils.get_conv_status(
             skipped, indirect, default_ignore, profile, u_ignore, na_list)
-        conv_utils.add_conv_status('profile', profile_type, name, conv_status,
-                                   converted_objs)
+        needs_review=None
+        if partially_migrated_profiles.get(name):
+            conv_status['status']='PARTIAL'
+            needs_review=partially_migrated_profiles.get(name)
+
+        conv_utils.add_conv_status(
+            "profile",
+            profile_type,
+            name,
+            conv_status,
+            converted_objs,
+            yaml.dump(profile),
+            needs_review)
 
-    def convert_http_profile(self, profile, name, avi_config, converted_objs,
-                             tenant):
+    def convert_http_profile(
+            self, profile, name, avi_config, converted_objs, tenant):
         """
         :param profile: parsed profile config dict.
         :param name: name of http profile.
         :param avi_config: dict to store converted avi config
         :param converted_objs: list of converted object
         :param tenant: Tenant for which config need to be converted
         :return: app_profile, skipped
         """
         supported_attr = self.supported_http
         skipped = [key for key in profile.keys() if key not in supported_attr]
-        app_profile = dict()
-        app_profile['name'] = name
-        app_profile['tenant_ref'] = conv_utils.get_object_ref(tenant, 'tenant')
-        app_profile['type'] = 'APPLICATION_PROFILE_TYPE_HTTP'
-        http_profile = dict()
-        encpt_cookie = profile.get('encrypt cookies', 'none')
-        encpt_cookie = False if encpt_cookie == 'none' else True
-        con_mltplxng = profile.get('oneconnect transformations', 'disabled')
-        con_mltplxng = False if con_mltplxng == 'disabled' else True
-        insert_xff = profile.get('insert xforwarded for', 'disabled')
-        insert_xff = True if insert_xff == 'enabled' else False
-        http_profile['x_forwarded_proto_enabled'] = insert_xff
-        xff_alt_names = profile.get('xff alternative names', None)
-        xff_alt_names = None if xff_alt_names == 'none' else xff_alt_names
-        http_profile['xff_alternate_name'] = xff_alt_names
-        header_size = profile.get('max header size', final.DEFAULT_MAX_HEADER)
-        http_profile['client_max_header_size'] = int(
+        app_profile = {}
+        app_profile["name"] = name
+        app_profile["tenant_ref"] = conv_utils.get_object_ref(tenant, "tenant")
+        app_profile["type"] = "APPLICATION_PROFILE_TYPE_HTTP"
+        http_profile = {}
+        encpt_cookie = profile.get("encrypt cookies", "none")
+        encpt_cookie = encpt_cookie != "none"
+        con_mltplxng = profile.get("oneconnect transformations", "disabled")
+        con_mltplxng = con_mltplxng != "disabled"
+        insert_xff = profile.get("insert xforwarded for", "disabled")
+        insert_xff = insert_xff == "enabled"
+        http_profile["x_forwarded_proto_enabled"] = insert_xff
+        xff_alt_names = profile.get("xff alternative names", None)
+        xff_alt_names = None if xff_alt_names == "none" else xff_alt_names
+        http_profile["xff_alternate_name"] = xff_alt_names
+        header_size = profile.get("max header size", final.DEFAULT_MAX_HEADER)
+        http_profile["client_max_header_size"] = int(
             header_size) / final.BYTES_IN_KB
-        http_profile['connection_multiplexing_enabled'] = con_mltplxng
-        http_profile['secure_cookie_enabled'] = encpt_cookie
-        if not profile.get('redirect-rewrite'):
-            http_profile['hsts_enabled'] = True
+        http_profile["connection_multiplexing_enabled"] = con_mltplxng
+        http_profile["secure_cookie_enabled"] = encpt_cookie
+        if not profile.get("redirect-rewrite"):
+            http_profile["hsts_enabled"] = True
         app_profile["http_profile"] = http_profile
-        fallback_host = profile.get("fallback", 'none')
-        fallback_host = None if fallback_host == 'none' else fallback_host
+        fallback_host = profile.get("fallback", "none")
+        fallback_host = None if fallback_host == "none" else fallback_host
         if fallback_host:
-            app_profile['fallback_host'] = fallback_host
+            app_profile["fallback_host"] = fallback_host
 
-        cache = profile.get('ramcache', 'disable')
-        if not cache == 'disable':
-            cache_config = dict()
-            cache_config['min_object_size'] = profile.get(
-                'ramcache min object size', final.MIN_CACHE_OBJ_SIZE)
-            cache_config['query_cacheable'] = True
-            cache_config['max_object_size'] = profile.get(
-                'ramcache max object size', final.MAX_CACHE_OBJ_SIZE)
-            age_header = profile.get('ramcache insert age header', 'disable')
-            if age_header == 'enable':
-                cache_config['age_header'] = True
-            else:
-                cache_config['age_header'] = False
-            cache_config['enabled'] = True
-            cache_config['default_expire'] = profile.get(
-                'ramcache max age', final.DEFAULT_CACHE_MAX_AGE)
+        cache = profile.get("ramcache", "disable")
+        if not cache == "disable":
+            cache_config = {}
+            cache_config["min_object_size"] = profile.get(
+                "ramcache min object size", final.MIN_CACHE_OBJ_SIZE)
+            cache_config["query_cacheable"] = True
+            cache_config["max_object_size"] = profile.get(
+                "ramcache max object size", final.MAX_CACHE_OBJ_SIZE)
+            age_header = profile.get("ramcache insert age header", "disable")
+            if age_header == "enable":
+                cache_config["age_header"] = True
+            else:
+                cache_config["age_header"] = False
+            cache_config["enabled"] = True
+            cache_config["default_expire"] = profile.get(
+                "ramcache max age", final.DEFAULT_CACHE_MAX_AGE)
             exclude_uri = profile.get("ramcache uri exclude", None)
             include_uri = profile.get("ramcache uri include", None)
             if exclude_uri and isinstance(exclude_uri, dict):
                 exclude_uri = exclude_uri.keys() + exclude_uri.values()
                 if None in exclude_uri:
                     exclude_uri.remove(None)
-                cache_config['mime_types_block_lists'] = exclude_uri
+                cache_config["mime_types_block_lists"] = exclude_uri
             if include_uri and isinstance(include_uri, dict):
                 include_uri = include_uri.keys() + include_uri.values()
                 if None in include_uri:
                     include_uri.remove(None)
-                cache_config['mime_types_list'] = include_uri
+                cache_config["mime_types_list"] = include_uri
             http_profile["cache_config"] = cache_config
-        compression = profile.get('compress', 'disable')
-        if not compression == 'disable':
-            compression_profile = dict()
+        compression = profile.get("compress", "disable")
+        if not compression == "disable":
+            compression_profile = {}
             compression_profile["type"] = "AUTO_COMPRESSION"
             compression_profile["compression"] = True
             encoding = profile.get("compress keep accept encoding", "disable")
-            if encoding == "disable":
-                encoding = True
-            else:
-                encoding = False
+            encoding = encoding == "disable"
             compression_profile["remove_accept_encoding_header"] = encoding
             content_type = profile.get("compress content type include", "")
-            content_type = None if content_type == 'none' else content_type
+            content_type = None if content_type == "none" else content_type
             ct_exclude = profile.get("compress content type exclude", "")
-            content_type_exclude = None if ct_exclude == 'none' else ct_exclude
+            content_type_exclude = None if ct_exclude == "none" else ct_exclude
             if content_type and isinstance(content_type, str):
                 content_type = content_type.split(" ")
             elif content_type and isinstance(content_type, dict):
-                content_type = list(content_type.keys()) + list(content_type.values())
+                content_type = list(content_type.keys()) + \
+                    list(content_type.values())
                 content_type = list(set(content_type))
                 content_type.remove(None)
             elif content_type_exclude:
                 content_type = final.DEFAULT_CONTENT_TYPE
             if content_type_exclude:
-                content_type_exclude = content_type_exclude.keys() + \
-                                       content_type_exclude.values()
-                content_type = [ct for ct in content_type
-                                if ct not in content_type_exclude]
+                content_type_exclude = content_type_exclude.keys() + content_type_exclude.values()
+                content_type = [
+                    ct for ct in content_type if ct not in content_type_exclude]
             if content_type:
                 sg_obj = conv_utils.get_content_string_group(
                     name, content_type, tenant)
-                avi_config['StringGroup'].append(sg_obj)
-                converted_objs.append({'string_group': sg_obj})
+                avi_config["StringGroup"].append(sg_obj)
+                converted_objs.append({"string_group": sg_obj})
                 cc_ref = name + "-content_type"
                 cc_ref = conv_utils.get_object_ref(
-                    cc_ref, 'stringgroup', tenant=tenant)
+                    cc_ref, "stringgroup", tenant=tenant)
                 compression_profile["compressible_content_ref"] = cc_ref
             http_profile["compression_profile"] = compression_profile
         app_profile["http_profile"] = http_profile
-        header_erase = profile.get('header-erase', None)
-        header_erase = None if header_erase == 'none' else header_erase
+        header_erase = profile.get("header-erase", None)
+        header_erase = None if header_erase == "none" else header_erase
 
         if header_erase:
-            header_erase = header_erase.replace('\"', '').strip()
-        header_insert = profile.get('header-insert', None)
-        header_insert = None if header_insert == 'none' else header_insert
+            header_erase = header_erase.replace('"', "").strip()
+        header_insert = profile.get("header-insert", None)
+        header_insert = None if header_insert == "none" else header_insert
         if header_insert:
-            header_insert = header_insert.replace('\"', '').strip()
+            header_insert = header_insert.replace('"', "").strip()
 
         if header_erase or header_insert:
             rules = []
             rule_index = 1
             # Added condition of header insert and header erase present then
             # create common rule with more action.
             if header_erase and header_insert:
-                header_erase = header_erase.split(':')[0]
-                header, val = header_insert.split(':')
+                header_erase = header_erase.split(":")[0]
+                header, val = header_insert.split(":")
                 header_erase_rule = conv_utils.create_hdr_erase_rule(
-                    'rule-header-erase', header_erase, rule_index)
+                    "rule-header-erase", header_erase, rule_index)
                 header_insert_rule = conv_utils.create_hdr_insert_rule(
-                    'rule-header-insert', header, val, rule_index)
-                header_erase_rule['hdr_action'].append(header_insert_rule[
-                                                           'hdr_action'][0])
+                    "rule-header-insert", header, val, rule_index)
+                header_erase_rule["hdr_action"].append(
+                    header_insert_rule["hdr_action"][0])
                 rules.append(header_erase_rule)
             elif header_erase:
-                if ':' in header_erase:
-                    header_erase = header_erase.split(':')[0]
-                rules.append(conv_utils.create_hdr_erase_rule(
-                    'rule-header-erase', header_erase, rule_index))
+                if ":" in header_erase:
+                    header_erase = header_erase.split(":")[0]
+                rules.append(
+                    conv_utils.create_hdr_erase_rule(
+                        "rule-header-erase",
+                        header_erase,
+                        rule_index))
             elif header_insert:
-                header, val = header_insert.split(':')
-                rules.append(conv_utils.create_hdr_insert_rule(
-                    'rule-header-insert', header, val, rule_index))
+                header, val = header_insert.split(":")
+                rules.append(
+                    conv_utils.create_hdr_insert_rule(
+                        "rule-header-insert",
+                        header,
+                        val,
+                        rule_index))
             rule_index += 1
             policy_name = name + '-HTTP-Policy-Set'
             policy = {
                 "name": policy_name,
                 "http_request_policy": {
-                    "rules": rules
-                },
-                "is_internal_policy": False
-            }
-            policy['tenant_ref'] = conv_utils.get_object_ref(
-                tenant, 'tenant')
-            avi_config['HTTPPolicySet'].append(policy)
+                    "rules": rules},
+                "is_internal_policy": False}
+            policy["tenant_ref"] = conv_utils.get_object_ref(tenant, "tenant")
+            avi_config["HTTPPolicySet"].append(policy)
             app_profile["HTTPPolicySet"] = policy_name
-            converted_objs.append({'policy_set': policy})
+            converted_objs.append({"policy_set": policy})
         return app_profile, skipped
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/scp_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/scp_util.py`

 * *Files 18% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 # SPDX-License-Identifier: Apache License 2.0
 
 import logging
 import os
 
 from avi.migrationtools.scp_util import SCPUtil
 
-
 LOG = logging.getLogger(__name__)
 
 
 def get_files_from_f5(local_path, host, username, pw=None, key=None, port=22):
     """
 
     :param local_path: relative path to file
@@ -18,36 +17,42 @@
     :param username: username for instance
     :param pw: password for instance
     :param key: keyfile.
     :return:
     """
     local_path = local_path + os.path.sep
     scp = SCPUtil(host, username, pw, key, port)
-    scp.get_all_files('/config/ssl/ssl.crl/', local_path)
-    scp.get_all_files('/config/ssl/ssl.crt/', local_path)
-    scp.get_all_files('/config/ssl/ssl.csr/', local_path)
-    scp.get_all_files('/config/ssl/ssl.key/', local_path)
-    scp.get_all_files('/config/monitors/', local_path)
+    scp.get_all_files("/config/ssl/ssl.crl/", local_path)
+    scp.get_all_files("/config/ssl/ssl.crt/", local_path)
+    scp.get_all_files("/config/ssl/ssl.csr/", local_path)
+    scp.get_all_files("/config/ssl/ssl.key/", local_path)
+    scp.get_all_files("/config/monitors/", local_path)
     # Added support to get cert and key for V13.
     try:
-        scp.get_all_partition_certkey('/config/filestore/files_d/', local_path)
+        scp.get_all_partition_certkey("/config/filestore/files_d/", local_path)
+    except:
+        pass
+    scp.get("/config/bigip.conf", local_path + "bigip.conf")
+    try:
+        scp.get("/config/profile_base.conf", local_path + "profile_base.conf")
     except:
         pass
-    scp.get('/config/bigip.conf', local_path + 'bigip.conf')
     try:
-        scp.get('/config/profile_base.conf', local_path + 'profile_base.conf')
+        scp.get(
+            "/usr/share/monitors/base_monitors.conf",
+            local_path +
+            "base_monitors.conf")
     except:
         pass
     try:
-        scp.get('/usr/share/monitors/base_monitors.conf', local_path +
-                'base_monitors.conf')
+        scp.get("/config/bigip_gtm.conf", local_path + "bigip_gtm.conf")
     except:
         pass
     try:
-        scp.get('/config/bigip_gtm.conf', local_path + 'bigip_gtm.conf')
+        scp.get_all_partition_config("/config/partitions/", local_path)
     except:
         pass
     try:
-        scp.get_all_partition_config('/config/partitions/', local_path)
+        scp.get('/config/cipher.conf', local_path + 'cipher.conf')
     except:
         pass
     scp.close()
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/avi_config.json` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/avi_config.json`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/bigip_v10.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/bigip_v10.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/bigip_v11.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/bigip_v11.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/cacert.pem` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/cacert.pem`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/cakey.pem` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/cakey.pem`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/default.crt` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/default.crt`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/default.key` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/default.key`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.crt` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.crt`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.key` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/certs/monitor.fmr.com.key`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/conftest.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/conftest.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/custom_config.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/custom_config.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/excel_reader.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/excel_reader.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/hol_advanced_bigip.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/hol_advanced_bigip.conf`

 * *Files 0% similar despite different names*

```diff
@@ -2723,14 +2723,25 @@
         /Common/client_ssl_profile {
             context clientside
         }
     }
     translate-address enabled
     translate-port enabled
 }
+ltm virtual /Common/101-hol-advanced-http-vs {
+    destination /Common/172.16.10.120:443
+    ip-protocol udp
+    mask 255.255.255.255
+    pool /Common/hol-advanced-pool-10
+    profiles {
+        /Common/udp { }
+    }
+    translate-address enabled
+    translate-port enabled
+}
 ltm profile client-ssl /Common/client_ssl_profile {
     app-service none
     cert /Common/monitor.fmr.com.crt
     cert-key-chain {
         client_ssl_cert_key_chain {
             cert /Common/monitor.fmr.com.crt
             chain /Common/monitor.fmr.com.crt
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/ignore-config.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/ignore-config.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/patch.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/patch.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_avi_to_ansible.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_avi_to_ansible.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_config_patch.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_config_patch.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_f5_conversion_v10.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_f5_conversion_v10.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_f5_conversion_v11.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_f5_conversion_v11.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_migrationtool.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_migrationtool.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,20 +1,18 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 """
 This testsuite contains the initial test cases for testing the
 f5 converter tool along with its options / parameters
 """
-import unittest
 import json
 import logging
 import os
 import subprocess
-import sys
 
 import pandas as pd
 import pytest
 import yaml
 from avi.migrationtools.f5_converter.test.conftest import option
 from avi.migrationtools.avi_migration_utils import MigrationUtil
 from avi.migrationtools.avi_migration_utils import get_count, set_update_count
@@ -23,15 +21,14 @@
 from avi.migrationtools.test.common.excel_reader \
     import percentage_success, output_sanitization, output_vs_level_status
 from avi.migrationtools.test.common.test_clean_reboot \
     import verify_controller_is_up, clean_reboot
 from avi.migrationtools.test.common.test_tenant_cloud \
     import create_segroup, create_vrf_context
 import ansible_runner
-from avi.migrationtools.avi_migration_utils import MigrationUtil
 common_avi_util = MigrationUtil()
 
 config_file = option.config
 input_file = option.file
 input_file_version = option.fileVersion
 output_file = option.out
 # config_file = pytest.config.getoption("--config")
@@ -95,14 +92,15 @@
                                                'ignore-config.yaml')),
     patch=os.path.abspath(os.path.join(os.path.dirname(__file__),
                                        'patch.yaml')),
     vs_filter='EngVIP,F5-VIP-80-001,F5-VIP-443-002',
     not_in_use=True,
     skip_file=False,
     ansible=True,
+    skip_disabled_vs=False,
     baseline_profile=None,
     f5_passphrase_file=os.path.abspath(os.path.join(
         os.path.dirname(__file__), 'passphrase.yaml')),
     f5_ansible_object=os.path.abspath(os.path.join(
         os.path.dirname(__file__), 'output',
         'avi_config_create_object.yml')),
     vs_level_status=True,
@@ -139,15 +137,15 @@
         password=None, controller_ip=None,
         tenant='admin', cloud_name=ARG_DEFAULT_VALUE['cloud_name'],
         vs_state=ARG_DEFAULT_VALUE['vs_state'],
         controller_version=None, f5_host_ip=None, f5_ssh_user=None,
         f5_ssh_password=None, f5_ssh_port=None, f5_key_file=None,
         ignore_config=None, partition_config=None, version=False,
         no_profile_merge=False, patch=None, vs_filter=None,
-        ansible_skip_types=[], ansible_filter_types=[], ansible=False,
+        ansible_skip_types=[], ansible_filter_types=[], ansible=False, skip_disabled_vs=False,
         prefix=None, convertsnat=False, not_in_use=False, baseline_profile=None,
         f5_passphrase_file=None, vs_level_status=False, test_vip=None,
         vrf=None, segroup=None, custom_config=None, skip_pki=False,
         distinct_app_profile=False, reuse_http_policy=False, args_config_file=None):
     args = Namespace(bigip_config_file=bigip_config_file,
                      skip_default_file=skip_default_file,
                      f5_config_version=f5_config_version,
@@ -157,16 +155,17 @@
                      tenant=tenant, cloud_name=cloud_name, vs_state=vs_state,
                      controller_version=controller_version,
                      f5_host_ip=f5_host_ip, f5_ssh_user=f5_ssh_user,
                      f5_ssh_password=f5_ssh_password,
                      f5_ssh_port=f5_ssh_port, f5_key_file=f5_key_file,
                      ignore_config=ignore_config,
                      partition_config=partition_config, version=version,
-                     no_object_merge=no_profile_merge, patch=patch,
+                     object_merge=no_profile_merge, patch=patch,
                      vs_filter=vs_filter, ansible_skip_types=ansible_skip_types,
+                     skip_disabled_vs=skip_disabled_vs,
                      ansible_filter_types=ansible_filter_types, ansible=ansible,
                      prefix=prefix, convertsnat=convertsnat,
                      not_in_use=not_in_use, baseline_profile=baseline_profile,
                      f5_passphrase_file=f5_passphrase_file,
                      vs_level_status=vs_level_status, test_vip=test_vip,
                      vrf=vrf, segroup=segroup,
                      custom_config=custom_config,
@@ -915,20 +914,20 @@
         o_file = "%s/%s" % (output_file, "hol_advanced_bigip-Output.json")
         with open(o_file) as json_file:
             data = json.load(json_file)
             vs_object = data['VirtualService']
 
             first_vs = [data for data in vs_object if data['name'] == "11-hol-advanced-http-vs"]
             second_vs = [data for data in vs_object if data['name'] == "12-hol-advanced-http-vs"]
-
-            first_pool = first_vs[0]['pool_ref'].split(
-                'name=')[1].split('&')[0]
-            second_pool = second_vs[0]['pool_ref'].split(
-                'name=')[1].split('&')[0]
-            assert first_pool == second_pool
+            if first_vs and second_vs:
+                first_pool = first_vs[0]['pool_ref'].split(
+                    'name=')[1].split('&')[0]
+                second_pool = second_vs[0]['pool_ref'].split(
+                    'name=')[1].split('&')[0]
+                assert first_pool == second_pool
 
     @pytest.mark.travis
     @pytest.mark.TCID1_48_1497_44_0
     def test_pool_without_sharing_on_v11(self):
         f5_conv(bigip_config_file=setup.get('config_file_name_v11'),
                 f5_config_version=setup.get('file_version_v11'),
                 controller_version=setup.get('controller_version_v17'),
@@ -941,19 +940,19 @@
         o_file = "%s/%s" % (output_file, "hol_advanced_bigip-Output.json")
         with open(o_file) as json_file:
             data = json.load(json_file)
             vs_object = data['VirtualService']
 
             first_vs = [data for data in vs_object if data['name'] == "10-hol-advanced-http-vs"]
             second_vs = [data for data in vs_object if data['name'] == "11-hol-advanced-http-vs"]
-
-            first_pool = first_vs[0]['pool_ref'].split('name=')[1].split('&')[0]
-            second_pool = second_vs[0]['pool_ref'].split('name=')[1].split(
-                '&')[0]
-            assert first_pool != second_pool
+            if first_vs and second_vs:
+                first_pool = first_vs[0]['pool_ref'].split('name=')[1].split('&')[0]
+                second_pool = second_vs[0]['pool_ref'].split('name=')[1].split(
+                    '&')[0]
+                assert first_pool != second_pool
 
     @pytest.mark.travis
     @pytest.mark.TCID1_48_1497_45_0
     def test_pool_sharing_on_v10(self):
         f5_conv(bigip_config_file=setup.get('config_file_name_v10'),
                 f5_config_version=setup.get('file_version_v10'),
                 controller_version=setup.get('controller_version_v17'),
@@ -996,18 +995,19 @@
             vs_object = data['VirtualService']
 
             first_vs = [data for data in vs_object if data['name'] ==
                         "F5-v10-VIP-443-001"]
             second_vs = [data for data in vs_object if data['name'] ==
                          "F5-v10-VIP-443-002"]
 
-            first_pool = first_vs[0]['pool_ref'].split('name=')[1].split('&')[0]
-            second_pool = second_vs[0]['pool_ref'].split('name=')[1].split(
-                '&')[0]
-            assert first_pool != second_pool
+            if first_vs and second_vs:
+                first_pool = first_vs[0]['pool_ref'].split('name=')[1].split('&')[0]
+                second_pool = second_vs[0]['pool_ref'].split('name=')[1].split(
+                    '&')[0]
+                assert first_pool != second_pool
 
     @pytest.mark.travis
     @pytest.mark.TCID1_48_1497_47_0
     def test_rule_config_v11(self):
         f5_conv(bigip_config_file=setup.get('config_file_name_v11'),
                 f5_config_version=setup.get('file_version_v11'),
                 controller_version=setup.get('controller_version_v17'),
@@ -1435,15 +1435,15 @@
         with open(o_file) as json_file:
             data = json.load(json_file)
             hm_object = data['HealthMonitor']
             monitor_urls = []
             for monitor in hm_object:
                 if 'https_monitor' in monitor:
                     monitor_urls.append(monitor['https_monitor'][
-                                            'http_request'])
+                        'http_request'])
                 elif 'http_monitor' in monitor:
                     monitor_urls.append(monitor['http_monitor']['http_request'])
             for eachUrl in monitor_urls:
                 request = eachUrl.split('\\r')[0]
                 assert (request.endswith('HTTP/1.1') or
                         request.endswith('HTTP/1.0'))
 
@@ -1543,18 +1543,16 @@
         with open(o_file) as json_file:
             data = json.load(json_file)
             vs_object = data['VirtualService']
             first_vs = [vs for vs in vs_object if vs['name']
                         == "81-hol-advanced-http-vs-dmz"][0]
             second_vs = [vs for vs in vs_object if vs['name']
                          == "82-hol-advanced-http-vs-dmz"][0]
-            vs1_http_policy = first_vs['http_policies'][0] \
-                ['http_policy_set_ref'].split("=")[-1]
-            vs2_http_policy = second_vs['http_policies'][0] \
-                ['http_policy_set_ref'].split("=")[-1]
+            vs1_http_policy = first_vs['http_policies'][0]['http_policy_set_ref'].split("=")[-1]
+            vs2_http_policy = second_vs['http_policies'][0]['http_policy_set_ref'].split("=")[-1]
             assert vs1_http_policy == vs2_http_policy
             http_policies = data['HTTPPolicySet']
             shared_http_policy = [policy for policy in http_policies
                                   if "hol_hdr_insert-HTTP-Policy-Set"
                                   in policy['name']]
             assert len(shared_http_policy) == 1
 
@@ -1574,20 +1572,18 @@
         with open(o_file) as json_file:
             data = json.load(json_file)
             vs_object = data['VirtualService']
             first_vs = [vs for vs in vs_object if vs['name']
                         == "vs_http_policy_share_1"][0]
             second_vs = [vs for vs in vs_object if vs['name']
                          == "vs_http_policy_share_2"][0]
-            vs1_http_policy = first_vs['http_policies'][0] \
-                ['http_policy_set_ref'].split("=")[-1]
-            vs2_http_policy = second_vs['http_policies'][0] \
-                ['http_policy_set_ref'].split("=")[-1]
+            vs1_http_policy = first_vs['http_policies'][0]['http_policy_set_ref'].split("=")[-1]
+            vs2_http_policy = second_vs['http_policies'][0]['http_policy_set_ref'].split("=")[-1]
             assert vs1_http_policy == vs2_http_policy == \
-                   '_sys_https_redirect'
+                '_sys_https_redirect'
             http_policies = data['HTTPPolicySet']
             shared_http_policy = [policy for policy in http_policies
                                   if "_sys_https_redirect"
                                   in policy['name']]
             assert len(shared_http_policy) == 1
 
     @pytest.mark.travis
@@ -1684,15 +1680,15 @@
                 na_attr = common_avi_util.format_string_to_json(na_attr)
                 for item in na_attr:
                     if isinstance(item, dict):
                         for k in item.keys():
                             if k == 'enforcement':
                                 enf = item[k]
                                 for item in enf:
-                                    assert item in ['max-requests', 'truncated-redirects',]
+                                    assert item in ['max-requests', 'truncated-redirects', ]
                                 break
 
     def test_profile_indirect_http_enforcement(self, cleanup):
         f5_conv(bigip_config_file=setup.get('config_file_name_v11'),
                 f5_config_version=setup.get('file_version_v11'),
                 controller_version=setup.get('controller_version_v17'),
                 tenant=file_attribute['tenant'],
@@ -1744,15 +1740,15 @@
                             for k in item.keys():
                                 if k == 'enforcement':
                                     enf = item[k]
                                     for item in enf:
                                         assert item not in ['max-requests', 'truncated-redirects', 'pipeline']
                                     break
 
-    def test_skipped_objects(self,cleanup):
+    def test_skipped_objects(self, cleanup):
         """
         test case for skipped objct
         """
         f5_conv(bigip_config_file=setup.get('config_file_name_v11'),
                 f5_config_version=setup.get('file_version_v11'),
                 controller_version=setup.get('controller_version_v17'),
                 tenant=file_attribute['tenant'],
@@ -1767,15 +1763,15 @@
         )
         data = pd.read_excel(self.excel_path)
         for k, row in data.iterrows():
             if row['F5 SubType'] in ["universal", "dest-addr"]:
                 assert row['Status'] == 'SKIPPED'
 
     def test_tenant_ref(self):
-        input =["/common/test-monitor", "common/test-monitor","common test-monitor"]
+        input = ["/common/test-monitor", "common/test-monitor", "common test-monitor"]
         for ipt in input:
             tenant, name = common_avi_util.get_tenant_ref(ipt)
             assert tenant == tenant.strip()
             assert tenant != "common"
             assert not name.__contains__("name=")
             assert not name.__contains__("/")
             assert not name.__contains__("=")
@@ -1787,24 +1783,27 @@
                 tenant=file_attribute['tenant'],
                 cloud_name=file_attribute['cloud_name'],
                 no_profile_merge=file_attribute['no_profile_merge'],
                 output_file_path=setup.get('output_file_path'),
                 f5_ssh_port=setup.get('f5_ssh_port'),
                 vs_filter='81-hol-advanced-http-vs-dmz')
 
+    def test_verify_vip_with_duplicate_protocol(self, cleanup):
+        f5_conv(bigip_config_file=setup.get('config_file_name_v11'),
+                f5_config_version=setup.get('file_version_v11'),
+                controller_version=setup.get('controller_version_v17'),
+                tenant=file_attribute['tenant'],
+                cloud_name=file_attribute['cloud_name'],
+                no_profile_merge=file_attribute['no_profile_merge'],
+                output_file_path=setup.get('output_file_path'),
+                f5_ssh_port=setup.get('f5_ssh_port'),
+                vs_filter='100-hol-advanced-http-vs,101-hol-advanced-http-vs')
+
         o_file = "%s/%s" % (output_file, "hol_advanced_bigip-Output.json")
         with open(o_file) as json_file:
             data = json.load(json_file)
-            vs_object = data['VirtualService'][0]
-            http_policy_set = data['HTTPPolicySet']
-        http_policy_name = vs_object.get('http_policies', None)[0] \
-            ['http_policy_set_ref'].split("=")[-1]
-        http_request_policy = [policy for policy in http_policy_set if policy['name'] == http_policy_name][0]
-        policy = http_request_policy.get('http_request_policy', None)
-        rule = policy.get('rules', None)[1]
-        hdr_action = rule.get('hdr_action')[0]
-        assert hdr_action['action'] == 'HTTP_ADD_HDR'
-        assert hdr_action['hdr']['name'] == 'via'
-
+            vs_object = data['VirtualService']
+            for each_vs in vs_object:
+                assert each_vs['name'] in ['100-hol-advanced-http-vs', '101-hol-advanced-http-vs']
 
 def teardown():
     pass
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_pool_converter.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_pool_converter.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_pool_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_pool_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_profile_conversion.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_profile_conversion.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/test/test_profile_converter.conf` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/test/test_profile_converter.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_converter/vs_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_converter/vs_converter.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,78 +1,103 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-import logging
 import copy
-import random
+import logging
 import re
+
 import avi.migrationtools.f5_converter.converter_constants as final
-from avi.migrationtools.f5_converter.conversion_util import F5Util
-from avi.migrationtools.f5_converter.policy_converter import used_pools
+import yaml
 from avi.migrationtools.avi_migration_utils import update_count
+from avi.migrationtools.f5_converter.conversion_util import F5Util
+from avi.migrationtools.f5_converter.policy_converter import (
+    http_to_https_policy_rule, used_pools)
+from avi.migrationtools.f5_converter.profile_converter import (
+    ssl_profile_with_sni_child, ssl_profile_with_sni_parent)
 from pkg_resources import parse_version
 
 LOG = logging.getLogger(__name__)
 # Creating f5 object for util library.
 conv_utils = F5Util()
-used_policy = list()
-used_app_profiles = list()
-via_header_rule_dict=dict()
-policy_with_via_header=dict()
+used_policy = []
+used_app_profiles = []
+via_header_rule_dict = {}
+policy_with_via_header = {}
+
 
 class VSConfigConv(object):
+    '''
+    Vs Conversion Class
+    '''
     @classmethod
-    def get_instance(cls, version, f5_virtualservice_attributes, prefix,
-                     con_snatpool, custom_mappings, distinct_app_profile):
+    def get_instance(
+            cls,
+            version,
+            f5_virtualservice_attributes,
+            prefix,
+            con_snatpool,
+            custom_mappings,
+            distinct_app_profile):
         """
 
         :param version:  version of f5 instance
         :param f5_virtualservice_attributes: yaml attribute file for object
         :param prefix: prefix for objects
         :param con_snatpool: flag for converting snat into  individual address
         :param custom_mappings: custom config to migrate irules
         :return:
         """
-        if version == '10':
-            return VSConfigConvV10(f5_virtualservice_attributes, prefix,
-                                   con_snatpool, custom_mappings,
-                                   distinct_app_profile)
-        if version in ['11', '12']:
-            return VSConfigConvV11(f5_virtualservice_attributes, prefix,
-                                   con_snatpool, custom_mappings,
-                                   distinct_app_profile)
+        if version == "10":
+            return VSConfigConvV10(
+                f5_virtualservice_attributes,
+                prefix,
+                con_snatpool,
+                custom_mappings,
+                distinct_app_profile)
+        if version in ["11", "12"]:
+            return VSConfigConvV11(
+                f5_virtualservice_attributes,
+                prefix,
+                con_snatpool,
+                custom_mappings,
+                distinct_app_profile)
 
     def get_persist_ref(self, f5_vs):
+        '''
+        get persistence reference
+        '''
         pass
 
-    def convert_translate_port(self, avi_config, f5_vs, app_prof, pool_ref,
-                               sys_dict):
+    def convert_translate_port(
+            self, avi_config, f5_vs, app_prof, pool_ref, sys_dict):
+        '''
+        this methoud is used for converting translate port
+        '''
         pass
 
     def create_partition_mapping(self, f5_vs, vs_name):
-        dest = f5_vs['destination']
+        """
+            f5_vs : F5 vs confifguration
+            vs_name : virtual service name
+        """
+        dest = f5_vs["destination"]
         tenant, vs_name = conv_utils.get_tenant_ref(vs_name)
         if not tenant:
-            tenant = 'admin'
-        if not tenant in dest:
+            tenant = "admin"
+        if tenant not in dest:
             vip = dest
         else:
-            vip = dest.split('/')[-1]
-        p_mapping = {
-            vip: {
-                'vs_name': vs_name,
-                'partition': tenant
-            }
-        }
+            vip = dest.split("/")[-1]
+        p_mapping = {vip: {"vs_name": vs_name, "partition": tenant}}
         return p_mapping
 
     def convert(self, f5_config, avi_config, vs_state, user_ignore, tenant,
                 cloud_name, controller_version, merge_object_mapping, sys_dict,
                 vrf=None, segroup=None, partition_mapping=None,
-                reuse_http_policy=False):
+                reuse_http_policy=False, skip_disabled_vs=False):
         """
 
         :param f5_config: Parsed f5 config dict
         :param avi_config: dict for avi conversion
         :param vs_state: State of created Avi VS object
         :param user_ignore: Ignore config defined by user
         :param tenant: Tenant for which config need to be converted
@@ -80,63 +105,89 @@
         :param controller_version: AVI controller version
         :param merge_object_mapping: flag for merge object
         :param sys_dict: baseline profile dict
         :param vrf: vrf user input to put vrf ref in VS object
         :param segroup: segroup user input to put se-group ref in VS object
         :return:
         """
+
         f5_snat_pools = f5_config.get("snatpool", {})
         vs_config = f5_config.get("virtual", {})
-        avi_config['VirtualService'] = []
-        avi_config['VSDataScriptSet'] = []
-        avi_config['NetworkSecurityPolicy'] = []
-        avi_config['VsVip'] = []
+        avi_config["VirtualService"] = []
+        avi_config["VSDataScriptSet"] = []
+        avi_config["NetworkSecurityPolicy"] = []
+        avi_config["VsVip"] = []
         print("Converting VirtualServices ...")
         # Added variable to get total object count.
         total_size = len(vs_config.keys())
         progressbar_count = 0
         for vs_name in vs_config.keys():
             progressbar_count += 1
             try:
-                LOG.debug("Converting VS: %s" % vs_name)
+                LOG.debug("Converting VS: %s", vs_name)
                 f5_vs = vs_config[vs_name]
-                vs_type = [key for key in f5_vs.keys()
-                           if key in self.unsupported_types]
+                vs_type = [
+                    key for key in f5_vs.keys() if key in self.unsupported_types]
                 if vs_type:
                     msg = ("VS type: %s not supported by Avi skipped VS: %s" %
                            (vs_type, vs_name))
+                    LOG.warning(msg)
+                    conv_utils.add_status_row(
+                        "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+                    continue
+                if skip_disabled_vs and "disabled" in f5_vs.keys():
+                    msg = ("VS : Skipping %s , As it is disabled on f5 " %
+                           (vs_name))
+                    LOG.warning(msg)
+                    conv_utils.add_status_row(
+                        "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+                    continue
+                if skip_disabled_vs and "disabled" in f5_vs.keys():
+                    msg = ("VS : Skipping %s , As it is disabled on f5 " %
+                           (vs_name))
                     LOG.warn(msg)
                     conv_utils.add_status_row('virtual', None, vs_name,
                                               final.STATUS_SKIPPED, msg)
                     continue
                 mapping = self.create_partition_mapping(f5_vs, vs_name)
                 partition_mapping.update(mapping)
 
-                vs_obj = self.convert_vs(
+                vs_obj, vs_sni_parent_obj = self.convert_vs(
                     vs_name, f5_vs, vs_state, avi_config, f5_snat_pools,
                     user_ignore, tenant, cloud_name, controller_version,
-                    merge_object_mapping, sys_dict, f5_config, vrf, 
+                    merge_object_mapping, sys_dict, f5_config, vrf,
                     reuse_http_policy)
                 if vs_obj:
                     if segroup:
                         segroup_ref = conv_utils.get_object_ref(
-                            segroup, 'serviceenginegroup', tenant=tenant,
-                            cloud_name=cloud_name)
-                        vs_obj['se_group_ref'] = segroup_ref
-                    avi_config['VirtualService'].append(vs_obj)
-                    LOG.debug("Conversion successful for VS: %s" % vs_name)
-            except:
-                update_count('error')
-                LOG.error("Failed to convert VS: %s" % vs_name, exc_info=True)
+                            segroup, "serviceenginegroup", tenant="admin", cloud_name=cloud_name)
+                        vs_obj["se_group_ref"] = segroup_ref
+                    avi_config["VirtualService"].append(vs_obj)
+                    LOG.debug("Conversion successful for VS: %s", vs_name)
+                    if vs_sni_parent_obj:
+                        if segroup:
+                            segroup_ref = conv_utils.get_object_ref(
+                                segroup, "serviceenginegroup", tenant="admin",
+                                cloud_name=cloud_name)
+                            vs_sni_parent_obj["se_group_ref"] = segroup_ref
+                        avi_config["VirtualService"].append(vs_sni_parent_obj)
+                # LOG.debug("Conversion successful for VS: %s" % vs_name)
+
+            except BaseException:
+                update_count("error")
+                LOG.error("Failed to convert VS: %s", vs_name, exc_info=True)
             # Added call to get the progress.
             msg = "virtualservice conversion started..."
             conv_utils.print_progress_bar(
-                progressbar_count, total_size, msg, prefix='Progress',
-                suffix='')
-        LOG.debug("Converted %s VS" % len(avi_config['VirtualService']))
+                progressbar_count,
+                total_size,
+                msg,
+                prefix="Progress",
+                suffix="")
+        LOG.debug("Converted %s VS", len(avi_config["VirtualService"]))
         f5_config.pop("virtual", {})
 
     def convert_vs(self, vs_name, f5_vs, vs_state, avi_config, snat_config,
                    user_ignore, tenant_ref, cloud_name, controller_version,
                    merge_object_mapping, sys_dict, f5_config, vrf=None,
                    reuse_http_policy=False):
         """
@@ -159,162 +210,182 @@
         tenant, vs_name = conv_utils.get_tenant_ref(vs_name)
         tenant_name = tenant
         if tenant_ref:
             tenant = tenant_ref
         # Added prefix for objects
         if self.prefix:
             vs_name = '{}-{}'.format(self.prefix, vs_name)
-        hash_profiles = avi_config.get('hash_algorithm', [])
+        hash_profiles = avi_config.get("hash_algorithm", [])
         description = f5_vs.get("description", None)
-        skipped = [key for key in f5_vs.keys()
-                   if key not in self.supported_attr]
-        enabled = (vs_state == 'enable')
+        skipped = [key for key in f5_vs.keys(
+        ) if key not in self.supported_attr]
+        enabled = vs_state == "enable"
         if enabled:
             enabled = False if "disabled" in f5_vs.keys() else True
         profiles = f5_vs.get("profiles", {})
         ssl_vs, ssl_pool = conv_utils.get_vs_ssl_profiles(
-            profiles, avi_config, self.prefix, merge_object_mapping, sys_dict,
-            f5_config)
+            profiles, avi_config, self.prefix, merge_object_mapping, sys_dict, f5_config)
 
-        if (ssl_vs and len(ssl_vs) > 1) or (ssl_pool and len(ssl_pool)> 1):
+        if (ssl_vs and len(ssl_vs) > 1) or (ssl_pool and len(ssl_pool) > 1):
             needs_review = True
 
         oc_prof = False
         for prof in profiles:
-            prof_name = prof.split('/')[-1] if '/' in prof else prof
-            if prof_name in avi_config.get('OneConnect', []):
+            prof_name = prof.split("/")[-1] if "/" in prof else prof
+            if prof_name in avi_config.get("OneConnect", []):
                 oc_prof = True
         enable_ssl = False
+        vs_sni_type = "VS_TYPE_NORMAL"
+        vh_type = "VS_TYPE_VH_SNI"
+        child_domain_name = None
+
         if ssl_vs:
             enable_ssl = True
+            ssl_profile_name = ssl_vs[0]["profile"].split("name=")[-1]
+            if ssl_profile_name in ssl_profile_with_sni_parent:
+                vs_sni_type = "VS_TYPE_VH_PARENT"
+
+            child_domain_name = ssl_profile_with_sni_child.get(
+                ssl_profile_name)
+            if child_domain_name:
+                vs_sni_type = "VS_TYPE_VH_CHILD"
+
         app_prof_conf = conv_utils.get_vs_app_profiles(
-            profiles, avi_config, tenant, self.prefix, oc_prof, enable_ssl,
-            merge_object_mapping, sys_dict)
-        app_prof = app_prof_conf.get('app_prof', None)
-        f_host = app_prof_conf.get('f_host', None)
-        realm = app_prof_conf.get('realm', None)
-        app_pol_name = app_prof_conf.get('app_pol_name', None)
+            profiles, avi_config, tenant, self.prefix, oc_prof,
+            enable_ssl, merge_object_mapping, sys_dict
+        )
+        app_prof = app_prof_conf.get("app_prof", None)
+        f_host = app_prof_conf.get("f_host", None)
+        realm = app_prof_conf.get("realm", None)
+        app_pol_name = app_prof_conf.get("app_pol_name", None)
 
         if not app_prof:
             msg = ('Profile type not supported by Avi Skipping VS : %s'
                    % vs_name)
             LOG.warning(msg)
-            conv_utils.add_status_row('virtual', None, vs_name,
-                                      final.STATUS_SKIPPED, msg)
-            return None
+            conv_utils.add_status_row(
+                "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+            return None, None
 
         ntwk_prof = conv_utils.get_vs_ntwk_profiles(
             profiles, avi_config, self.prefix, merge_object_mapping, sys_dict)
 
         # If one connect profile is not assigned to f5 VS and avi app profile
         # assigned to VS has connection_multiplexing_enabled value True then
         # clone profile and make connection_multiplexing_enabled as False
         pool_ref = f5_vs.get("pool", None)
         app_name = conv_utils.get_name(app_prof[0])
-        app_prof_obj = [obj for obj in (sys_dict['ApplicationProfile'] +
-                                        avi_config['ApplicationProfile']) if
-                        obj['name'] == app_name]
+        app_prof_obj = [
+            obj for obj in (
+                sys_dict["ApplicationProfile"] +
+                avi_config["ApplicationProfile"]) if obj["name"] == app_name]
         cme = True
         app_prof_type = None
         if app_prof_obj:
-            app_prof_type = app_prof_obj[0].get('type')
+            app_prof_type = app_prof_obj[0].get("type")
         else:
-            if app_name == 'System-L4-Application':
-                app_prof_type = 'APPLICATION_PROFILE_TYPE_L4'
-            elif app_name in ['System-HTTP', 'System-Secure-HTTP']:
-                app_prof_type = 'APPLICATION_PROFILE_TYPE_HTTP'
-            elif app_name == 'System-SSL-Application':
-                app_prof_type = 'APPLICATION_PROFILE_TYPE_SSL'
-
-        if app_prof_type == 'APPLICATION_PROFILE_TYPE_HTTP':
-            cme = app_prof_obj[0]['http_profile'].get(
-                'connection_multiplexing_enabled', False)
+            if app_name == "System-L4-Application":
+                app_prof_type = "APPLICATION_PROFILE_TYPE_L4"
+            elif app_name in ["System-HTTP", "System-Secure-HTTP"]:
+                app_prof_type = "APPLICATION_PROFILE_TYPE_HTTP"
+            elif app_name == "System-SSL-Application":
+                app_prof_type = "APPLICATION_PROFILE_TYPE_SSL"
+
+        if app_prof_type == "APPLICATION_PROFILE_TYPE_HTTP":
+            cme = app_prof_obj[0]["http_profile"].get(
+                "connection_multiplexing_enabled", False)
         if app_prof_obj and not (cme and oc_prof):
             # Check if already cloned profile present
             app_prof_cmd = [obj for obj in (
                     sys_dict['ApplicationProfile'] +
                     avi_config['ApplicationProfile']) if
                             obj['name'] == '%s-cmd' % app_name]
             if app_prof_cmd:
-                app_name = app_prof_cmd[0]['name']
+                app_name = app_prof_cmd[0]["name"]
                 app_prof[0] = conv_utils.get_object_ref(
-                    app_name, 'applicationprofile',
-                    tenant=conv_utils.get_name(app_prof_cmd[0]['tenant_ref']))
+                    app_name, "applicationprofile",
+                    tenant=conv_utils.get_name(app_prof_cmd[0]["tenant_ref"])
+                )
             else:
                 app_prof_cmd = copy.deepcopy(app_prof_obj[0])
                 app_prof_cmd['name'] = '%s-cmd' % app_prof_cmd['name']
                 if 'http_profile' in app_prof_cmd:
                     app_prof_cmd['http_profile'][
                         'connection_multiplexing_enabled'] = False
                 avi_config['ApplicationProfile'].append(app_prof_cmd)
                 app_name = app_prof_cmd['name']
                 app_prof[0] = conv_utils.get_object_ref(
-                    app_name, 'applicationprofile',
-                    tenant=conv_utils.get_name(app_prof_cmd['tenant_ref']))
+                    app_name, "applicationprofile", tenant=conv_utils.get_name(
+                        app_prof_cmd["tenant_ref"]))
         destination = f5_vs.get("destination", None)
+        description = f5_vs.get("description", None)
         d_tenant, destination = conv_utils.get_tenant_ref(destination)
+
+        ip_protocol=f5_vs.get("ip-protocol")
         # if destination is not present then skip vs.
         services_obj, ip_addr, vsvip_ref, vrf_ref = conv_utils.get_service_obj(
-            destination, avi_config, enable_ssl, controller_version, tenant,
-            cloud_name, self.prefix, vs_name, vrf)
+            destination, avi_config, enable_ssl, controller_version,
+            tenant, cloud_name, self.prefix, vs_name, ip_protocol,vrf
+        )
+
         # Added check for same vip in same vrf
         if vsvip_ref == '':
+
             msg = "Skipped: Virtualservice %s has repeated vip not in " \
                   "different vrf" % vs_name
             LOG.debug(msg)
-            conv_utils.add_status_row('virtual', None, vs_name,
-                                      final.STATUS_SKIPPED, msg)
-            return
+            conv_utils.add_status_row(
+                "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+            return None, None
         # Added Check for if port is no digit skip vs.
         if not services_obj and not ip_addr and not vsvip_ref:
             msg = "Skipped Virtualservice : %s" % vs_name
             LOG.debug(msg)
-            conv_utils.add_status_row('virtual', None, vs_name,
-                                      final.STATUS_SKIPPED, msg)
-            return
+            conv_utils.add_status_row(
+                "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+            return None, None
 
         is_pool_group = False
         if pool_ref:
             p_tenant, pool_ref = conv_utils.get_tenant_ref(pool_ref)
             if tenant_ref:
                 p_tenant = tenant_ref
             persist_ref = self.get_persist_ref(f5_vs)
-            avi_persistence = avi_config['ApplicationPersistenceProfile']
-            syspersist = sys_dict['ApplicationPersistenceProfile']
+            avi_persistence = avi_config["ApplicationPersistenceProfile"]
+            syspersist = sys_dict["ApplicationPersistenceProfile"]
             persist_type = None
             if persist_ref:
                 # Called tenant ref to get object name
                 persist_ref = conv_utils.get_tenant_ref(persist_ref)[1]
                 if self.prefix:
                     persist_ref = '{}-{}'.format(self.prefix, persist_ref)
-                persist_profile_objs = (
-                        [ob for ob in syspersist if ob['name'] ==
-                         merge_object_mapping['app_per_profile'].get(
-                             persist_ref)] or
-                        [obj for obj in avi_persistence if
-                         (obj["name"] == persist_ref or persist_ref in obj.get(
-                             "dup_of", []))])
-                persist_type = (persist_profile_objs[0]['persistence_type'] if
-                                persist_profile_objs else None)
+                persist_profile_objs = [
+                    ob for ob in syspersist if ob["name"] ==
+                    merge_object_mapping["app_per_profile"].get(persist_ref)
+                ] or [obj for obj in avi_persistence
+                      if (obj["name"] == persist_ref or
+                          persist_ref in obj.get("dup_of", []))]
+                persist_type = persist_profile_objs[0]["persistence_type"] \
+                    if persist_profile_objs else None
             # Pool cloned if controller version < 17.1.6 or VS has non http
             # cookie persistence or app profile type is different and poolgroup
             # cloned
             pool_ref, is_pool_group = conv_utils.clone_pool_if_shared(
                 pool_ref, avi_config, vs_name, tenant, p_tenant, persist_type,
                 controller_version, app_prof[0], sys_dict,
                 cloud_name=cloud_name, prefix=self.prefix)
             if ssl_pool:
                 if is_pool_group:
-                    conv_utils.add_ssl_to_pool_group(avi_config, pool_ref,
-                                                     ssl_pool[0], tenant)
+                    conv_utils.add_ssl_to_pool_group(
+                        avi_config, pool_ref, ssl_pool[0], tenant)
                     conv_utils.remove_http_mon_from_pool_group(
                         avi_config, pool_ref, tenant, sys_dict)
                 else:
-                    conv_utils.add_ssl_to_pool(avi_config['Pool'], pool_ref,
-                                               ssl_pool[0], tenant)
+                    conv_utils.add_ssl_to_pool(
+                        avi_config["Pool"], pool_ref, ssl_pool[0], tenant)
                     conv_utils.remove_http_mon_from_pool(
                         avi_config, pool_ref, tenant, sys_dict)
             else:
                 # TODO Remove this once controller support this scenario.
                 if is_pool_group:
                     conv_utils.remove_https_mon_from_pool_group(
                         avi_config, pool_ref, tenant, sys_dict)
@@ -336,47 +407,55 @@
                             avi_config['Pool'], pool_ref, persist_ref,
                             hash_profiles, avi_persistence, tenant,
                             merge_object_mapping, syspersist, app_prof_type)
 
                 if not pool_updated:
                     skipped.append("persist")
                     LOG.warning(
-                        "persist profile %s not found for vs:%s" %
-                        (persist_ref, vs_name))
-            if (oc_prof and not ssl_vs and
-                    persist_type == 'PERSISTENCE_TYPE_TLS' or
-                    persist_type == 'PERSISTENCE_TYPE_TLS'
-                    and not enable_ssl):
+                        "persist profile %s not found for vs:%s ",
+                        persist_ref, vs_name)
+            if (
+                oc_prof
+                and not ssl_vs
+                and persist_type == "PERSISTENCE_TYPE_TLS"
+                or persist_type == "PERSISTENCE_TYPE_TLS"
+                and not enable_ssl
+            ):
                 msg = ("Skipped VS : '%s' Secure persistence is applicable only"
                        " if SSL is enabled for Virtual Service" % vs_name)
                 LOG.warning(msg)
-                conv_utils.add_status_row('virtual', None, vs_name,
-                                          final.STATUS_SKIPPED, msg)
-                return
+                conv_utils.add_status_row(
+                    "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+                return None, None
             # TODO: Followiong condition to be removed after controller adds
             # TODO: support for PERSISTENCE_TYPE_TLS for SSL VS
-            elif (persist_type == 'PERSISTENCE_TYPE_TLS' and
-                  app_prof_type == 'APPLICATION_PROFILE_TYPE_SSL'):
+            if persist_type == "PERSISTENCE_TYPE_TLS" and \
+                    app_prof_type == "APPLICATION_PROFILE_TYPE_SSL":
                 msg = ("Skipped VS : '%s' Only client-ip persistence is "
                        "applicable for SSL VS" % vs_name)
                 LOG.warning(msg)
-                conv_utils.add_status_row('virtual', None, vs_name,
-                                          final.STATUS_SKIPPED, msg)
-                return
+                conv_utils.add_status_row(
+                    "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+                return None, None
             if f_host:
                 conv_utils.update_pool_for_fallback(
-                    f_host, avi_config['Pool'], pool_ref)
+                    f_host, avi_config["Pool"], pool_ref)
         ip_addr = ip_addr.strip()
-        matches = re.findall('^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', ip_addr)
-        if not matches or ip_addr == '0.0.0.0':
-            LOG.warning('Avi does not support IPv6 : %s. '
-                        'Generated random ipv4 for vs: %s' % (ip_addr, vs_name))
-            vs_name += '-needs-ipv6-ip'
-            ip_addr = ".".join(map(str, (
-                random.randint(0, 255) for _ in range(4))))
+        ip_type = "V4"
+        if f5_vs.get("nat64", None):
+            ip_type = "v6"
+        matches = re.findall(
+            "^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$", ip_addr)
+        # if not matches or ip_addr == '0.0.0.0':
+        #  LOG.warning('Avi does not support IPv6 : %s. '
+        #              'Generated random ipv4 for vs: %s' % (ip_addr, vs_name))
+        #  vs_name += '-needs-ipv6-ip'
+        #  ip_addr = ".".join(map(str, (
+        #      random.randint(0, 255) for _ in range(4))))
+        #  ip_type="V6"
 
         if app_prof_obj:
             if self.distinct_app_profile and app_prof[0] in used_app_profiles:
                 app_prof[0] = conv_utils.clone_app_profile_for_vs(
                     app_prof[0], app_prof_obj[0], vs_name, tenant, avi_config)
             used_app_profiles.append(app_prof[0])
 
@@ -385,541 +464,664 @@
         #     'ip_address': {
         #         'addr': ip_addr,
         #         'type': 'V4'
         #     },
         #     'vip_id': '1'
         # }
         vs_obj = {
-            'name': vs_name,
-            'description': description,
-            'type': 'VS_TYPE_NORMAL',
-            'enabled': enabled,
-            'traffic_enabled': enabled,
-            'cloud_ref': conv_utils.get_object_ref(
-                cloud_name, 'cloud', tenant=tenant),
-            'services': services_obj,
-            'application_profile_ref': app_prof[0],
-            'vs_datascripts': [],
-            'tenant_ref': conv_utils.get_object_ref(tenant, 'tenant')
+            "name": vs_name,
+            "description": description,
+            "type": vs_sni_type,
+            "enabled": enabled,
+            "traffic_enabled": enabled,
+            "cloud_ref": conv_utils.get_object_ref(
+                cloud_name,
+                "cloud",
+                tenant=tenant),
+            "services": services_obj,
+            "application_profile_ref": app_prof[0],
+            "vs_datascripts": [],
+            "tenant_ref": conv_utils.get_object_ref(
+                tenant,
+                "tenant"),
+            "vh_type": vh_type,
         }
 
         if vrf:
-            vrf_ref = conv_utils.get_object_ref(vrf, 'vrfcontext',
-                                                tenant=tenant_name,
-                                                cloud_name=cloud_name)
+            vrf_ref = conv_utils.get_object_ref(
+                vrf, "vrfcontext", tenant=tenant_name, cloud_name=cloud_name)
         if vrf_ref:
-            vs_obj['vrf_context_ref'] = vrf_ref
+            vs_obj["vrf_context_ref"] = vrf_ref
             # Added code for assigning VS's vrf ref to poolgroup/pool having no
             # vrf ref
             if is_pool_group:
                 conv_utils.set_pool_group_vrf(pool_ref, vrf_ref, avi_config)
             elif pool_ref:
                 conv_utils.set_pool_vrf(pool_ref, vrf_ref, avi_config)
         else:
             # Added code for removing vrf ref from poolgroup/pool if VS is not
             # having vrf ref
             if is_pool_group:
                 conv_utils.remove_pool_group_vrf(pool_ref, avi_config)
             elif pool_ref:
                 conv_utils.remove_pool_vrf(pool_ref, avi_config)
-
-        vsvip_addr = {
-                'addr': ip_addr,
-                'type': 'V4'
+        vs_sni_parent_obj = []
+        if vs_sni_type == "VS_TYPE_VH_CHILD":
+            vs_sni_parent_obj = {
+                "name": "%s-sni-parent" % vs_name,
+                "description": description,
+                "type": "VS_TYPE_VH_PARENT",
+                "enabled": enabled,
+                "services": services_obj,
+                "traffic_enabled": enabled,
+                "cloud_ref": conv_utils.get_object_ref(
+                    cloud_name,
+                    "cloud",
+                    tenant=tenant),
+                "tenant_ref": conv_utils.get_object_ref(
+                    tenant,
+                    "tenant"),
+                "vh_type": vh_type,
             }
-        if parse_version(controller_version) >= parse_version('17.1'):
+
+        vsvip_addr = {"addr": ip_addr, "type": ip_type}
+        if parse_version(controller_version) >= parse_version("17.1"):
             # vs_obj['vip'] = [vip]
-            vs_obj['vsvip_ref'] = vsvip_ref
+            if vs_sni_type == "VS_TYPE_VH_CHILD":
+                vs_sni_parent_obj["vsvip_ref"] = vsvip_ref
+            else:
+                vs_obj["vsvip_ref"] = vsvip_ref
             # vs_obj['ip_address'] = vsvip_addr
         else:
-            vs_obj['ip_address'] = vsvip_addr
+            if vs_sni_type == "VS_TYPE_VH_CHILD":
+                vs_sni_parent_obj["ip_address"] = vsvip_addr
+            else:
+                vs_obj["ip_address"] = vsvip_addr
+
+        if vs_sni_type == "VS_TYPE_VH_CHILD":
+            vs_obj["vh_parent_vs_ref"] = conv_utils.get_object_ref(
+                vs_sni_parent_obj.get("name"),
+                "virtualservice", tenant=tenant, cloud_name=cloud_name)
+            vs_obj["vh_domain_name"] = [child_domain_name]
+            vs_obj.pop("services")
+        #  avi_config['VirtualService'].append(vs_sni_parent_obj)
+
         # Policy tracking starts from here
         vs_policies = [app_pol_name] if app_pol_name else []
         vs_ds_rules = None
-        vs_ds = list()
+        vs_ds = []
         nw_policy = None
-        converted_rules = list()
-        if 'rules' in f5_vs:
-            if isinstance(f5_vs['rules'], str):
-                vs_ds_rules = [conv_utils.get_tenant_ref(f5_vs['rules'])[1]]
+        converted_rules = []
+        if "rules" in f5_vs:
+            if isinstance(f5_vs["rules"], str):
+                vs_ds_rules = [conv_utils.get_tenant_ref(f5_vs["rules"])[1]]
             else:
-                vs_ds_rules = [conv_utils.get_tenant_ref(name)[1] for name in
-                               f5_vs['rules'].keys()]
+                vs_ds_rules = [conv_utils.get_tenant_ref(
+                    name)[1] for name in f5_vs["rules"].keys()]
 
-            vs_ds, req_policies, nw_policy, converted_rules = (
+            vs_ds, req_policies, nw_policy, converted_rules = \
                 conv_utils.convert_irules(
                     vs_ds_rules, self.rule_config, avi_config, self.prefix,
-                    vs_name, tenant, reuse_http_policy))
+                    vs_name, tenant, reuse_http_policy
+                )
             vs_policies = vs_policies + req_policies
         if vs_ds:
             vs_datascripts = []
             index = 1
-            for ds in vs_ds:
+            for data_script in vs_ds:
                 vs_datascripts.append(
-                    {
-                        "index": index,
-                        "vs_datascript_set_ref": conv_utils.get_object_ref(
-                            ds, 'vsdatascriptset', tenant=tenant)
-                    }
+                    {"index": index, "vs_datascript_set_ref": conv_utils.get_object_ref(
+                        data_script, "vsdatascriptset", tenant=tenant)}
                 )
                 index += 1
-            vs_obj['vs_datascripts'] = vs_datascripts
+            vs_obj["vs_datascripts"] = vs_datascripts
 
-        if 'policies' in f5_vs:
-            if isinstance(f5_vs['policies'], str):
+        if "policies" in f5_vs:
+            if isinstance(f5_vs["policies"], str):
                 vs_policies.extend(['%s-%s' % (
                     self.prefix, conv_utils.get_tenant_ref(
                         f5_vs['policies'])[1]) if self.prefix else
                                     conv_utils.get_tenant_ref(
                                         f5_vs['policies'])[1]])
             else:
                 vs_policies.extend(['%s-%s' % (
                     self.prefix, conv_utils.get_tenant_ref(name)[1]) if
                                     self.prefix else conv_utils.get_tenant_ref(
                     name)[1] for name in f5_vs['policies'].keys()])
-        if app_prof_obj and 'HTTPPolicySet' in app_prof_obj[0]:
-            vs_policies.append(app_prof_obj[0]['HTTPPolicySet'])
+        if app_prof_obj and "HTTPPolicySet" in app_prof_obj[0]:
+            vs_policies.append(app_prof_obj[0]["HTTPPolicySet"])
         if vs_policies:
             self.get_policy_vs(vs_policies, avi_config, vs_name, tenant,
                                cloud_name, vs_obj, reuse_http_policy)
         p_ref = None
         if is_pool_group:
             p_ref = conv_utils.get_object_ref(
-                pool_ref, 'poolgroup', tenant=p_tenant)
+                pool_ref, "poolgroup", tenant=p_tenant)
         elif pool_ref:
             p_ref = conv_utils.get_object_ref(
-                pool_ref, 'pool', tenant=p_tenant)
+                pool_ref, "pool", tenant=p_tenant)
         if p_ref and used_pools.get(p_ref):
-            not_same = [pol_obj for pol_obj in used_pools[p_ref] if pol_obj
-                        not in vs_policies]
+            not_same = [pol_obj for pol_obj in used_pools[p_ref]
+                        if pol_obj not in vs_policies]
             if not_same:
                 if is_pool_group:
-                    LOG.debug('Pool group %s attached to vs %s is shared '
-                              'with policy %s of another vs, hence cloned',
-                              pool_ref, vs_name, str(not_same))
+                    LOG.debug(
+                        "Pool group %s attached to vs %s is shared with policy %s \
+                        of another vs, hence cloned",
+                        pool_ref,
+                        vs_name,
+                        str(not_same),
+                    )
                     pool_ref = conv_utils.clone_pool_group(
-                        pool_ref, vs_name, avi_config, False, p_tenant,
-                        cloud_name=cloud_name)
+                        pool_ref, vs_name, avi_config,
+                        False, p_tenant, cloud_name=cloud_name)
                 else:
-                    LOG.debug('Pool %s attached to vs %s is shared with '
-                              'policy %s of another vs, hence cloned', pool_ref,
-                              vs_name, str(not_same))
+                    LOG.debug(
+                        "Pool %s attached to vs %s is shared with policy %s of another vs,\
+                            hence cloned", pool_ref, vs_name, str(not_same), )
                     pool_ref = conv_utils.clone_pool(
-                        pool_ref, vs_name, avi_config['Pool'], False, p_tenant)
+                        pool_ref, vs_name, avi_config["Pool"], False, p_tenant)
         if is_pool_group:
-            vs_obj['pool_group_ref'] = conv_utils.get_object_ref(
-                pool_ref, 'poolgroup', tenant=tenant, cloud_name=cloud_name)
+            vs_obj["pool_group_ref"] = conv_utils.get_object_ref(
+                pool_ref, "poolgroup", tenant=tenant, cloud_name=cloud_name)
         elif pool_ref:
-            vs_obj['pool_ref'] = conv_utils.get_object_ref(
-                pool_ref, 'pool', tenant=tenant, cloud_name=cloud_name)
+            vs_obj["pool_ref"] = conv_utils.get_object_ref(
+                pool_ref, "pool", tenant=tenant, cloud_name=cloud_name)
         # app prof ref is not used inside the below method call
-        self.convert_translate_port(avi_config, f5_vs, app_prof[0], pool_ref,
-                                    sys_dict)
-        conn_limit = int(f5_vs.get(self.connection_limit, '0'))
-        if conn_limit > 0:
+        self.convert_translate_port(
+            avi_config, f5_vs, app_prof[0], pool_ref, sys_dict)
+        conn_limit = int(f5_vs.get(self.connection_limit, "0"))
+        if conn_limit > 0 and vs_sni_type != "VS_TYPE_VH_CHILD":
             vs_obj["performance_limits"] = {
-                "max_concurrent_connections": conn_limit
-            }
+                "max_concurrent_connections": conn_limit}
 
         if realm:
-            vs_obj['client_auth'] = realm
+            vs_obj["client_auth"] = realm
 
-        source = f5_vs.get('source', '0.0.0.0/0')
-        if '%' in source:
-            s_parts = source.split('%')
-        elif '/' in source:
-            s_parts = source.split('/')
+        source = f5_vs.get("source", "0.0.0.0/0")
+        if "%" in source:
+            s_parts = source.split("%")
+        elif "/" in source:
+            s_parts = source.split("/")
         else:
             s_parts = [source]
-        if not s_parts[0] == '0.0.0.0':
-            parts = source.split('/')
-            if '%' in parts[0]:
-                parts[0] = parts[0].split('%')[0]
+        if not s_parts[0] == "0.0.0.0":
+            parts = source.split("/")
+            if "%" in parts[0]:
+                parts[0] = parts[0].split("%")[0]
             mask = 24
             if len(parts) > 1:
                 mask = parts[1]
             policy_name = ('vs-%s-ns' % vs_name)
             if self.prefix:
                 policy_name = '%s-%s' % (self.prefix, policy_name)
             policy = conv_utils.create_network_security_rule(
                 policy_name, parts[0], mask, tenant)
 
             if nw_policy:
-                old_policy = [obj for obj in avi_config['NetworkSecurityPolicy']
-                              if obj['name'] == nw_policy][0]
-                policy['rules'][0]['index'] = 2
-                policy['rules'][0]['name'] = 'Rule 2'
-                old_policy['rules'].append(policy['rules'][0])
+                old_policy = [obj for obj in avi_config["NetworkSecurityPolicy"]
+                              if obj["name"] == nw_policy][0]
+                policy["rules"][0]["index"] = 2
+                policy["rules"][0]["name"] = "Rule 2"
+                old_policy["rules"].append(policy["rules"][0])
             else:
-                avi_config['NetworkSecurityPolicy'].append(policy)
+                avi_config["NetworkSecurityPolicy"].append(policy)
                 nw_policy = policy_name
 
         if nw_policy:
-            vs_obj['network_security_policy_ref'] = conv_utils.get_object_ref(
-                nw_policy, 'networksecuritypolicy', tenant=tenant)
+            vs_obj["network_security_policy_ref"] = conv_utils.get_object_ref(
+                nw_policy, "networksecuritypolicy", tenant=tenant, cloud_name=cloud_name)
 
         # Checking snat conversion flag and snat info for creating
         # snat ip object
         snat = f5_vs.get("source-address-translation", {})
         snat_pool_name = snat.get("pool", f5_vs.get("snatpool", None))
         snat_pool = snat_config.pop(snat_pool_name, None)
         if snat_pool:
             if self.con_snatpool:
-                LOG.debug("Converting the snat as input flag and snat "
-                          "information is set")
+                LOG.debug(
+                    "Converting the snat as input flag and snat "
+                    "information is set")
                 snat_list = conv_utils.get_snat_list_for_vs(snat_pool)
                 if len(snat_list) > 32:
                     vs_obj["snat_ip"] = snat_list[0:32]
-                    LOG.warning('Ignore the snat IPs, its count is beyond 32 '
-                                'for vs : %s' % vs_name)
+                    LOG.warning(
+                        "Ignore the snat IPs, its count is beyond 32 "
+                        "for vs : %s",
+                        vs_name)
                 else:
                     vs_obj["snat_ip"] = snat_list
-                conv_status = {'status': final.STATUS_SUCCESSFUL}
-                message = 'Mapped indirectly to VS -> SNAT IP Address'
-                conv_utils.add_conv_status('snatpool', '', snat_pool_name,
-                                           conv_status, message)
+                conv_status = {"status": final.STATUS_SUCCESSFUL}
+                message = "Mapped indirectly to VS -> SNAT IP Address"
+                conv_utils.add_conv_status(
+                    "snatpool", "", snat_pool_name, conv_status, message)
             else:
                 msg = ("Skipped: snat conversion as input flag is not set"
                        " for vs : %s" % vs_name)
                 LOG.debug(msg)
-                conv_status = {'status': final.STATUS_SKIPPED}
-                skipped.append("source-address-translation" if f5_vs.get(
-                    "source-address-translation") else "snatpool" if f5_vs.get(
-                    "snatpool") else None)
-                conv_utils.add_conv_status('snatpool', '', snat_pool_name,
-                                           conv_status, msg)
+                conv_status = {"status": final.STATUS_SKIPPED}
+                skipped.append(
+                    "source-address-translation"
+                    if f5_vs.get("source-address-translation")
+                    else "snatpool"
+                    if f5_vs.get("snatpool")
+                    else None
+                )
+                conv_utils.add_conv_status(
+                    "snatpool", "", snat_pool_name, conv_status, msg)
+
         if ntwk_prof:
-            vs_obj['network_profile_ref'] = ntwk_prof[0]
-            ntwk_prof_name = ntwk_prof[0].split('name=')[-1]
-            ntwk_prof_config = [np for np in avi_config['NetworkProfile'] if np['name'] == ntwk_prof_name]
-            ntwk_verified_accept = ntwk_prof_config[0].get('verified-accept')
-            if ntwk_verified_accept and ntwk_verified_accept != 'disabled':
+            vs_obj["network_profile_ref"] = ntwk_prof[0]
+            ntwk_prof_name = ntwk_prof[0].split("name=")[-1]
+            ntwk_prof_config = [
+                np for np in avi_config["NetworkProfile"] if np["name"] == ntwk_prof_name]
+            ntwk_verified_accept = ntwk_prof_config[0].get("verified-accept")
+            if ntwk_verified_accept and ntwk_verified_accept != "disabled":
                 vs_obj['"remove_listening_port_on_vs_down'] = True
+            if ntwk_prof_config[0]["profile"].get(
+                    "tcp_fast_path_profile") and f5_vs.get("mirror") == "enabled":
+                ntwk_prof_config[0]["connection_mirror"] = True
 
         if enable_ssl:
-            vs_obj['ssl_profile_ref'] = ssl_vs[0]["profile"]
+            vs_obj["ssl_profile_ref"] = ssl_vs[0]["profile"]
             if ssl_vs[0]["cert"]:
-                vs_obj['ssl_key_and_certificate_refs'] = [ssl_vs[0]["cert"]]
+                vs_obj["ssl_key_and_certificate_refs"] = [ssl_vs[0]["cert"]]
             if ssl_vs[0]["pki"] and app_name != "http":
-                app_profiles = [obj for obj in (
-                        sys_dict['ApplicationProfile'] +
-                        avi_config['ApplicationProfile'])
-                                if obj['name'] == app_name]
-                if app_profiles[0]["type"] == \
-                        'APPLICATION_PROFILE_TYPE_HTTP':
-                    app_profiles[0]["http_profile"][
-                        "ssl_client_certificate_mode"] = ssl_vs[0]["mode"]
-                    app_profiles[0]["http_profile"]["pki_profile_ref"] = \
-                        ssl_vs[0]["pki"]
+                app_profiles = [
+                    obj for obj in (
+                        sys_dict["ApplicationProfile"] +
+                        avi_config["ApplicationProfile"]) if obj["name"] == app_name]
+                if app_profiles[0]["type"] == "APPLICATION_PROFILE_TYPE_HTTP":
+                    app_profiles[0]["http_profile"]["ssl_client_certificate_mode"] =\
+                        ssl_vs[0]["mode"]
+                    app_profiles[0]["http_profile"]["pki_profile_ref"] = ssl_vs[0]["pki"]
 
         # Added code to skipped L4 VS if pool or pool group not present
-        if vs_obj['application_profile_ref']:
-            application_profile_obj = \
-                [obj for obj in (sys_dict['ApplicationProfile'] +
-                                 avi_config['ApplicationProfile'])
-                 if obj['name'] == app_name]
-            if application_profile_obj and application_profile_obj[0]['type'] \
-                    == 'APPLICATION_PROFILE_TYPE_L4':
-                if not vs_obj.get('pool_ref', vs_obj.get('pool_group_ref')):
+        if vs_obj["application_profile_ref"]:
+            application_profile_obj = [
+                obj for obj in (
+                    sys_dict["ApplicationProfile"] +
+                    avi_config["ApplicationProfile"]) if obj["name"] == app_name]
+            if application_profile_obj and application_profile_obj[
+                    0]["type"] == "APPLICATION_PROFILE_TYPE_L4":
+                if not vs_obj.get("pool_ref", vs_obj.get("pool_group_ref")):
                     msg = ("Failed to convert L4 VS dont have pool or pool "
                            "group ref: %s" % vs_name)
                     LOG.debug(msg)
-                    conv_utils.add_status_row('virtual', None,
-                                              vs_name,
-                                              final.STATUS_SKIPPED,
-                                              msg)
-                    return
+                    conv_utils.add_status_row(
+                        "virtual", None, vs_name, final.STATUS_SKIPPED, msg)
+                    return None, None
+
         if app_prof:
-            self.app_profile_with_via_host_name(app_name,vs_obj,avi_config,tenant,cloud_name,sys_dict,profiles,merge_object_mapping)  
+            self.app_profile_with_via_host_name(
+                app_name,
+                vs_obj,
+                avi_config,
+                tenant,
+                cloud_name,
+                sys_dict,
+                profiles,
+                merge_object_mapping)
+            self.enabling_http_to_https_redirects_in_app_profile(
+                app_name, vs_obj, avi_config, sys_dict)
         for attr in self.ignore_for_value:
             ignore_val = self.ignore_for_value[attr]
             actual_val = f5_vs.get(attr, None)
             if not actual_val:
                 continue
             if isinstance(ignore_val, str) and actual_val == ignore_val:
                 skipped.remove(attr)
             elif isinstance(ignore_val, list) and actual_val in ignore_val:
                 skipped.remove(attr)
-        conv_status = dict()
-        conv_status['user_ignore'] = [val for val in skipped
-                                      if val in user_ignore]
+        conv_status = {}
+        conv_status["user_ignore"] = [
+            val for val in skipped if val in user_ignore]
 
         if vs_ds_rules:
-            vs_ds.append('_sys_https_redirect')
-            skipped_rules = [rule for rule in vs_ds_rules if rule not in
-                             converted_rules]
+            vs_ds.append("_sys_https_redirect")
+            skipped_rules = [
+                rule for rule in vs_ds_rules if rule not in converted_rules]
             if skipped_rules:
                 skipped.append('rules: %s' % skipped_rules)
         na_list = [val for val in skipped if val in self.vs_na_attr]
         skipped = [attr for attr in skipped if attr not in self.vs_na_attr]
         skipped = [attr for attr in skipped if attr not in user_ignore]
-        conv_status['indirect'] = [val for val in skipped if
-                                   val in self.vs_indirect_attr]
-        skipped = [attr for attr in skipped if attr not in self.vs_indirect_attr]
-        conv_status['na_list'] = [val for val in skipped if val in na_list]
+        conv_status["indirect"] = [
+            val for val in skipped if val in self.vs_indirect_attr]
+        skipped = [
+            attr for attr in skipped if attr not in self.vs_indirect_attr]
+        conv_status["na_list"] = [val for val in skipped if val in na_list]
         skipped = [attr for attr in skipped if attr not in na_list]
-        conv_status['skipped'] = skipped
+        conv_status["skipped"] = skipped
         status = final.STATUS_SUCCESSFUL
         if skipped:
             status = final.STATUS_PARTIAL
         conv_status['status'] = status
         review_flag = 'Yes' if needs_review else None
-        conv_utils.add_conv_status('virtual', None, vs_name,
-                                   conv_status, vs_obj, review_flag)
+        conv_utils.add_conv_status(
+            'virtual',
+            None,
+            vs_name,
+            conv_status,
+            vs_obj,
+            yaml.dump(f5_vs),
+            review_flag)
 
-        return vs_obj
+        return vs_obj, vs_sni_parent_obj
 
-    def get_policy_vs(self, vs_policies, avi_config, vs_name, tenant,
-                      cloud_name, vs_obj, reuse_http_policy=False):
+    def get_policy_vs(self, vs_policies, avi_config, vs_name,
+                      tenant, cloud_name, vs_obj, reuse_http_policy=False):
         """
         This method gets all the policy attached to vs, also clone it if
         required
         :param vs_policies: dict of policies
         :param avi_config: dict for avi conversion
         :param vs_name: name of vs
         :param tenant: tenant for which output to converted
         :param cloud_name: cloud for which output to converted
         :param vs_obj: virtualservice object
         :return:
         """
         for pol_name in vs_policies:
-            policy_obj = [ob for ob in avi_config['HTTPPolicySet'] if ob[
-                'name'] == pol_name]
+            policy_obj = [
+                ob for ob in avi_config["HTTPPolicySet"] if ob["name"] == pol_name]
             if policy_obj:
                 if reuse_http_policy:
                     pass
                 elif pol_name in used_policy:
-                    LOG.debug('Cloning the policy %s for vs %s',
-                              pol_name, vs_name)
+                    LOG.debug(
+                        "Cloning the policy %s for vs %s",
+                        pol_name,
+                        vs_name)
                     clone_policy = conv_utils.clone_http_policy_set(
                         policy_obj[0], vs_name, avi_config, tenant, cloud_name)
-                    pol_name = clone_policy['name']
-                    pol_tenant = conv_utils.get_name(clone_policy['tenant_ref'])
+                    pol_name = clone_policy["name"]
+                    pol_tenant = conv_utils.get_name(
+                        clone_policy["tenant_ref"])
                     if pol_tenant == tenant:
-                        avi_config['HTTPPolicySet'].append(clone_policy)
-                        LOG.debug('Policy cloned %s for vs %s', pol_name,
-                                  vs_name)
+                        avi_config["HTTPPolicySet"].append(clone_policy)
+                        LOG.debug(
+                            "Policy cloned %s for vs %s", pol_name, vs_name)
+                        if policy_obj[0]["name"] in http_to_https_policy_rule:
+                            http_to_https_policy_rule.append(pol_name)
                     else:
-                        LOG.debug('Policy with different tenant not '
-                                   'supported  %s for vs %s', pol_name,
-                                  vs_name)
+                        LOG.debug(
+                            "Policy with different tenant not "
+                            "supported  %s for vs %s", pol_name, vs_name)
                         continue
                 if pol_name not in used_policy:
                     used_policy.append(pol_name)
                 pol = {
-                    'index': 11,
-                    'http_policy_set_ref':
-                        conv_utils.get_object_ref(
-                            pol_name, 'httppolicyset',
-                            tenant=conv_utils.get_name(
-                                policy_obj[0]['tenant_ref']))
+                    "index": 11,
+                    "http_policy_set_ref": conv_utils.get_object_ref(
+                        pol_name,
+                        "httppolicyset",
+                        tenant=conv_utils.get_name(
+                            policy_obj[0]["tenant_ref"])),
                 }
-                if not vs_obj.get('http_policies'):
-                    vs_obj['http_policies'] = []
+                if not vs_obj.get("http_policies"):
+                    vs_obj["http_policies"] = []
                 else:
-                    ind = max([pol_index['index'] for pol_index in vs_obj[
-                        'http_policies']])
-                    pol['index'] = ind + 1
-                vs_obj['http_policies'].append(pol)
-
-    def create_rule_action_for_via_header(self,via_header,via_request):
-        rule_dict={
-        "enable": True,
-         "hdr_action":
-             [{"action": "HTTP_ADD_HDR",
-               "hdr":
-                   {"name": "via",
-                    "value":
-                        {
-                            "val": via_header
-                            }
-                        }
-                   }
-              ],
-             "index" : "1",
-             "name": "Rule 1"}
-        if via_request=="append":
-            rule_dict["hdr_action"][0]["action"]="HTTP_ADD_HDR"
+                    ind = max(pol_index["index"]
+                              for pol_index in vs_obj["http_policies"])
+                    pol["index"] = ind + 1
+                vs_obj["http_policies"].append(pol)
+
+    def create_rule_action_for_via_header(self, via_header, via_request):
+        """
+        This method will create rule action for via header
+        """
+        rule_dict = {"enable": True, "hdr_action": [{"action": "HTTP_ADD_HDR", "hdr": {
+            "name": "via", "value": {"val": via_header}}}], "index": "1", "name": "Rule 1", }
+        if via_request == "append":
+            rule_dict["hdr_action"][0]["action"] = "HTTP_ADD_HDR"
         if via_request == "remove":
-            rule_dict["hdr_action"][0]["action"]="HTTP_REMOVE_HDR"
+            rule_dict["hdr_action"][0]["action"] = "HTTP_REMOVE_HDR"
         via_header_key="%s-%s" % (via_header,via_request)
-        via_header_rule_dict[via_header_key]=rule_dict
+        via_header_rule_dict[via_header_key] = rule_dict
         return rule_dict
 
-    def add_via_header_rule_to_http_policy(self,rule_dict,vs_obj,http_policy,tenant,avi_config,cloud_name):
+    def add_via_header_rule_to_http_policy(
+            self,
+            rule_dict,
+            vs_obj,
+            http_policy,
+            tenant,
+            avi_config,
+            cloud_name):
+        """
+        this method will add rule to http policy
+
+        Args:
+            rule_dict : passes rule config
+            vs_obj : passed vs  object configuration
+            http_policy : http policy
+            avi_config : passed avi configuration
+            tenant: Tenant for which config need to be converted
+            cloud_name: cloud for which config need to be converted
+        """
         http_policy_name = None
-        if http_policy :
-            if http_policy['http_request_policy']:
-                index=len(http_policy['http_request_policy']['rules'])+1
-                if rule_dict not in http_policy['http_request_policy']['rules']:
-                    rule_dict['index']=index
-                    http_policy['http_request_policy']["rules"].append(rule_dict)
+        if http_policy:
+            if http_policy["http_request_policy"]:
+                index = len(http_policy["http_request_policy"]["rules"]) + 1
+                if rule_dict not in http_policy["http_request_policy"]["rules"]:
+                    rule_dict["index"] = index
+                    http_policy["http_request_policy"]["rules"].append(
+                        rule_dict)
             else:
-                http_policy['http_request_policy']["rules"]=[rule_dict]
-            http_policy_name=http_policy['name']
+                http_policy["http_request_policy"]["rules"] = [rule_dict]
+            http_policy_name = http_policy["name"]
         else:
-            policy_set={
+            policy_set = {
                 "name" :  "%s-HTTP-Policy-Set" % vs_obj['name'],
-                'tenant_ref' : conv_utils.get_object_ref(tenant,'tenant'),
-                'http_request_policy':{
-                    'rules':[rule_dict]
-                }
+                "tenant_ref": conv_utils.get_object_ref(tenant, "tenant"),
+                "http_request_policy": {"rules": [rule_dict]},
             }
             http_policy_name = policy_set['name']
             avi_config['HTTPPolicySet'].append(policy_set)
-            vs_policies=[policy_set.get('name')]
+            vs_policies = [policy_set.get('name')]
             self.get_policy_vs(vs_policies, avi_config, vs_obj['name'], tenant,
-                      cloud_name, vs_obj)
-        return http_policy_name
+                               cloud_name, vs_obj)
 
-    def app_profile_with_via_host_name(self,app_name,vs_obj,avi_config,tenant,cloud_name,sys_dict,profiles,merge_object_mapping):
+        return http_policy_name
 
-        application_profile_obj = \
-                [obj for obj in (sys_dict['ApplicationProfile'] +
-                                 avi_config['ApplicationProfile'])
-                 if obj['name'] == app_name]
+    def app_profile_with_via_host_name(
+            self,
+            app_name,
+            vs_obj,
+            avi_config,
+            tenant,
+            cloud_name,
+            sys_dict,
+            profiles,
+            merge_object_mapping):
+        '''
+        Application profile with via host name
+        '''
+
+        application_profile_obj = [
+            obj for obj in (
+                sys_dict["ApplicationProfile"] +
+                avi_config["ApplicationProfile"]) if obj["name"] == app_name]
         f5_prof_obj = application_profile_obj
         if f5_prof_obj and f5_prof_obj[0].get("via-host-name"):
             f5_prof_obj = f5_prof_obj[0]
             via_host_name = f5_prof_obj.get("via-host-name")
-            via_request = f5_prof_obj.get('via-request')
-            if via_request in ['append','remove']:
+            via_request = f5_prof_obj.get("via-request")
+            if via_request in ["append", "remove"]:
                 if via_header_rule_dict.get("%s-%s" % (via_host_name,via_request)):
                     via_rule = via_header_rule_dict.get("%s-%s" % (via_host_name,via_request))
                 else:
-                    via_rule = self.create_rule_action_for_via_header(via_host_name,via_request)
-                pol_name = vs_obj.get('http_policies')
+                    via_rule = self.create_rule_action_for_via_header(
+                        via_host_name, via_request)
+                pol_name = vs_obj.get("http_policies")
                 via_header_request = "%s-%s" % (via_host_name,via_request)
-                policy_name= None
-                if pol_name :
+                policy_name = None
+                if pol_name:
                     http_policy_ref = pol_name[0].get("http_policy_set_ref")
                     http_policy_name = http_policy_ref.split("name=")[-1]
-                    if http_policy_name :
-                        policy_obj = [ob for ob in avi_config['HTTPPolicySet'] if ob[
-                                'name'] == http_policy_name]
-                        if policy_with_via_header.get(http_policy_name) :
-                            if not via_header_request in policy_with_via_header.get(http_policy_name):
-                                policy_name = self.add_via_header_rule_to_http_policy(via_rule,vs_obj,policy_obj[0],tenant,avi_config,cloud_name)
+                    if http_policy_name:
+                        policy_obj = [
+                            ob for ob in avi_config["HTTPPolicySet"]
+                            if ob["name"] == http_policy_name]
+                        if policy_with_via_header.get(http_policy_name):
+                            if via_header_request not in policy_with_via_header.get(
+                                    http_policy_name):
+                                policy_name = self.add_via_header_rule_to_http_policy(
+                                    via_rule, vs_obj, policy_obj[0], tenant, avi_config, cloud_name
+                                )
                         else:
-                            policy_name = self.add_via_header_rule_to_http_policy(via_rule,vs_obj,policy_obj[0],tenant,avi_config,cloud_name)
-                else :
-                    policy_name = self.add_via_header_rule_to_http_policy(via_rule,vs_obj,pol_name,tenant,avi_config,cloud_name)
+                            policy_name = self.add_via_header_rule_to_http_policy(
+                                via_rule, vs_obj, policy_obj[0], tenant, avi_config, cloud_name)
+                else:
+                    policy_name = self.add_via_header_rule_to_http_policy(
+                        via_rule, vs_obj, pol_name, tenant, avi_config, cloud_name)
                 if policy_name:
                     if not policy_with_via_header.get(policy_name):
-                        policy_with_via_header[policy_name] = [via_header_request]
+                        policy_with_via_header[policy_name] = [
+                            via_header_request]
                     else:
-                        policy_with_via_header[policy_name].append(via_header_request)
+                        policy_with_via_header[policy_name].append(
+                            via_header_request)
+
+    def enabling_http_to_https_redirects_in_app_profile(
+            self, app_name, vs_obj, avi_config, sys_dict):
+        """
+        This method enable http_to_https flag in application profile
+        Args:
+            app_name: Application profile name
+            vs_obj: virtual service object
+            avi_config: passed avi convertion config
+            sys_dict: Baseline dict
+        """
+        policy = vs_obj.get("http_policies")
+        if policy:
+            http_policy_ref = policy[0].get("http_policy_set_ref")
+            http_policy_name = http_policy_ref.split("name=")[-1]
+
+            if http_policy_name and http_policy_name in http_to_https_policy_rule:
+                app_profile_obj = [
+                    obj for obj in (
+                        sys_dict["ApplicationProfile"] +
+                        avi_config["ApplicationProfile"]) if obj["name"] == app_name]
+                if app_profile_obj:
+                    app_profile_obj[0]["http_profile"]["http_to_https"] = True
+
 
 class VSConfigConvV11(VSConfigConv):
-    def __init__(self, f5_virtualservice_attributes, prefix, con_snatpool,
-                 custom_mappings, distinct_app_profile):
+    '''
+    class for vs conversion for v11 version
+    '''
+
+    def __init__(self, f5_virtualservice_attributes, prefix,
+                 con_snatpool, custom_mappings, distinct_app_profile):
         """
 
         :param f5_virtualservice_attributes: yaml attribute file for object
         :param prefix: prefix for object
         :param con_snatpool: flag for snat conversion
         :param custom_mappings: custom config to migrate irules
         """
-        self.supported_attr = f5_virtualservice_attributes['VS_supported_attr']
-        self.ignore_for_value = \
-            f5_virtualservice_attributes['VS_ignore_for_value']
-        self.unsupported_types = \
-            f5_virtualservice_attributes['VS_unsupported_types']
-        self.vs_na_attr = \
-            f5_virtualservice_attributes['VS_na_attr']
-        self.vs_indirect_attr = \
-            f5_virtualservice_attributes['VS-indirect-attr']
-        self.connection_limit = 'connection-limit'
+        self.supported_attr = f5_virtualservice_attributes["VS_supported_attr"]
+        self.ignore_for_value = f5_virtualservice_attributes["VS_ignore_for_value"]
+        self.unsupported_types = f5_virtualservice_attributes["VS_unsupported_types"]
+        self.vs_na_attr = f5_virtualservice_attributes["VS_na_attr"]
+        self.vs_indirect_attr = f5_virtualservice_attributes["VS-indirect-attr"]
+        self.connection_limit = "connection-limit"
         # Added prefix for objects
         self.prefix = prefix
         # Added flag for snat conversion
         self.con_snatpool = con_snatpool
         self.rule_config = custom_mappings.get(
-            final.RULE_CUSTOM_KEY, dict()
-        ) if custom_mappings else dict()
+            final.RULE_CUSTOM_KEY, {}) if custom_mappings else {}
         self.distinct_app_profile = distinct_app_profile
 
     def get_persist_ref(self, f5_vs):
         """
 
         :param f5_vs:  parsed f5 vs dict
         :return:
         """
         persist_ref = f5_vs.get("persist", None)
         if persist_ref:
-            persist_ref = [key for key in persist_ref.keys()][0]
+            persist_ref = list(persist_ref.keys())[0]
         return persist_ref
 
-    def convert_translate_port(self, avi_config, f5_vs, app_prof, pool_ref,
-                               sys_dict):
+    def convert_translate_port(
+            self, avi_config, f5_vs, app_prof, pool_ref, sys_dict):
         """
         This method looks for translate-port property and sets the service
         port in pool and remove the monitor if monitor don't have port
         :param avi_config: dict for avi conversion
         :param f5_vs: parsed f5 vs dict
         :param app_prof: application profile
         :param pool_ref: pool reference name
         :param sys_dict: baseline dict
         :return:
         """
-        port_translate = f5_vs.get('translate-port', None)
+        port_translate = f5_vs.get("translate-port", None)
         if port_translate:
-            if port_translate == 'disabled':
+            if port_translate == "disabled":
                 conv_utils.update_pool_for_service_port(
-                    avi_config['Pool'], pool_ref, avi_config['HealthMonitor'],
-                    sys_dict['HealthMonitor'])
-            elif port_translate == 'enabled':
+                    avi_config["Pool"],
+                    pool_ref, avi_config["HealthMonitor"],
+                    sys_dict["HealthMonitor"])
+            elif port_translate == "enabled":
                 return
 
+
 class VSConfigConvV10(VSConfigConv):
-    def __init__(self, f5_virtualservice_attributes, prefix, con_snatpool,
-                 custom_mappings, distinct_app_profile):
+    '''
+    class for vs conversion for v10 version
+    '''
+
+    def __init__(self, f5_virtualservice_attributes, prefix,
+                 con_snatpool, custom_mappings, distinct_app_profile):
         """
 
         :param f5_virtualservice_attributes: yaml attribute file for object
         :param prefix: prefix for object
         :param con_snatpool: flag for snat conversion
         :param custom_mappings: custom config to migrate irules
         """
-        self.supported_attr = f5_virtualservice_attributes['VS_supported_attr']
-        self.ignore_for_value = \
-            f5_virtualservice_attributes['VS_ignore_for_value']
-        self.vs_na_attr = \
-            f5_virtualservice_attributes['VS_na_attr']
-        self.unsupported_types = \
-            f5_virtualservice_attributes['VS_unsupported_types']
-        self.vs_indirect_attr = \
-            f5_virtualservice_attributes['VS-indirect-attr']
-        self.connection_limit = 'limit'
+        self.supported_attr = f5_virtualservice_attributes["VS_supported_attr"]
+        self.ignore_for_value = f5_virtualservice_attributes["VS_ignore_for_value"]
+        self.vs_na_attr = f5_virtualservice_attributes["VS_na_attr"]
+        self.unsupported_types = f5_virtualservice_attributes["VS_unsupported_types"]
+        self.vs_indirect_attr = f5_virtualservice_attributes["VS-indirect-attr"]
+        self.connection_limit = "limit"
         # Added prefix for objects
         self.prefix = prefix
         # Added flag for snat conversion
         self.con_snatpool = con_snatpool
         self.rule_config = custom_mappings.get(
-            final.RULE_CUSTOM_KEY, dict()
-        ) if custom_mappings else dict()
+            final.RULE_CUSTOM_KEY, {}) if custom_mappings else {}
         self.distinct_app_profile = distinct_app_profile
 
     def get_persist_ref(self, f5_vs):
+        """
+        This method will presistence reference
+        """
         persist_ref = f5_vs.get("persist", None)
         return persist_ref
 
-    def convert_translate_port(self, avi_config, f5_vs, app_prof, pool_ref,
-                               sys_dict):
+    def convert_translate_port(
+            self, avi_config, f5_vs, app_prof, pool_ref, sys_dict):
         """
         This method looks for translate-port property and sets the service
         port in pool and remove the monitor if monitor don't have port
         :param avi_config: dict for avi conversion
         :param f5_vs: parsed f5 vs dict
         :param app_prof: application profile
         :param pool_ref: pool reference name
         :param sys_dict: baseline dict
         :return:
         """
-        port_translate = f5_vs.get('translate service', None)
+        port_translate = f5_vs.get("translate service", None)
         if port_translate:
-            if port_translate == 'disabled':
+            if port_translate == "disabled":
                 conv_utils.update_pool_for_service_port(
-                    avi_config['Pool'], pool_ref, avi_config['HealthMonitor'],
-                    sys_dict['HealthMonitor'])
-            elif port_translate == 'enabled':
-                return
+                    avi_config["Pool"],
+                    pool_ref, avi_config["HealthMonitor"],
+                    sys_dict["HealthMonitor"])
+            elif port_translate == "enabled":
+                return
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/f5_discovery.py` & `avimigrationtools-22.1.4/avi/migrationtools/f5_discovery.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,16 +20,16 @@
 from collections import defaultdict
 from datetime import datetime
 
 try:
     from bigsuds import BIGIP               # version 10
     from f5.bigip import ManagementRoot     # version 11+
 except ImportError:
-    print ("Please Install bigsuds and f5 sdk python packages using "
-           "`pip install bigsuds f5-sdk`")
+    print("Please Install bigsuds and f5 sdk python packages using "
+          "`pip install bigsuds f5-sdk`")
     sys.exit(1)
 
 profile_mappings = {
     'l4': ['fastl4', 'tcp'],
     'l7': ['http', 'https', 'fasthttp', 'clientssl', 'oneconnect'],
     'dns': ['dns'],
     'udp': ['udp']
@@ -101,15 +101,15 @@
                         types['type']: types['value']['high']
                         for types in data[k]['traffic_list']
                     }
                     if k in traffic_global_dict:
                         traffic_global_dict[k].append(unpacked_entries)
                     else:
                         traffic_global_dict[k] = [unpacked_entries]
-    
+
         new_traffic_global_dict = {}
 
         for k in traffic_global_dict.keys():
             intermediate = defaultdict(list)
 
             if int(version) > 10:
                 mean_key = ['clientside.curConns']
@@ -239,15 +239,15 @@
                     pool_details = vsval['pool']['members'][0]
                     pool_list.append({
                         'name': pool_details.get('name'),
                         'status': pool_details.get('state'),
                         'vs_enabled': vs_state,
                     })
                     if pool_details.get('state') == 'up':
-                        total_enabled_pools = total_enabled_pools + 1 
+                        total_enabled_pools = total_enabled_pools + 1
                 else:
                     # using vs state for now
                     pool_list.append({'name': vsval['pool'].get(
                         'name'), 'status': vs_state, 'vs_enabled': vs_state, })
 
             vs_list.append(temp_dict)
 
@@ -275,20 +275,20 @@
             else:
                 continue
             # write headers
             if init == 0:
                 for keys in vs['details'].keys():
                     col = col + 1
                     worksheet.write(row, col, keys.strip(), bold)
-                worksheet.write(row, col+1, "Max Connections", bold)    
-                worksheet.write(row, col+2, "Number of Open connections", bold)    
-                worksheet.write(row, col+3, "Requests / sec", bold)    
-                worksheet.write(row, col+4, "Connections / sec", bold)    
-                worksheet.write(row, col+5, "bytes / sec", bold)    
-                worksheet.write(row, col+6, "pkts / sec", bold)  
+                worksheet.write(row, col+1, "Max Connections", bold)
+                worksheet.write(row, col+2, "Number of Open connections", bold)
+                worksheet.write(row, col+3, "Requests / sec", bold)
+                worksheet.write(row, col+4, "Connections / sec", bold)
+                worksheet.write(row, col+5, "bytes / sec", bold)
+                worksheet.write(row, col+6, "pkts / sec", bold)
                 row = row + 2
             init = init + 1
             col = 2
 
             worksheet.write(row, 0, vs_name, bold)
             status = disabled
             v = ''
@@ -306,16 +306,16 @@
                     v = ''
                 worksheet.write(row, col, v, state)
                 col = col + 1
             if type(vs['max_conn']) is not int:
                 worksheet.write(row, col, vs['max_conn'].get('value'), bold)
             else:
                 worksheet.write(row, col, vs['max_conn'], bold)
-            
-            # write necessary details 
+
+            # write necessary details
             if int(version) > 10:
                 open_conn = (new_traffic_global_dict[vs_name]
                              ['clientside.curConns'])
                 req_psec = (new_traffic_global_dict[vs_name]
                             ['totRequests'])
                 conn_psec = (new_traffic_global_dict[vs_name]
                              ['clientside.totConns'])
@@ -330,23 +330,23 @@
                             ['STATISTIC_CLIENT_SIDE_PACKETS_OUT'])
                 conn_psec = (new_traffic_global_dict[vs_name]
                              ['STATISTIC_CLIENT_SIDE_TOTAL_CONNECTIONS'])
                 bytes_psec = (new_traffic_global_dict[vs_name]
                               ['STATISTIC_CLIENT_SIDE_BYTES_OUT'])
                 pkts_psec = (new_traffic_global_dict[vs_name]
                              ['STATISTIC_CLIENT_SIDE_PACKETS_OUT'])
-              
-            worksheet.write(row, col+1, open_conn, bold)    
-            worksheet.write(row, col+2, req_psec, bold)    
-            worksheet.write(row, col+3, conn_psec, bold)    
-            worksheet.write(row, col+4, bytes_psec, bold)    
+
+            worksheet.write(row, col+1, open_conn, bold)
+            worksheet.write(row, col+2, req_psec, bold)
+            worksheet.write(row, col+3, conn_psec, bold)
+            worksheet.write(row, col+4, bytes_psec, bold)
             worksheet.write(row, col+5, pkts_psec, bold)
 
             row = row + 1
-        
+
             # write total
             if init == len(vs_list):
                 # doing offset
                 end_row = row
                 row = 1
                 col = 0
                 for r in range(len(vs['details'].keys()) + 1):
@@ -397,15 +397,15 @@
                                 'name': vs,
                                 'details': t_entries[
                                     t_entries.keys()[0]][
                                     'nestedStats']['entries']})
                     else:
                         traffic_list.append(
                             {'name': vs, 'details': vsval['traffic']})
-    
+
                 # write traffic details on different page
                 row, col = 0, 0
                 worksheet_traffic.write('A1', 'Vs Name', bold)
                 init = 0
                 if int(self.version) > 10:
                     for t_vs in traffic_list:
                         # for Title Creation
@@ -437,18 +437,18 @@
 
         # adding some more summary
         worksheet_summary.write(9, 5, "Total vs", bold)
         worksheet_summary.write(9, 6, str(total_vs))
 
         worksheet_summary.write(10, 5, "Total enabled vs", bold)
         worksheet_summary.write(10, 6, str(total_enabled_vs))
-        
+
         worksheet_summary.write(11, 5, "Total pools", bold)
         worksheet_summary.write(11, 6, str(total_pools))
-        
+
         print("====================")
         print(" Summary")
         print("====================")
         print("Total vs: ", total_vs)
         print("Total enabled vs: ", total_enabled_vs)
         print("Total pools: ", total_pools)
 
@@ -563,15 +563,15 @@
 
                 max_conn = 0
 
                 for t in traffic['statistics'][0]['statistics']:
                     if (t.get('type') ==
                             'STATISTIC_CLIENT_SIDE_MAXIMUM_CONNECTIONS'):
                         max_conn = int(t['value']['high'])
-                
+
                 vs_object['max_conn'] = max_conn
 
                 if traffic and len(traffic['statistics']):
                     vs_object['traffic_list'] = traffic['statistics'][0][
                         'statistics']
                 self.avi_object_temp[vs_object['name']] = vs_object
             self.avi_object.append(self.avi_object_temp)
@@ -677,15 +677,15 @@
                     u'clientside.maxConns', 0)
                 vs_object['max_conn'] = max_conn
 
                 # if str(vs.name) == 'miska-http':
                 #     print "========  ========"
                 #     print virtual_obj.stats.load().entries
                 #     print "================"
-                    
+
                 self.avi_object_temp[vs_object['name']] = vs_object
             self.avi_object.append(self.avi_object_temp)
         # print 'Inventory: %s' % self.avi_object
 
 
 if __name__ == '__main__':
     HELP_STR = '''
@@ -704,33 +704,33 @@
     parser.add_argument('--f5_user', help='f5 host username')
     parser.add_argument('--f5_password', help='f5 host password')
     parser.add_argument('-o', '--output_file_path', default='output',
                         help='folder location for output file')
 
     parser.add_argument('-c', '--cli-out', action='store_true',
                         help='Print the human readable output')
-    
+
     parser.add_argument('-i', '--interval', default=2,
                         help='Take the sample data with interval '
                              '[default 2 mins]')
 
     parser.add_argument('--f5_port',
                         help='f5 host port id non default port is used ',
                         default=443)
 
     args = parser.parse_args()
     if not args.f5_ip:
         print('Please provide f5 host')
-        exit(0)
+        sys.exit(0)
     if not args.f5_user:
         print('Please provide ssh username of f5 host')
-        exit(0)
+        sys.exit(0)
     if not args.f5_password:
         print('Please provide ssh password of f5 host')
-        exit(0)
+        sys.exit(0)
 
     if not os.path.isdir(args.output_file_path):
         print("Creating output directory ...")
         os.makedirs(args.output_file_path)
 
     f5_inventory_conv = F5InventoryConv.get_instance(
         args.f5_config_version, args.f5_ip, args.f5_port, args.f5_user,
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_config_convertor.py` & `avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_config_convertor.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_convertor.py` & `avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_convertor.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_parser.py` & `avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_parser.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/gss_utils.py` & `avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/gss_utils.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/parser_files/gslb_template.jinja` & `avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/parser_files/gslb_template.jinja`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/gss_convertor/test/test_run.py` & `avimigrationtools-22.1.4/avi/migrationtools/gss_convertor/test/test_run.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/command_status.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/command_status.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/csvs_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/csvs_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_config_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_config_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_monitor_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_monitor_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_service_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_service_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/gslb_vs_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/gslb_vs_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/lbvs_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/lbvs_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/monitor_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/monitor_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_config_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_config_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_converter.py`

 * *Files 1% similar despite different names*

```diff
@@ -138,15 +138,16 @@
         avi_config = ns_conf_converter.convert(
             ns_config, self.tenant, self.cloud_name,
             self.controller_version, output_dir, input_dir, skipped_cmds,
             self.vs_state, self.object_merge_check, report_name, self.prefix,
             vs_name_dict, self.profile_path, self.redirect,
             self.ns_passphrase_file, user_ignore, self.vs_level_status,
             self.vrf, self.segroup)
-
+        # validating avi config for max object length allowed
+        self.trim_object_length(avi_config)
         avi_config = self.process_for_utils(
             avi_config)
         # Check if flag true then skip not in use object
         if self.not_in_use:
             avi_config = wipe_out_not_in_use(avi_config)
         self.write_output(
             avi_config, output_dir, '%s-Output.json' % report_name)
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_gslb_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_gslb_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/netscaler_parser.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/netscaler_parser.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ns_constants.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ns_constants.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ns_service_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ns_service_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ns_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ns_util.py`

 * *Files 0% similar despite different names*

```diff
@@ -1422,20 +1422,20 @@
         df = pandas.DataFrame(row_list, columns=fieldnames)
         # create pivot table using pandas
         pivot_table = pandas.pivot_table(df,
                                          index=["Status", "Netscaler Command"],
                                          values=[], aggfunc=[len], fill_value=0)
         # create dataframe for pivot table using pandas
         pivot_df = pandas.DataFrame(pivot_table)
-        master_book = load_workbook(xlsx_report)
-        master_writer = pandas.ExcelWriter(xlsx_report, engine='openpyxl')
-        master_writer.book = master_book
+        main_book = load_workbook(xlsx_report)
+        main_writer = pandas.ExcelWriter(xlsx_report, engine='openpyxl',mode='a')
+        main_writer._book = main_book
         # Add pivot table in Pivot sheet
-        pivot_df.to_excel(master_writer, 'Pivot Sheet')
-        master_writer.save()
+        pivot_df.to_excel(main_writer, 'Pivot Sheet')
+        main_writer.close()
 
     def update_skip_duplicates(self, obj, obj_list, obj_type,
                                merge_object_mapping, name, ent_type, prefix,
                                syslist):
         """
         This method merge duplicate objects
         :param obj: Source object to find duplicates for
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/policy_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/policy_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/profile_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/profile_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/scp_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/scp_util.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/ssl_ciphers.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/ssl_ciphers.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/certs/ns-server.key` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/certs/ns-server.key`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/ignore-config.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/ignore-config.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/input_vs_configuration.conf` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/input_vs_configuration.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/netscaler_e2e_test.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/netscaler_e2e_test.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/ns.conf` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/ns.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/ns_passphrase.conf` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/ns_passphrase.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.cfg` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.cfg`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_complete_vs_configuration.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_csv_status.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_csv_status.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_migrationtool.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_migrationtool.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_netscaler_config.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_netscaler_config.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/netscaler_converter/test/test_upload_output_config.py` & `avimigrationtools-22.1.4/avi/migrationtools/netscaler_converter/test/test_upload_output_config.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/__init__.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/__init__.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/alb_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/alb_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/base_client.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/base_client.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/command_status.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/command_status.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -108,14 +108,15 @@
      - "interval"
      - "timeout"
      - "rise_count"
      - "fall_count"
      - "display_name"
      - "resource_type"
      - "id"
+     - "description"
 
     Monitor_http_attr:
     - "request_url"
     - "request_method"
     - "request_version"
     - "request_body"
     - "response_status_codes"
@@ -167,14 +168,15 @@
     - "active_monitor_paths"
     - "snat_translation"
     - "tcp_multiplexing_enabled"
     - "tcp_multiplexing_number"
     - "min_active_members"
     - "resource_type"
     - "id"
+    - "description"
 
     Pool_supported_attr_convert_servers_config:
     - "display_name"
     - "ip_address"
     - "port"
     - "admin_state"
     - "weight"
@@ -211,14 +213,15 @@
 
     tcp_na_list:
     - "close_timeout"
 
     Network_Profile_supported_attr:
     - "display_name"
     - "resource_type"
+    - "description"
     - "id"
     - "idle_timeout"
     - 'ha_flow_mirroring_enabled'
     - 'flow_mirroring_enabled'
 
     VS_supported_attr:
     - 'application_profile_path'
@@ -280,36 +283,42 @@
     - "protocols"
     - "session_cache_enabled"
     - "session_cache_timeout"
     - "display_name"
     - "id"
     - "resource_type"
     - 'prefer_server_ciphers'
+    - "description"
 
     SSLProfile_Client_Indirect_Attributes:
      - "is_secure"
      - "is_fips"
 
     SSLProfile_Server_Supported_Attributes:
     - "ciphers"
     - "protocols"
     - "session_cache_enabled"
     - "session_cache_timeout"
     - "display_name"
     - "id"
     - "resource_type"
+    - "description"
 
     SSLProfile_Server_Indirect_Attributes:
         - "is_secure"
         - "is_fips"
 
+    SSLProfile_NA_Attributes:
+    - "cipher_group_label"
+
     PersistenceProfile_Supported_Attributes:
     - "display_name"
     - "id"
     - "resource_type"
+    - "description"
 
     CookiePersistenceProfile_Supported_Attributes:
     - "cookie_name"
     - "cookie_max_idle"
     - "cookie_fallback"
     - "cookie_time"
     - "cookie_domain"
@@ -349,20 +358,20 @@
     - "LBJwtCertificateKey"
     - "LBJwtSymmetricKey"
     - "LBJwtPublicKey"
 
 
     Common_Na_List:
     - "path"
-    - "relative_path" 
-    - "parent_path" 
-    - "unique_id" 
-    - "realization_id" 
-    - "marked_for_delete" 
-    - "overridden" 
-    - "_create_time" 
-    - "_create_user" 
-    - "_last_modified_time" 
-    - "_last_modified_user" 
-    - "_system_owned" 
-    - "_protection" 
+    - "relative_path"
+    - "parent_path"
+    - "unique_id"
+    - "realization_id"
+    - "marked_for_delete"
+    - "overridden"
+    - "_create_time"
+    - "_create_user"
+    - "_last_modified_time"
+    - "_last_modified_user"
+    - "_system_owned"
+    - "_protection"
     - "_revision"
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/conversion_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/conversion_util.py`

 * *Files 0% similar despite different names*

```diff
@@ -221,23 +221,25 @@
         status_wb.close()
         # create dataframe for row list
         df = pandas.DataFrame(csv_writer_dict_list, columns=fieldnames)
         # create pivot table using pandas
         pivot_table = \
             pandas.pivot_table(df, index=["Status", "NsxT type", "NsxT SubType"],
                                values=[], aggfunc=[len], fill_value=0)
+
         # create dataframe for pivot table using pandas
         pivot_df = pandas.DataFrame(pivot_table)
         main_book = \
             load_workbook(report_path)
-        main_writer = pandas.ExcelWriter(report_path, engine='openpyxl')
+        main_writer = pandas.ExcelWriter(report_path, engine="openpyxl",mode='a')
         main_writer._book = main_book
+
         # Add pivot table in Pivot sheet
         pivot_df.to_excel(main_writer, 'Pivot Sheet')
-        main_writer._save()
+        main_writer.close()
 
     def vs_complexity_level(self):
         """
         This method calculate the complexity of vs.
         :return:
         """
         # Get the VS object list which is having status successful and partial.
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/converter_constants.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/converter_constants.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/get_certificates.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/get_certificates.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/install_nsx_dependencies.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/install_nsx_dependencies.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/monitor_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/monitor_converter.py`

 * *Files 0% similar despite different names*

```diff
@@ -126,15 +126,15 @@
             try:
                 LOG.info('[MONITOR] Migration started for HM {}'.format(lb_hm['display_name']))
                 progressbar_count += 1
                 monitor_type, name = self.get_name_type(lb_hm)
                 if '/' in monitor_type:
                     monitor_type = monitor_type.split('/')[-1]
                 m_tenant, m_name = conv_utils.get_tenant_ref(name)
-                # Check if custom cofig present for this HM
+                # Check if custom config present for this HM
                 r_hm = [obj for obj in custom_config if
                         obj['monitor_name'] == m_name]
                 if r_hm:
                     LOG.debug(
                         "Found custom config for %s replacing with custom config"
                         % m_name)
                     r_hm = r_hm[0]
@@ -416,15 +416,15 @@
                 if cert['name'].__contains__(name) and cert['type'] == cert_type:
                     return cert
             return None
 
         if not ca_cert:
             key, ca_cert = conv_utils.create_self_signed_cert()
             name = '%s-%s' % (name, final.PLACE_HOLDER_STR)
-            LOG.warning('Create self cerificate and key for : %s' % name)
+            LOG.warning('Create self certificate and key for : %s' % name)
 
         ssl_kc_obj = None
 
         if ca_cert:
             cert = {"certificate": ca_cert if type(ca_cert) == str else ca_cert.decode()}
             ssl_kc_obj = {
                 'name': name,
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsx_cleanup.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsx_cleanup.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_cleanup.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/cleanup.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,15 +26,15 @@
     def __init__(self, args):
         '''
 
         :param args:
         '''
         self.nsxt_ip = args.nsxt_ip
         self.nsxt_user = args.nsxt_user
-        self.nsxt_passord = args.nsxt_password
+        self.nsxt_password = args.nsxt_password
         self.nsxt_port = args.nsxt_port
         self.cleanup_vs_names = args.vs_filter
         self.output_file_path = args.output_file_path if args.output_file_path \
             else 'output'
 
         output_dir = os.path.normpath(self.output_file_path)
 
@@ -62,15 +62,15 @@
     def initiate_cleanup(self):
 
         if not os.path.exists(self.output_file_path):
             os.mkdir(self.output_file_path)
         self.init_logger_path()
 
         if self.cleanup_vs_names:
-            nsx_c = NSXCleanup(self.nsxt_user, self.nsxt_passord, self.nsxt_ip, self.nsxt_port)
+            nsx_c = NSXCleanup(self.nsxt_user, self.nsxt_password, self.nsxt_ip, self.nsxt_port)
             nsx_c.nsx_cleanup(self.cleanup_vs_names)
 
             if nsx_c.vs_not_found:
                 print_msg = "\033[93m"+"Warning: Following virtual service/s could not be found"+'\033[0m'
                 print(print_msg)
                 print(nsx_c.vs_not_found)
         else:
@@ -82,15 +82,15 @@
         LOG.info("Total Warning: {}".format(get_count('warning')))
         LOG.info("Total Errors: {}".format(get_count('error')))
 
 
 if __name__ == "__main__":
     HELP_STR = """
     Usage:
-    python nsxt_converter.py -n 192.168.100.101 -u admin -p password 
+    python nsxt_converter.py -n 192.168.100.101 -u admin -p password
     """
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.RawTextHelpFormatter, description=HELP_STR)
 
     # Added command line args to take skip type for ansible playbook
     parser.add_argument('--vs_filter',
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_client.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_client.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_config_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_config_converter.py`

 * *Files 1% similar despite different names*

```diff
@@ -44,15 +44,15 @@
 }
 
 
 def convert(nsx_lb_config, input_path, output_path, tenant, prefix,
             migrate_to, object_merge_check, controller_version, ssh_root_password, nsxt_util, migration_input_config=None,
             vs_state=False, vs_level_status=False, vrf=None,
             segroup=None, not_in_use=True, custom_mapping=None, traffic_enabled=False, cloud_tenant="admin",
-            nsxt_ip=None, nsxt_passord=None):
+            nsxt_ip=None, nsxt_password=None):
 
     # load the yaml file attribute in nsxt_attributes.
     nsxt_attributes = conv_const.init()
     input_config = input_path + os.path.sep + "config.json"
     with open(input_config, "w", encoding='utf-8') as text_file:
         json.dump(nsx_lb_config, text_file, indent=4)
 
@@ -63,15 +63,15 @@
         merge_object_type = ['ApplicationProfile', 'NetworkProfile',
                              'SSLProfile', 'PKIProfile', 'SSLKeyAndCertificate',
                              'ApplicationPersistenceProfile', 'HealthMonitor',
                              'IpAddrGroup', 'VSDataScriptSet']
         for key in merge_object_type:
             sys_dict[key] = []
             avi_config_dict[key] = []
-        
+
         monitor_converter = MonitorConfigConv(nsxt_attributes, object_merge_check, merge_object_mapping, sys_dict)
         monitor_converter.convert(avi_config_dict, nsx_lb_config, prefix,tenant,custom_mapping)
 
         pool_converter = PoolConfigConv(nsxt_attributes, object_merge_check, merge_object_mapping, sys_dict)
         pool_converter.convert(avi_config_dict, nsx_lb_config,nsxt_util, prefix, tenant)
 
         profile_converter = ProfileConfigConv(nsxt_attributes, object_merge_check, merge_object_mapping, sys_dict)
@@ -80,15 +80,15 @@
         ssl_profile_converter = SslProfileConfigConv(nsxt_attributes, object_merge_check, merge_object_mapping, sys_dict)
         ssl_profile_converter.convert(avi_config_dict, nsx_lb_config, prefix,tenant)
 
         persist_conv = PersistantProfileConfigConv(nsxt_attributes, object_merge_check, merge_object_mapping, sys_dict)
         persist_conv.convert(avi_config_dict, nsx_lb_config, prefix,tenant)
 
         vs_converter = VsConfigConv(nsxt_attributes,object_merge_check, merge_object_mapping,sys_dict,
-                                    nsxt_ip, nsxt_passord)
+                                    nsxt_ip, nsxt_password)
         vs_converter.convert(avi_config_dict, nsx_lb_config, prefix,
                              tenant, vs_state, controller_version, traffic_enabled,
                              cloud_tenant, ssh_root_password, nsxt_util, migration_input_config,
                              vrf, segroup)
         conv_utils.remove_dup_of(avi_config_dict)
         # Validating the aviconfig after generation
         conv_utils.validation(avi_config_dict)
@@ -100,21 +100,21 @@
     output_config = output_path + os.path.sep + "avi_config.json"
 
    # with open(output_config, "w", encoding='utf-8') as text_file:
        # json.dump(avi_config_dict, text_file, indent=4)
 
     # Add nsxt converter status report in xslx report
     try:
-        conv_utils.add_complete_conv_status(
-            output_path, avi_config_dict, "nsxt-report", vs_level_status)
-    except Exception as e:
-        msg = "Error in writing excel sheet for converted configuration."
-        LOG.error(msg)
-        print("\033[91m" + msg + " Message: ", str(e) +"\033[0m")
-        sys.exit(1)
+         conv_utils.add_complete_conv_status(
+             output_path, avi_config_dict, "nsxt-report", vs_level_status)
+     except Exception as e:
+         msg = "Error in writing excel sheet for converted configuration."
+         LOG.error(msg)
+         print("\033[91m" + msg + " Message: ", str(e) + "\033[0m")
+         sys.exit(1)
 
     for key in avi_config_dict:
         if key != 'META':
             if key == 'VirtualService':
                 if vs_level_status:
                     LOG.info('Total Objects of %s : %s (%s  migrated , %s full conversions)'
                              % (key,len(nsx_lb_config['LbVirtualServers']), len(avi_config_dict[key]),
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_converter.py`

 * *Files 0% similar despite different names*

```diff
@@ -72,15 +72,15 @@
         self.segroup = args.segroup
         self.patch = args.patch
         self.traffic_enabled = args.traffic_enabled
         self.default_params_file = args.default_params_file
         self.cloud_tenant = args.cloud_tenant
         self.ssh_root_password = args.ssh_root_password
 
-    def conver_lb_config(self, args):
+    def convert_lb_config(self, args):
 
         try:
             if not os.path.exists(self.output_file_path):
                 os.mkdir(self.output_file_path)
             self.init_logger_path()
             output_dir = os.path.normpath(self.output_file_path)
 
@@ -395,15 +395,15 @@
                              'prompt will appear if no value provided')
     parser.add_argument('-t', '--alb_controller_tenant', help='tenant name for auto upload',
                         default="admin")
     parser.add_argument('--cloud_tenant', help="tenant for cloud ref")
     parser.add_argument('-i', '--default_params_file',
                         help='absolute path for nsx-t default params file')
     parser.add_argument('-n', '--nsxt_ip',
-                        help='Ip of NSXT', required=True)
+                        help='Ip of NSX-T', required=True)
     parser.add_argument('-u', '--nsxt_user',
                         help='NSX-T User name', required=True)
     parser.add_argument('-p', '--nsxt_password',
                         help='NSX-T Password')
     parser.add_argument('-port', '--nsxt_port', default=443,
                         help='NSX-T Port')
     parser.add_argument( '--ssh_root_password',
@@ -458,11 +458,11 @@
         else:
             print('\033[91m'+'ERROR: please provide alb_controller_password either through environment variable or as a script parameter'+"\033[0m")
             exit()
     if not args.ssh_root_password:
         if os.environ.get('ssh_root_password'):
             args.ssh_root_password = os.environ.get('ssh_root_password')
     nsxt_converter = NsxtConverter(args)
-    nsxt_converter.conver_lb_config(args)
+    nsxt_converter.convert_lb_config(args)
     end = datetime.now()
     print("The time of execution of above program is :",
           str(end - start))
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_rollback.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_rollback.py`

 * *Files 0% similar despite different names*

```diff
@@ -26,15 +26,15 @@
     def __init__(self, args):
         '''
 
         :param args:
         '''
         self.nsxt_ip = args.nsxt_ip
         self.nsxt_user = args.nsxt_user
-        self.nsxt_passord = args.nsxt_password
+        self.nsxt_password = args.nsxt_password
         self.nsxt_port = args.nsxt_port
 
         self.controller_ip = args.alb_controller_ip
         self.controller_version = args.alb_controller_version
         self.user = args.alb_controller_user
         self.password = args.alb_controller_password
         self.alb_controller_tenant = None
@@ -83,15 +83,15 @@
 
     def initiate_rollback(self):
 
         if not os.path.exists(self.output_file_path):
             os.mkdir(self.output_file_path)
         self.init_logger_path()
 
-        nsx_util = NSXUtil(self.nsxt_user, self.nsxt_passord, self.nsxt_ip, self.nsxt_port,
+        nsx_util = NSXUtil(self.nsxt_user, self.nsxt_password, self.nsxt_ip, self.nsxt_port,
                            self.controller_ip, self.user, self.password, self.controller_version)
         vs_not_found, vs_with_no_lb = nsx_util.rollback_vs(self.vs_filter, self.input_data,
                                                            self.prefix, self.alb_controller_tenant)
         if vs_not_found:
             print_msg = "\033[93m" + "Warning: Following virtual service/s could not be found" + "\033[0m"
             print(print_msg)
             print(vs_not_found)
@@ -108,15 +108,15 @@
         LOG.info("Total Warning: {}".format(get_count('warning')))
         LOG.info("Total Errors: {}".format(get_count('error')))
 
 
 if __name__ == "__main__":
     HELP_STR = """
     Usage:
-    python nsxt_converter.py -n 192.168.100.101 -u admin -p password 
+    python nsxt_converter.py -n 192.168.100.101 -u admin -p password
     """
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.RawTextHelpFormatter, description=HELP_STR)
 
     parser.add_argument('-c', '--alb_controller_ip',
                         help='controller ip for auto upload')
@@ -124,15 +124,15 @@
                         help='Target Avi controller version')
     parser.add_argument('--alb_controller_user',
                         help='controller username')
     parser.add_argument('--alb_controller_password',
                         help='controller password. Input '
                              'prompt will appear if no value provided')
     parser.add_argument('-n', '--nsxt_ip',
-                        help='Ip of NSXT', required=True)
+                        help='Ip of NSX-T', required=True)
     parser.add_argument('-u', '--nsxt_user',
                         help='NSX-T User name')
     parser.add_argument('-p', '--nsxt_password',
                         help='NSX-T Password')
     parser.add_argument('-port', '--nsxt_port', default=443,
                         help='NSX-T Port')
     parser.add_argument('-o', '--output_file_path',
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,15 +26,15 @@
     def __init__(self, args):
         '''
 
         :param args:
         '''
         self.nsxt_ip = args.nsxt_ip
         self.nsxt_user = args.nsxt_user
-        self.nsxt_passord = args.nsxt_password
+        self.nsxt_password = args.nsxt_password
         self.nsxt_port = args.nsxt_port
 
         self.controller_ip = args.alb_controller_ip
         self.controller_version = args.alb_controller_version
         self.user = args.alb_controller_user
         self.password = args.alb_controller_password
         self.alb_controller_tenant = None
@@ -73,15 +73,15 @@
 
     def initiate_cutover_vs(self):
 
         if not os.path.exists(self.output_file_path):
             os.mkdir(self.output_file_path)
         self.init_logger_path()
 
-        nsx_util = NSXUtil(self.nsxt_user, self.nsxt_passord, self.nsxt_ip, self.nsxt_port,
+        nsx_util = NSXUtil(self.nsxt_user, self.nsxt_password, self.nsxt_ip, self.nsxt_port,
                            self.controller_ip, self.user, self.password, self.controller_version)
         vs_not_found = nsx_util.cutover_vs(self.vs_filter, self.prefix, self.alb_controller_tenant)
         if vs_not_found:
             print_msg = "\033[93m" + "Warning: Following virtual service/s could not be found" + "\033[0m"
             print(print_msg)
             print(vs_not_found)
 
@@ -90,15 +90,15 @@
         LOG.info("Total Warning: {}".format(get_count('warning')))
         LOG.info("Total Errors: {}".format(get_count('error')))
 
 
 if __name__ == "__main__":
     HELP_STR = """
     Usage:
-    python nsxt_converter.py -n 192.168.100.101 -u admin -p password 
+    python nsxt_converter.py -n 192.168.100.101 -u admin -p password
     """
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.RawTextHelpFormatter, description=HELP_STR)
 
     parser.add_argument('-c', '--alb_controller_ip',
                         help='controller ip for auto upload')
@@ -109,15 +109,15 @@
     parser.add_argument('--alb_controller_password',
                         help='controller password. Input '
                              'prompt will appear if no value provided')
     parser.add_argument('--vs_filter',
                         help='comma separated names of virtual services for performing cutover.\n',
                         required=True)
     parser.add_argument('-n', '--nsxt_ip',
-                        help='Ip of NSXT', required=True)
+                        help='Ip of NSX-T', required=True)
     parser.add_argument('-u', '--nsxt_user',
                         help='NSX-T User name')
     parser.add_argument('-p', '--nsxt_password',
                         help='NSX-T Password')
     parser.add_argument('-port', '--nsxt_port', default=443,
                         help='NSX-T Port')
     parser.add_argument('-o', '--output_file_path',
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/nsxt_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/nsxt_util.py`

 * *Files 2% similar despite different names*

```diff
@@ -119,42 +119,56 @@
         return vs_details.get(vs_id)
     return None
 
 
 def get_object_segments(vs_id, obj_ip):
     vs = vs_details.get(vs_id, None)
     if not vs:
+        LOG.debug("virtual service not found with id %s " % vs_id)
         return None
+    cloud = vs.get("cloud")
+    if cloud == "Cloud Not Found":
+        LOG.debug("cloud is not configured for vs %s " % vs_id)
+        return None
+
     segments = []
     if vs.get("Segments"):
         seg_list = vs.get("Segments")
         for seg in seg_list:
             seg_name = seg["name"]
             for subnet in seg["subnet"]:
                 if subnet.get("network_range"):
                     network_range = subnet["network_range"]
                 a_network = ipaddress.ip_network(network_range, False)
                 address_in_network = ipaddress.ip_address(obj_ip) in a_network
                 if address_in_network:
-                    return [dict(
+                    segments.append( dict(
                         seg_name=seg_name,
-                        subnets=subnet)]
+                        subnets=subnet))
+    else:
+        LOG.debug("segmnets are not configured  for vs %s " % vs_id )
+        return None
+
+    if segments:
+        LOG.debug("segments found for vs %s with attached pool server ip %s are %s" %(vs_id,obj_ip,segments))
+        return segments
+
     return None
 
 
 def get_certificate_data(certificate_ref, nsxt_ip, ssh_root_password):
     import paramiko
     import json
 
     try:
         ssh = paramiko.SSHClient()
         ssh.load_system_host_keys()
         ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
         ssh.connect(nsxt_ip, username='root', password=ssh_root_password,
-                    allow_agent=False, look_for_keys=False, banner_timeout=60)
+                     allow_agent=False, look_for_keys=False, banner_timeout=60)
 
         cmd = "curl --header 'Content-Type: application/json' --header 'x-nsx-username: admin' " \
               "http://'admin':'{}'@127.0.0.1:7440/nsxapi/api/v1/trust-management/certificates".\
             format(ssh_root_password)
         stdin, stdout, stderr = ssh.exec_command(cmd)
 
         output_dict = ''
@@ -404,37 +418,44 @@
                 if cl.get("nsxt_configuration"):
                     if cl["nsxt_configuration"].get("transport_zone"):
                         tz = cl["nsxt_configuration"].get("transport_zone")
                     elif cl["nsxt_configuration"].get("data_network_config"):
                         tz = cl["nsxt_configuration"]["data_network_config"].get("transport_zone")
                         if cl["nsxt_configuration"]["data_network_config"].get("tz_type") == "OVERLAY":
                             tz_type = "OVERLAY"
-                            data_netwrk = cl["nsxt_configuration"]["data_network_config"]
-                            if data_netwrk.get("tier1_segment_config"):
-                                if data_netwrk["tier1_segment_config"].get("manual"):
-                                    tier1_lrs = data_netwrk["tier1_segment_config"]["manual"].get("tier1_lrs")
+                            LOG.debug("Cloud details %s and type %s" % (cl.get("name"),tz_type))
+
+                            data_network = cl["nsxt_configuration"]["data_network_config"]
+                            if data_network.get("tier1_segment_config"):
+                                if data_network["tier1_segment_config"].get("manual"):
+                                    tier1_lrs = data_network["tier1_segment_config"]["manual"].get("tier1_lrs")
                                     if tier1_lrs:
                                         is_seg_present = [True for tier in tier1_lrs if
                                                           get_name_and_entity(tier.get("segment_id"))[-1] == seg_id]
                         elif cl["nsxt_configuration"]["data_network_config"].get("tz_type") == "VLAN":
                             tz_type = "VLAN"
-                            data_netwrk = cl["nsxt_configuration"]["data_network_config"]
-                            vlan_seg = data_netwrk.get("vlan_segments")
+                            LOG.debug("Cloud details %s and type %s" % (cl.get("name"),tz_type))
+                            data_network = cl["nsxt_configuration"]["data_network_config"]
+                            vlan_seg = data_network.get("vlan_segments")
                             is_seg_present = [True for seg in vlan_seg if get_name_and_entity(seg)[-1] == seg_id]
+
                     if tz.find("/") != -1:
                         tz = tz.split("/")[-1]
                     if tz == tz_id and is_seg_present:
+                        LOG.debug("Cloud found for tier %s with transpot zone %s is %s" % (tier1,tz_id,cl.get("name")))
                         return cl.get("name")
                     elif tz == tz_id and not is_seg_present:
                         if cl["nsxt_configuration"]["data_network_config"].get("tz_type") == "VLAN":
                             vlan_cloud_list.append(cl)
                             continue
                         elif cl["nsxt_configuration"]["data_network_config"].get("tz_type") == "OVERLAY":
                             overlay_cloud_list.append(cl)
                             continue
+                        LOG.debug("Cloud found for tier %s with transpot zone %s is %s" % (tier1,tz_id,cl.get("name")))
+                        LOG.debug("Segments are not configured for cloud %s , so configuring the segments " % (tier1,tz_id,cl.get("name")))
 
         if vlan_cloud_list:
             cloud_info = self.session.get_object_by_name("cloud", vlan_cloud_list[0]['name'], tenant=self.cloud_tenant)
             cloud_vlan_segments = cloud_info.get("nsxt_configuration").get("data_network_config").get("vlan_segments")
             cloud_vlan_segments.append("/infra/segments/{}".format(seg_id))
             cloud_info.get("nsxt_configuration").get("data_network_config").update({
                 "vlan_segments": cloud_vlan_segments
@@ -452,16 +473,18 @@
                 })
                 cloud_info.get("nsxt_configuration").get("data_network_config").get("tier1_segment_config").get("manual").update({
                     "tier1_lrs": cloud_tier1_lrs
                 })
                 response = self.session.put("cloud/{}".format(cloud_info.get("uuid")), cloud_info,
                                             tenant=self.cloud_tenant)
                 if response.status_code == 200:
+                    LOG.debug("Segments configured  for cloud %s " , (cloud_info.get("name")))
                     return cloud_info.get("name")
                 else:
+                    LOG.debug("FAILED: Segments configuration  failed  for cloud %s getting response %s " % (cloud_info.get("name"),response.status_code))
                     continue
 
         return "Cloud Not Found"
 
     def get_lb_services_details(self):
         lb_services = self.nsx_api_client.infra.LbServices.list().to_dict().get('results', [])
         for lb in lb_services:
@@ -473,31 +496,43 @@
             interface_list = self.nsx_api_client.infra.tier_1s.locale_services.Interfaces.list(tier, ls_id).results
             network = None
             tz_id = None
             cloud_name = None
             lb_details = []
             lb_tier1_lr = None
             warning_mesg=None
+            is_cloud_configured=False
+
             if len(interface_list):
-                interface = interface_list[0].id
-                segment_id = get_name_and_entity(interface_list[0].segment_path)[-1]
-                segment = self.nsx_api_client.infra.Segments.get(segment_id)
-                if hasattr(segment, "vlan_ids") and segment.vlan_ids:
-                    network = "Vlan"
-                else:
-                    network = "Overlay"
 
-                if network == "Overlay" and len(interface_list) > 0:
-                    lb_tier1_lr = segment.connectivity_path
+                for intf in interface_list:
+                    #segment_path="/infra/segments/virtualwire-1"
+                    segment_id = get_name_and_entity(intf.segment_path)[-1]
+                    segment = self.nsx_api_client.infra.Segments.get(segment_id)
+
+                    tz_path = segment.transport_zone_path
+                    tz_id = get_name_and_entity(tz_path)[-1]
+                    if hasattr(segment, "vlan_ids") and segment.vlan_ids:
+                        network = "Vlan"
+                    else:
+                        network = "Overlay"
+
+                    if network == "Overlay" and len(interface_list) > 0:
+                        lb_tier1_lr = segment.connectivity_path
+
+
+                    cloud_name = self.get_cloud_type(self.cloud, tz_id, segment_id, lb_tier1_lr if lb_tier1_lr else tier)
+                    if cloud_name == "Cloud Not Found":
+                        continue
+                    is_cloud_configured=True
+                    break
 
-                tz_path = segment.transport_zone_path
-                tz_id = get_name_and_entity(tz_path)[-1]
-                cloud_name = self.get_cloud_type(self.cloud, tz_id, segment_id, lb_tier1_lr if lb_tier1_lr else tier)
 
                 for intrf in interface_list:
+                    #segment_path="/infra/segments/virtualwire-1"
                     segment_id = get_name_and_entity(intrf.segment_path)[-1]
                     subnets = []
                     for subnet in intrf.subnets:
                         subnets.append({
                             "network_range": (str(subnet.ip_addresses[0]) + "/" + str(subnet.prefix_len))
                         })
                     segments = {
@@ -505,64 +540,66 @@
                         "subnet": subnets}
                     lb_details.append(segments)
 
             else:
                 segment_list = self.nsx_api_client.infra.Segments.list().to_dict().get('results', [])
 
                 is_tier_linked_segment_found = False
+
                 for seg in segment_list:
                     if seg.get("connectivity_path"):
                         gateway_name = get_name_and_entity(seg["connectivity_path"])[-1]
                         if gateway_name == tier:
-                            is_tier_linked_segment_found = True
                             tz_path = seg.get("transport_zone_path")
                             tz_id = get_name_and_entity(tz_path)[-1]
                             dhcp_present = False
                             for subnet in seg["subnets"]:
                                 if "dhcp_config" in subnet.keys() and not dhcp_present:
                                     dhcp_present = True
-                            cloud_name = self.get_cloud_type(self.cloud, tz_id, seg.get("id"), tier)
-                            if cloud_name == "Cloud Not Found":
-                                continue
-                            is_dhcp_configured_on_avi, is_static_ip_pool_configured, is_ip_subnet_configured,\
-                            static_ip_for_se_flag = self.get_dhcp_config_details_on_avi_side(cloud_name, seg.get("id"))
-
-                            if not is_dhcp_configured_on_avi and (not is_static_ip_pool_configured or
-                                                                  not is_ip_subnet_configured or
-                                                                  not static_ip_for_se_flag):
-                                warning_mesg = "Warning : configuration of  %s network is incomplete ," \
-                                               "please check it once " % seg.get("display_name")
-
-                            if seg.get("vlan_ids"):
-                                network = "Vlan"
-                            else:
-                                network = "Overlay"
+                            if not is_cloud_configured:
+                                cloud_name = self.get_cloud_type(self.cloud, tz_id, seg.get("id"), tier)
+                                if cloud_name != "Cloud Not Found":
+                                    is_cloud_configured=True
+                                    if seg.get("vlan_ids"):
+                                        network = "Vlan"
+                                    else:
+                                        network = "Overlay"
+
+                                    is_dhcp_configured_on_avi,is_static_ip_pool_configured,is_ip_subnet_configured,static_ip_for_se_flag = \
+                                    self.get_dhcp_config_details_on_avi_side(cloud_name,seg.get("id"))
+
+                                    if not is_dhcp_configured_on_avi and (not is_static_ip_pool_configured or not is_ip_subnet_configured or not static_ip_for_se_flag):
+                                        warning_mesg = "Warning : configuration of  %s network is incomplete , please check it once " % seg.get("display_name")
+                                        LOG.debug(warning_mesg)
+
                             if seg.get("subnets"):
                                 subnets = []
                                 for subnet in seg["subnets"]:
                                     subnets.append({
                                         "network_range": subnet["network"]
                                     })
                                 segments = {
                                     "name": seg.get("id"),
                                     "subnet": subnets}
                                 lb_details.append(segments)
-                            
-                            if cloud_name == "Cloud Not Found":
-                                continue
-                            break
 
-                if not is_tier_linked_segment_found:
-                    self.lb_services[lb["id"]] = {
-                        "lb_name": lb["id"],
-                        "lb_skip_reason": "Skipping because NSX Load Balancer has no segments "
-                                          "or service interfaces configured"
-                    }
-                    continue
+            if not is_cloud_configured:
 
+                warning_mesg="cloud is not configured for load balancer %s with id %s " % (lb["display_name"],lb["id"])
+                LOG.debug(warning_mesg)
+                lb_details=[]
+
+
+                if not is_tier_linked_segment_found:
+                     self.lb_services[lb["id"]] = {
+                         "lb_name": lb["id"],
+                         "lb_skip_reason": "Skipping because NSX Load Balancer has no segments "
+                                           "or service interfaces configured"
+                     }
+                     continue
             self.lb_services[lb["id"]] = {
                 "lb_name": lb["id"],
                 "Network": network,
                 "Cloud": cloud_name,
                 "lb_tier1_lr": lb_tier1_lr
                 }
             if lb_details:
@@ -575,26 +612,26 @@
         is_static_ip_pool_configured = False
         is_ip_subnet_configured = False
         static_ip_for_se_flag = False
         cloud_id = [cl.get("uuid") for cl in self.cloud if cl.get("name") == cloud_name]
         segment_list = self.session.get("network/?&cloud_ref.uuid=" + cloud_id[0]).json()["results"]
         segment = [seg for seg in segment_list if seg.get("attrs")[0].get("value").split('segments/')[-1] == seg_id]
         if segment :
-            is_dhcp_configured_on_avi = segment[0].get("dhcp_enabled") 
+            is_dhcp_configured_on_avi = segment[0].get("dhcp_enabled")
             if segment[0].get("configured_subnets"):
                 configured_subnets = segment[0].get("configured_subnets")
                 if configured_subnets[0].get("prefix"):
                     is_ip_subnet_configured = True
                     if configured_subnets[0].get("static_ip_ranges"):
                         is_static_ip_pool_configured = True
                         if configured_subnets[0].get("static_ip_ranges")[0].get("type") in ["STATIC_IPS_FOR_VIP_AND_SE","STATIC_IPS_FOR_SE"]:
                              static_ip_for_se_flag = True
 
         return is_dhcp_configured_on_avi,is_static_ip_pool_configured,is_ip_subnet_configured,static_ip_for_se_flag
-           
+
     def get_all_virtual_service(self):
         """
         :return:list of virtual server objects
         """
         virtual_services = self.nsx_api_client.infra.LbVirtualServers.list().to_dict().get('results', [])
         return virtual_services
 
@@ -690,15 +727,19 @@
                 vs_object["rules"] = False
                 normal_vs += 1
             if vs.get("enabled"):
                 enab_vs += 1
             else:
                 disab_vs += 1
             self.avi_object_temp[vs_object['id']] = vs_object
+
+
         self.avi_vs_object.append(self.avi_object_temp)
+        LOG.debug("Inventory details %s" % self.avi_vs_object)
+
         vs_stats["complex_vs"] = vs_with_rules
         vs_stats["normal_vs"] = normal_vs
         vs_stats["enabled_vs"] = enab_vs
         vs_stats["disabled_vs"] = disab_vs
 
     def get_pool_details(self):
         temp_pool_list = {}
@@ -992,25 +1033,25 @@
                         "type": "V4"
                     }
                 ]
         }
         return new_network_service
 
     def update_network_service_obj(self, network_obj, floating_ip):
-        floating_ip_list = network_obj.get("routing_service").get("floating_intf_ip")
-        is_floating_ip_found = False
-        for obj in floating_ip_list:
-            if obj.get("addr") == floating_ip:
-                is_floating_ip_found = True
-                break
-        if not is_floating_ip_found:
-            floating_ip_list.append({
-                            "addr": floating_ip,
-                            "type": "V4"
-                        })
+         floating_ip_list = network_obj.get("routing_service").get("floating_intf_ip")
+         is_floating_ip_found = False
+         for obj in floating_ip_list:
+             if obj.get("addr") == floating_ip:
+                 is_floating_ip_found = True
+                 break
+         if not is_floating_ip_found:
+             floating_ip_list.append({
+                 "addr": floating_ip,
+                 "type": "V4"
+             })
 
     def get_nsx_group_details(self,group_path):
         domain_id = group_path.split('domains/')[1].split("/groups")[0]
         ns_group_id = group_path.split('groups/')[1]
         ns_groups_list = self.nsx_api_client.infra.domains.Groups.list(domain_id).to_dict().get("results", [])
         ns_group = [ns_g for ns_g in ns_groups_list if ns_g['id'] == ns_group_id]
         ns_group_name = ns_group[0]['display_name']
@@ -1071,8 +1112,8 @@
             )
             addr_list.append(
                 addr_dict
             )
         ip_group['addrs'] = addr_list
         ip_group['tenant_ref'] = conv_utils.get_object_ref(tenant, 'tenant')
         alb_config['IpAddrGroup'].append(ip_group)
-        return ip_group['name']
+        return ip_group['name']
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/persistant_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/persistant_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/policy_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/policy_converter.py`

 * *Files 0% similar despite different names*

```diff
@@ -130,15 +130,15 @@
                 continue
             if not len(na_action_list):
                 match_conditions = policy.get("match_conditions")
                 match_strategy = policy.get("match_strategy")
                 phase = policy.get("phase")
                 actions = policy.get("actions")
                 # if check all type of matches if any one not supported then check match_strategy is ALL
-                # then skip other migrate whaterver supported
+                # then skip other migrate whatever  supported
                 if match_strategy == "ALL" and match_conditions:
                     na_match_list = list(filter(lambda x: x["type"] in self.rule_match_na, match_conditions))
                     if len(na_match_list) > 0:
                         LOG.info('[VS-RULES: {}] SKIPPING RULE One of Match Conditions is Not supported {}'.format(
                             policy_set_name,
                             [match['type'] for match in na_match_list]))
                         status_rule_list.append('[VS-RULES: {}] SKIPPING RULE One of Match Conditions is Not supported '
@@ -1097,8 +1097,8 @@
 
         return match, total_action_count
 
     def unable_session_reuse_in_ssl_profile(self):
         client_ssl_ref = self.alb_vs_config.get('ssl_profile_ref')
         client_ssl_name = client_ssl_ref.split('name=')[1]
         ssl_config = [config for config in self.alb_config["SSLProfile"] if config['name'] == client_ssl_name ]
-        ssl_config[0]['enable_ssl_session_reuse'] = False
+        ssl_config[0]['enable_ssl_session_reuse'] = False
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/pools_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/pools_converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -65,15 +65,15 @@
                 }
                 if lb_type.get('lb_algorithm_hash'):
                     alb_pl['lb_algorithm_hash'] = lb_type['lb_algorithm_hash']
 
                 vs_list = [vs["id"] for vs in nsx_lb_config["LbVirtualServers"] if
                            (vs.get("pool_path") and vs.get("pool_path").split("/")[-1] == lb_pl.get("id"))]
 
-                vs_list_for_sorry_pool = [vs["id"] for vs in nsx_lb_config["LbVirtualServers"] 
+                vs_list_for_sorry_pool = [vs["id"] for vs in nsx_lb_config["LbVirtualServers"]
                                           if vs.get("sorry_pool_path")
                                           and vs.get("sorry_pool_path").split("/")[-1] == lb_pl.get("id")]
 
                 vs_list_for_rules_select_action_pool = [vs['id'] for vs in nsx_lb_config['LbVirtualServers']
                                                         if vs.get('rules')
                                                         for vs_rules in vs['rules']
                                                         for action in vs_rules.get('actions')
@@ -87,14 +87,15 @@
                 if not pool_temp:
                     pool_temp = list(filter(lambda pl: pl["name"] == name, alb_config['PoolGroup']))
                 if pool_temp:
                     name = '%s-%s' % (name, lb_pl["id"])
                 is_sry_pool_present = False
                 pool_skip = True
                 pool_count = 0
+                is_pool_orphan=True
                 pool_members_list = list()
                 if lb_pl.get('member_group'):
                     ns_grp_name, ip_addr_grp = nsxt_util.get_nsx_group_details(lb_pl['member_group']['group_path'])
                     if ip_addr_grp:
                         for ip in ip_addr_grp:
                             pool_members_list.append(dict(
                                 ip_address=ip))
@@ -111,30 +112,44 @@
                 elif lb_pl.get('members'):
                     pool_members_list = lb_pl['members']
                 if pool_members_list:
                     lb_list = {}
                     if vs_list:
                         pool_seg_list,is_member_ip_in_range,pool_skip = self.check_pool_member_ip_ranges\
                             (vs_list, pool_count, lb_list, pool_members_list, pool_skip, name, vs_pool_segment_list)
+                        is_pool_orphan=False
 
                     if vs_list_for_sorry_pool:
                         pool_seg_list,is_member_ip_in_range ,pool_skip= self.check_pool_member_ip_ranges \
                             (vs_list_for_sorry_pool, pool_count, lb_list, pool_members_list, pool_skip, name,
                              vs_sorry_pool_segment_list)
                         if is_member_ip_in_range:
                             is_sry_pool_present = True
+                        is_pool_orphan=False
 
                     if vs_list_for_rules_select_action_pool:
                         pool_seg_list,is_member_ip_in_range, pool_skip = self.check_pool_member_ip_ranges \
                             (vs_list_for_rules_select_action_pool, pool_count, lb_list, pool_members_list, pool_skip, name,
                              vs_select_pool_action_list)
+                        is_pool_orphan=False
+
+
+                    if is_pool_orphan:
+                        skipped_pools_list.append(name)
+                        skip_msg = 'Pool is orphan , it is not associated with any vs'
+                        conv_utils.add_status_row('pool', None, lb_pl['display_name'],
+                                                  conv_const.STATUS_SKIPPED, skip_msg)
+                        LOG.warning("POOL {} not migrated. Reason: {}".format(name,
+                                                                              skip_msg))
+                        conv_utils.print_progress_bar(progressbar_count, total_size, msg, prefix='Progress', suffix='')
+                        continue
 
                     if pool_skip:
                         skipped_pools_list.append(name)
-                        skip_msg = 'Member ip not falling in segment rnge'
+                        skip_msg = 'Member ip not falling in segment range'
                         conv_utils.add_status_row('pool', None, lb_pl['display_name'],
                                                   conv_const.STATUS_SKIPPED, skip_msg)
                         LOG.warning("POOL {} not migrated. Reason: {}".format(name,
                                                                               skip_msg))
                         conv_utils.print_progress_bar(progressbar_count, total_size, msg, prefix='Progress', suffix='')
                         continue
                 else:
@@ -488,14 +503,15 @@
             for vs_id in vs_list:
                 if vs_id in pool_segment_list.keys():
                     pool_skip = False
                     is_member_ip_in_range=True
                     continue
                 lb = get_lb_service_name(vs_id)
                 if not lb:
+                    LOG.debug("lb not configured for vs %s" % vs_id)
                     continue
                 pool_segment = get_object_segments(vs_id,
                                                    member.get("ip_address"))
                 if pool_segment:
                     pool_skip = False
                     is_member_ip_in_range = True
                     if lb in lb_list.keys():
@@ -503,19 +519,21 @@
                         continue
 
                     if pool_count == 0:
                         pool_segment_list[vs_id] = {
                             "pool_name": pool_name,
                             "pool_segment": pool_segment
                         }
-                        lb_list[lb] = pool_segment_list.get(vs_id)    
+                        lb_list[lb] = pool_segment_list.get(vs_id)
                     else:
                         new_pool_name = '%s-%s' % (pool_name, pool_segment[0].get("subnets").get("network_range"))
                         new_pool_name = new_pool_name.replace('/', '-')
                         vs_pool_segment_list[vs_id] = {
                             "pool_name": new_pool_name,
                             "pool_segment": pool_segment
                         }
                         lb_list[lb] = pool_segment_list.get(vs_id)
                     pool_count += 1
 
         return pool_segment_list, is_member_ip_in_range,pool_skip
+
+
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/profile_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/profile_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/ssl_profile_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/ssl_profile_converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,14 +22,15 @@
 
         """
         self.supported_client_ssl_attributes = nsxt_profile_attributes['SSLProfile_Client_Supported_Attributes']
         self.supported_server_ssl_attributes = nsxt_profile_attributes['SSLProfile_Server_Supported_Attributes']
         self.common_na_attr = nsxt_profile_attributes['Common_Na_List']
         self.indirect_client_ssl_attr = nsxt_profile_attributes["SSLProfile_Client_Indirect_Attributes"]
         self.indirect_server_ssl_attr = nsxt_profile_attributes["SSLProfile_Server_Indirect_Attributes"]
+        self.ssl_na_attr=nsxt_profile_attributes["SSLProfile_NA_Attributes"]
         self.object_merge_check = object_merge_check
         self.merge_object_mapping = merge_object_mapping
         self.sys_dict = sys_dict
         self.ssl_profile_count = 0
 
     def convert(self, alb_config, nsx_lb_config, prefix, tenant):
         alb_config["SSLProfile"] = []
@@ -48,15 +49,15 @@
 
             for lb_ssl in nsx_lb_config["LbClientSslProfiles"]:
                 try:
                     LOG.info('[SSL-PROFILE] Migration started for AP {}'.format(lb_ssl['display_name']))
                     skipped = [val for val in lb_ssl.keys()
                                if val not in self.supported_client_ssl_attributes]
                     na_attr = [val for val in lb_ssl.keys()
-                               if val in self.common_na_attr]
+                               if val in self.common_na_attr or val in self.ssl_na_attr]
                     na_list.append(na_attr)
                     progressbar_count += 1
                     name = lb_ssl.get('display_name')
                     if prefix:
                         name = name = '%s-%s' % (prefix, name)
                     if self.object_merge_check:
                         if name in self.merge_object_mapping['ssl_profile'].keys():
@@ -157,15 +158,15 @@
 
             for lb_ssl in nsx_lb_config["LbServerSslProfiles"]:
                 try:
                     LOG.info('[SSL-PROFILE] Migration started for AP {}'.format(lb_ssl['display_name']))
                     skipped = [val for val in lb_ssl.keys()
                                if val not in self.supported_client_ssl_attributes]
                     na_attr = [val for val in lb_ssl.keys()
-                               if val in self.common_na_attr]
+                               if val in self.common_na_attr or val in self.ssl_na_attr]
                     na_list.append(na_attr)
                     progressbar_count += 1
                     name = lb_ssl.get('display_name')
                     if prefix:
                         name = '%s-%s' % (prefix, name)
                     if self.object_merge_check:
                         if name in self.merge_object_mapping['ssl_profile'].keys():
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/avi_config.json` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/avi_config.json`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/config.json` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/config.json`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/excel_reader.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/excel_reader.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_migrationtool.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_migrationtool.py`

 * *Files 0% similar despite different names*

```diff
@@ -88,15 +88,15 @@
                      not_in_use=not_in_use, ansible_skip_types=ansible_skip_types, controller_version=controller_version,
                      ansible_filter_types=ansible_filter_types, vs_level_status=vs_level_status,
                      option=option, ansible=ansible, no_object_merge=object_merge_check,
                      vs_state=vs_state, vs_filter=vs_filter, segroup=segroup, patch=patch,
                      traffic_enabled=traffic_enabled, default_params_file=default_params_file, cloud_tenant=cloud_tenant
                      )
     nsxt_converter = NsxtConverter(args)
-    nsxt_converter.conver_lb_config(args)
+    nsxt_converter.convert_lb_config(args)
 
 
 class TestNSXTConverter:
 
     @pytest.fixture
     def cleanup(self):
         import avi.migrationtools.nsxt_converter.conversion_util as conv
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_monitor_converter.conf` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_monitor_converter.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_monitor_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_monitor_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_nsxt_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_nsxt_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_nsxt_functional.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_nsxt_functional.py`

 * *Files 0% similar despite different names*

```diff
@@ -101,15 +101,15 @@
                      not_in_use=not_in_use, ansible_skip_types=ansible_skip_types, controller_version=controller_version,
                      ansible_filter_types=ansible_filter_types, vs_level_status=vs_level_status,
                      option=option, ansible=ansible, no_object_merge=object_merge_check,
                      vs_state=vs_state, vs_filter=vs_filter, segroup=segroup, patch=patch,
                      traffic_enabled=traffic_enabled, default_params_file=default_params_file, cloud_tenant=cloud_tenant
                      )
     nsxt_converter = NsxtConverter(args)
-    nsxt_converter.conver_lb_config(args)
+    nsxt_converter.convert_lb_config(args)
 
 
 class TestNSXTConverter:
 
     @pytest.fixture
     def cleanup(self):
         import avi.migrationtools.nsxt_converter.conversion_util as conv
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_pool_converter.conf` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_pool_converter.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_pool_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_pool_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_profile_converter.conf` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_profile_converter.conf`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/test/test_profile_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/test/test_profile_converter.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/v_client.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/v_client.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/nsxt_converter/vs_converter.py` & `avimigrationtools-22.1.4/avi/migrationtools/nsxt_converter/vs_converter.py`

 * *Files 0% similar despite different names*

```diff
@@ -571,15 +571,15 @@
                                                                         pl_config[0].get("members"))
 
                                 # Create NetworkService for the created SEGroup
                                 tier_name = tier1_lr.split("/")[-1]
                                 floating_ip = "0.0.0.0"
                                 if migration_input_config and migration_input_config.get('network_service'):
                                     floating_ip = migration_input_config.get('network_service'). \
-                                        get("{}-{}".format(tier_name, "floating-ip"))
+                                         get("{}-{}".format(tier_name, "floating-ip"))
                                 if cloud_type == "Vlan":
                                     ns_vrf_name = "global"
                                 else:
                                     ns_vrf_name = tier_name
 
                                 ns_name = "{}-{}-{}".format(pci_se_group_name, ns_vrf_name, "ns")
 
@@ -588,18 +588,20 @@
                                 if is_network_service_created_obj:
                                     for network_obj in alb_config["NetworkService"]:
                                         if network_obj["name"] == is_network_service_created_obj["name"]:
                                             nsxt_util.update_network_service_obj(network_obj, floating_ip)
                                 else:
                                     ns_cloud_ref = conv_utils.get_object_ref(cloud_name, 'cloud',
                                                                              cloud_tenant=cloud_tenant)
+
                                     ns_vrf_ref = conv_utils.get_object_ref(ns_vrf_name, 'vrfcontext',
-                                                                           cloud_name=cloud_name,
-                                                                           cloud_tenant=cloud_tenant,
-                                                                           tenant=tenant)
+                                                                            cloud_name=cloud_name,
+                                                                            cloud_tenant=cloud_tenant,
+                                                                            tenant=tenant)
+
                                     tenant_ref = conv_utils.get_object_ref(cloud_tenant, 'tenant')
                                     new_network_service = nsxt_util.create_network_service_obj(ns_name,
                                                                                                alb_vs["se_group_ref"],
                                                                                                ns_cloud_ref, ns_vrf_ref,
                                                                                                floating_ip, tenant_ref)
                                     alb_config["NetworkService"].append(new_network_service)
                                     is_network_service_created["{}-{}-{}".format(pci_se_group_name, cloud_name, ns_vrf_name)] = new_network_service
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/pb_attributes.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/pb_attributes.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/scp_util.py` & `avimigrationtools-22.1.4/avi/migrationtools/scp_util.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
-import paramiko
 import logging
 import os
 from stat import S_ISDIR
+import paramiko
+
 
 LOG = logging.getLogger(__name__)
 
 
 class SCPUtil(object):
     def __init__(self, hostname, username, password=None, pkey=None, port=22):
         """Initialize and setup connection"""
@@ -72,16 +73,15 @@
         files = self.get_all_file_names(partition_path)
         for file in files:
             remote_file = partition_path + file + '/bigip.conf'
             if self.isdir(partition_path + file) and self.rexists(remote_file):
                 try:
                     self.get(remote_file, local_path + file + '_bigip.conf')
                 except IOError as e:
-                    LOG.error(
-                        "conf file not found in partition dir : %s" % file)
+                    LOG.error("conf file not found in partition dir : %s", file)
 
     def get_all_partition_certkey(self, partition_path, local_path):
         """
         This method gets all cert and key file from partition directories and
         dumps into local path
         :param partition_path:
         :param local_path:
@@ -100,16 +100,15 @@
                 try:
                     local_filename = filename.replace(':Common:', '')
                     if ':' in local_filename:
                         local_filename = local_filename.split(':')[-1]
                     self.get(partition_path + os.sep + filename, local_path +
                              os.sep + local_filename)
                 except IOError as e:
-                    LOG.error("cert key file not found in partition dir : %s" %
-                              filename)
+                    LOG.error("cert key file not found in partition dir : %s", filename)
 
     def isdir(self, path):
         self._openSFTPConnection()
         try:
             return S_ISDIR(self.sftp.stat(path).st_mode)
         except IOError:
             # Path does not exist, so by definition not a directory
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/setup.py` & `avimigrationtools-22.1.4/avi/migrationtools/setup.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,29 +23,29 @@
              'avi/migrationtools/gss_convertor/gss_convertor.py',
              'avi/migrationtools/ace_converter/ace_converter.py',
              'avi/migrationtools/config_patch.py',
              'avi/migrationtools/ansible/avi_config_to_ansible.py',
              'avi/migrationtools/f5_discovery.py',
              'avi/migrationtools/nsxt_converter/nsxt_converter.py',
              'avi/migrationtools/nsxt_converter/install_nsx_dependencies.py',
-             'avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py',
+             'avi/migrationtools/nsxt_converter/nsxt_cleanup.py',
              'avi/migrationtools/nsxt_converter/nsxt_rollback.py',
-             'avi/migrationtools/nsxt_converter/nsxt_cleanup.py'],
+             'avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py'],
     classifiers=[
         'Operating System :: OS Independent',
         'Programming Language :: Python',
         'Programming Language :: Python :: 2.7',
         'Topic :: Internet :: WWW/HTTP',
         'Topic :: Internet :: WWW/HTTP :: Dynamic Content',
     ],
     include_package_data=True,
     install_requires=['pyyaml', 'requests', 'pyparsing', 'paramiko', 'avisdk',
                       'pycrypto', 'ecdsa', 'pyOpenssl', 'nose-html-reporting',
                       'nose-testconfig', 'ConfigParser', 'xlsxwriter', 'jinja2',
-                      'pandas>=1.5.0', 'openpyxl', 'appdirs',  'pexpect',
+                      'pandas', 'openpyxl', 'appdirs',  'pexpect',
                       'unittest2', 'networkx', 'xmltodict'],
     package_data={'avi': ['*.cfg', '*.conf', '*.crt', '*.crl', '*.json',
                           '*.jinja', '*.key', '*.pem', '*.xml',
                           '*.yaml', '*.yml'],
                   'avi.migrationtools.gss_convertor.parser_files': [
         "gslb_template.jinja"]
     }
```

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/test/common/config.yaml` & `avimigrationtools-22.1.4/avi/migrationtools/test/common/config.yaml`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/test/common/excel_reader.py` & `avimigrationtools-22.1.4/avi/migrationtools/test/common/excel_reader.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_clean_reboot.py` & `avimigrationtools-22.1.4/avi/migrationtools/test/common/test_clean_reboot.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_tenant_cloud.py` & `avimigrationtools-22.1.4/avi/migrationtools/test/common/test_tenant_cloud.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_validation.py` & `avimigrationtools-22.1.4/avi/migrationtools/test/common/test_validation.py`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/test/common/test_validation_avi.json` & `avimigrationtools-22.1.4/avi/migrationtools/test/common/test_validation_avi.json`

 * *Files identical despite different names*

### Comparing `avimigrationtools-22.1.3b1/avi/migrationtools/vs_filter.py` & `avimigrationtools-22.1.4/avi/migrationtools/vs_filter.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,17 +9,15 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 
 import argparse
 import json
 import os
-import yaml
 from avi.migrationtools.avi_migration_utils import MigrationUtil
-from urllib.parse import urlparse
 
 # Read avi object to API path map from yaml file.
 mg_util = MigrationUtil()
 
 path_key_map = mg_util.get_path_key_map()
 
 warning_list = []
@@ -31,26 +29,28 @@
     Filters vs and its references from full configuration
     :param avi_config: full configuration
     :param vs_names: comma separated vs names to filter
     :param prefix: prefix for an object
     :param skip_ref_objects: comma separated names of objects ref to be skipped
     :return: Filtered config dict
     """
-    new_config = dict()
+    new_config = {}
     new_config['VirtualService'] = []
     virtual_services = []
-    if vs_names and type(vs_names) == str:
+    if vs_names and isinstance(vs_names, str):
         virtual_services = vs_names.split(',')
-    elif vs_names and type(vs_names) == list:
+    elif vs_names and isinstance(vs_names, list):
         virtual_services = vs_names
 
     for vs_name in virtual_services:
         if prefix:
             if not vs_name.startswith(prefix):
                 vs_name = prefix+"-"+vs_name
+        if len(vs_name) > 256:
+            vs_name = mg_util.get_updated_vs_name_after_triming(vs_name, avi_config)
         vs = [vs for vs in avi_config['VirtualService']
               if vs['name'] == vs_name]
         if not vs:
             vs_log = 'WARNING: VS object not found with name %s' % vs_name
             warning_list.append(vs_log)
             continue
         vs = vs[0]
@@ -161,15 +161,15 @@
                              'Choices: cloud_ref,tenant_ref,se_group_ref')
 
     args = parser.parse_args()
 
     if not args.skip_ref_objects:
         args.skip_ref_objects = skip_ref_object_list
     else:
-        if type(args.skip_ref_objects) == str:
+        if isinstance(args.skip_ref_objects, str):
             args.skip_ref_objects = args.skip_ref_objects.split(',')
 
     avi_config_file = open(args.avi_config_file)
     old_avi_config = json.loads(avi_config_file.read())
     new_avi_config = filter_for_vs(old_avi_config, args.vs_names, skip_ref_objects=args.skip_ref_objects)
 
     if not args.print_only:
```

### Comparing `avimigrationtools-22.1.3b1/avimigrationtools.egg-info/SOURCES.txt` & `avimigrationtools-22.1.4/avimigrationtools.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -29,14 +29,15 @@
 avi/migrationtools/ansible/__init__.py
 avi/migrationtools/ansible/ansible_config_converter.py
 avi/migrationtools/ansible/ansible_constant.py
 avi/migrationtools/ansible/ansible_traffic_generation.py
 avi/migrationtools/ansible/avi_config_to_ansible.py
 avi/migrationtools/common/avi_resource_types.yaml
 avi/migrationtools/f5_converter/__init__.py
+avi/migrationtools/f5_converter/ciphers_converter.py
 avi/migrationtools/f5_converter/clone_cross_tenant_obj.py
 avi/migrationtools/f5_converter/command_status.yaml
 avi/migrationtools/f5_converter/config.yaml
 avi/migrationtools/f5_converter/conversion_util.py
 avi/migrationtools/f5_converter/converter_constants.py
 avi/migrationtools/f5_converter/datagroup_converter.py
 avi/migrationtools/f5_converter/f5_config_converter.py
@@ -125,14 +126,15 @@
 avi/migrationtools/netscaler_converter/test/test_upload_output_config.py
 avi/migrationtools/netscaler_converter/test/certs/CD.cert.key
 avi/migrationtools/netscaler_converter/test/certs/ns-server.key
 avi/migrationtools/netscaler_converter/test/certs/test1.key
 avi/migrationtools/nsxt_converter/__init__.py
 avi/migrationtools/nsxt_converter/alb_converter.py
 avi/migrationtools/nsxt_converter/base_client.py
+avi/migrationtools/nsxt_converter/cleanup.py
 avi/migrationtools/nsxt_converter/command_status.yaml
 avi/migrationtools/nsxt_converter/conversion_util.py
 avi/migrationtools/nsxt_converter/converter_constants.py
 avi/migrationtools/nsxt_converter/custom_config.yaml
 avi/migrationtools/nsxt_converter/get_certificates.py
 avi/migrationtools/nsxt_converter/install_nsx_dependencies.py
 avi/migrationtools/nsxt_converter/monitor_converter.py
@@ -145,16 +147,18 @@
 avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py
 avi/migrationtools/nsxt_converter/nsxt_util.py
 avi/migrationtools/nsxt_converter/patch.yaml
 avi/migrationtools/nsxt_converter/persistant_converter.py
 avi/migrationtools/nsxt_converter/policy_converter.py
 avi/migrationtools/nsxt_converter/pools_converter.py
 avi/migrationtools/nsxt_converter/profile_converter.py
+avi/migrationtools/nsxt_converter/rollback.py
 avi/migrationtools/nsxt_converter/ssl_profile_converter.py
 avi/migrationtools/nsxt_converter/test_cd.py
+avi/migrationtools/nsxt_converter/traffic_cutover.py
 avi/migrationtools/nsxt_converter/v_client.py
 avi/migrationtools/nsxt_converter/vs_converter.py
 avi/migrationtools/nsxt_converter/test/__init__.py
 avi/migrationtools/nsxt_converter/test/avi_config.json
 avi/migrationtools/nsxt_converter/test/config.json
 avi/migrationtools/nsxt_converter/test/config.yaml
 avi/migrationtools/nsxt_converter/test/conftest.py
```

### Comparing `avimigrationtools-22.1.3b1/setup.py` & `avimigrationtools-22.1.4/setup.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Copyright 2021 VMware, Inc.
 # SPDX-License-Identifier: Apache License 2.0
 
 import os
 from setuptools import setup, find_packages
 
-AVI_PIP_VERSION = '22.1.3b1'
+AVI_PIP_VERSION = '22.1.4'
 
 # allow setup.py to be run from any path
 os.chdir(os.path.normpath(os.path.join(os.path.abspath(__file__), os.pardir)))
 
 setup(
     name='avimigrationtools',
     version=AVI_PIP_VERSION,
@@ -23,29 +23,29 @@
              'avi/migrationtools/gss_convertor/gss_convertor.py',
              'avi/migrationtools/ace_converter/ace_converter.py',
              'avi/migrationtools/config_patch.py',
              'avi/migrationtools/ansible/avi_config_to_ansible.py',
              'avi/migrationtools/f5_discovery.py',
              'avi/migrationtools/nsxt_converter/nsxt_converter.py',
              'avi/migrationtools/nsxt_converter/install_nsx_dependencies.py',
-             'avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py',
+             'avi/migrationtools/nsxt_converter/nsxt_cleanup.py',
              'avi/migrationtools/nsxt_converter/nsxt_rollback.py',
-             'avi/migrationtools/nsxt_converter/nsxt_cleanup.py'],
+             'avi/migrationtools/nsxt_converter/nsxt_traffic_cutover.py'],
     classifiers=[
         'Operating System :: OS Independent',
         'Programming Language :: Python',
         'Programming Language :: Python :: 2.7',
         'Topic :: Internet :: WWW/HTTP',
         'Topic :: Internet :: WWW/HTTP :: Dynamic Content',
     ],
     include_package_data=True,
     install_requires=['pyyaml', 'requests', 'pyparsing', 'paramiko', 'avisdk',
                       'pycrypto', 'ecdsa', 'pyOpenssl', 'nose-html-reporting',
                       'nose-testconfig', 'ConfigParser', 'xlsxwriter', 'jinja2',
-                      'pandas>=1.5.0', 'openpyxl', 'appdirs',  'pexpect',
+                      'pandas', 'openpyxl', 'appdirs',  'pexpect',
                       'unittest2', 'networkx', 'xmltodict'],
     package_data={'avi': ['*.cfg', '*.conf', '*.crt', '*.crl', '*.json',
                           '*.jinja', '*.key', '*.pem', '*.xml',
                           '*.yaml', '*.yml'],
                   'avi.migrationtools.gss_convertor.parser_files': [
         "gslb_template.jinja"]
     }
```

